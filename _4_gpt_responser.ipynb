{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import subprocess\n",
    "\n",
    "def get_api_key():\n",
    "    # Read API key from file\n",
    "    with open('api_key.txt', 'r', encoding='utf-8') as file:\n",
    "        api_key = file.read().strip()\n",
    "    # Never upload api_key publicly!\n",
    "    with open(\".gitignore\", \"a\") as gitignore:\n",
    "        gitignore.write(\"api_key.txt\")\n",
    "    return api_key\n",
    "\n",
    "def get_response(prompt, gpt_api_model):\n",
    "    # Make a request using the API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=gpt_api_model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    # Get the generated answer\n",
    "    answer = response['choices'][0]['message']['content'].strip()\n",
    "    return answer\n",
    "\n",
    "def record_response(file_path, answer):\n",
    "    # Record the answer\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(answer)   \n",
    "    except:\n",
    "        print(f\"Answer Write Error\")\n",
    "        \n",
    "def ask_to_gpt(file_path, prompt, gpt_api_model):\n",
    "    response_file_path = file_path.replace(\".java\", \"_response.txt\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(file_path)\n",
    "        try:\n",
    "            answer = get_response(prompt+content, gpt_api_model)\n",
    "            record_response(response_file_path, answer)\n",
    "        except Exception as e:\n",
    "            if isinstance(e, openai.error.RateLimitError):\n",
    "                print(f\"Rate Limit Error: {str(e)}\")\n",
    "                # Wait and try again\n",
    "                time.sleep(30)  # Adjust this time as needed\n",
    "                ask_to_gpt(file_path, prompt, gpt_api_model)\n",
    "            elif \"8192\" in str(e):  # Exceeds maximum available tokens (file size)\n",
    "                print(f\"File Size Exceeds: {str(e)}\")\n",
    "                with open(\"blackList.txt\", 'a', encoding='utf-8') as f:\n",
    "                    f.write(file_path+\"\\n\")\n",
    "            else:\n",
    "                print(f\"Response Error: {str(e)}\")\n",
    "\n",
    "def get_response_java_files(gpt_api_model):\n",
    "    blackListFile = \"blackList.txt\"\n",
    "    if os.path.exists(blackListFile):\n",
    "        with open(blackListFile, 'r', encoding='utf-8') as b:\n",
    "            blackList = b.read()\n",
    "    else:\n",
    "        blackList = \"\"\n",
    "    \n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if \"_after_\" in file and file.endswith(\".java\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                response_file_path = file_path.replace(\".java\", \"_response.txt\")\n",
    "                \n",
    "                # Ignore files that exceed the maximum available tokens (file size)\n",
    "                if file_path in blackList:\n",
    "                    continue\n",
    "                # Ignore test files\n",
    "                if \"_test_\" in file_path:\n",
    "                    continue\n",
    "                # Ignore files that already have a response\n",
    "                if not os.path.exists(response_file_path):\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    # 30KB - gpt4.0 / 80KB - gpt3.5\n",
    "                    if file_size <= 30 * 1024:\n",
    "                        prompt = \"Can you check the following code, and if there are any CWE or CVE-related vulnerabilities, please point them out with the respective CWE or CVE numbers and describe them?\\n\"\n",
    "                        ask_to_gpt(file_path, prompt, gpt_api_model)\n",
    "                    else:\n",
    "                        print(f\"Ignored {file_path} - File size exceeds 30KB\")\n",
    "    \n",
    "def get_response_diff_files(gpt_api_model):\n",
    "    blackListFile = \"blackList.txt\"\n",
    "    if os.path.exists(blackListFile):\n",
    "        with open(blackListFile, 'r', encoding='utf-8') as b:\n",
    "            blackList = b.read()\n",
    "    else:\n",
    "        blackList = \"\"\n",
    "    \n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if \"_diff_\" in file and file.endswith(\".java\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                response_file_path = file_path.replace(\".java\", \"_response.txt\")\n",
    "                \n",
    "                # Ignore files that exceed the maximum available tokens (file size)\n",
    "                if file_path in blackList:\n",
    "                    continue\n",
    "                # Ignore test files\n",
    "                if \"_test_\" in file_path:\n",
    "                    continue\n",
    "                # Ignore files that already have a response\n",
    "                if not os.path.exists(response_file_path):\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    # 30KB - gpt4.0 / 80KB - gpt3.5\n",
    "                    if file_size <= 30 * 1024:\n",
    "                        prompt = \"Could you read the following diff file and, if there are any security vulnerabilities in the changes, please point out the related CWE or CVE numbers along with the reasons they occurred?\\n\"\n",
    "                        ask_to_gpt(file_path, prompt, gpt_api_model)\n",
    "                    else:\n",
    "                        print(f\"Ignored {file_path} - File size exceeds 30KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b46dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # You can edit the directory list\n",
    "    directories = [\"guava\"]  # [\"h2database\", \"bc-java\", \"pgjdbc\", \"junit4\", \"gson\", \"guava\"]\n",
    "    working_directory = \"commit-files\"\n",
    "    gpt_api_model = \"gpt-4\" # gpt-3.5-turbo-16k\n",
    "    # Commit logger (directories)\n",
    "    \n",
    "    openai.api_key = get_api_key()\n",
    "    \n",
    "    # Assuming it was already created in step 3\n",
    "    os.chdir(working_directory)\n",
    "    \n",
    "    for directory in directories:\n",
    "        os.chdir(directory)\n",
    "        # Choose the necessary operation\n",
    "        # get_response_java_files(gpt_api_model)\n",
    "        get_response_diff_files(gpt_api_model)\n",
    "        os.chdir(\"..\")\n",
    "    os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b86d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de38e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"VIChecker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f209f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
