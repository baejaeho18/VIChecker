{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225bab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b32c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "\t{\n",
      "\t\t\"commitHash\": \"95ca43034fe661556f56dee7c39b6d7b784a0a2e\",\n",
      "\t\t\"parent\": \"c1c7dff2ad082a110aaab3c2c9dc1678773f1a92\",\n",
      "\t\t\"subject\": \"Change default handoffConditionTimeout to 15 minutes. (#14539)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-default-handoffConditionTimeout-to-15-minutes.-14539\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Change default handoffConditionTimeout to 15 minutes.  Most of the time, when handoff is taking this long, it's because something is preventing Historicals from loading new data. In this case, we have two choices:  1) Stop making progress on ingestion, wait for Historicals to load stuff,    and keep the waiting-for-handoff segments available on realtime tasks.    (handoffConditionTimeout = 0, the current default)  2) Continue making progress on ingestion, by exiting the realtime tasks    that were waiting for handoff. Once the Historicals get their act    together, the segments will be loaded, as they are still there on    deep storage. They will just not be continuously available.    (handoffConditionTimeout > 0)  I believe most users would prefer [2], because [1] risks ingestion falling behind the stream, which causes many other problems. It can cause data loss if the stream ages-out data before we have a chance to ingest it.  Due to the way tuningConfigs are serialized -- defaults are baked into the serialized form that is written to the database -- this default change will not change anyone's existing supervisors. It will take effect for newly created supervisors.  * Fix tests.  * Update docs/development/extensions-core/kafka-supervisor-reference.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/kinesis-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  ---------  Co-authored-by: Katya Macedo <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jul 2023 13:17:14 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1c7dff2ad082a110aaab3c2c9dc1678773f1a92\",\n",
      "\t\t\"parent\": \"589aac8b317104fd34b5c57e0ca248e6ca3e4703\",\n",
      "\t\t\"subject\": \"Using DruidExceptions in MSQ (changes related to the Broker) (#14534)\",\n",
      "\t\t\"sanitized_subject_line\": \"Using-DruidExceptions-in-MSQ-changes-related-to-the-Broker-14534\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"MSQ engine returns correct error codes for invalid user inputs in the query context. Also, using DruidExceptions for MSQ related errors happening in the Broker with improved error messages. \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jul 2023 19:08:49 +0000\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"589aac8b317104fd34b5c57e0ca248e6ca3e4703\",\n",
      "\t\t\"parent\": \"f4ee58eaa8bee182304b185445aec70c708eb602\",\n",
      "\t\t\"subject\": \"Make errorCode of InsertTimeOutOfBoundsFault consistent with others (#14495)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-errorCode-of-InsertTimeOutOfBoundsFault-consistent-with-others-14495\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The errorCode of this fault when serialized over the wire was being set to the name of the class `InsertTimeOutOfBoundsFault` instead of the CODE `InsertTimeOutOfBounds`. All other faults' errorCodes are serialized as the respective Fault's code, so making consistent here as well.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jul 2023 14:34:21 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f4ee58eaa8bee182304b185445aec70c708eb602\",\n",
      "\t\t\"parent\": \"450ecd6370d47aff58b4160efd95a82396897d5f\",\n",
      "\t\t\"subject\": \"Add `aggregatorMergeStrategy` property in SegmentMetadata queries (#14560)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-aggregatorMergeStrategy-property-in-SegmentMetadata-queries-14560\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add aggregatorMergeStrategy property to SegmentMetadaQuery.  - Adds a new property aggregatorMergeStrategy to segmentMetadata query. aggregatorMergeStrategy currently supports three types of merge strategies - the legacy strict and lenient strategies, and the new latest strategy. - The latest strategy considers the latest aggregator from the latest segment by time order when there's a conflict when merging aggregators from different segments. - Deprecate lenientAggregatorMerge property; The API validates that both the new and old properties are not set, and returns an exception. - When merging segments as part of segmentMetadata query, the segments have a more elaborate id -- <datasource>_<interval>_merged_<partition_number> format, similar to the name format that segments usually contain. Previously it was simply \\\"merged\\\". - Adjust unit tests to test the latest strategy, to assert the returned complete SegmentAnalysis object instead of just the aggregators for completeness.  * Don't explicitly set strict strategy in tests  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/querying/segmentmetadataquery.md  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  ---------  Co-authored-by: Katya Macedo <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jul 2023 12:37:36 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"450ecd6370d47aff58b4160efd95a82396897d5f\",\n",
      "\t\t\"parent\": \"7650a71d3766f8a37a896f0928e5b280ba53d5b5\",\n",
      "\t\t\"subject\": \"More efficient generation of ImmutableWorkerHolder from WorkerHolder. (#14546)\",\n",
      "\t\t\"sanitized_subject_line\": \"More-efficient-generation-of-ImmutableWorkerHolder-from-WorkerHolder.-14546\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* More efficient generation of ImmutableWorkerHolder from WorkerHolder.  Taking the work done in #12096 a little further:  1) Applying a similar optimization to WorkerHolder (HttpRemoteTaskRunner).    The original patch only helped with the ZkWorker (RemoteTaskRunner).  2) Improve the ZkWorker version somewhat by avoiding multiple iterations    through the task announcements map.  * Pick better names and use better logic.  * Only runnable tasks.  * Fix test.  * Fix testBlacklistZKWorkers50Percent.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jul 2023 07:57:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7650a71d3766f8a37a896f0928e5b280ba53d5b5\",\n",
      "\t\t\"parent\": \"0dcb19f7e3277f58c17070e646cc0bc6f5d9ebac\",\n",
      "\t\t\"subject\": \"Add window query test files from Drill (#14561)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-window-query-test-files-from-Drill-14561\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 20:14:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0dcb19f7e3277f58c17070e646cc0bc6f5d9ebac\",\n",
      "\t\t\"parent\": \"65e1b27aa709dc3e11ae75993656243377744666\",\n",
      "\t\t\"subject\": \"Add Continuous Profiling to Unit Tests (#14506)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Continuous-Profiling-to-Unit-Tests-14506\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Uses a custom continusou jfr profiler.  Modifies the github actions for tests to do profiling only in the case of jdk17, as the profiler requires jdk17+ to use the JFR streaming API plus a few other language features in the code.  Continuous Profiling service is provided to the Apache Druid project free of charge by Imply and any committer can request free access to the UI.\",\n",
      "\t\t\"author_name\": \"Sam Rash\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 17:50:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65e1b27aa709dc3e11ae75993656243377744666\",\n",
      "\t\t\"parent\": \"12ce187ae4da7bcdd5719b95ef338eee062b8f73\",\n",
      "\t\t\"subject\": \"Fix a resource leak with Window processing (#14573)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-a-resource-leak-with-Window-processing-14573\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix a resource leak with Window processing  Additionally, in order to find the leak, there were adjustments to the StupidPool to track leaks a bit better. It would appear that the pool objects get GC'd during testing for some reason which was causing some incorrect identification of leaks from objects that had been returned but were GC'd along with the pool.  * Suppress unused warning\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 17:25:42 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"12ce187ae4da7bcdd5719b95ef338eee062b8f73\",\n",
      "\t\t\"parent\": \"d21c54fb73d8b1e18910cfbe680f183b8e8b59b0\",\n",
      "\t\t\"subject\": \"Update slack text (#14578)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-slack-text-14578\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 12:08:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d21c54fb73d8b1e18910cfbe680f183b8e8b59b0\",\n",
      "\t\t\"parent\": \"89aee6caaae41ecd99b6d99042bd62427ae4e6cb\",\n",
      "\t\t\"subject\": \"Cross reference  backpressure info (#14508)\",\n",
      "\t\t\"sanitized_subject_line\": \"Cross-reference-backpressure-info-14508\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Jill Osborne <jill.osborne@imply.io> Co-authored-by: Cristian Popa <cristian.popa@imply.io> \",\n",
      "\t\t\"author_name\": \"cristian-popa\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 10:02:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"89aee6caaae41ecd99b6d99042bd62427ae4e6cb\",\n",
      "\t\t\"parent\": \"3ff51487b7cbf26f95ef414f3b5d505a8620804f\",\n",
      "\t\t\"subject\": \"Fixing an issue in sequential merge  (#14574)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-an-issue-in-sequential-merge-14574\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing an issue in sequential merge where workers without any partial key statistics would get stuck because controller did not change the worker state.  * Removing empty check  * Adding IT for MSQ sequential bug fix.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 22:05:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3ff51487b7cbf26f95ef414f3b5d505a8620804f\",\n",
      "\t\t\"parent\": \"3711c0d987213a0086053916a23775768f6f0a6b\",\n",
      "\t\t\"subject\": \"Add ZooKeeper connection state alerts and metrics. (#14333)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-ZooKeeper-connection-state-alerts-and-metrics.-14333\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add ZooKeeper connection state alerts and metrics.  - New metric \\\"zk/connected\\\" is an indicator showing 1 when connected,   0 when disconnected. - New metric \\\"zk/disconnected/time\\\" measures time spent disconnected. - New alert when Curator connection state enters LOST or SUSPENDED.  * Use right GuardedBy.  * Test fixes, coverage.  * Adjustment.  * Fix tests.  * Fix ITs.  * Improved injection.  * Adjust metric name, add tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 09:34:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3711c0d987213a0086053916a23775768f6f0a6b\",\n",
      "\t\t\"parent\": \"cc8b210e4c6acc4f1ccb0af6fe163209357ddf18\",\n",
      "\t\t\"subject\": \"Reduce heap footprint of GenericIndexed. (#14563)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-heap-footprint-of-GenericIndexed.-14563\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Two changes:  1) Intern DecompressingByteBufferObjectStrategy. Saves ~32 bytes per column.  2) Split GenericIndexed into GenericIndexed.V1 and GenericIndexed.V2. The    major benefit here is isolating out the ByteBuffers that are only needed    for V2. This saves ~80 bytes for V1 (one buffer instead of two).\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 08:11:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc8b210e4c6acc4f1ccb0af6fe163209357ddf18\",\n",
      "\t\t\"parent\": \"7142b0c39eca2d6f111db827d5e5b035cc4d9347\",\n",
      "\t\t\"subject\": \"AggregatorFactory: Use guessAggregatorHeapFootprint when factorizeWithSize is not implemented. (#14567)\",\n",
      "\t\t\"sanitized_subject_line\": \"AggregatorFactory-Use-guessAggregatorHeapFootprint-when-factorizeWithSize-is-not-implemented.-14567\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"There are two ways of estimating heap footprint of an Aggregator:  1) AggregatorFactory#guessAggregatorHeapFootprint 2) AggregatorFactory#factorizeWithSize + Aggregator#aggregateWithSize  When the second path is used, the default implementation of factorizeWithSize is now updated to delegate to guessAggregatorHeapFootprint, making these equivalent. The old logic used getMaxIntermediateSize, which is less accurate.  Also fixes a bug where, when using the second path, calling factorizeWithSize on PassthroughAggregatorFactory would fail because getMaxIntermediateSize was not implemented. (There is no buffer aggregator, so there would be no need.)\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 07:33:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7142b0c39eca2d6f111db827d5e5b035cc4d9347\",\n",
      "\t\t\"parent\": \"d76903f10ba45423205f70b751f1bc2b4f616c16\",\n",
      "\t\t\"subject\": \"Enable result level cache for GroupByStrategyV2 on broker (#11595)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-result-level-cache-for-GroupByStrategyV2-on-broker-11595\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Cache is disabled for GroupByStrategyV2 on broker since the pr #3820 [groupBy v2: Results not fully merged when caching is enabled on the broker]. But we can enable the result-level cache on broker for GroupByStrategyV2 and keep the segment-level cache disabled.\",\n",
      "\t\t\"author_name\": \"hqx871\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jul 2023 15:00:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d76903f10ba45423205f70b751f1bc2b4f616c16\",\n",
      "\t\t\"parent\": \"854ef98235979eb8586a49c0ed62e0bd16940474\",\n",
      "\t\t\"subject\": \"Tasks API documentation refactor (#14492)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tasks-API-documentation-refactor-14492\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 13:19:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"854ef98235979eb8586a49c0ed62e0bd16940474\",\n",
      "\t\t\"parent\": \"0ca3ba0b301801293ec1c0ccddfeab76ace58586\",\n",
      "\t\t\"subject\": \"Minor doc fixes. (#14565)\",\n",
      "\t\t\"sanitized_subject_line\": \"Minor-doc-fixes.-14565\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com> \",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 13:12:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0ca3ba0b301801293ec1c0ccddfeab76ace58586\",\n",
      "\t\t\"parent\": \"a764ed7fde0a605cebd56f34009b07ae04c78fdf\",\n",
      "\t\t\"subject\": \"Add service/heartbeat metric into statsd-reporter (#14564)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-service-heartbeat-metric-into-statsd-reporter-14564\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"YongGang\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 12:38:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a764ed7fde0a605cebd56f34009b07ae04c78fdf\",\n",
      "\t\t\"parent\": \"c91148c43b72c59230d20857d810621805ceb802\",\n",
      "\t\t\"subject\": \"Update Jupyter notebook tutorial instructions for ARM devices (#14459)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Jupyter-notebook-tutorial-instructions-for-ARM-devices-14459\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 10:01:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c91148c43b72c59230d20857d810621805ceb802\",\n",
      "\t\t\"parent\": \"5ce536355e80cbb72e7319359c2047508d907e7d\",\n",
      "\t\t\"subject\": \"Bump tough-cookie from 4.0.0 to 4.1.3 in /web-console (#14557)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-tough-cookie-from-4.0.0-to-4.1.3-in-web-console-14557\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [tough-cookie](https://github.com/salesforce/tough-cookie) from 4.0.0 to 4.1.3. - [Release notes](https://github.com/salesforce/tough-cookie/releases) - [Changelog](https://github.com/salesforce/tough-cookie/blob/master/CHANGELOG.md) - [Commits](https://github.com/salesforce/tough-cookie/compare/v4.0.0...v4.1.3)  --- updated-dependencies: - dependency-name: tough-cookie   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com> Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 08:53:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ce536355e80cbb72e7319359c2047508d907e7d\",\n",
      "\t\t\"parent\": \"8087aa2b803ca21498c7578de3c1e1d8118a63f4\",\n",
      "\t\t\"subject\": \"Fix planning bug while using sort merge frame processor (#14450)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-planning-bug-while-using-sort-merge-frame-processor-14450\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"sqlJoinAlgorithm is now a hint to the planner to execute the join in the specified manner. The planner can decide to ignore the hint if it deduces that the specified algorithm can be detrimental to the performance of the join beforehand.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 09:58:44 +0000\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8087aa2b803ca21498c7578de3c1e1d8118a63f4\",\n",
      "\t\t\"parent\": \"30a91be15a4b728d4a3c6e8ff4fb0d8ae554a1a6\",\n",
      "\t\t\"subject\": \"Adding the null check in combine and fold in doublesSketch (#14568)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-the-null-check-in-combine-and-fold-in-doublesSketch-14568\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Pranav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 14:28:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"30a91be15a4b728d4a3c6e8ff4fb0d8ae554a1a6\",\n",
      "\t\t\"parent\": \"66cac08a52cc357a4c775dbb64919941f7733c57\",\n",
      "\t\t\"subject\": \"Add log statements for tmpStorageBytes in MSQ (#14449)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-log-statements-for-tmpStorageBytes-in-MSQ-14449\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add log statements for tmpStorageBytes in MSQ  * Add log  * Update log message\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jul 2023 11:02:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"66cac08a52cc357a4c775dbb64919941f7733c57\",\n",
      "\t\t\"parent\": \"c3f84f9ea07e034f23f4252ac9b90d49988791da\",\n",
      "\t\t\"subject\": \"Refactor HllSketchBuildAggregatorFactory (#14544)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-HllSketchBuildAggregatorFactory-14544\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor HllSketchBuildAggregatorFactory  The usage of ColumnProcessors and HllSketchBuildColumnProcessorFactory made it very difficult to figure out what was going on from just looking at the AggregatorFactory or Aggregator code.  It also didn't properly double check that you could use UTF8 ahead of time, even though it's entirely possible to validate it before trying to use it.  This refactor makes keeps the general indirection that had been implemented by the Consumer<Supplier<HllSketch>> but centralizes the decision logic and makes it easier to understand the code.  * Test fixes  * Add test that validates the types are maintained  * Add back indirection to avoid buffer calls  * Cover floats and doubles are the same thing  * Static checks\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Jul 2023 09:57:09 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c3f84f9ea07e034f23f4252ac9b90d49988791da\",\n",
      "\t\t\"parent\": \"58a35bf07e6ec20427bd1dbcd5e1ca37d4c7c757\",\n",
      "\t\t\"subject\": \"Suppress CVEs (#14291)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVEs-14291\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Address various CVEs by upgrading dependencies or adding suppression with a justification\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Jul 2023 15:19:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58a35bf07e6ec20427bd1dbcd5e1ca37d4c7c757\",\n",
      "\t\t\"parent\": \"63ee69b4e8698fd33e5e8988be150a74fd966e19\",\n",
      "\t\t\"subject\": \"Deprecate EntryExistsException in Druid 27 and remove in Druid 28 (#14554)\",\n",
      "\t\t\"sanitized_subject_line\": \"Deprecate-EntryExistsException-in-Druid-27-and-remove-in-Druid-28-14554\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Also deprecate UnknownSegmentIdsException.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 8 Jul 2023 15:40:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"63ee69b4e8698fd33e5e8988be150a74fd966e19\",\n",
      "\t\t\"parent\": \"5f94a2a9c2a801225e5ebceb92e0112ed2a0dca2\",\n",
      "\t\t\"subject\": \"Claim full support for Java 17. (#14384)\",\n",
      "\t\t\"sanitized_subject_line\": \"Claim-full-support-for-Java-17.-14384\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Claim full support for Java 17.  No production code has changed, except the startup scripts.  Changes:  1) Allow Java 17 without DRUID_SKIP_JAVA_CHECK.  2) Include the full list of opens and exports on both Java 11 and 17.  3) Document that Java 17 is both supported and preferred.  4) Switch some tests from Java 11 to 17 to get better coverage on the    preferred version.  * Doc update.  * Update errorprone.  * Update docker_build_containers.sh.  * Update errorprone in licenses.yaml.  * Add some more run-javas.  * Additional run-javas.  * Update errorprone.  * Suppress new errorprone error.  * Add exports and opens in ForkingTaskRunner for Java 11+.  Test, doc changes.  * Additional errorprone updates.  * Update for errorprone.  * Restore old fomatting in LdapCredentialsValidator.  * Copy bin/ too.  * Fix Java 15, 17 build line in docker_build_containers.sh.  * Update busybox image.  * One more java command.  * Fix interpolation.  * IT commandline refinements.  * Switch to busybox 1.34.1-glibc.  * POM adjustments, build and test one IT on 17.  * Additional debugging.  * Fix silly thing.  * Adjust command line.  * Add exports and opens one more place.  * Additional harmonization of strong encapsulation parameters.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 12:52:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5f94a2a9c2a801225e5ebceb92e0112ed2a0dca2\",\n",
      "\t\t\"parent\": \"021a01df4575519dd73aa734804f3a3ad4c1e225\",\n",
      "\t\t\"subject\": \"Add link to Slack channel (#14553)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-link-to-Slack-channel-14553\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 10:09:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"021a01df4575519dd73aa734804f3a3ad4c1e225\",\n",
      "\t\t\"parent\": \"9e617373a0cd2467e8565a54335849c9f48b39d0\",\n",
      "\t\t\"subject\": \"RTR, HRTR: Fix incorrect maxLazyWorkers check in markLazyWorkers. (#14545)\",\n",
      "\t\t\"sanitized_subject_line\": \"RTR-HRTR-Fix-incorrect-maxLazyWorkers-check-in-markLazyWorkers.-14545\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Recently #14532 fixed a problem when maxLazyWorkers == 0 and lazyWorkers starts out empty. Unfortunately, even after that patch, there remained a more general version of this problem when maxLazyWorkers == lazyWorkers.size(). This patch fixes it.  I'm not sure if this would actually happen in production, because the provisioning strategies do try to avoid calling markWorkersLazy until previously-initiated terminations have finished. Nevertheless, it still seems like a good thing to fix.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 10:08:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e617373a0cd2467e8565a54335849c9f48b39d0\",\n",
      "\t\t\"parent\": \"afa8c7b8abec1337003af76160ea94ef8cd09f0a\",\n",
      "\t\t\"subject\": \"Handle dimensionless group by queries with partitioning\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-dimensionless-group-by-queries-with-partitioning\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 21:51:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"afa8c7b8abec1337003af76160ea94ef8cd09f0a\",\n",
      "\t\t\"parent\": \"40d0dc9e0e02c89f91762a400ecdd84b950907ca\",\n",
      "\t\t\"subject\": \"Adding Ability for MSQ to write select results to durable storage. (#14527)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-Ability-for-MSQ-to-write-select-results-to-durable-storage.-14527\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"One of the most requested features in druid is to have an ability to download big result sets. As part of #14416 , we added an ability for MSQ to be queried via a query friendly endpoint. This PR builds upon that work and adds the ability for MSQ to write select results to durable storage.  We write the results to the durable storage location <prefix>/results/<queryId> in the druid frame format. This is exposed to users by /v2/sql/statements/:queryId/results.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 20:49:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"40d0dc9e0e02c89f91762a400ecdd84b950907ca\",\n",
      "\t\t\"parent\": \"95115d722af6d7eb26384a261c16776fbf01917b\",\n",
      "\t\t\"subject\": \"Use separate executor to handle task updates in TaskQueue (#14533)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-separate-executor-to-handle-task-updates-in-TaskQueue-14533\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Description: `TaskQueue.notifyStatus` is often a heavy call as it performs the following operations: - Update task status in metadata DB - Update task locks in metadata DB - Request (synchronously) the task runner to shutdown the completed task - Clean up in-memory data structures  This method can often be slow and can cause worker sync / task runners to slow down.  Main changes: - Run task completion callbacks in a separate executor to handle task completion updates - Add new config `druid.indexer.queue.taskCompleteHandlerNumThreads` - Add metrics to monitor number of processed and queued items - There are still other paths that can invoke `notifyStatus`, but those need not be moved to the new executor as they are synchronous on purpose.  Other changes: - Add new metrics `task/status/queue/count`, `task/status/handled/count` - Add `TaskCountStatsProvider.getStats()` which deprecates the other `getXXXTaskCount` methods. - Use `CoordinatorRunStats` to collect and report metrics. This class has been used as is for now but will later be renamed and repurposed to use across all Druid services. \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 20:43:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"95115d722af6d7eb26384a261c16776fbf01917b\",\n",
      "\t\t\"parent\": \"1fe61bc869924d51a3e3133a5894afb3896640af\",\n",
      "\t\t\"subject\": \"CVE fixes - update of multiple dependencies.  (#14519)\",\n",
      "\t\t\"sanitized_subject_line\": \"CVE-fixes-update-of-multiple-dependencies.-14519\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Apache Druid brings multiple direct and transitive dependencies that are affected by plethora of CVEs. This PR attempts to update all the dependencies that did not require code refactoring. This PR modifies pom files, license file and OWASP Dependency Check suppression file.\",\n",
      "\t\t\"author_name\": \"Jan Werner\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 20:27:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1fe61bc869924d51a3e3133a5894afb3896640af\",\n",
      "\t\t\"parent\": \"d63eff3b1b6b15fac1bb278a784ce6c391a52ce2\",\n",
      "\t\t\"subject\": \"ChangeRequestHttpSyncer: Don't wait 1ms when checking isInitialized(). (#14547)\",\n",
      "\t\t\"sanitized_subject_line\": \"ChangeRequestHttpSyncer-Don-t-wait-1ms-when-checking-isInitialized-.-14547\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The wait doesn't seem to serve a purpose, other than causing delays when checking isInitialized() for a large number of things that have not yet been initialized.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 05:54:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d63eff3b1b6b15fac1bb278a784ce6c391a52ce2\",\n",
      "\t\t\"parent\": \"dd78e00dc543609db2c75c23f9546fc46cb86ad8\",\n",
      "\t\t\"subject\": \"Reduce contention in HttpRemoteTaskRunner.getKnownTasks() (#14541)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-contention-in-HttpRemoteTaskRunner.getKnownTasks-14541\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jul 2023 13:43:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dd78e00dc543609db2c75c23f9546fc46cb86ad8\",\n",
      "\t\t\"parent\": \"037f09bef2224b0912b0f225c7653929dd98af88\",\n",
      "\t\t\"subject\": \"Fix ColumnSignature error message and jdk17 test issue. (#14538)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-ColumnSignature-error-message-and-jdk17-test-issue.-14538\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix ColumnSignature error message and jdk17 test issue.  On jdk17, the \\\"problem\\\" part of the error message could change from NullPointerException to:    Cannot invoke \\\"String.length()\\\" because \\\"s\\\" is null  Due to the new more-helpful NPEs in Java 17. This broke the expectation and led to test failures on this case.  This patch fixes the problem by improving the error message so it isn't a generic NullPointerException.  * Fix format.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 15:10:59 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"037f09bef2224b0912b0f225c7653929dd98af88\",\n",
      "\t\t\"parent\": \"d02bb8bb6e1e6d0aae3ebdb06f2f1ea335b8ad6d\",\n",
      "\t\t\"subject\": \"HttpRemoteTaskRunner: Fix markLazyWorkers for maxLazyWorkers == 0. (#14532)\",\n",
      "\t\t\"sanitized_subject_line\": \"HttpRemoteTaskRunner-Fix-markLazyWorkers-for-maxLazyWorkers-0.-14532\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 11:51:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d02bb8bb6e1e6d0aae3ebdb06f2f1ea335b8ad6d\",\n",
      "\t\t\"parent\": \"5fc122a144cbb9dcc3471e518872ef2d2a135504\",\n",
      "\t\t\"subject\": \"Set explain attributes after the query is prepared (#14490)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-explain-attributes-after-the-query-is-prepared-14490\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add support for DML WITH AS.  * One more UT for with as subquery.  * Add a test with join query  * Use root query prepared node instead of individual SqlNode types.  - Set the explain plan attributes after the query is prepared when the query is planned and we've the finalized output names in the root source rel node. - Adjust tests; add unit test for negative ordinal case. - Remove the exception / error handling logic from resolveClusteredBy function since the validations now happen before it comes to the function  * Update comment.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 14:13:32 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5fc122a144cbb9dcc3471e518872ef2d2a135504\",\n",
      "\t\t\"parent\": \"277b35725619d6d6b63b5c925a72ffb19a37d703\",\n",
      "\t\t\"subject\": \"Add window-focused tests from Drill (#13773)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-window-focused-tests-from-Drill-13773\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit borrows some test definitions from Drill's test suite and tries to use them to flesh out the full validation of window function capbilities.  In order to be able to run these tests, we also add the ability to run a Scan operation against segments, which also meant an implementation of RowsAndColumns for frames.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 09:20:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"277b35725619d6d6b63b5c925a72ffb19a37d703\",\n",
      "\t\t\"parent\": \"87bb1b970915631149812e7a92892bc8850cf3eb\",\n",
      "\t\t\"subject\": \"Optimize IntervalIterator (#14530)\",\n",
      "\t\t\"sanitized_subject_line\": \"Optimize-IntervalIterator-14530\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"UniformGranularityTest's test to test a large number of intervals runs through 10 years of 1 second intervals.  This pushes a lot of stuff through IntervalIterator and shows up in terms of test runtime as one of the hottest tests.  Most of the time is going to constructing jodatime objects because it is doing things with DateTime objects instead of millis.  Change the calls to use millis instead and things go faster. \",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 14:44:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"87bb1b970915631149812e7a92892bc8850cf3eb\",\n",
      "\t\t\"parent\": \"a6547febaf8dcfb35f11073972317d7129035c98\",\n",
      "\t\t\"subject\": \"Fix bug during initialization of HttpServerInventoryView (#14517)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bug-during-initialization-of-HttpServerInventoryView-14517\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"If a server is removed during `HttpServerInventoryView.serverInventoryInitialized`, the initialization gets stuck as this server is never synced. The method eventually times out (default 250s).  Fix: Mark a server as stopped if it is removed. `serverInventoryInitialized` only waits for non-stopped servers to sync.  Other changes: - Add new metrics for better debugging of slow broker/coordinator startup   - `segment/serverview/sync/healthy`: whether the server view is syncing properly with a server   - `segment/serverview/sync/unstableTime`: time for which sync with a server has been unstable   - Clean up logging in `HttpServerInventoryView` and `ChangeRequestHttpSyncer` - Minor refactor for readability - Add utility class `Stopwatch` - Add tests and stubs\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 13:04:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a6547febaf8dcfb35f11073972317d7129035c98\",\n",
      "\t\t\"parent\": \"78db7a44148bfba0acdfe6612daa3113914808b7\",\n",
      "\t\t\"subject\": \"Remove unused coordinator dynamic configs (#14524)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-unused-coordinator-dynamic-configs-14524\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"After #13197 , several coordinator configs are now redundant as they are not being used anymore, neither with `smartSegmentLoading` nor otherwise.  Changes: - Remove dynamic configs `emitBalancingStats`: balancer error stats are always emitted, debug stats can be logged by using `debugDimensions` - `useBatchedSegmentSampler`, `percentOfSegmentsToConsiderPerMove`: batched segment sampling is always used - Add test to verify deserialization with unknown properties - Update `CoordinatorRunStats` to always track stats, this can be optimized later.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 12:11:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"78db7a44148bfba0acdfe6612daa3113914808b7\",\n",
      "\t\t\"parent\": \"f29a9faa94839bacfaad94bdeb4f439fe379dd18\",\n",
      "\t\t\"subject\": \"A query in MSQ would issue wrong error code (#14531)\",\n",
      "\t\t\"sanitized_subject_line\": \"A-query-in-MSQ-would-issue-wrong-error-code-14531\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"with a RuntimeException. Now the RuntimeException is being replaced by an user facing DruidException of Invalid category which would allow calcite not to throw an uncategorized exception.\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jul 2023 08:59:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f29a9faa94839bacfaad94bdeb4f439fe379dd18\",\n",
      "\t\t\"parent\": \"50b7e5d20e551163c6ed45eb8c39617ff5634d7b\",\n",
      "\t\t\"subject\": \"Better surfacing of invalid pattern errors for SQL REGEXP_EXTRACT function (#14505)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-surfacing-of-invalid-pattern-errors-for-SQL-REGEXP_EXTRACT-function-14505\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Jul 2023 17:12:54 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"50b7e5d20e551163c6ed45eb8c39617ff5634d7b\",\n",
      "\t\t\"parent\": \"609833c97bb44fee50f4fb84e44ad7c6cb053714\",\n",
      "\t\t\"subject\": \"docs: fix links (#14504)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-links-14504\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Jul 2023 12:29:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"609833c97bb44fee50f4fb84e44ad7c6cb053714\",\n",
      "\t\t\"parent\": \"cc159f431722fc0a2c692f913fd4e016f862e40e\",\n",
      "\t\t\"subject\": \"Do not emit negative lag because of stale offsets (#14292)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-emit-negative-lag-because-of-stale-offsets-14292\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The latest topic offsets are polled frequently and used to determine the lag based on the current offsets. However, when the offsets are stale (which can happen due to connection issues commonly), we may see a negative lag .  This PR prevents emission of metrics when the offsets are stale and at least one of the partitions has a negative lag.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Jul 2023 14:44:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc159f431722fc0a2c692f913fd4e016f862e40e\",\n",
      "\t\t\"parent\": \"e2676c390ee663149ffd984db156eb8b0fb7bddc\",\n",
      "\t\t\"subject\": \"docs: k8s-jobs role needs batch apigroup (#14343)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-k8s-jobs-role-needs-batch-apigroup-14343\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jakub Matyszewski\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Jul 2023 14:34:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e2676c390ee663149ffd984db156eb8b0fb7bddc\",\n",
      "\t\t\"parent\": \"4ee7b14f5fe61839c68c121511c1307df1b367a5\",\n",
      "\t\t\"subject\": \"Downgrade busybox version to fix k8s IT (#14518)\",\n",
      "\t\t\"sanitized_subject_line\": \"Downgrade-busybox-version-to-fix-k8s-IT-14518\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Jul 2023 12:21:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ee7b14f5fe61839c68c121511c1307df1b367a5\",\n",
      "\t\t\"parent\": \"c04a36d15b15ea0f2fea92d756a02335b5dbbb4b\",\n",
      "\t\t\"subject\": \"update links in jupyter notebook (#14404)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-links-in-jupyter-notebook-14404\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Jul 2023 13:50:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c04a36d15b15ea0f2fea92d756a02335b5dbbb4b\",\n",
      "\t\t\"parent\": \"27a70d569db7a0274e222d5ba1aa32cb587ce529\",\n",
      "\t\t\"subject\": \"Run IntelliJ-inspections in parallel to static-checks & web-checks in GHA (#14515)\",\n",
      "\t\t\"sanitized_subject_line\": \"Run-IntelliJ-inspections-in-parallel-to-static-checks-web-checks-in-GHA-14515\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, IntelliJ-inspections are run sequentially w.r.t static-checks, thereby increasing build time. Moving IntelliJ-inspections to a separate job to improve builds time and get a quick insight into such issues early on.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Jul 2023 17:10:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"27a70d569db7a0274e222d5ba1aa32cb587ce529\",\n",
      "\t\t\"parent\": \"2d5b27358e0a1abefcc3c7ddeb3af613ddf88df5\",\n",
      "\t\t\"subject\": \"Add page information to SqlStatementResource API (#14512)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-page-information-to-SqlStatementResource-API-14512\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"    * Changes the get results API in SqlStatementResource to take a page number instead of row/offset.     * Adds \\\"pages\\\" containing information on each page to the results status.     * Update the \\\"numRows\\\" and \\\"sizeInByes\\\" to \\\"numTotalRows\\\" and \\\"totalSizeInBytes\\\" respectively, which are totalled across all pages. \",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Jul 2023 15:20:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d5b27358e0a1abefcc3c7ddeb3af613ddf88df5\",\n",
      "\t\t\"parent\": \"277aaa5c572725b7cacb4e7be36bad164a50f889\",\n",
      "\t\t\"subject\": \"Logging the fieldName in the coerce exceptions  (#14483)\",\n",
      "\t\t\"sanitized_subject_line\": \"Logging-the-fieldName-in-the-coerce-exceptions-14483\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Logging the fieldName in the coerce exceptions\",\n",
      "\t\t\"author_name\": \"Pranav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Jul 2023 14:13:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"277aaa5c572725b7cacb4e7be36bad164a50f889\",\n",
      "\t\t\"parent\": \"58f3faf2996051a037555d665da6a8781215e037\",\n",
      "\t\t\"subject\": \"remove druid.processing.columnCache.sizeBytes and CachingIndexed, combine string column implementations (#14500)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-druid.processing.columnCache.sizeBytes-and-CachingIndexed-combine-string-column-implementations-14500\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* combine string column implementations changes: * generic indexed, front-coded, and auto string columns now all share the same column and index supplier implementations * remove CachingIndexed implementation, which I think is largely no longer needed by the switch of many things to directly using ByteBuffer, avoiding the cost of creating Strings * remove ColumnConfig.columnCacheSizeBytes since CachingIndexed was the only user \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 2 Jul 2023 19:37:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58f3faf2996051a037555d665da6a8781215e037\",\n",
      "\t\t\"parent\": \"048dbcee8846d51a38b228c8aaac88851278277e\",\n",
      "\t\t\"subject\": \"SortMergeJoinFrameProcessor: Fix two bugs with buffering. (#14196)\",\n",
      "\t\t\"sanitized_subject_line\": \"SortMergeJoinFrameProcessor-Fix-two-bugs-with-buffering.-14196\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"1) Fix a problem where the fault wasn't reported when the left-hand side    had too many buffered frames. (Instead, frames continued to be buffered,    eventually running the server out of memory.)  2) Always update the mark when rewinding isn't necessary. It fixes a problem where    frames would be needlessly buffered when there isn't a key match across    the two sides.  3) Memory reserved for building the trackers now change based on the heap sized\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 2 Jul 2023 19:52:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"048dbcee8846d51a38b228c8aaac88851278277e\",\n",
      "\t\t\"parent\": \"67fbd8e7fcf71e8a0dc716b612317226e02bff88\",\n",
      "\t\t\"subject\": \"MSQ: Improve InsertTimeOutOfBounds error message. (#14511)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Improve-InsertTimeOutOfBounds-error-message.-14511\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Nicer and actionable error message for `InsertTimeOutOfBounds` fault\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 2 Jul 2023 01:44:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"67fbd8e7fcf71e8a0dc716b612317226e02bff88\",\n",
      "\t\t\"parent\": \"4b2d87336a56eafe6c28fc93f1040e737013671e\",\n",
      "\t\t\"subject\": \"Add \\\"stringEncoding\\\" parameter to DataSketches HLL. (#11201)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-stringEncoding-parameter-to-DataSketches-HLL.-11201\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add \\\"stringEncoding\\\" parameter to DataSketches HLL.  Builds on the concept from #11172 and adds a way to feed HLL sketches with UTF-8 bytes.  This must be an option rather than always-on, because prior to this patch, HLL sketches used UTF-16LE encoding when hashing strings. To remain compatible with sketch images created prior to this patch -- which matters during rolling updates and when reading sketches that have been written to segments -- we must keep UTF-16LE as the default.  Not currently documented, because I'm not yet sure how best to expose this functionality to users. I think the first place would be in the SQL layer: we could have it automatically select UTF-8 or UTF-16LE when building sketches at query time. We need to be careful about this, though, because UTF-8 isn't always faster. Sometimes, like for the results of expressions, UTF-16LE is faster. I expect we will sort this out in future patches.  * Fix benchmark.  * Fix style issues, improve test coverage.  * Put round back, to make IT updates easier.  * Fix test.  * Fix issue with filtered aggregators and add test.  * Use DS native update(ByteBuffer) method. Improve test coverage.  * Add another suppression.  * Fix ITAutoCompactionTest.  * Update benchmarks.  * Updates.  * Fix conflict.  * Adjustments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 30 Jun 2023 12:45:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4b2d87336a56eafe6c28fc93f1040e737013671e\",\n",
      "\t\t\"parent\": \"e10e35aa2ca953e65f1337a08800e0a29aaefd44\",\n",
      "\t\t\"subject\": \"Add additional index on task table (#14470)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-additional-index-on-task-table-14470\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Pranav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 29 Jun 2023 15:32:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e10e35aa2ca953e65f1337a08800e0a29aaefd44\",\n",
      "\t\t\"parent\": \"a6cabbe10f02d87f9299490a07dd437a4a559b8c\",\n",
      "\t\t\"subject\": \"Add REGEXP_REPLACE function. (#14460)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-REGEXP_REPLACE-function.-14460\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add REGEXP_REPLACE function.  Replaces all instances of a pattern with a replacement string.  * Fixes.  * Improve test coverage.  * Adjust behavior.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 29 Jun 2023 13:47:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a6cabbe10f02d87f9299490a07dd437a4a559b8c\",\n",
      "\t\t\"parent\": \"c798d3fb2e840df5700615a0fb994f61acbed46e\",\n",
      "\t\t\"subject\": \"SQL: Avoid \\\"intervals\\\" for non-table-based datasources. (#14336)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Avoid-intervals-for-non-table-based-datasources.-14336\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In these other cases, stick to plain \\\"filter\\\". This simplifies lots of logic downstream, and doesn't hurt since we don't have intervals-specific optimizations outside of tables.  Fixes an issue where we couldn't properly filter on a column from an external datasource if it was named __time.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 29 Jun 2023 09:57:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c798d3fb2e840df5700615a0fb994f61acbed46e\",\n",
      "\t\t\"parent\": \"fd1a88a6b3f746f88946fce8a71662b63390ce94\",\n",
      "\t\t\"subject\": \"Fix flaky SqlStatementResourceTest. (#14498)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-SqlStatementResourceTest.-14498\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Mocks generally have state and should not be static. In particular, the \\\"Yielder\\\" included in one of the mocks can only be iterated once, which made the test suite order-dependent.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 29 Jun 2023 05:42:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd1a88a6b3f746f88946fce8a71662b63390ce94\",\n",
      "\t\t\"parent\": \"34c55a0bde701e18fbe064bfe574caedb752ff4f\",\n",
      "\t\t\"subject\": \".asf.yaml: Add required \\\"repository\\\" field. (#14499)\",\n",
      "\t\t\"sanitized_subject_line\": \".asf.yaml-Add-required-repository-field.-14499\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Our new .asf.yaml is not getting picked up because custom_subjects must include \\\"repository\\\".\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 15:05:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"34c55a0bde701e18fbe064bfe574caedb752ff4f\",\n",
      "\t\t\"parent\": \"c36f12f1d8bf81cf110dd41853627be175816b00\",\n",
      "\t\t\"subject\": \"SQL: SUBSTRING support for non-literals. (#14480)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-SUBSTRING-support-for-non-literals.-14480\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: SUBSTRING support for non-literals.  * Fix AssertionError test.  * Fix header.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 13:43:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c36f12f1d8bf81cf110dd41853627be175816b00\",\n",
      "\t\t\"parent\": \"e552f68e774cf8727e6bf504fed9c94fa3a0a849\",\n",
      "\t\t\"subject\": \"Support complex variance object inputs for variance SQL agg function (#14463)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-complex-variance-object-inputs-for-variance-SQL-agg-function-14463\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support complex variance object inputs for variance SQL agg function  * Add test  * Include complexTypeChecker, address PR comments  * Checkstyle, javadoc link\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 13:14:19 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e552f68e774cf8727e6bf504fed9c94fa3a0a849\",\n",
      "\t\t\"parent\": \"82fbb31c7c55f01629191e5072683f0fdb87c7db\",\n",
      "\t\t\"subject\": \"Update .asf.yaml to simplify email subjects. (#14494)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-.asf.yaml-to-simplify-email-subjects.-14494\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, github notification emails to commits@druid.apache.org have a wide variety of subject lines. This foils email client threading and makes the firehose of emails hard to follow. This is an attempt, inspired by the config for plc4x, to make the emails easier to follow.  After this change, it may even make sense to send some to dev@ instead of commits@.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 10:56:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"82fbb31c7c55f01629191e5072683f0fdb87c7db\",\n",
      "\t\t\"parent\": \"233233c92d906372cff3144e3d03191ab45f32f4\",\n",
      "\t\t\"subject\": \"Properly read SQL-compatible segments in default-value mode. (#14142)\",\n",
      "\t\t\"sanitized_subject_line\": \"Properly-read-SQL-compatible-segments-in-default-value-mode.-14142\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Properly read SQL-compatible segments in default-value mode.  Main changes:  1) Dictionary-encoded and front-coded string columns: in default-value    mode, detect cases where a dictionary has the empty string in it, then    either combine it with null (if null is present) or replace it with    null (if null is not present).  2) Numeric nullable columns: in default-value mode, ignore the null    value bitmap. This causes all null numbers to be read as zeroes.  Testing strategy:  1) Add a mmappedWithSqlCompatibleNulls case to BaseFilterTest that    writes segments under SQL-compatible mode, and reads them under    default-value mode.  2) Unit tests for the new wrapper classes (CombineFirstTwoEntriesIndexed,    CombineFirstTwoValuesColumnarInts, CombineFirstTwoValuesColumnarMultiInts,    CombineFirstTwoValuesIndexedInts).  * Fix a mistake, use more singlethreadedness.  * WIP  * Tests, improvements.  * Style.  * See Spot bug.  * Remove unused method.  * Address review comments.  1) Read bitmaps even if we don't retain them. 2) Combine StringFrontCodedDictionaryEncodedColumn and ScalarStringDictionaryEncodedColumn.  * Add missing tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 10:30:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"233233c92d906372cff3144e3d03191ab45f32f4\",\n",
      "\t\t\"parent\": \"cb3a9d2b5778c568f8a6fad096b95bfd1f36bd21\",\n",
      "\t\t\"subject\": \"Add query context parameter to control limiting select rows (#14476)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-query-context-parameter-to-control-limiting-select-rows-14476\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add query context parameter to control limiting select rows  * Add unit tests  * Address review comments  * Address review comments  * Address review comments\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 17:54:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb3a9d2b5778c568f8a6fad096b95bfd1f36bd21\",\n",
      "\t\t\"parent\": \"baa64e6d8a71b1d3816dea6144ca4322d0432e53\",\n",
      "\t\t\"subject\": \"Adding Interactive API's for MSQ engine (#14416)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-Interactive-API-s-for-MSQ-engine-14416\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR aims to expose a new API called \\\"@path(\\\"/druid/v2/sql/statements/\\\")\\\" which takes the same payload as the current \\\"/druid/v2/sql\\\" endpoint and allows users to fetch results in an async manner.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 17:51:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"baa64e6d8a71b1d3816dea6144ca4322d0432e53\",\n",
      "\t\t\"parent\": \"fd20bbd30ecee969fd3f38cbe1d45de7d763f531\",\n",
      "\t\t\"subject\": \"update hadoop version to 3.3.6 (#14489)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-hadoop-version-to-3.3.6-14489\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 15:03:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd20bbd30ecee969fd3f38cbe1d45de7d763f531\",\n",
      "\t\t\"parent\": \"0335aaa279d95063c6a172cf3f1ffdf6e46f592b\",\n",
      "\t\t\"subject\": \"Fix another infinite loop and remove Mockito usage (#14493)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-another-infinite-loop-and-remove-Mockito-usage-14493\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix another infinite loop and remove Mockito usage  The ConfigManager objects were `started()` without ever being stopped.  This scheduled a poll call that never-ended, to make matters worse, the poll interval was set to 0 ms, making an infinite poll with 0 sleep, i.e. an infinite loop.  Also introduce test classes and remove usage of mocks  * Checkstyle\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Jun 2023 21:49:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0335aaa279d95063c6a172cf3f1ffdf6e46f592b\",\n",
      "\t\t\"parent\": \"2cfb00b1de928a48a1c61bc04c10cdbccab33866\",\n",
      "\t\t\"subject\": \"Add query results directory and prevent the auto cleaner from cleaning it (#14446)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-query-results-directory-and-prevent-the-auto-cleaner-from-cleaning-it-14446\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Adds support for automatic cleaning of a \\\"query-results\\\" directory in durable storage. This directory will be cleaned up only if the task id is not known to the overlord. This will allow the storage of query results after the task has finished running.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Jun 2023 10:14:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2cfb00b1de928a48a1c61bc04c10cdbccab33866\",\n",
      "\t\t\"parent\": \"c78d885b80a913deaf2c99600275df423daa81f0\",\n",
      "\t\t\"subject\": \"Add missing `isNull()` implementation to `FilteredAggregator` (#14465)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-missing-isNull-implementation-to-FilteredAggregator-14465\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Jun 2023 16:35:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c78d885b80a913deaf2c99600275df423daa81f0\",\n",
      "\t\t\"parent\": \"4bd6bd0d4f61effa392cb5736d392ca12f7f3b40\",\n",
      "\t\t\"subject\": \"Cache parsed expressions and binding analysis in more places. (#14124)\",\n",
      "\t\t\"sanitized_subject_line\": \"Cache-parsed-expressions-and-binding-analysis-in-more-places.-14124\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Cache parsed expressions and binding analysis in more places.  Main changes:  1) Cache parsed and analyzed expressions within PlannerContext for a    single SQL query.  2) Cache parsed expressions together with input binding analysis using    a new class AnalyzeExpr.  This speeds up SQL planning, because SQL planning involves parsing analyzing the same expression strings over and over again.  * Fixes.  * Fix style.  * Fix test.  * Simplify: get rid of AnalyzedExpr, focus on caching.  * Rename parse -> parseExpression.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Jun 2023 13:40:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4bd6bd0d4f61effa392cb5736d392ca12f7f3b40\",\n",
      "\t\t\"parent\": \"2f0a43790c22318b9c48ed0f38db7350fef267ef\",\n",
      "\t\t\"subject\": \"Improve CostBalancerStrategy, deprecate cachingCost (#14484)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-CostBalancerStrategy-deprecate-cachingCost-14484\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes to `cost` strategy: - In every `ServerHolder`, track the number of segments per datasource per interval - Perform cost computations for a given interval just once, and then multiply by a constant factor to account for the total segment count in that interval - Do not perform joint cost computations with segments that are outside the compute interval (\\u00b1 45 days) for the segment being considered for move - Remove metrics `segment/cost/*` as they were coordinator killers! Turning on these metrics (by setting `emitBalancingStats` to true) has often caused the coordinator to be stuck for hours. Moreover, they are too complicated to decipher and do not provide any meaningful insight into a Druid cluster. - Add new simpler metrics `segment/balancer/compute/*` to track cost computation time, count and errors.  Other changes: - Remove flaky test from `CostBalancerStrategyTest`. - Add tests to verify that computed cost has remained unchanged - Remove usages of mock `BalancerStrategy` from `LoadRuleTest`, `BalanceSegmentsTest` - Clean up `BalancerStrategy` interface \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Jun 2023 13:23:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f0a43790c22318b9c48ed0f38db7350fef267ef\",\n",
      "\t\t\"parent\": \"6ba10c8b6caf1de5afd782ba70edda406466c892\",\n",
      "\t\t\"subject\": \"Make GuavaUtilsTest use less CPU (#14487)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-GuavaUtilsTest-use-less-CPU-14487\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 21:45:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ba10c8b6caf1de5afd782ba70edda406466c892\",\n",
      "\t\t\"parent\": \"f546cd64a9640ed14c9c0f44481678d39530e3b5\",\n",
      "\t\t\"subject\": \"fix bug with json_value expression array extraction (#14461)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-with-json_value-expression-array-extraction-14461\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 21:02:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f546cd64a9640ed14c9c0f44481678d39530e3b5\",\n",
      "\t\t\"parent\": \"903addf7c281099cb3fd510c0ebebfa5d62c5584\",\n",
      "\t\t\"subject\": \"MSQ: Ensure that the allocated segment aligns with the requested granularity (#14475)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Ensure-that-the-allocated-segment-aligns-with-the-requested-granularity-14475\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Throw an `InsertCannotAllocateSegmentFault` if the allocated segment is not aligned with the requested granularity. - Tests to verify new behaviour \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Jun 2023 09:25:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"903addf7c281099cb3fd510c0ebebfa5d62c5584\",\n",
      "\t\t\"parent\": \"79bff4bbf7b317ec0d552d595e07b6da29b810b4\",\n",
      "\t\t\"subject\": \"Make agg and scalar routines test to depend on specific routine names. (#14482)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-agg-and-scalar-routines-test-to-depend-on-specific-routine-names.-14482\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 23:03:08 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"79bff4bbf7b317ec0d552d595e07b6da29b810b4\",\n",
      "\t\t\"parent\": \"579b93f282aae871cd97fb4066d45f0884019b6c\",\n",
      "\t\t\"subject\": \"Improvements to `EXPLAIN PLAN` attributes (#14441)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improvements-to-EXPLAIN-PLAN-attributes-14441\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Updates: use the target table directly, sanitized replace time chunks and clustered by cols.  * Add DruidSqlParserUtil and tests.  * minor refactor  * Use SqlUtil.isLiteral  * Throw ValidationException if CLUSTERED BY column descending order is specified.  - Fails query planning  * Some more tests.  * fixup existing comment  * Update comment  * checkstyle fix: remove unused imports  * Remove InsertCannotOrderByDescendingFault and deprecate the fault in readme.  * minor naming  * move deprecated field to the bottom  * update docs.  * add one more example.  * Collapsible query and result  * checkstyle fixes  * Code cleanup  * order by changes  * conditionally set attributes only for explain queries.  * Cleaner ordinal check.  * Add limit test and update javadoc.  * Commentary and minor adjustments.  * Checkstyle fixes.  * One more checkArg.  * add unexpected kind to exception.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 23:01:11 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"579b93f282aae871cd97fb4066d45f0884019b6c\",\n",
      "\t\t\"parent\": \"fc08617e9ef2c12dae341c37b74334d7fd690eb7\",\n",
      "\t\t\"subject\": \"API reference refactor (#14372)\",\n",
      "\t\t\"sanitized_subject_line\": \"API-reference-refactor-14372\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 15:48:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fc08617e9ef2c12dae341c37b74334d7fd690eb7\",\n",
      "\t\t\"parent\": \"8211379de689d64d60fcaa8aa131b733b186c47d\",\n",
      "\t\t\"subject\": \"[Docs] Clean up druid.processing.intermediaryData.storage.type description (#14431)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Clean-up-druid.processing.intermediaryData.storage.type-description-14431\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 11:46:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8211379de689d64d60fcaa8aa131b733b186c47d\",\n",
      "\t\t\"parent\": \"b7434be99e803cba22360a67ebe63948cb0def24\",\n",
      "\t\t\"subject\": \"MSQ: Change default clusterStatisticsMergeMode to SEQUENTIAL. (#14310)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Change-default-clusterStatisticsMergeMode-to-SEQUENTIAL.-14310\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Change default clusterStatisticsMergeMode to SEQUENTIAL.  This is an undocumented parameter that controls how cluster-by statistics are merged. In PARALLEL mode, statistics are gathered from workers all at once. In SEQUENTIAL mode, statistics are gathered time chunk by time chunk. This improves accuracy for jobs with many time chunks, and reduces memory usage.  The main downside of SEQUENTIAL is that it can take longer, but in most situations I've seen, PARALLEL is only really usable in cases where the sketches are small enough that SEQUENTIAL would also run relatively quickly. So it seems like SEQUENTIAL is a better default.  * Switch off-test from SEQUENTIAL to PARALLEL.  * Fix sequential merge for situations where there are no time chunks at all.  * Add a couple more tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 10:54:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b7434be99e803cba22360a67ebe63948cb0def24\",\n",
      "\t\t\"parent\": \"114380749d230a280b416444fb10110e41258322\",\n",
      "\t\t\"subject\": \"Add ServiceStatusMonitor to monitor service health (#14443)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-ServiceStatusMonitor-to-monitor-service-health-14443\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add OverlordStatusMonitor and CoordinatorStatusMonitor to monitor service leader status  * make the monitor more general  * resolve conflict  * use Supplier pattern to provide metrics  * reformat code and doc  * move service specific tag to dimension  * minor refine  * update doc  * reformat code  * address comments  * remove declared exception  * bind HeartbeatSupplier conditionally in Coordinator\",\n",
      "\t\t\"author_name\": \"YongGang\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 10:26:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"114380749d230a280b416444fb10110e41258322\",\n",
      "\t\t\"parent\": \"1647d5f4a07b76a8bf7cd190c5778ec07e99b3d2\",\n",
      "\t\t\"subject\": \"MSQ: Improve the parse exception errors and the handling of null UTF characters in Strings in Frames  (#14398)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Improve-the-parse-exception-errors-and-the-handling-of-null-UTF-characters-in-Strings-in-Frames-14398\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 18:14:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1647d5f4a07b76a8bf7cd190c5778ec07e99b3d2\",\n",
      "\t\t\"parent\": \"d7c9c2f3671d1e9cefff463eb5cb557e9e882f38\",\n",
      "\t\t\"subject\": \"Limit the subquery results by memory usage (#13952)\",\n",
      "\t\t\"sanitized_subject_line\": \"Limit-the-subquery-results-by-memory-usage-13952\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Users can now add a guardrail to prevent subquery\\u2019s results from exceeding the set number of bytes by setting druid.server.http.maxSubqueryRows in Broker's config or maxSubqueryRows in the query context. This feature is experimental for now and would default back to row-based limiting in case it fails to get the accurate size of the results consumed by the query.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Jun 2023 18:12:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7c9c2f3671d1e9cefff463eb5cb557e9e882f38\",\n",
      "\t\t\"parent\": \"72cf91fbc0ed9cc2abce91df878ab431678b12f3\",\n",
      "\t\t\"subject\": \"SqlResults: Coerce arrays to lists for VARCHAR. (#14260)\",\n",
      "\t\t\"sanitized_subject_line\": \"SqlResults-Coerce-arrays-to-lists-for-VARCHAR.-14260\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SqlResults: Coerce arrays to lists for VARCHAR.  Useful for STRING_TO_MV, which returns VARCHAR at the SQL layer and an ExprEval with String[] at the native layer.  * Fix style.  * Improve test coverage.  * Remove unnecessary throws.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 25 Jun 2023 09:35:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"72cf91fbc0ed9cc2abce91df878ab431678b12f3\",\n",
      "\t\t\"parent\": \"970288067ac2979dff0ddeed97003cd631ad9ee8\",\n",
      "\t\t\"subject\": \"Upgrade Avro to latest version (#14440)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-Avro-to-latest-version-14440\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Upgraded Avro to 1.11.1\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 24 Jun 2023 14:51:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"970288067ac2979dff0ddeed97003cd631ad9ee8\",\n",
      "\t\t\"parent\": \"3d19b748fb9fde49f074a8234e797a46bd894d48\",\n",
      "\t\t\"subject\": \"Fix flaky HttpEmitterConfigTest and ParametrizedUriEmitterConfigTest. (#14481)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-HttpEmitterConfigTest-and-ParametrizedUriEmitterConfigTest.-14481\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Recently, we have seen flakiness in these two tests, apparently due to computations based on Runtime.getRuntime().maxMemory() differing during static initialization and in the actual tests. I can't think of a reason why this would be happening, but anyway, this patch switches the tests to use the statics instead of recomputing Runtime.getRuntime().maxMemory().\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 16:27:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3d19b748fb9fde49f074a8234e797a46bd894d48\",\n",
      "\t\t\"parent\": \"1d6c9657ec362199b80993b68a0bfbe4118ea29a\",\n",
      "\t\t\"subject\": \"SQL OperatorConversions: Introduce.aggregatorBuilder, allow CAST-as-literal. (#14249)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-OperatorConversions-Introduce.aggregatorBuilder-allow-CAST-as-literal.-14249\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL OperatorConversions: Introduce.aggregatorBuilder, allow CAST-as-literal.  Four main changes:  1) Provide aggregatorBuilder, a more consistent way of defining the    SqlAggFunction we need for all of our SQL aggregators. The mechanism    is analogous to the one we already use for SQL functions    (OperatorConversions.operatorBuilder).  2) Allow CASTs of constants to be considered as \\\"literalOperands\\\". This    fixes an issue where various of our operators are defined with    OperandTypes.LITERAL as part of their checkers, which doesn't allow    casts. However, in these cases we generally _do_ want to allow casts.    The important piece is that the value must be reducible to a constant,    not that the SQL text is literally a literal.  3) Update DataSketches SQL aggregators to use the new aggregatorBuilder    functionality. The main user-visible effect here is [2]: the aggregators    would now accept, for example, \\\"CAST(0.99 AS DOUBLE)\\\" as a literal    argument. Other aggregators could be updated in a future patch.  4) Rename \\\"requiredOperands\\\" to \\\"requiredOperandCount\\\", because the    old name was confusing. (It rhymes with \\\"literalOperands\\\" but the    arguments mean different things.)  * Adjust method calls.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 16:25:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d6c9657ec362199b80993b68a0bfbe4118ea29a\",\n",
      "\t\t\"parent\": \"ddd0fc1b855b2d9645d052561a1cf4e89544ed8a\",\n",
      "\t\t\"subject\": \"Clarify compaction docs. (#14225)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clarify-compaction-docs.-14225\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Clarify compaction docs.  The prior wording made it sound like segmentGranularity, queryGranularity, and rollup are always required for granularitySpec. They are not required, but they are strongly recommended. The adjusted wording hopefully does a better job of making that clear.  * Fix link.  * Wording adjustments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 15:24:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ddd0fc1b855b2d9645d052561a1cf4e89544ed8a\",\n",
      "\t\t\"parent\": \"155fde33ff7cccdb7dfd9ece3b3fd8f800f5948f\",\n",
      "\t\t\"subject\": \"S3: Attach SSE key to doesObjectExist calls. (#14290)\",\n",
      "\t\t\"sanitized_subject_line\": \"S3-Attach-SSE-key-to-doesObjectExist-calls.-14290\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* S3: Attach SSE key to doesObjectExist calls.  We did not previously attach the SSE key to the doesObjectExist request, leading to an inconsistency that may cause problems on \\\"S3-compatible\\\" implementations. This patch implements doesObjectExist using similar logic to the S3 client itself, but calls our implementation of getObjectMetadata rather than the S3 client's, ensuring the request is decorated with the SSE key.  * Fix tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 15:23:59 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"155fde33ff7cccdb7dfd9ece3b3fd8f800f5948f\",\n",
      "\t\t\"parent\": \"b6d6e3b827878c61516c302e36f9c0cf189b6248\",\n",
      "\t\t\"subject\": \"Add metrics to SegmentMetadataCache refresh (#14453)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-metrics-to-SegmentMetadataCache-refresh-14453\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"New metrics: - `segment/metadatacache/refresh/time`: time taken to refresh segments per datasource - `segment/metadatacache/refresh/count`: number of segments being refreshed per datasource\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 16:51:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b6d6e3b827878c61516c302e36f9c0cf189b6248\",\n",
      "\t\t\"parent\": \"7e2cf35d7b0485b5fe5abeb021c5811ee812b0c7\",\n",
      "\t\t\"subject\": \"Update start-druid-main.py (#14471)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-start-druid-main.py-14471\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Quick typo correction.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 14:07:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7e2cf35d7b0485b5fe5abeb021c5811ee812b0c7\",\n",
      "\t\t\"parent\": \"9b1779734b0bf59b790742b632a1761413482d03\",\n",
      "\t\t\"subject\": \"Fix compatibility issue with SqlTaskResource (#14466)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-compatibility-issue-with-SqlTaskResource-14466\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix compatibility issue with SqlTaskResource  The DruidException changes broke the response format for errors coming back from the SqlTaskResource, so fix those\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Jun 2023 01:15:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9b1779734b0bf59b790742b632a1761413482d03\",\n",
      "\t\t\"parent\": \"31b9d5695d8db387f6422a4e334b43dba4cee6e1\",\n",
      "\t\t\"subject\": \"fix website mvn build (#14458)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-website-mvn-build-14458\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * fix website mvn build * remove the i18n/en.json file add to gitignore * add spellcheck to mvn test phase\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Jun 2023 12:14:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31b9d5695d8db387f6422a4e334b43dba4cee6e1\",\n",
      "\t\t\"parent\": \"90b8f850a5e948776eaa2e3b1ba56206b96e1e57\",\n",
      "\t\t\"subject\": \"Extend InitializedNullHandlingTest instead of NullHandlingTest (#14467)\",\n",
      "\t\t\"sanitized_subject_line\": \"Extend-InitializedNullHandlingTest-instead-of-NullHandlingTest-14467\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"NullHandlingTest is an actual test, it shouldn't be used as a base class\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Jun 2023 15:01:50 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90b8f850a5e948776eaa2e3b1ba56206b96e1e57\",\n",
      "\t\t\"parent\": \"f8f2fe8b7b06b7b2f08c5d3ae6c99de0a07bcf31\",\n",
      "\t\t\"subject\": \"Allow empty tiered replicants map for load rules (#14432)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-empty-tiered-replicants-map-for-load-rules-14432\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Add property `useDefaultTierForNull` for all load rules. This property determines the default value of `tieredReplicants` if it is not specified. When true, the default is `_default_tier => 2 replicas`. When false, the default is empty, i.e. no replicas on any tier. - Fix validation to allow empty replicants map, so that the segment is used but not loaded anywhere.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Jun 2023 14:44:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f8f2fe8b7b06b7b2f08c5d3ae6c99de0a07bcf31\",\n",
      "\t\t\"parent\": \"1a9aefbb0f6dfe4eff752bf78bf2df221b5944a5\",\n",
      "\t\t\"subject\": \"Skip tests based on files changed in the PR (#14445)\",\n",
      "\t\t\"sanitized_subject_line\": \"Skip-tests-based-on-files-changed-in-the-PR-14445\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Our CI system has a lot of tests. And much of this testing is really unnecessary for most of the PRs. This PR adds some checks so we can skip these expensive tests when we know they are not necessary.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Jun 2023 12:27:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1a9aefbb0f6dfe4eff752bf78bf2df221b5944a5\",\n",
      "\t\t\"parent\": \"92a7febacbe71f13cdfc2e8b976cadff57606a0f\",\n",
      "\t\t\"subject\": \"Move from Jupyter notebook to Jupyter Lab and introduce a notebook folder structure (#14419)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-from-Jupyter-notebook-to-Jupyter-Lab-and-introduce-a-notebook-folder-structure-14419\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sergio Ferragut\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Jun 2023 09:11:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"92a7febacbe71f13cdfc2e8b976cadff57606a0f\",\n",
      "\t\t\"parent\": \"1ea9158a50ecb3c6e928c8bbc85bdade9ab80ed6\",\n",
      "\t\t\"subject\": \"Revert \\\"Add method to authorize native query using authentication result (#14376)\\\" (#14452)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Add-method-to-authorize-native-query-using-authentication-result-14376-14452\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit 8b212e73d75e08db718a1121da0f201fff723cf2.\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Jun 2023 10:42:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1ea9158a50ecb3c6e928c8bbc85bdade9ab80ed6\",\n",
      "\t\t\"parent\": \"f5cc823d0f8acdf660860fcb75db34e38c039d8f\",\n",
      "\t\t\"subject\": \"Added new SysMonitorOshi v0 using Oshi library (#14359)\",\n",
      "\t\t\"sanitized_subject_line\": \"Added-new-SysMonitorOshi-v0-using-Oshi-library-14359\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Added a new monitor SysMonitorOshi to replace SysMonitor. The new monitor has a wider support for different machine architectures including ARM instances. Please switch to SysMonitorOshi as SysMonitor is now deprecated and will be removed in future releases.\",\n",
      "\t\t\"author_name\": \"Hardik Bajaj\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Jun 2023 20:57:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f5cc823d0f8acdf660860fcb75db34e38c039d8f\",\n",
      "\t\t\"parent\": \"09d6c5a45ed9c737e711403a864903dcbbf22830\",\n",
      "\t\t\"subject\": \"Handle nulls in DruidCoordinator.getReplicationFactor (#14447)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-nulls-in-DruidCoordinator.getReplicationFactor-14447\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Jun 2023 15:25:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"09d6c5a45ed9c737e711403a864903dcbbf22830\",\n",
      "\t\t\"parent\": \"50461c3bd58da60ec3cdfbc9a962d4a594ec7c6a\",\n",
      "\t\t\"subject\": \"Decouple logical planning and native query generation in SQL planning (#14232)\",\n",
      "\t\t\"sanitized_subject_line\": \"Decouple-logical-planning-and-native-query-generation-in-SQL-planning-14232\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add a new planning strategy that explicitly decouples the DAG from building the native query.  With this mode, it is Calcite's job to generate a \\\"logical DAG\\\" which is all of the various DruidProject, DruidFilter, etc. nodes.  We then take those nodes and use them to build a native query.  The current commit doesn't pass all tests, but it does work for some things and is a decent starting baseline.\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Jun 2023 16:00:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"50461c3bd58da60ec3cdfbc9a962d4a594ec7c6a\",\n",
      "\t\t\"parent\": \"cfd07a95b7d592a333ca51597e9bbdd68e18a88a\",\n",
      "\t\t\"subject\": \"Enable smartSegmentLoading on the Coordinator (#13197)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-smartSegmentLoading-on-the-Coordinator-13197\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit does a complete revamp of the coordinator to address problem areas: - Stability: Fix several bugs, add capabilities to prioritize and cancel load queue items - Visibility: Add new metrics, improve logs, revamp `CoordinatorRunStats` - Configuration: Add dynamic config `smartSegmentLoading` to automatically set optimal values for all segment loading configs such as `maxSegmentsToMove`, `replicationThrottleLimit` and `maxSegmentsInNodeLoadingQueue`.  Changed classes: - Add `StrategicSegmentAssigner` to make assignment decisions for load, replicate and move - Add `SegmentAction` to distinguish between load, replicate, drop and move operations - Add `SegmentReplicationStatus` to capture current state of replication of all used segments - Add `SegmentLoadingConfig` to contain recomputed dynamic config values - Simplify classes `LoadRule`, `BroadcastRule` - Simplify the `BalancerStrategy` and `CostBalancerStrategy` - Add several new methods to `ServerHolder` to track loaded and queued segments - Refactor `DruidCoordinator`  Impact: - Enable `smartSegmentLoading` by default. With this enabled, none of the following dynamic configs need to be set: `maxSegmentsToMove`, `replicationThrottleLimit`, `maxSegmentsInNodeLoadingQueue`, `useRoundRobinSegmentAssignment`, `emitBalancingStats` and `replicantLifetime`. - Coordinator reports richer metrics and produces cleaner and more informative logs - Coordinator uses an unlimited load queue for all serves, and makes better assignment decisions\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Jun 2023 14:27:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cfd07a95b7d592a333ca51597e9bbdd68e18a88a\",\n",
      "\t\t\"parent\": \"2b676ac7f8e6bafd8369c4dc5c1d800a25c2e7ab\",\n",
      "\t\t\"subject\": \"Errors take 3 (#14004)\",\n",
      "\t\t\"sanitized_subject_line\": \"Errors-take-3-14004\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Introduce DruidException, an exception whose goal in life is to be delivered to a user.  DruidException itself has javadoc on it to describe how it should be used.  This commit both introduces the Exception and adjusts some of the places that are generating exceptions to generate DruidException objects instead, as a way to show how the Exception should be used.  This work was a 3rd iteration on top of work that was started by Paul Rogers.  I don't know if his name will survive the squash-and-merge, so I'm calling it out here and thanking him for starting on this.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Jun 2023 01:11:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b676ac7f8e6bafd8369c4dc5c1d800a25c2e7ab\",\n",
      "\t\t\"parent\": \"128133fadcae97f9c45f9e529c229bef2cc96614\",\n",
      "\t\t\"subject\": \"Quieter KafkaSupervisors in all bundled log4j2.xml. (#14444)\",\n",
      "\t\t\"sanitized_subject_line\": \"Quieter-KafkaSupervisors-in-all-bundled-log4j2.xml.-14444\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Follow-up to #13392, which added this to a single log4j2.xml.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Jun 2023 12:04:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"128133fadcae97f9c45f9e529c229bef2cc96614\",\n",
      "\t\t\"parent\": \"bd07c3dd43428608678e337c7935f237a64f533d\",\n",
      "\t\t\"subject\": \"Add column replication_factor column to sys.segments table (#14403)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-column-replication_factor-column-to-sys.segments-table-14403\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Description: Druid allows a configuration of load rules that may cause a used segment to not be loaded on any historical. This status is not tracked in the sys.segments table on the broker, which makes it difficult to determine if the unavailability of a segment is expected and if we should not wait for it to be loaded on a server after ingestion has finished.  Changes: - Track replication factor in `SegmentReplicantLookup` during evaluation of load rules - Update API `/druid/coordinator/v1metadata/segments` to return replication factor - Add column `replication_factor` to the sys.segments virtual table and populate it in `MetadataSegmentView` - If this column is 0, the segment is not assigned to any historical and will not be loaded.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 18 Jun 2023 10:02:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bd07c3dd43428608678e337c7935f237a64f533d\",\n",
      "\t\t\"parent\": \"04fb75719e7dd76d051dbd4cf8f9c2712b227793\",\n",
      "\t\t\"subject\": \"Don't need to double synchronize on simple map operations (#14435)\",\n",
      "\t\t\"sanitized_subject_line\": \"Don-t-need-to-double-synchronize-on-simple-map-operations-14435\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Don't need to double syncronize on simple map operations  * remove lock\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Jun 2023 17:30:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"04fb75719e7dd76d051dbd4cf8f9c2712b227793\",\n",
      "\t\t\"parent\": \"64af9bfe5bfcbe81e865c7c2bb3b898297b1d76c\",\n",
      "\t\t\"subject\": \"Fail query planning if a `CLUSTERED BY` column contains descending order (#14436)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fail-query-planning-if-a-CLUSTERED-BY-column-contains-descending-order-14436\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Throw ValidationException if CLUSTERED BY column descending order is specified.  - Fails query planning  * Some more tests.  * fixup existing comment  * Update comment  * checkstyle fix: remove unused imports  * Remove InsertCannotOrderByDescendingFault and deprecate the fault in readme.  * move deprecated field to the bottom\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Jun 2023 18:10:12 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"64af9bfe5bfcbe81e865c7c2bb3b898297b1d76c\",\n",
      "\t\t\"parent\": \"359bd63cc99a543e65e9814fdc39718a630316e3\",\n",
      "\t\t\"subject\": \"Add groupId to metrics (#14402)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-groupId-to-metrics-14402\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add group id as a dimension  * Revert changes  * Add to forking task runner  * Add missing metrics  * Fix indenting  * revert metrics  * Fix indentation\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Jun 2023 09:28:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"359bd63cc99a543e65e9814fdc39718a630316e3\",\n",
      "\t\t\"parent\": \"85656a467c66cffbe616dfa5e3646a0ac82b9afc\",\n",
      "\t\t\"subject\": \"allow expression \\\"best effort\\\" type determination to better handle mixed type arrays (#14438)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-expression-best-effort-type-determination-to-better-handle-mixed-type-arrays-14438\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Jun 2023 00:02:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"85656a467c66cffbe616dfa5e3646a0ac82b9afc\",\n",
      "\t\t\"parent\": \"5d76d0ea7468216c2dd64060f2382c85bbd6b717\",\n",
      "\t\t\"subject\": \"MSQ: Load broadcast tables on workers. (#14437)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Load-broadcast-tables-on-workers.-14437\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"They were not previously loaded because supportsQueries was false. This patch sets supportsQueries to true, and clarifies in Task javadocs that supportsQueries can be true for tasks that aren't directly queryable over HTTP.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Jun 2023 12:02:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5d76d0ea7468216c2dd64060f2382c85bbd6b717\",\n",
      "\t\t\"parent\": \"4935f2470a9303e228a274949103ac38f4612c45\",\n",
      "\t\t\"subject\": \"Fix segment/deleted/count metric not being emitted  (#14433)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-segment-deleted-count-metric-not-being-emitted-14433\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix segment/deleted/count metric  * Fix segment/deleted/count metric  * Fix segment/deleted/count metric\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Jun 2023 14:08:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4935f2470a9303e228a274949103ac38f4612c45\",\n",
      "\t\t\"parent\": \"ff5ae4db6c4330b164ad3550c7c9c976699e4ff5\",\n",
      "\t\t\"subject\": \"Limit results generated by SELECT queries in MSQ (#14370)\",\n",
      "\t\t\"sanitized_subject_line\": \"Limit-results-generated-by-SELECT-queries-in-MSQ-14370\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Limit select results in MSQ  * reduce number of files in test  * add truncated flag  * avoid materializing select results to list, use iterable instead  * javadocs\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Jun 2023 13:13:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ff5ae4db6c4330b164ad3550c7c9c976699e4ff5\",\n",
      "\t\t\"parent\": \"ca116cf88639cbe8f4705d43b4730dc550272111\",\n",
      "\t\t\"subject\": \"fix kafka input format reader schema discovery and partial schema discovery (#14421)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-kafka-input-format-reader-schema-discovery-and-partial-schema-discovery-14421\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix kafka input format reader schema discovery and partial schema discovery to actually work right, by re-using dimension filtering logic of MapInputRowParser\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Jun 2023 00:11:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca116cf88639cbe8f4705d43b4730dc550272111\",\n",
      "\t\t\"parent\": \"5314db9f85d9768cc881a054dea33a8616fdedfa\",\n",
      "\t\t\"subject\": \"adjust broker parallel merge to help managed blocking be more well behaved (#14427)\",\n",
      "\t\t\"sanitized_subject_line\": \"adjust-broker-parallel-merge-to-help-managed-blocking-be-more-well-behaved-14427\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Jun 2023 00:10:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5314db9f85d9768cc881a054dea33a8616fdedfa\",\n",
      "\t\t\"parent\": \"e426d370ea974546fdb7fe6f43e44fba015181d7\",\n",
      "\t\t\"subject\": \"Adding the file mapper to handle v2 buffer deserialization (#14429)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-the-file-mapper-to-handle-v2-buffer-deserialization-14429\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Pranav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 19:41:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e426d370ea974546fdb7fe6f43e44fba015181d7\",\n",
      "\t\t\"parent\": \"f6169d437be85d13e402984d1b05b19a99d73e4c\",\n",
      "\t\t\"subject\": \"Start with solo accumulator and empty partition (#14426)\",\n",
      "\t\t\"sanitized_subject_line\": \"Start-with-solo-accumulator-and-empty-partition-14426\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Starting parallel merge with solo accumulator and empty partitions  * shutshown pool in test\",\n",
      "\t\t\"author_name\": \"Pranav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 16:20:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f6169d437be85d13e402984d1b05b19a99d73e4c\",\n",
      "\t\t\"parent\": \"76e70654acdce8213bcf66a9943dfb1374fc329f\",\n",
      "\t\t\"subject\": \"use the latest datasketches-java-4.1.0 (#14430)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-the-latest-datasketches-java-4.1.0-14430\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: AlexanderSaydakov <AlexanderSaydakov@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Alexander Saydakov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 16:03:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"76e70654acdce8213bcf66a9943dfb1374fc329f\",\n",
      "\t\t\"parent\": \"6fd28fc185152deca659168be6631103b8208544\",\n",
      "\t\t\"subject\": \"Fix issues when startup timeout is hit (#14425)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-issues-when-startup-timeout-is-hit-14425\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 11:49:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6fd28fc185152deca659168be6631103b8208544\",\n",
      "\t\t\"parent\": \"8454cc619a846c099de224f6185eb01abe658193\",\n",
      "\t\t\"subject\": \"Web console: split the Ingestion view into two views: Supervisors and Tasks (#14395)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-split-the-Ingestion-view-into-two-views-Supervisors-and-Tasks-14395\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* init split  * don't crash if unable to get running tasks  * update snapshots  * push down state into call  * googies  * simplify  * update e2e tests  * feedback fixes  * update e2e tests  * better icons  * fix test  * adjust colors\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 10:42:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8454cc619a846c099de224f6185eb01abe658193\",\n",
      "\t\t\"parent\": \"be5a6593a946442a57ce9bcd87d977c41b954d33\",\n",
      "\t\t\"subject\": \"auto columns fixes (#14422)\",\n",
      "\t\t\"sanitized_subject_line\": \"auto-columns-fixes-14422\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * auto columns no longer participate in generic 'null column' handling, this was a mistake to try to support and caused ingestion failures due to mismatched ColumnFormat, and will be replaced in the future with nested common format constant column functionality (not in this PR) * fix bugs with auto columns which contain empty objects, empty arrays, or primitive types mixed with either of these empty constructs * fix bug with bound filter when upper is null equivalent but is strict\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Jun 2023 08:57:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"be5a6593a946442a57ce9bcd87d977c41b954d33\",\n",
      "\t\t\"parent\": \"b8495d45a1dfb398e16dd8fee42984b39e5fb401\",\n",
      "\t\t\"subject\": \"Reset `RuntimeInfo` to fix flaky test `ParametrizedUriEmitterConfigTest`. (#14405)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reset-RuntimeInfo-to-fix-flaky-test-ParametrizedUriEmitterConfigTest-.-14405\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add injector so JVM settings are correctly set up and bound for the test.  * Add VisibleForTesting IDE annotation.  * spacing\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Jun 2023 18:07:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b8495d45a1dfb398e16dd8fee42984b39e5fb401\",\n",
      "\t\t\"parent\": \"61120dc49a2c7a94f7421c9cbf68bfe88844131f\",\n",
      "\t\t\"subject\": \"Expose Druid functions in `INFORMATION_SCHEMA.ROUTINES` table. (#14378)\",\n",
      "\t\t\"sanitized_subject_line\": \"Expose-Druid-functions-in-INFORMATION_SCHEMA.ROUTINES-table.-14378\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add INFORMATION_SCHEMA.ROUTINES to expose Druid operators and functions.  * checkstyle  * remove IS_DETERMISITIC.  * test  * cleanup test  * remove logs and simplify  * fixup unit test  * Add docs for INFORMATION_SCHEMA.ROUTINES table.  * Update test and add another SQL query.  * add stuff to .spelling and checkstyle fix.  * Add more tests for custom operators.  * checkstyle and comment.  * Some naming cleanup.  * Add FUNCTION_ID  * The different Calcite function syntax enums get translated to FUNCTION  * Update docs.  * Cleanup markdown table.  * fixup test.  * fixup intellij inspection  * Review comment: nullable column; add a function to determine function syntax.  * More tests; add non-function syntax operators.  * More unit tests. Also add a separate test for DruidOperatorTable.  * actually just validate non-zero count.  * switch up the order  * checkstyle fixes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Jun 2023 15:44:04 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"61120dc49a2c7a94f7421c9cbf68bfe88844131f\",\n",
      "\t\t\"parent\": \"66c3cc139190ed74e1bcc5fdccfd2370ebc9e3ea\",\n",
      "\t\t\"subject\": \"fix Kafka input format to throw ParseException if timestamp is missing (#14413)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-Kafka-input-format-to-throw-ParseException-if-timestamp-is-missing-14413\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Jun 2023 09:00:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"66c3cc139190ed74e1bcc5fdccfd2370ebc9e3ea\",\n",
      "\t\t\"parent\": \"1c76ebad3b63069f8c3e5b422b945212badab196\",\n",
      "\t\t\"subject\": \"Handle unparseable SupervisorSpec in metadata store (#14382)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-unparseable-SupervisorSpec-in-metadata-store-14382\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Skip a supervisor spec entry which cannot be deserialised into a `SupervisorSpec` object. - Log an error for the unparseable spec\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Jun 2023 08:02:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c76ebad3b63069f8c3e5b422b945212badab196\",\n",
      "\t\t\"parent\": \"326f2c5020d4a9a02128efc160b49fbc935fc6f2\",\n",
      "\t\t\"subject\": \"Minor doc updates. (#14409)\",\n",
      "\t\t\"sanitized_subject_line\": \"Minor-doc-updates.-14409\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Jun 2023 15:24:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"326f2c5020d4a9a02128efc160b49fbc935fc6f2\",\n",
      "\t\t\"parent\": \"8b212e73d75e08db718a1121da0f201fff723cf2\",\n",
      "\t\t\"subject\": \"Add more statement attributes to explain plan result. (#14391)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-more-statement-attributes-to-explain-plan-result.-14391\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR adds the following to the ATTRIBUTES column in the explain plan output: - partitionedBy - clusteredBy - replaceTimeChunks  This PR leverages the work done in #14074, which added a new column ATTRIBUTES to encapsulate all the statement-related attributes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Jun 2023 19:18:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8b212e73d75e08db718a1121da0f201fff723cf2\",\n",
      "\t\t\"parent\": \"b5f45832b1a151814589c5ccf308137d6802f122\",\n",
      "\t\t\"subject\": \"Add method to authorize native query using authentication result (#14376)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-method-to-authorize-native-query-using-authentication-result-14376\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Jun 2023 11:06:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b5f45832b1a151814589c5ccf308137d6802f122\",\n",
      "\t\t\"parent\": \"267cbac6ff6bac1001f72f517f1d27ded9c4ca75\",\n",
      "\t\t\"subject\": \"Add 'Flaky test' issue template (#14394)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Flaky-test-issue-template-14394\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add 'Flaky test' issue template  * Update flaky_test.md\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 11 Jun 2023 19:02:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"267cbac6ff6bac1001f72f517f1d27ded9c4ca75\",\n",
      "\t\t\"parent\": \"6e158704cb058e7c50db025eef1afc796ca80780\",\n",
      "\t\t\"subject\": \"Add logs for deleting files using storage connector (#14350)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-logs-for-deleting-files-using-storage-connector-14350\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add logs for deleting files using storage connector  * Address review comments  * Update log message format\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 11 Jun 2023 21:24:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6e158704cb058e7c50db025eef1afc796ca80780\",\n",
      "\t\t\"parent\": \"31c386ee1bb7f87a661e8f9ff65609c1e4590fd4\",\n",
      "\t\t\"subject\": \"Do not retry INSERT task into metadata if max_allowed_packet limit is violated (#14271)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-retry-INSERT-task-into-metadata-if-max_allowed_packet-limit-is-violated-14271\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes - Add a `DruidException` which contains a user-facing error message, HTTP response code - Make `EntryExistsException` extend `DruidException` - If metadata store max_allowed_packet limit is violated while inserting a new task, throw `DruidException` with response code 400 (bad request) to prevent retries - Add `SQLMetadataConnector.isRootCausePacketTooBigException` with impl for MySQL \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 10 Jun 2023 12:15:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31c386ee1bb7f87a661e8f9ff65609c1e4590fd4\",\n",
      "\t\t\"parent\": \"4d146ca87dfe1b44010b35efb30b091c68e303f7\",\n",
      "\t\t\"subject\": \"Fixup typo and java code snippets in JDBC docs. (#14399)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixup-typo-and-java-code-snippets-in-JDBC-docs.-14399\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Jun 2023 12:39:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4d146ca87dfe1b44010b35efb30b091c68e303f7\",\n",
      "\t\t\"parent\": \"23c2dcaf8d294b4cba9d225cae41cb9148131fd6\",\n",
      "\t\t\"subject\": \"Upgrades the React dependency to v18 (#14380)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrades-the-React-dependency-to-v18-14380\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use react 18  * Remove deprecated usage of Toaster  * Make AppToaster lazy  * Update testing-library, snapshots  * Licenses  * Document lazy-init, add license header\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Jun 2023 12:09:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"23c2dcaf8d294b4cba9d225cae41cb9148131fd6\",\n",
      "\t\t\"parent\": \"5eb255656606227f0412a42d2ae12a590e432a06\",\n",
      "\t\t\"subject\": \"Add NullHandling module initialization for `LookupDimensionSpecTest` (#14393)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-NullHandling-module-initialization-for-LookupDimensionSpecTest-14393\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Jun 2023 09:07:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5eb255656606227f0412a42d2ae12a590e432a06\",\n",
      "\t\t\"parent\": \"87149d5975febdffe0509dd095dfb02f9deedfb7\",\n",
      "\t\t\"subject\": \"Add workflow links to README to jump into detailed pages (#14383)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-workflow-links-to-README-to-jump-into-detailed-pages-14383\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Jun 2023 08:31:50 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"87149d5975febdffe0509dd095dfb02f9deedfb7\",\n",
      "\t\t\"parent\": \"ff577a69a584008c4d31fce37da0d4fc2f291ae4\",\n",
      "\t\t\"subject\": \"Remove AbstractIndex (#14388)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-AbstractIndex-14388\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The class apparently only exists to add a toString() method to Indexes, which basically just crashes any debugger on any meaningfully sized index.  It's a pointless abstract class that basically only causes pain.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Jun 2023 19:52:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ff577a69a584008c4d31fce37da0d4fc2f291ae4\",\n",
      "\t\t\"parent\": \"12e8fa5c97a37ca7636bafda17a0cbb85ff0747f\",\n",
      "\t\t\"subject\": \"doc: escape tags in markdown in prepration for docusaurus2 (#14379)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-escape-tags-in-markdown-in-prepration-for-docusaurus2-14379\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Jun 2023 11:26:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"12e8fa5c97a37ca7636bafda17a0cbb85ff0747f\",\n",
      "\t\t\"parent\": \"6a4cbab4b8a55efa482aacc0399353ac5589e5e1\",\n",
      "\t\t\"subject\": \"Prevent coordinator from getting stuck if leadership changes during coordinator run (#14385)\",\n",
      "\t\t\"sanitized_subject_line\": \"Prevent-coordinator-from-getting-stuck-if-leadership-changes-during-coordinator-run-14385\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Add a timeout of 1 minute to resultFuture.get() in `CostBalancerStrategy.chooseBestServer`. 1 minute is the typical time for a full coordinator run and is more than enough time for cost computations of a single segment. - Raise an alert if an exception is encountered while computing costs and if the executor has not been shutdown. This is because a shutdown is intentional and does not require an alert.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Jun 2023 15:29:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6a4cbab4b8a55efa482aacc0399353ac5589e5e1\",\n",
      "\t\t\"parent\": \"6370769cbf7e1d5f7f7c55e7963babd03e47a69d\",\n",
      "\t\t\"subject\": \"Upgrade parquet-mr version (#14070)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-parquet-mr-version-14070\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Upgrade parquet version  * Move parquet version to hadoop3  * Fix license  * Exclude audience annotations\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Jun 2023 08:54:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6370769cbf7e1d5f7f7c55e7963babd03e47a69d\",\n",
      "\t\t\"parent\": \"01b22ca0221b2bfa75d98a2605f97fe130dfac15\",\n",
      "\t\t\"subject\": \"Fix documentation for druid.query.scheduler.numThreads. (#14381)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-documentation-for-druid.query.scheduler.numThreads.-14381\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix documentation for druid.query.scheduler.numThreads. \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Jun 2023 14:48:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"01b22ca0221b2bfa75d98a2605f97fe130dfac15\",\n",
      "\t\t\"parent\": \"2d258a95ad7e63191ae4d40a6d61f045df9f09fa\",\n",
      "\t\t\"subject\": \"Hll Sketch and Theta sketch estimate can now be used as an expression (#14312)\",\n",
      "\t\t\"sanitized_subject_line\": \"Hll-Sketch-and-Theta-sketch-estimate-can-now-be-used-as-an-expression-14312\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Hll Sketch estimate can now be used as an expression * Theta sketch estimate now can be used as an expression\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Jun 2023 20:14:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d258a95ad7e63191ae4d40a6d61f045df9f09fa\",\n",
      "\t\t\"parent\": \"5da601c47e8ec49a1413691acde7f56f16c27127\",\n",
      "\t\t\"subject\": \"Fix `EARLIEST_BY`/`LATEST_BY` signature and include function name in signature. (#14352)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-EARLIEST_BY-LATEST_BY-signature-and-include-function-name-in-signature.-14352\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix EarliestLatestBySqlAggregator signature; Include function name for all signatures.  * Single quote function signatures, space between args and remove \\n.  * fixup UT assertion\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Jun 2023 09:41:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5da601c47e8ec49a1413691acde7f56f16c27127\",\n",
      "\t\t\"parent\": \"cfc2a8d2869dd9899d483f758d4edbf44cb59d85\",\n",
      "\t\t\"subject\": \"fix npe (#14369)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-npe-14369\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Jun 2023 17:01:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cfc2a8d2869dd9899d483f758d4edbf44cb59d85\",\n",
      "\t\t\"parent\": \"a0d49baad6a23f58b6591f78358baf2887339364\",\n",
      "\t\t\"subject\": \"Switch to @blueprint/datetime2 (#14371)\",\n",
      "\t\t\"sanitized_subject_line\": \"Switch-to-blueprint-datetime2-14371\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump blueprint packages  * Switch to datetime2 components  * Update licenses  * Update snapshots\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Jun 2023 22:18:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a0d49baad6a23f58b6591f78358baf2887339364\",\n",
      "\t\t\"parent\": \"c14e54cf934a57dccd71382cd7c64d24dfab83c1\",\n",
      "\t\t\"subject\": \"MSQ: Fix issue with rollup ingestion and aggregators with multiple names. (#14367)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Fix-issue-with-rollup-ingestion-and-aggregators-with-multiple-names.-14367\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The same aggregator can have two output names for a SQL like:    INSERT INTO foo   SELECT x, COUNT(*) AS y, COUNT(*) AS z   FROM t   GROUP BY 1   PARTITIONED BY ALL  In this case, the SQL planner will create a query with a single \\\"count\\\" aggregator mapped to output names \\\"y\\\" and \\\"z\\\". The prior MSQ code did not properly handle this case, instead throwing an error like:    Expected single output for query column[a0] but got [[1, 2]]\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Jun 2023 10:28:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c14e54cf934a57dccd71382cd7c64d24dfab83c1\",\n",
      "\t\t\"parent\": \"49c056af17bcec8fec7d84f4bdd6eddd2e6726f6\",\n",
      "\t\t\"subject\": \"Remove context params from class component ctors (#14366)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-context-params-from-class-component-ctors-14366\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Jun 2023 11:15:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"49c056af17bcec8fec7d84f4bdd6eddd2e6726f6\",\n",
      "\t\t\"parent\": \"8e4f003f02174a3329e674e971a29ea9e9dd4bac\",\n",
      "\t\t\"subject\": \"docs: add basic contributor guide for docs (#14365)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-basic-contributor-guide-for-docs-14365\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Jun 2023 10:53:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8e4f003f02174a3329e674e971a29ea9e9dd4bac\",\n",
      "\t\t\"parent\": \"139156cf6bd7cf28978b2aae6489ebfe6de020f7\",\n",
      "\t\t\"subject\": \"Fix flaky Revised ITs failures on GHA runners (#14348)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-Revised-ITs-failures-on-GHA-runners-14348\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix read timed out failures and remove containers before test  * remove containers before loading images  * add labels to IT docker containers, download stable minio docker image release instead of latest\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Jun 2023 18:58:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"139156cf6bd7cf28978b2aae6489ebfe6de020f7\",\n",
      "\t\t\"parent\": \"7fd215b2e76287e6063928a9e3267f842553c577\",\n",
      "\t\t\"subject\": \"Reduce the spam in broker logs (#14368)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-the-spam-in-broker-logs-14368\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Jun 2023 18:56:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7fd215b2e76287e6063928a9e3267f842553c577\",\n",
      "\t\t\"parent\": \"4ff6026d30e4da53dc0e37bc2279d9e030773787\",\n",
      "\t\t\"subject\": \"Document storeCompactionState (#14354)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-storeCompactionState-14354\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Jun 2023 11:09:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ff6026d30e4da53dc0e37bc2279d9e030773787\",\n",
      "\t\t\"parent\": \"45014bd5b458851e2a8601101a4fa818cebb3004\",\n",
      "\t\t\"subject\": \"Adding SegmentMetadataEvent and publishing them via KafkaEmitter (#14281)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-SegmentMetadataEvent-and-publishing-them-via-KafkaEmitter-14281\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In this PR, we are enhancing KafkaEmitter, to emit metadata about published segments (SegmentMetadataEvent) into a Kafka topic. This segment metadata information that gets published into Kafka, can be used by any other downstream services to query Druid intelligently based on the segments published. The segment metadata gets published into kafka topic in json string format similar to other events.\",\n",
      "\t\t\"author_name\": \"Harini Rajendran\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Jun 2023 21:28:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45014bd5b458851e2a8601101a4fa818cebb3004\",\n",
      "\t\t\"parent\": \"b482fda503be3ebfe9c537c24efb10cf2fa3efb0\",\n",
      "\t\t\"subject\": \"Handle all types of exceptions when initializing input source in sampler API (#14355)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-all-types-of-exceptions-when-initializing-input-source-in-sampler-API-14355\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The sampler API returns a `400 bad request` response if it encounters a `SamplerException`. Otherwise, it returns a generic `500 Internal server error` response, with the message \\\"The RuntimeException could not be mapped to a response, re-throwing to the HTTP container\\\".  This commit updates `RecordSupplierInputSource` to handle all types of exceptions instead of just `InterruptedException`and wrap them in a `SamplerException` so that the actual error is propagated back to the user.\",\n",
      "\t\t\"author_name\": \"Andreas Maechler\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Jun 2023 19:43:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b482fda503be3ebfe9c537c24efb10cf2fa3efb0\",\n",
      "\t\t\"parent\": \"55effd92cfe80c23e1005e70a86da585764a7771\",\n",
      "\t\t\"subject\": \"Ignore misc.xml (#14362)\",\n",
      "\t\t\"sanitized_subject_line\": \"Ignore-misc.xml-14362\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Jun 2023 12:00:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"55effd92cfe80c23e1005e70a86da585764a7771\",\n",
      "\t\t\"parent\": \"70952c097724aad11a7d5fa9d71a30fb605207b9\",\n",
      "\t\t\"subject\": \"Docs: Typo and language cleanup in Kinesis ingestion docs (#14356)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Typo-and-language-cleanup-in-Kinesis-ingestion-docs-14356\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Andreas Maechler\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Jun 2023 08:18:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"70952c097724aad11a7d5fa9d71a30fb605207b9\",\n",
      "\t\t\"parent\": \"04a82da63d12d400f37d759450851e1034b9c406\",\n",
      "\t\t\"subject\": \"docs: add sql array functions to nav (#14361)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-sql-array-functions-to-nav-14361\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs: add sql array functions to nav  * fix typo  * add sql array functions to list  * fix spelling errors\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Jun 2023 16:45:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"04a82da63d12d400f37d759450851e1034b9c406\",\n",
      "\t\t\"parent\": \"e75fb8e8e374f3d66e0f969c62216f64ea2d367e\",\n",
      "\t\t\"subject\": \"Input source security fixes (#14266)\",\n",
      "\t\t\"sanitized_subject_line\": \"Input-source-security-fixes-14266\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"It was found that several supported tasks / input sources did not have implementations for the methods used by the input source security feature, causing these tasks and input sources to fail when used with this feature. This pr adds the needed missing implementations. Also securing the sampling endpoint with input source security, when enabled.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Jun 2023 16:37:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e75fb8e8e374f3d66e0f969c62216f64ea2d367e\",\n",
      "\t\t\"parent\": \"d60290e76df6eb350cad0880750f258c9f9aa708\",\n",
      "\t\t\"subject\": \"Account for data format and compression in MSQ auto taskAssignment (#14307)\",\n",
      "\t\t\"sanitized_subject_line\": \"Account-for-data-format-and-compression-in-MSQ-auto-taskAssignment-14307\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  This change allows for consideration of the input format and compression  when computing how to split the input files among available tasks, in MSQ ingestion, when considering the value of the  `maxInputBytesPerWorker` query context parameter. This query parameter allows users to control the maximum number of bytes, with granularity of input file / object, that ingestion tasks will be assigned to ingest. With this change, this context parameter now denotes the estimated weighted size in bytes of the input to split on, with consideration for input format and compression format, rather than the actual file size, reported by the file system.  We assume uncompressed newline delimited json as a baseline, with scaling factor of `1`. This means that when computing the byte weight that a file has towards the input splitting, we take the file size as is, if uncompressed json, 1:1. It was found during testing that gzip compressed json, and parquet, has scale factors of `4` and `8` respectively, meaning that each byte of data is weighted 4x and 8x respectively, when computing input splits. This weighted byte scaling is only considered for MSQ ingestion that uses either LocalInputSource or CloudObjectInputSource at the moment. The default value of the `maxInputBytesPerWorker` query context parameter has been updated from 10 GiB, to 512 MiB\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Jun 2023 12:53:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d60290e76df6eb350cad0880750f258c9f9aa708\",\n",
      "\t\t\"parent\": \"2da84de87fb9c31fb351c0ef8cc6f9b3c0bd1c9a\",\n",
      "\t\t\"subject\": \"Remove extraneous apostrophe in the native batch docs (#14358)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-extraneous-apostrophe-in-the-native-batch-docs-14358\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Jun 2023 08:57:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2da84de87fb9c31fb351c0ef8cc6f9b3c0bd1c9a\",\n",
      "\t\t\"parent\": \"2012a6bd8e2102aa03328381331f64fb7a9e5d39\",\n",
      "\t\t\"subject\": \"docs: remove the note about segments (#14161)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-remove-the-note-about-segments-14161\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 31 May 2023 16:37:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2012a6bd8e2102aa03328381331f64fb7a9e5d39\",\n",
      "\t\t\"parent\": \"37cb76d54519db1d059d11b3524c43cd7cd10e52\",\n",
      "\t\t\"subject\": \"Docs: fix broken link to Python API jupyter notebook (#14332)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-fix-broken-link-to-Python-API-jupyter-notebook-14332\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 31 May 2023 08:12:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37cb76d54519db1d059d11b3524c43cd7cd10e52\",\n",
      "\t\t\"parent\": \"c244c3de5325e479a86c302e5dc8bbdd881c1e74\",\n",
      "\t\t\"subject\": \"fixes dataSourceName varaible ref (#14340)\",\n",
      "\t\t\"sanitized_subject_line\": \"fixes-dataSourceName-varaible-ref-14340\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 13:15:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c244c3de5325e479a86c302e5dc8bbdd881c1e74\",\n",
      "\t\t\"parent\": \"70c06fc0e129a2a9fc684141bcd8671f4b70f3c3\",\n",
      "\t\t\"subject\": \"fix hdfs initialization issue (#14276)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-hdfs-initialization-issue-14276\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix hdfs initialization issue  * add PR  * remove conf settings  * Improve comments  * move hdfs storage validation to start handler  * restore exception\",\n",
      "\t\t\"author_name\": \"panhongan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 12:41:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"70c06fc0e129a2a9fc684141bcd8671f4b70f3c3\",\n",
      "\t\t\"parent\": \"2086ff88bcdbfdba507d52d78bd3c7605beab280\",\n",
      "\t\t\"subject\": \"Advise against using WEEK granularity for Native Batch and MSQ (#14341)\",\n",
      "\t\t\"sanitized_subject_line\": \"Advise-against-using-WEEK-granularity-for-Native-Batch-and-MSQ-14341\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 11:40:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2086ff88bcdbfdba507d52d78bd3c7605beab280\",\n",
      "\t\t\"parent\": \"1ac5544da7867bce784c9aeec3a67879a6b2f100\",\n",
      "\t\t\"subject\": \"Add logging for task stop operations (#14192)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-logging-for-task-stop-operations-14192\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Log more details when task cannot be stopped for various reasons \",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 18:50:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1ac5544da7867bce784c9aeec3a67879a6b2f100\",\n",
      "\t\t\"parent\": \"5fd3e01ef013fff6316344709c7ba524b8320132\",\n",
      "\t\t\"subject\": \"Updated default value of maxTotalRows to reflect the value in the code (#14298)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updated-default-value-of-maxTotalRows-to-reflect-the-value-in-the-code-14298\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Pramod Immaneni\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 14:41:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5fd3e01ef013fff6316344709c7ba524b8320132\",\n",
      "\t\t\"parent\": \"d4cacebf79c9795aa36b5e0776df44ed735b93d0\",\n",
      "\t\t\"subject\": \"More specific exclusions in the `examples` folder. (#14347)\",\n",
      "\t\t\"sanitized_subject_line\": \"More-specific-exclusions-in-the-examples-folder.-14347\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR changes how we skip java UT and ITs with changes in the examples folder. After this change, any Markdown files within the examples folder and jupyter-notebooks directory will be excluded. The rationale behind these more specific exclusions is that some ITs use json files checked in examples, so we want to trigger the full workflow for all other changes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 12:01:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4cacebf79c9795aa36b5e0776df44ed735b93d0\",\n",
      "\t\t\"parent\": \"8091c6a547eaa812a0ff09bbb0c49f16f9ebf19c\",\n",
      "\t\t\"subject\": \"Add tests for CostBalancerStrategy (#14230)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-tests-for-CostBalancerStrategy-14230\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - `CostBalancerStrategyTest`   - Focus on verification of cost computations rather than choosing servers in this test   - Add new tests `testComputeCost` and `testJointSegmentsCost`   - Add tests to demonstrate that with a long enough interval gap, all costs become negligible   - Retain `testIntervalCost` and `testIntervalCostAdditivity`   - Remove redundant tests such as `testStrategyMultiThreaded`, `testStrategySingleThreaded`as verification of this behaviour is better suited to `BalancingStrategiesTest`. - `CostBalancerStrategyBenchmark`   - Remove usage of static method from `CostBalancerStrategyTest`   - Explicitly setup cluster and segments to use for benchmarking\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 08:52:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8091c6a547eaa812a0ff09bbb0c49f16f9ebf19c\",\n",
      "\t\t\"parent\": \"0e51c2702a20a1c9318446a35db01514563abbf0\",\n",
      "\t\t\"subject\": \"Update default values in CoordinatorDynamicConfig (#14269)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-default-values-in-CoordinatorDynamicConfig-14269\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The defaults of the following config values in the `CoordinatorDynamicConfig` are being updated.  1. `maxSegmentsInNodeLoadingQueue = 500` (previous = 100) 2. `replicationThrottleLimit = 500` (previous = 10) Rationale: With round-robin segment assignment now being the default assignment technique, the Coordinator can assign a large number of under-replicated/unavailable segments very quickly, without getting stuck in `RunRules` duty due to very slow strategy-based cost computations.  3. `maxSegmentsToMove = 100` (previous = 5) Rationale: A very low value (say 5) is ineffective in balancing especially if there are many segments to balance. A very large value can cause excessive moves, which has these disadvantages: - Load of moving segments competing with load of unavailable/under-replicated segments - Unnecessary network costs due to constant download and delete of segments  These defaults will be revisited after #13197 is merged.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 May 2023 08:51:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0e51c2702a20a1c9318446a35db01514563abbf0\",\n",
      "\t\t\"parent\": \"914c006b8e8a4354989170ae72e9578691158966\",\n",
      "\t\t\"subject\": \"update operations per run (#14325)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-operations-per-run-14325\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 May 2023 14:05:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"914c006b8e8a4354989170ae72e9578691158966\",\n",
      "\t\t\"parent\": \"4131c0df133a425ea74b121cecc6c24de66784de\",\n",
      "\t\t\"subject\": \"increase middlemanager heap server size in tests (#14345)\",\n",
      "\t\t\"sanitized_subject_line\": \"increase-middlemanager-heap-server-size-in-tests-14345\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 May 2023 10:45:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4131c0df133a425ea74b121cecc6c24de66784de\",\n",
      "\t\t\"parent\": \"8d256e35b4b67abafd9b923c973bbdb6d68ead2e\",\n",
      "\t\t\"subject\": \"use the latest datasketches-java-4.0.0 (#14334)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-the-latest-datasketches-java-4.0.0-14334\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use the latest datasketches-java-4.0.0  * updated versions of datasketches  * adjusted expectation  * fixed the expectations  ---------  Co-authored-by: AlexanderSaydakov <AlexanderSaydakov@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Alexander Saydakov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 27 May 2023 22:19:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8d256e35b4b67abafd9b923c973bbdb6d68ead2e\",\n",
      "\t\t\"parent\": \"0cde3a8b522fbd5c09222069ac51689a614b8ec2\",\n",
      "\t\t\"subject\": \"MSQ ignores tombstone segments for downloads. (#14342)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-ignores-tombstone-segments-for-downloads.-14342\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 27 May 2023 14:21:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0cde3a8b522fbd5c09222069ac51689a614b8ec2\",\n",
      "\t\t\"parent\": \"1873fca6c73f816db45482eda3e59abc6fd4e8f5\",\n",
      "\t\t\"subject\": \"Fix regression in batch segment allocation (#14337)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-regression-in-batch-segment-allocation-14337\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve batch segment allocation logs  * Fix batch seg alloc regression  * Fix logs  * Fix logs  * Fix tests and logs\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 May 2023 22:34:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1873fca6c73f816db45482eda3e59abc6fd4e8f5\",\n",
      "\t\t\"parent\": \"88831b1dd0fd2afef28aa2d90b91e4464aebd92f\",\n",
      "\t\t\"subject\": \"Web console: update DQT to latest version and fix bigint crash (#14318)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-update-DQT-to-latest-version-and-fix-bigint-crash-14318\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update dqt  * don't crash on bigint values  * better submit experiance  * bump to an even version\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 May 2023 17:40:45 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"88831b1dd0fd2afef28aa2d90b91e4464aebd92f\",\n",
      "\t\t\"parent\": \"4096f51f0b29b3b4787ac12aa1a7493ac216c6c5\",\n",
      "\t\t\"subject\": \"Docs: Updates docker compose to turn off kraft which causes errors (#14335)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Updates-docker-compose-to-turn-off-kraft-which-causes-errors-14335\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 May 2023 09:33:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4096f51f0b29b3b4787ac12aa1a7493ac216c6c5\",\n",
      "\t\t\"parent\": \"22ba457d2998caafd9d52cdb781786b385a36016\",\n",
      "\t\t\"subject\": \"add configurable ColumnTypeMergePolicy to SegmentMetadataCache (#14319)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-configurable-ColumnTypeMergePolicy-to-SegmentMetadataCache-14319\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR adds a new interface to control how SegmentMetadataCache chooses ColumnType when faced with differences between segments for SQL schemas which are computed, exposed as druid.sql.planner.metadataColumnTypeMergePolicy and adds a new 'least restrictive type' mode to allow choosing the type that data across all segments can best be coerced into and sets this as the default behavior.  This is a behavior change around when segment driven schema migrations take effect for the SQL schema. With latestInterval, the SQL schema will be updated as soon as the first job with the new schema has published segments, while using leastRestrictive, the schema will only be updated once all segments are reindexed to the new type. The benefit of leastRestrictive is that it eliminates a bunch of type coercion errors that can happen in SQL when types are varied across segments with latestInterval because the newest type is not able to correctly represent older data, such as if the segments have a mix of ARRAY and number types, or any other combinations that lead to odd query plans.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 May 2023 20:32:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"22ba457d2998caafd9d52cdb781786b385a36016\",\n",
      "\t\t\"parent\": \"338bdb35ea19b495bc6eb587ab99978edb16ce46\",\n",
      "\t\t\"subject\": \"Expr getCacheKey now delegates to children (#14287)\",\n",
      "\t\t\"sanitized_subject_line\": \"Expr-getCacheKey-now-delegates-to-children-14287\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Expr getCacheKey now delegates to children  * Removed the LOOKUP_EXPR_CACHE_KEY as we do not need it  * Adding an unit test  * Update processing/src/main/java/org/apache/druid/math/expr/Expr.java  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  ---------  Co-authored-by: Clint Wylie <cjwylie@gmail.com>\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 May 2023 14:49:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"338bdb35ea19b495bc6eb587ab99978edb16ce46\",\n",
      "\t\t\"parent\": \"a5e04d95a47a78dfac54954c1e47727400991797\",\n",
      "\t\t\"subject\": \"Return `RESOURCES` in `EXPLAIN PLAN` as an ordered collection (#14323)\",\n",
      "\t\t\"sanitized_subject_line\": \"Return-RESOURCES-in-EXPLAIN-PLAN-as-an-ordered-collection-14323\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make resources an ordered collection so it's deterministic.  * test cleanup  * fixup docs.  * Replace deprecated ObjectNode#put() calls with ObjectNode#set().\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 May 2023 00:55:00 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a5e04d95a47a78dfac54954c1e47727400991797\",\n",
      "\t\t\"parent\": \"6b3a6113c4f6f9e460152b9319b42e7c9d1faaa7\",\n",
      "\t\t\"subject\": \"Add `TYPE_NAME` to the complex serde classes and replace the hardcoded names. (#14317)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-TYPE_NAME-to-the-complex-serde-classes-and-replace-the-hardcoded-names.-14317\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add TYPE_NAME to the serde classes and reuse them instead of hardcoded strings.  * Static check fixes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 May 2023 00:54:47 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6b3a6113c4f6f9e460152b9319b42e7c9d1faaa7\",\n",
      "\t\t\"parent\": \"3f6610aaf1a7cd3c263e535d7550e5271bc21abc\",\n",
      "\t\t\"subject\": \"Doc: List supported values for Kafka `headerFormat` (#14316)\",\n",
      "\t\t\"sanitized_subject_line\": \"Doc-List-supported-values-for-Kafka-headerFormat-14316\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 May 2023 15:41:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3f6610aaf1a7cd3c263e535d7550e5271bc21abc\",\n",
      "\t\t\"parent\": \"cb65135b9925711d200716a9e27a3b638db2002f\",\n",
      "\t\t\"subject\": \"fixed wording in OSS query laning doc (#14324)\",\n",
      "\t\t\"sanitized_subject_line\": \"fixed-wording-in-OSS-query-laning-doc-14324\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Nhi Pham <nhipham@Nhi-Pham.local>\",\n",
      "\t\t\"author_name\": \"Nhi Pham\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 May 2023 11:58:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb65135b9925711d200716a9e27a3b638db2002f\",\n",
      "\t\t\"parent\": \"36a084e0212a6934f580a45ae77e8b4e6e47ae86\",\n",
      "\t\t\"subject\": \"Fix log streaming (#14285)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-log-streaming-14285\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix log streaming  * Add watch log  * Add unit tests  * long running client  * singleton client  * Remove accidental close\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 May 2023 11:19:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36a084e0212a6934f580a45ae77e8b4e6e47ae86\",\n",
      "\t\t\"parent\": \"9faf9ecf2081422bd2e8f46d795a1a2a01bfa7a7\",\n",
      "\t\t\"subject\": \"Fix GHA workflows naming & Run ITs if UTs fail on coverage (#14158)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-GHA-workflows-naming-Run-ITs-if-UTs-fail-on-coverage-14158\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, there is no way to run ITs if unit-tests fail on coverage. This PR allows Revised, Standard ITs to run even when unit-tests fail on coverage errors, still failing the workflow. This PR also fixes existing GHA workflow naming.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 May 2023 11:44:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9faf9ecf2081422bd2e8f46d795a1a2a01bfa7a7\",\n",
      "\t\t\"parent\": \"269137c6828c5a2a4f7308c33d239c2c019c87b7\",\n",
      "\t\t\"subject\": \"docs: add line about write datasource perm for overlord api (#14114)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-line-about-write-datasource-perm-for-overlord-api-14114\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 May 2023 14:56:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"269137c6828c5a2a4f7308c33d239c2c019c87b7\",\n",
      "\t\t\"parent\": \"7f66fd049b25d2524bfc16527a620037ff110b25\",\n",
      "\t\t\"subject\": \"Update Ingestion section (#14023)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Ingestion-section-14023\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Victoria Lim <lim.t.victoria@gmail.com> \",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 May 2023 09:42:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f66fd049b25d2524bfc16527a620037ff110b25\",\n",
      "\t\t\"parent\": \"e9fed1445f2124b94fdba5976a90b7b52cd5baff\",\n",
      "\t\t\"subject\": \"don't show merged stats until needed (#14311)\",\n",
      "\t\t\"sanitized_subject_line\": \"don-t-show-merged-stats-until-needed-14311\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 May 2023 20:32:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e9fed1445f2124b94fdba5976a90b7b52cd5baff\",\n",
      "\t\t\"parent\": \"51f722b7f1a5f30430c7d56d65936e21dfa188e1\",\n",
      "\t\t\"subject\": \"Revert PreResponseAuthorizationCheckFilter (#13813)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-PreResponseAuthorizationCheckFilter-13813\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Make it permissive like it used to be again so that we ensure that validation errors make it out.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 May 2023 18:16:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"51f722b7f1a5f30430c7d56d65936e21dfa188e1\",\n",
      "\t\t\"parent\": \"058eb99a8b94535173ea98df437c596c3825a0e9\",\n",
      "\t\t\"subject\": \"Fix labels (#14282)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-labels-14282\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix labels  * move to a util function  * style  * PR comments  * rename class\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 May 2023 11:51:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"058eb99a8b94535173ea98df437c596c3825a0e9\",\n",
      "\t\t\"parent\": \"c546df3866bff286e30c2c922075a9dfc6d3a318\",\n",
      "\t\t\"subject\": \"Docs: Update Docker profile and fix method call in `druidapi` tutorial (#14308)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Update-Docker-profile-and-fix-method-call-in-druidapi-tutorial-14308\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 May 2023 07:29:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c546df3866bff286e30c2c922075a9dfc6d3a318\",\n",
      "\t\t\"parent\": \"7400ed3c9325e9237c52ea12a5fcf490e603b249\",\n",
      "\t\t\"subject\": \"Add `examples/` to CI UT/IT ignore (#14306)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-examples-to-CI-UT-IT-ignore-14306\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Skip UT/IT on examples only changes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 17:46:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7400ed3c9325e9237c52ea12a5fcf490e603b249\",\n",
      "\t\t\"parent\": \"c84c174caafae9cf8df2735fe7fa08e3f55abf5b\",\n",
      "\t\t\"subject\": \"Fixup data deletion tutorial docs (#14283)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixup-data-deletion-tutorial-docs-14283\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 17:05:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c84c174caafae9cf8df2735fe7fa08e3f55abf5b\",\n",
      "\t\t\"parent\": \"cb10bb97835eac8962bb9b296b471b6cd6a3e67c\",\n",
      "\t\t\"subject\": \"update tutorials to use clarify druid host location for Docker Compose + Druid version (#14295)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-tutorials-to-use-clarify-druid-host-location-for-Docker-Compose-Druid-version-14295\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 15:41:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb10bb97835eac8962bb9b296b471b6cd6a3e67c\",\n",
      "\t\t\"parent\": \"26ff01a0fd855eac8df29b0a3b2f18aff6e93148\",\n",
      "\t\t\"subject\": \"add website to java ci ignore (#14303)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-website-to-java-ci-ignore-14303\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 14:50:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"26ff01a0fd855eac8df29b0a3b2f18aff6e93148\",\n",
      "\t\t\"parent\": \"1d1454b22cac402f4867df2502df75df0d7261e3\",\n",
      "\t\t\"subject\": \"streamline release process docs (#14268)\",\n",
      "\t\t\"sanitized_subject_line\": \"streamline-release-process-docs-14268\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"remove release:prepare without skipping tests because there is no good reason to run tests locally in this step inline with creating a tag.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 13:57:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d1454b22cac402f4867df2502df75df0d7261e3\",\n",
      "\t\t\"parent\": \"d92b9fbfac977cd995d4d0ef9da6f3944f387fb1\",\n",
      "\t\t\"subject\": \"update NOTICE year, update kafka notice in licenses.yaml (#14299)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-NOTICE-year-update-kafka-notice-in-licenses.yaml-14299\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 04:32:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d92b9fbfac977cd995d4d0ef9da6f3944f387fb1\",\n",
      "\t\t\"parent\": \"1dd20773ae4a3b8bb998309c5751dc8bbe5fa6ec\",\n",
      "\t\t\"subject\": \"more resilient segment metadata, dont parallel merge internal segment metadata queries (#14296)\",\n",
      "\t\t\"sanitized_subject_line\": \"more-resilient-segment-metadata-dont-parallel-merge-internal-segment-metadata-queries-14296\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 04:12:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1dd20773ae4a3b8bb998309c5751dc8bbe5fa6ec\",\n",
      "\t\t\"parent\": \"ceda1e98b91c50f96e112ecb275a7acf3955cfb8\",\n",
      "\t\t\"subject\": \"remove website node-scss dep (#14275)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-website-node-scss-dep-14275\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 04:10:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ceda1e98b91c50f96e112ecb275a7acf3955cfb8\",\n",
      "\t\t\"parent\": \"b038a11280b4f9dfed8bb26f876b6654953c47e2\",\n",
      "\t\t\"subject\": \"docs: add docs for schema auto-discovery (#14065)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-docs-for-schema-auto-discovery-14065\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* wip schemaless  * wip  * more cleanup  * update tuningconfig example  * updates based on feedback from clint  * remove errant comma  * update dimension object to include auto  * update to include string schemaless way  * fix spelling errors  * updates for type-aware and string-based changes  * Update docs/ingestion/schema-design.md  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * update spelling file  * Update docs/ingestion/schema-design.md  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  * copyedits  * fix anchor  ---------  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Clint Wylie <cjwylie@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 01:36:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b038a11280b4f9dfed8bb26f876b6654953c47e2\",\n",
      "\t\t\"parent\": \"bbbb031057bf8e258eebf125ff4f0ea602b8daec\",\n",
      "\t\t\"subject\": \"fix issues with handling arrays with all null elements and arrays of booleans in strict mode (#14297)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issues-with-handling-arrays-with-all-null-elements-and-arrays-of-booleans-in-strict-mode-14297\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 May 2023 01:33:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bbbb031057bf8e258eebf125ff4f0ea602b8daec\",\n",
      "\t\t\"parent\": \"96a3c00754223626ff1df3799522277a086ec0a1\",\n",
      "\t\t\"subject\": \"Do not cancel old GHA workflows triggered on branch commits (#14279)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-cancel-old-GHA-workflows-triggered-on-branch-commits-14279\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* group and limit workflows only on PRs and not on branch commits  * also apply to Static Checks CI\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 May 2023 12:13:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"96a3c00754223626ff1df3799522277a086ec0a1\",\n",
      "\t\t\"parent\": \"e8ef31fe92a7da18396258b831eeaa4f142006af\",\n",
      "\t\t\"subject\": \"Fixing an issue with filtering on a single dimension by converting In\\u2026 (#14277)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-an-issue-with-filtering-on-a-single-dimension-by-converting-In-14277\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing an issue with filtering on a single dimension by converting In filter to a selector filter as needed with Filters.toFilter  * Adding a test so that any future refactoring does not break this behavior  * Made comment a bit more meaningful\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 May 2023 20:10:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e8ef31fe92a7da18396258b831eeaa4f142006af\",\n",
      "\t\t\"parent\": \"66d4ea014c1372e0a303fa0f9a4f3b16dac921d3\",\n",
      "\t\t\"subject\": \"Fix condition for timeout in worker task launcher (#14270)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-condition-for-timeout-in-worker-task-launcher-14270\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix condition for timeout in worker task launcher\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 May 2023 08:30:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"66d4ea014c1372e0a303fa0f9a4f3b16dac921d3\",\n",
      "\t\t\"parent\": \"c4aa98953b536b2b038b1f19809e3905ab497cbd\",\n",
      "\t\t\"subject\": \"Docs: Tutorial for streaming ingestion using Kafka + Docker file to use with Jupyter tutorials (#13984)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Tutorial-for-streaming-ingestion-using-Kafka-Docker-file-to-use-with-Jupyter-tutorials-13984\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 May 2023 15:20:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c4aa98953b536b2b038b1f19809e3905ab497cbd\",\n",
      "\t\t\"parent\": \"3c0983c8e9e3b5286bf0f22da0d3a3cac6708e36\",\n",
      "\t\t\"subject\": \"202304-docs-removeDF (#14132)\",\n",
      "\t\t\"sanitized_subject_line\": \"202304-docs-removeDF-14132\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 May 2023 15:08:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c0983c8e9e3b5286bf0f22da0d3a3cac6708e36\",\n",
      "\t\t\"parent\": \"10bce22e680f590e8c07fff980fcbe6c7fb0ea33\",\n",
      "\t\t\"subject\": \"Extend the IT framework to allow tests in extensions (#13877)\",\n",
      "\t\t\"sanitized_subject_line\": \"Extend-the-IT-framework-to-allow-tests-in-extensions-13877\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The \\\"new\\\" IT framework provides a convenient way to package and run integration tests (ITs), but only for core modules. We have a use case to run an IT for a contrib extension: the proposed gRPC query extension. This PR provides the IT framework functionality to allow non-core ITs.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 May 2023 20:29:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"10bce22e680f590e8c07fff980fcbe6c7fb0ea33\",\n",
      "\t\t\"parent\": \"e9913abbbfed82c11d1f876f30f24a768267ab48\",\n",
      "\t\t\"subject\": \"Configure maxBytesPerWorker directly instead of using StageDefinition (#14257)\",\n",
      "\t\t\"sanitized_subject_line\": \"Configure-maxBytesPerWorker-directly-instead-of-using-StageDefinition-14257\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Configure maxBytesPerWorker directly instead of using StageDefinition\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 May 2023 16:51:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e9913abbbfed82c11d1f876f30f24a768267ab48\",\n",
      "\t\t\"parent\": \"f9861808bc7e1ce4d7358260e024540d13015aad\",\n",
      "\t\t\"subject\": \"Add new lock types: APPEND and REPLACE (#14258)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-new-lock-types-APPEND-and-REPLACE-14258\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add new lock types: APPEND and REPLACE\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 May 2023 22:38:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f9861808bc7e1ce4d7358260e024540d13015aad\",\n",
      "\t\t\"parent\": \"8bda7297e15c21581cab1395d6e25cdc085c3c48\",\n",
      "\t\t\"subject\": \"Be able to load segments on Peons (#14239)\",\n",
      "\t\t\"sanitized_subject_line\": \"Be-able-to-load-segments-on-Peons-14239\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Be able to load segments on Peons  This change introduces a new config on WorkerConfig that indicates how many bytes of each storage location to use for storage of a task.  Said config is divided up amongst the locations and slots and then used to set TaskConfig.tmpStorageBytesPerTask  The Peons use their local task dir and tmpStorageBytesPerTask as their StorageLocations for the SegmentManager such that they can accept broadcast segments.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 16:51:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8bda7297e15c21581cab1395d6e25cdc085c3c48\",\n",
      "\t\t\"parent\": \"9e0708f5e6d8d2ab43535030937b7030f56088e1\",\n",
      "\t\t\"subject\": \"doc: fix unnest datasource syntax (#14272)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-fix-unnest-datasource-syntax-14272\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 13:05:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e0708f5e6d8d2ab43535030937b7030f56088e1\",\n",
      "\t\t\"parent\": \"ba11b3d462220c9470f434242e657cc7ce877d9c\",\n",
      "\t\t\"subject\": \"update heap size of coordinator, overlord services in docker IT environment (#14214)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-heap-size-of-coordinator-overlord-services-in-docker-IT-environment-14214\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 23:19:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ba11b3d462220c9470f434242e657cc7ce877d9c\",\n",
      "\t\t\"parent\": \"6254658f619a42c4ab0af1d7e61e861bd67d2083\",\n",
      "\t\t\"subject\": \"Refactor: Add OverlordDuty to replace OverlordHelper and align with CoordinatorDuty (#14235)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-Add-OverlordDuty-to-replace-OverlordHelper-and-align-with-CoordinatorDuty-14235\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Replace `OverlordHelper` with `OverlordDuty` to align with `CoordinatorDuty`   - Each duty has a `run()` method and defines a `Schedule` with an initial delay and period.   - Update existing duties `TaskLogAutoCleaner` and `DurableStorageCleaner` - Add utility class `Configs` - Update log, error messages and javadocs - Other minor style improvements\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 22:39:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6254658f619a42c4ab0af1d7e61e861bd67d2083\",\n",
      "\t\t\"parent\": \"58dcbf9399ff2705ba51f9481e02c9ce7fc82df9\",\n",
      "\t\t\"subject\": \"docs: fix links (#14111)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-links-14111\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 09:59:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58dcbf9399ff2705ba51f9481e02c9ce7fc82df9\",\n",
      "\t\t\"parent\": \"9eebeead4472a44f31cdc2b9fd48919f89446ea2\",\n",
      "\t\t\"subject\": \"queue tasks in kubernetes task runner if capacity is fully utilized (#14156)\",\n",
      "\t\t\"sanitized_subject_line\": \"queue-tasks-in-kubernetes-task-runner-if-capacity-is-fully-utilized-14156\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* queue tasks if all slots in use  * Declare hamcrest-core dependency  * Use AtomicBoolean for shutdown requested  * Use AtomicReference for peon lifecycle state  * fix uninitialized read error  * fix indentations  * Make tasks protected  * fix KubernetesTaskRunnerConfig deserialization  * ensure k8s task runner max capacity is Integer.MAX_VALUE  * set job duration as task status duration  * Address pr comments  ---------  Co-authored-by: George Shiqi Wu <george.wu@imply.io>\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 09:41:44 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9eebeead4472a44f31cdc2b9fd48919f89446ea2\",\n",
      "\t\t\"parent\": \"8ef99f091a730bd525c94d5b36a9d663afcf4475\",\n",
      "\t\t\"subject\": \"Tune stale bot to pick older issues first (#14267)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tune-stale-bot-to-pick-older-issues-first-14267\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 11:45:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ef99f091a730bd525c94d5b36a9d663afcf4475\",\n",
      "\t\t\"parent\": \"eae9e07ea933fc7f74ec658e0f8074add079085e\",\n",
      "\t\t\"subject\": \"Fix jdk setup in GHA (#14091)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-jdk-setup-in-GHA-14091\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Instead of downloading jdk everytime we run CI, we're using inbuilt temurin jdk distributions 8, 11, 17 by settiing JAVA_HOME variable. This is not working as expected since we were not setting this as global environment variable as a result all CI builds are running on jdk11. This PR fixes the issue.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 10:36:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eae9e07ea933fc7f74ec658e0f8074add079085e\",\n",
      "\t\t\"parent\": \"9875090bee7f98e2467c0b2fa45ca3a3121b90c8\",\n",
      "\t\t\"subject\": \"suppress CVE-2021-40331 since it applies to ranger-hive-plugin which afaict we do not use (#14261)\",\n",
      "\t\t\"sanitized_subject_line\": \"suppress-CVE-2021-40331-since-it-applies-to-ranger-hive-plugin-which-afaict-we-do-not-use-14261\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 21:58:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9875090bee7f98e2467c0b2fa45ca3a3121b90c8\",\n",
      "\t\t\"parent\": \"47a70d03e8c6bd1a5232a98519d2a7dec8a7b6ac\",\n",
      "\t\t\"subject\": \"fix segment metadata queries for auto ingested columns that had all null values (#14262)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-segment-metadata-queries-for-auto-ingested-columns-that-had-all-null-values-14262\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 20:58:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47a70d03e8c6bd1a5232a98519d2a7dec8a7b6ac\",\n",
      "\t\t\"parent\": \"cc37987dff0607363183ea01e8495b6f50f0a29b\",\n",
      "\t\t\"subject\": \"Docs: Minor rephrase in indexing-service.md (#14231)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Minor-rephrase-in-indexing-service.md-14231\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix language in indexing-service  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 May 2023 08:22:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc37987dff0607363183ea01e8495b6f50f0a29b\",\n",
      "\t\t\"parent\": \"f128b9b666abe096c64058db374c974cc16085b3\",\n",
      "\t\t\"subject\": \"docs: copyedits for MSQ join algos (#14012)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-copyedits-for-MSQ-join-algos-14012\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 14:21:09 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f128b9b666abe096c64058db374c974cc16085b3\",\n",
      "\t\t\"parent\": \"a58cebe4917dadc65ecd3143668288229a57d22a\",\n",
      "\t\t\"subject\": \"Updates to filter processing for inner query in Joins (#14237)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updates-to-filter-processing-for-inner-query-in-Joins-14237\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 17:21:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a58cebe4917dadc65ecd3143668288229a57d22a\",\n",
      "\t\t\"parent\": \"64e6283eca37e3197224da23bc71a5d12a190122\",\n",
      "\t\t\"subject\": \"add array_to_mv function to convert arrays into mvds to assist with migration from mvds to arrays (#14236)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-array_to_mv-function-to-convert-arrays-into-mvds-to-assist-with-migration-from-mvds-to-arrays-14236\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 04:43:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"64e6283eca37e3197224da23bc71a5d12a190122\",\n",
      "\t\t\"parent\": \"47e48ee65710719c6af1605fedf7a5063c83cc38\",\n",
      "\t\t\"subject\": \"Do not allow retention rules to be null (#14223)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-allow-retention-rules-to-be-null-14223\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Do not allow retention rules for any datasource or cluster to be null - Allow empty rules at the datasource level but not at the cluster level - Add validation to ensure that `druid.manager.rules.defaultRule` is always set correctly - Minor style refactors \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 14:33:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47e48ee65710719c6af1605fedf7a5063c83cc38\",\n",
      "\t\t\"parent\": \"e833a4700d0a85edd87bbf5ec82b9e650012a54f\",\n",
      "\t\t\"subject\": \"Remove incorrect optimization (#14246)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-incorrect-optimization-14246\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 00:54:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e833a4700d0a85edd87bbf5ec82b9e650012a54f\",\n",
      "\t\t\"parent\": \"f3ff36a004e78f9fed59e9388b893616be884f82\",\n",
      "\t\t\"subject\": \"suppress hadoop3 cve that seem not applicable to us (#14252)\",\n",
      "\t\t\"sanitized_subject_line\": \"suppress-hadoop3-cve-that-seem-not-applicable-to-us-14252\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 May 2023 23:08:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f3ff36a004e78f9fed59e9388b893616be884f82\",\n",
      "\t\t\"parent\": \"aaaff747409729ce11dc81e2de75eb6faa0fed76\",\n",
      "\t\t\"subject\": \"Move the stale bot to a GHA action (#14238)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-the-stale-bot-to-a-GHA-action-14238\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Move the stale bot to a GHA action\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 May 2023 11:31:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"aaaff747409729ce11dc81e2de75eb6faa0fed76\",\n",
      "\t\t\"parent\": \"6db11bfc60b469ae5caaaf7e23b2e4fa5ab1d18e\",\n",
      "\t\t\"subject\": \"fix npe regression in json_value when filtering non-existent paths (#14250)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-npe-regression-in-json_value-when-filtering-non-existent-paths-14250\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix npe regression in json_value when filtering non-existent paths  * more coverage\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 May 2023 22:39:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6db11bfc60b469ae5caaaf7e23b2e4fa5ab1d18e\",\n",
      "\t\t\"parent\": \"625c4745b120e996494ef364abc5a8f58a00f98f\",\n",
      "\t\t\"subject\": \"suppress some cves and fix javadoc build when using java 17 (#14241)\",\n",
      "\t\t\"sanitized_subject_line\": \"suppress-some-cves-and-fix-javadoc-build-when-using-java-17-14241\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 May 2023 15:47:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"625c4745b120e996494ef364abc5a8f58a00f98f\",\n",
      "\t\t\"parent\": \"161d12eb445e3f2123020a7d82beea9cd5bb7182\",\n",
      "\t\t\"subject\": \"add context flag \\\"useAutoColumnSchemas\\\" to use new auto types for MSQ segment generation (#14175)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-context-flag-useAutoColumnSchemas-to-use-new-auto-types-for-MSQ-segment-generation-14175\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 May 2023 15:37:14 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"161d12eb445e3f2123020a7d82beea9cd5bb7182\",\n",
      "\t\t\"parent\": \"bd0080c4cec6067def6928e8f00444a335de01e6\",\n",
      "\t\t\"subject\": \"Fix unit tests for java 17 (#14207)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-unit-tests-for-java-17-14207\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fix a unit test that fails in java 17\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 May 2023 20:02:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bd0080c4cec6067def6928e8f00444a335de01e6\",\n",
      "\t\t\"parent\": \"152e9375e2c120e141a34b13c5a386d231952d82\",\n",
      "\t\t\"subject\": \"Update default values in docs (#14233)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-default-values-in-docs-14233\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 May 2023 19:13:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"152e9375e2c120e141a34b13c5a386d231952d82\",\n",
      "\t\t\"parent\": \"8805d8d7db61c892c62981e7eec00c6b6037e16d\",\n",
      "\t\t\"subject\": \"update documentation about multiValueHandling (#14197)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-documentation-about-multiValueHandling-14197\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update documentation about multiValueHandling  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: Gian Merlino <gianmerlino@gmail.com>  * fix spelling  ---------  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Gian Merlino <gianmerlino@gmail.com>\",\n",
      "\t\t\"author_name\": \"Shingo Kitagawa\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 16:16:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8805d8d7db61c892c62981e7eec00c6b6037e16d\",\n",
      "\t\t\"parent\": \"0a3889b192f3d3bcf976a22fa679f6bfa56a75b0\",\n",
      "\t\t\"subject\": \"fix issues with filtering nulls on values coerced to numeric types (#14139)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issues-with-filtering-nulls-on-values-coerced-to-numeric-types-14139\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issues with filtering nulls on values coerced to numeric types * fix issues with 'auto' type numeric columns in default value mode * optimize variant typed columns without nested data * more tests for 'auto' type column ingestion\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 13:19:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0a3889b192f3d3bcf976a22fa679f6bfa56a75b0\",\n",
      "\t\t\"parent\": \"3c62c00d4c86ff002480a28c917afd4bc8dd3451\",\n",
      "\t\t\"subject\": \"account for auto allowing for leading and trailing spaces (#14224)\",\n",
      "\t\t\"sanitized_subject_line\": \"account-for-auto-allowing-for-leading-and-trailing-spaces-14224\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 13:18:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c62c00d4c86ff002480a28c917afd4bc8dd3451\",\n",
      "\t\t\"parent\": \"a7a4bfd331e320d8925e6f39fdc4861319e5b8bd\",\n",
      "\t\t\"subject\": \"Fix Typos in DruidToGraphiteEventConverter (#14219)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Typos-in-DruidToGraphiteEventConverter-14219\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"minseok\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 17:46:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7a4bfd331e320d8925e6f39fdc4861319e5b8bd\",\n",
      "\t\t\"parent\": \"4d8feeb279cc144998e06bd2c9ab30044a77862b\",\n",
      "\t\t\"subject\": \"modify QueryScheduler to lazily acquire lanes when executing queries to avoid leaks (#14184)\",\n",
      "\t\t\"sanitized_subject_line\": \"modify-QueryScheduler-to-lazily-acquire-lanes-when-executing-queries-to-avoid-leaks-14184\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR fixes an issue that could occur if druid.query.scheduler.numThreads is configured and any exception occurs after QueryScheduler.run has been called to create a Sequence. This would result in total and/or lane specific locks being acquired, but because the sequence was not actually being evaluated, the \\\"baggage\\\" which typically releases these locks was not being executed. An example of how this can happen is if a group-by having filter, which wraps and transforms this sequence happens to explode while wrapping the sequence. The end result is that the locks are acquired, but never released, eventually halting the ability to execute any queries.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 11:42:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4d8feeb279cc144998e06bd2c9ab30044a77862b\",\n",
      "\t\t\"parent\": \"eed5f4f2916a0b7458b3c2b819afb370d72f610e\",\n",
      "\t\t\"subject\": \"Fix planning in CASE expressions with complex WHEN and ELSE expressions (#14220)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-planning-in-CASE-expressions-with-complex-WHEN-and-ELSE-expressions-14220\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 11:35:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eed5f4f2916a0b7458b3c2b819afb370d72f610e\",\n",
      "\t\t\"parent\": \"fb38085ddbb439974325b230739e129ebcbf9ba1\",\n",
      "\t\t\"subject\": \"Add labels to k8s jobs for the PodTemplateTaskAdapter (#14205)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-labels-to-k8s-jobs-for-the-PodTemplateTaskAdapter-14205\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add labels  * Add prefix  * remove newline  * fix syntax  * Update prefix\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 May 2023 10:56:52 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fb38085ddbb439974325b230739e129ebcbf9ba1\",\n",
      "\t\t\"parent\": \"123c4908c84660d5fd4dcbd2c840fd8f112b6566\",\n",
      "\t\t\"subject\": \"Add wait for worker shutdown to MSQ task cancel (#14198)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-wait-for-worker-shutdown-to-MSQ-task-cancel-14198\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add wait for worker shutdown to MSQ task cancel  * Fix checkstyle\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 16:29:59 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"123c4908c84660d5fd4dcbd2c840fd8f112b6566\",\n",
      "\t\t\"parent\": \"4c15e978f136f60008435a927ee2c0cb1858ada7\",\n",
      "\t\t\"subject\": \"Ephemeral storage is respected from the overlod for peon tasks (#14201)\",\n",
      "\t\t\"sanitized_subject_line\": \"Ephemeral-storage-is-respected-from-the-overlod-for-peon-tasks-14201\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Churro\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 16:27:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4c15e978f136f60008435a927ee2c0cb1858ada7\",\n",
      "\t\t\"parent\": \"6ca3fb9b089037581f04b9ed15ffc227a9f37054\",\n",
      "\t\t\"subject\": \"Web console: misc bug fixes (#14216)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-misc-bug-fixes-14216\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fixing little things  * clear edit columns when switching to SQL tab  * updated snapshots\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 15:45:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ca3fb9b089037581f04b9ed15ffc227a9f37054\",\n",
      "\t\t\"parent\": \"46dabab36dc86d307f3c96bee5b833dfe7be124e\",\n",
      "\t\t\"subject\": \"Remove the redundant ISO-8601 text in the readme. (#14210)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-the-redundant-ISO-8601-text-in-the-readme.-14210\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 11:27:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"46dabab36dc86d307f3c96bee5b833dfe7be124e\",\n",
      "\t\t\"parent\": \"01e88848ceb7d16d389830ee3cff9ed7ba46f366\",\n",
      "\t\t\"subject\": \"Fix NPE in test parse exception report. Add more tests with different thresholds. (#14209)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-NPE-in-test-parse-exception-report.-Add-more-tests-with-different-thresholds.-14209\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 10:05:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"01e88848ceb7d16d389830ee3cff9ed7ba46f366\",\n",
      "\t\t\"parent\": \"48cde236c43e3dcb19f66c4a91726f0a93c8f4cf\",\n",
      "\t\t\"subject\": \"restore .idea/misc.xml to see if it fixes intellij inspection ci (#14208)\",\n",
      "\t\t\"sanitized_subject_line\": \"restore-.idea-misc.xml-to-see-if-it-fixes-intellij-inspection-ci-14208\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 May 2023 11:47:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48cde236c43e3dcb19f66c4a91726f0a93c8f4cf\",\n",
      "\t\t\"parent\": \"edfd46ed458bab0baf93e6d64373b3b5b061ff41\",\n",
      "\t\t\"subject\": \"Add columnMappings to explain plan output (#14187)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-columnMappings-to-explain-plan-output-14187\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add columnMappings to explain plan output  * * fix checkstyle * add tests  * * improve test coverage  * * temporarily remove unit-test need to run ITs  * * depend on build  * * temporarily lower unit test threshold  * * add back dependency on unit-tests  * * add license headers  * * fix header order  * * review comments  * * fix intellij inspection errors  * * revert code coverage change\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 May 2023 10:36:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"edfd46ed458bab0baf93e6d64373b3b5b061ff41\",\n",
      "\t\t\"parent\": \"68f908e511e10217f56ccbbf77d8fc80b13aa512\",\n",
      "\t\t\"subject\": \"Better actionable error message when druid services are not running (#14202)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-actionable-error-message-when-druid-services-are-not-running-14202\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We have seen that the first-time users often don't know the next steps if druid services are unresponsive for some reason. This PR makes some of those messages a bit more clear.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 May 2023 18:03:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"68f908e511e10217f56ccbbf77d8fc80b13aa512\",\n",
      "\t\t\"parent\": \"954f3917ef8a310e070d8eaef1369551fa51b223\",\n",
      "\t\t\"subject\": \"Fix uncaught `ParseException` when reading Avro from Kafka (#14183)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-uncaught-ParseException-when-reading-Avro-from-Kafka-14183\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In StreamChunkParser#parseWithInputFormat, we call byteEntityReader.read() without handling a potential ParseException, which is thrown during this function call by the delegate AvroStreamReader#intermediateRowIterator. A ParseException can be thrown if an Avro stream has corrupt data or data that doesn't conform to the schema specified or for other decoding reasons. This exception if uncaught, can cause ingestion to fail.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 May 2023 12:35:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"954f3917ef8a310e070d8eaef1369551fa51b223\",\n",
      "\t\t\"parent\": \"ac7181bbda10fe4bd556892cfdebe5cef3a7a2fa\",\n",
      "\t\t\"subject\": \"Add check for required avroBytesDecoder property that otherwise causes NPE. (#14177)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-check-for-required-avroBytesDecoder-property-that-otherwise-causes-NPE.-14177\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 May 2023 09:53:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ac7181bbda10fe4bd556892cfdebe5cef3a7a2fa\",\n",
      "\t\t\"parent\": \"ad93635e4599adee2cf558cd1b9dbaaffbe9031e\",\n",
      "\t\t\"subject\": \"Persist supervisor spec only after successful start (#14150)\",\n",
      "\t\t\"sanitized_subject_line\": \"Persist-supervisor-spec-only-after-successful-start-14150\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Persist spec after successful start  * Fix checkstyle.  * checkstyle after mvn install\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 May 2023 18:27:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ad93635e4599adee2cf558cd1b9dbaaffbe9031e\",\n",
      "\t\t\"parent\": \"6f0cdd0c3ff3ece039150f49df70dd4a49454495\",\n",
      "\t\t\"subject\": \"Web console: allow stringly schemas in the data loader (#14189)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-allow-stringly-schemas-in-the-data-loader-14189\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* allow stringly schemas  * fix copy  * feedback fixes  * feedback  * fix copy  * add warning  * indicate submitting  * Update web-console/src/views/load-data-view/load-data-view.tsx  Co-authored-by: Abhishek Radhakrishnan <abhishek.rb19@gmail.com>  * feedback fix  * copy fix  ---------  Co-authored-by: Abhishek Radhakrishnan <abhishek.rb19@gmail.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 May 2023 23:13:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f0cdd0c3ff3ece039150f49df70dd4a49454495\",\n",
      "\t\t\"parent\": \"387e682fbcc8a7a061a929f75b7604a96dde3094\",\n",
      "\t\t\"subject\": \"`TaskStartTimeoutFault` now depends on the last successful worker launch time. (#14172)\",\n",
      "\t\t\"sanitized_subject_line\": \"TaskStartTimeoutFault-now-depends-on-the-last-successful-worker-launch-time.-14172\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* `TaskStartTimeoutFault` now depends on the last successful worker launch time.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 May 2023 00:05:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"387e682fbcc8a7a061a929f75b7604a96dde3094\",\n",
      "\t\t\"parent\": \"078d5ac59063476c0905a4c71b180bff9ac220cd\",\n",
      "\t\t\"subject\": \"Fix memory calculations for WorkerMemoryParameters for machines with relatively less heap space (#14117)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-memory-calculations-for-WorkerMemoryParameters-for-machines-with-relatively-less-heap-space-14117\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update worker memory parameters\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 May 2023 09:24:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"078d5ac59063476c0905a4c71b180bff9ac220cd\",\n",
      "\t\t\"parent\": \"90ea192d9ce912b7fea36acf4cf3d46934de62cf\",\n",
      "\t\t\"subject\": \"Preference to first worker error in-case job fails with `TooManyAttemptsForWorker` (#14170)\",\n",
      "\t\t\"sanitized_subject_line\": \"Preference-to-first-worker-error-in-case-job-fails-with-TooManyAttemptsForWorker-14170\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 May 2023 14:47:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90ea192d9ce912b7fea36acf4cf3d46934de62cf\",\n",
      "\t\t\"parent\": \"32af570fb22ed47175cdce3fbd1f329c9278748e\",\n",
      "\t\t\"subject\": \"fix bugs with auto encoded long vector deserializers (#14186)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bugs-with-auto-encoded-long-vector-deserializers-14186\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR fixes an issue when using 'auto' encoded LONG typed columns and the 'vectorized' query engine. These columns use a delta based bit-packing mechanism, and errors in the vectorized reader would cause it to incorrectly read column values for some bit sizes (1 through 32 bits). This is a regression caused by #11004, which added the optimized readers to improve performance, so impacts Druid versions 0.22.0+.  While writing the test I finally got sad enough about IndexSpec not having a \\\"builder\\\", so I made one, and switched all the things to use it. Apologies for the noise in this bug fix PR, the only real changes are in VSizeLongSerde, and the tests that have been modified to cover the buggy behavior, VSizeLongSerdeTest and ExpressionVectorSelectorsTest. Everything else is just cleanup of IndexSpec usage.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 May 2023 11:49:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"32af570fb22ed47175cdce3fbd1f329c9278748e\",\n",
      "\t\t\"parent\": \"f976837eaaf9bfd74909476f7c670fbdf44e7110\",\n",
      "\t\t\"subject\": \"fix API doc formatting (#14167)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-API-doc-formatting-14167\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 29 Apr 2023 09:29:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f976837eaaf9bfd74909476f7c670fbdf44e7110\",\n",
      "\t\t\"parent\": \"d0654e217480b5e28e793bf1dbd609cae9e5bac9\",\n",
      "\t\t\"subject\": \"allow marking segments as used when the whole datasoruce is unused (#14185)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-marking-segments-as-used-when-the-whole-datasoruce-is-unused-14185\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Apr 2023 19:45:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d0654e217480b5e28e793bf1dbd609cae9e5bac9\",\n",
      "\t\t\"parent\": \"98db960794688951d18ef1fbab7fe65ef10de1f7\",\n",
      "\t\t\"subject\": \"Register emitter (#14180)\",\n",
      "\t\t\"sanitized_subject_line\": \"Register-emitter-14180\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 18:32:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"98db960794688951d18ef1fbab7fe65ef10de1f7\",\n",
      "\t\t\"parent\": \"84c11df980b90e059ae08d116f3dfdd1ef7974a1\",\n",
      "\t\t\"subject\": \"fix task query error decode (#14174)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-task-query-error-decode-14174\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 15:26:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"84c11df980b90e059ae08d116f3dfdd1ef7974a1\",\n",
      "\t\t\"parent\": \"d4e478c90918edbb83799372691439d3b55f82ee\",\n",
      "\t\t\"subject\": \"Make LoggingEmitter more useful by using Markers (#14121)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-LoggingEmitter-more-useful-by-using-Markers-14121\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make LoggingEmitter more useful  * Skip code coverage for facade classes  * fix spellcheck  * code review  * fix dependency  * logging.md  * fix checkstyle  * Add back jacoco version to main pom\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 15:06:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4e478c90918edbb83799372691439d3b55f82ee\",\n",
      "\t\t\"parent\": \"fceb5058337a981eb8d9a21c7f7f342d34b5e892\",\n",
      "\t\t\"subject\": \"NVL function docs update (#14169)\",\n",
      "\t\t\"sanitized_subject_line\": \"NVL-function-docs-update-14169\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 11:17:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fceb5058337a981eb8d9a21c7f7f342d34b5e892\",\n",
      "\t\t\"parent\": \"6579c1c5b62e2fa17e73aa40ad867d32e02e14e9\",\n",
      "\t\t\"subject\": \"Web console: allow __time in MSQ (#14165)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-allow-__time-in-MSQ-14165\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* works in MSQ  * fix spec conversion\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 09:02:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6579c1c5b62e2fa17e73aa40ad867d32e02e14e9\",\n",
      "\t\t\"parent\": \"63268a50236bf7b621b07cf64eacb69c955b0efe\",\n",
      "\t\t\"subject\": \"remove unneeded TaskLogStreamer binding override (#14176)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-unneeded-TaskLogStreamer-binding-override-14176\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 19:39:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"63268a50236bf7b621b07cf64eacb69c955b0efe\",\n",
      "\t\t\"parent\": \"5aa119dfdaed4b0727e62659c18df5816685551a\",\n",
      "\t\t\"subject\": \"Relaunch track of failed workers without work orders (#14166)\",\n",
      "\t\t\"sanitized_subject_line\": \"Relaunch-track-of-failed-workers-without-work-orders-14166\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* If a worker dies after it has finished generating results, MSQ decides to not retry it as it has no active work orders. However, since we don't keep track of it further, if it is required for a future stage, the controller hangs waiting for the worker to be ready. This PR keeps tracks of any workers the controller decides to not restart immediately and while starting workers for the next stage, queues these workers for retry.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 19:38:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5aa119dfdaed4b0727e62659c18df5816685551a\",\n",
      "\t\t\"parent\": \"42c8c84eb6ddddfbc780c6c932cfee928515490b\",\n",
      "\t\t\"subject\": \"Add retry to opening retrying stream (#14126)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-retry-to-opening-retrying-stream-14126\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add retry to opening retrying stream * Add retry to S3Entity for network issues  * Fix tests and clean up code\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Apr 2023 16:52:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"42c8c84eb6ddddfbc780c6c932cfee928515490b\",\n",
      "\t\t\"parent\": \"6c99fbea921f07c1731d5e35148346deb290c565\",\n",
      "\t\t\"subject\": \"TimeBoundary: Use cursor when datasource is not a regular table. (#14151)\",\n",
      "\t\t\"sanitized_subject_line\": \"TimeBoundary-Use-cursor-when-datasource-is-not-a-regular-table.-14151\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* TimeBoundary: Use cursor when datasource is not a regular table.  Fixes a bug where TimeBoundary could return incorrect results with INNER Join or inline data.  * Addl Javadocs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Apr 2023 17:00:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c99fbea921f07c1731d5e35148346deb290c565\",\n",
      "\t\t\"parent\": \"5db7396c7864baf79cb88c8d2b3de938f991a0b5\",\n",
      "\t\t\"subject\": \"fix typo in s3 docs. add readme to s3 module. (#14135)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-typo-in-s3-docs.-add-readme-to-s3-module.-14135\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix typo in s3 docs. add readme to s3 module.  * Update extensions-core/s3-extensions/README.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * cleanup readme for s3 extension and link to repo markdown doc instead of web docs  ---------  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Apr 2023 14:03:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5db7396c7864baf79cb88c8d2b3de938f991a0b5\",\n",
      "\t\t\"parent\": \"e4d99c3e26d7d98dd4848e25b3a78f6b3551207d\",\n",
      "\t\t\"subject\": \"fix(avro-json-path-expressions): allow more complex jsonpath expressions (#14149)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-avro-json-path-expressions-allow-more-complex-jsonpath-expressions-14149\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"robo220\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Apr 2023 14:58:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e4d99c3e26d7d98dd4848e25b3a78f6b3551207d\",\n",
      "\t\t\"parent\": \"774073b2e7f3ab47a0b1fd3c45fb03bb2281038c\",\n",
      "\t\t\"subject\": \"set count on rule history api (#14164)\",\n",
      "\t\t\"sanitized_subject_line\": \"set-count-on-rule-history-api-14164\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Apr 2023 01:44:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"774073b2e7f3ab47a0b1fd3c45fb03bb2281038c\",\n",
      "\t\t\"parent\": \"752475b7992b1ef458c24b750eb05a4b4c9207a3\",\n",
      "\t\t\"subject\": \"Update Hadoop3 as default build version (#14005)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Hadoop3-as-default-build-version-14005\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Hadoop 2 often causes red security scans on Druid distribution because of the dependencies it brings. We want to move away from Hadoop 2 and provide Hadoop 3 distribution available. Switch druid to building with Hadoop 3 by default. Druid will still be compatible with Hadoop 2 and users can build hadoop-2 compatible distribution using hadoop2 profile.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Apr 2023 12:52:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"752475b7992b1ef458c24b750eb05a4b4c9207a3\",\n",
      "\t\t\"parent\": \"2dfb693d4c1cecdab0c1cd75f5810cfbbd1e75e6\",\n",
      "\t\t\"subject\": \"Fix two concurrency issues with segment fetching. (#14042)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-two-concurrency-issues-with-segment-fetching.-14042\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix two concurrency issues with segment fetching.  1) SegmentLocalCacheManager: Fix a concurrency issue where certain directory    cleanup happened outside of directoryWriteRemoveLock. This created the    possibility that segments would be deleted by one thread, while being    actively downloaded by another thread.  2) TaskDataSegmentProcessor (MSQ): Fix a concurrency issue when two stages    in the same process both use the same segment. For example: a self-join    using distributed sort-merge. Prior to this change, the two stages could    delete each others' segments.  3) ReferenceCountingResourceHolder: increment() returns a new ResourceHolder,    rather than a Releaser. This allows it to be passed to callers without them    having to hold on to both the original ResourceHolder *and* a Releaser.  4) Simplify various interfaces and implementations by using ResourceHolder    instead of Pair and instead of split-up fields.  * Add test.  * Fix style.  * Remove Releaser.  * Updates from master.  * Add some GuardedBys.  * Use the correct GuardedBy.  * Adjustments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 20:49:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2dfb693d4c1cecdab0c1cd75f5810cfbbd1e75e6\",\n",
      "\t\t\"parent\": \"a7d4162195a630c380d75516c24229cc23e25271\",\n",
      "\t\t\"subject\": \"Improved handling for zero-length intervals. (#14136)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improved-handling-for-zero-length-intervals.-14136\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improved handling for zero-length intervals.  1) Return an empty list from VersionedIntervalTimeline.lookup when    provided with an empty interval. (The logic doesn't quite work when    intervals are empty, which led to #14129.)  2) Don't return zero-length intervals from JodaUtils.condenseIntervals.  3) Detect \\\"incorrect\\\" comparator in JodaUtils.condenseIntervals, and    recreate the SortedSet if needed. (Not strictly related to the theme    of this patch. Just another thing in the same file.)  4) Remove unused method JodaUtils.containOverlappingIntervals.  Fixes #14129.  * Fix TimewarpOperatorTest.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 17:12:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7d4162195a630c380d75516c24229cc23e25271\",\n",
      "\t\t\"parent\": \"89e7948159771735908e3e68823356ecd34df93a\",\n",
      "\t\t\"subject\": \"Compaction: Block input specs not aligned with segmentGranularity. (#14127)\",\n",
      "\t\t\"sanitized_subject_line\": \"Compaction-Block-input-specs-not-aligned-with-segmentGranularity.-14127\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Compaction: Block input specs not aligned with segmentGranularity.  When input intervals are not aligned with segmentGranularity, data may be overshadowed if it lies in the space between the input intervals and the output segmentGranularity.  In MSQ REPLACE, this is a validation error. IMO the same behavior makes sense for compaction tasks. In case anyone was depending on the ability to compact nonaligned intervals, a configuration parameter allowNonAlignedInterval is provided. I don't expect it to be used much.  * Remove unused.  * ITCompactionTaskTest uses non-aligned intervals.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 17:06:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"89e7948159771735908e3e68823356ecd34df93a\",\n",
      "\t\t\"parent\": \"ee06137787af0b090fbee57d2b21d612fe8dbadd\",\n",
      "\t\t\"subject\": \"MSQ: Subclass CalciteJoinQueryTest, other supporting changes. (#14105)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Subclass-CalciteJoinQueryTest-other-supporting-changes.-14105\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Subclass CalciteJoinQueryTest, other supporting changes.  The main change is the new tests: we now subclass CalciteJoinQueryTest in CalciteSelectJoinQueryMSQTest twice, once for Broadcast and once for SortMerge.  Two supporting production changes for default-value mode:  1) InputNumberDataSource is marked as concrete, to allow leftFilter to    be pushed down to it.  2) In default-value mode, numeric frame field readers can now return nulls.    This is necessary when stacking joins on top of joins: nulls must be    preserved for semantics that match broadcast joins and native queries.  3) In default-value mode, StringFieldReader.isNull returns true on empty    strings in addition to nulls. This is more consistent with the behavior    of the selectors, which map empty strings to null as well in that mode.  As an effect of change (2), the InsertTimeNull change from #14020 (to replace null timestamps with default timestamps) is reverted. IMO, this is fine, as either behavior is defensible, and the change from #14020 hasn't been released yet.  * Adjust tests.  * Style fix.  * Additional tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 12:10:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee06137787af0b090fbee57d2b21d612fe8dbadd\",\n",
      "\t\t\"parent\": \"73f050027b9a3183daec38b532723fcd242c19c4\",\n",
      "\t\t\"subject\": \"better native json error UX (#14155)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-native-json-error-UX-14155\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 10:30:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"73f050027b9a3183daec38b532723fcd242c19c4\",\n",
      "\t\t\"parent\": \"cade80b582b5636b778a71e2f4274595a57038ef\",\n",
      "\t\t\"subject\": \"MSQ: Preserve original ParseException when writing frames. (#14122)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Preserve-original-ParseException-when-writing-frames.-14122\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 11:47:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cade80b582b5636b778a71e2f4274595a57038ef\",\n",
      "\t\t\"parent\": \"9d4cc501f73a03543e19081c332331fccac67562\",\n",
      "\t\t\"subject\": \"Change time column name when reading from external sources in MSQ (#14148)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-time-column-name-when-reading-from-external-sources-in-MSQ-14148\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"When ingesting from an external source which already contains a column \\\"__time\\\", currently, the value is dropped. Changing the time column name in the external input slice reader resolves this.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Apr 2023 11:13:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9d4cc501f73a03543e19081c332331fccac67562\",\n",
      "\t\t\"parent\": \"accd5536dfecac3b59bf695b030c62fda8204bf8\",\n",
      "\t\t\"subject\": \"return task status reported by peon (#14040)\",\n",
      "\t\t\"sanitized_subject_line\": \"return-task-status-reported-by-peon-14040\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* return task status reported by peon  * Write TaskStatus to file in AbstractTask.cleanUp  * Get TaskStatus from task log  * Fix merge conflicts in AbstractTaskTest  * Add unit tests for TaskLogPusher, TaskLogStreamer, NoopTaskLogs to satisfy code coverage  * Add license headerss  * Fix style  * Remove unknown exception declarations\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 24 Apr 2023 12:05:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"accd5536dfecac3b59bf695b030c62fda8204bf8\",\n",
      "\t\t\"parent\": \"887f8db1b52b5d9cdc978ec71a528d6993290647\",\n",
      "\t\t\"subject\": \"Allow for Log4J to be configured for peons but still ensure console logging is enforced (#14094)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-for-Log4J-to-be-configured-for-peons-but-still-ensure-console-logging-is-enforced-14094\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Allow for Log4J to be configured for peons but still ensure console logging is enforced  This change will allow for log4j to be configured for peons but require console logging is still configured for them to ensure peon logs are saved to deep storage.  Also fixed the test ConsoleLoggingEnforcementTest to use a valid appender for the non console Config as the previous config was incorrect and would never return a logger.  * fix checkstyle  * add warning to logger when it overwrites all loggers to be console  * optimize calls for altering logging config for ConsoleLoggingEnforcementConfigurationFactory  add getName to the druid logger class  * update docs, and error message  * edit docs to be more clear  * fix checkstyle issues  * CI fixes - LoggerTest code coverage and fix spelling issue for logging docs\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 24 Apr 2023 10:41:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"887f8db1b52b5d9cdc978ec71a528d6993290647\",\n",
      "\t\t\"parent\": \"b95708f389a4a86b0f3ec4a2cc5d53d157a27d03\",\n",
      "\t\t\"subject\": \"preserve explicitly specified dimension schema in \\\"logical\\\" schema of sampler response (#14144)\",\n",
      "\t\t\"sanitized_subject_line\": \"preserve-explicitly-specified-dimension-schema-in-logical-schema-of-sampler-response-14144\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 23 Apr 2023 21:28:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b95708f389a4a86b0f3ec4a2cc5d53d157a27d03\",\n",
      "\t\t\"parent\": \"f643abdad9592eed91689c38a3b67ad25b7cf10c\",\n",
      "\t\t\"subject\": \"quick fix the tier selector (#14143)\",\n",
      "\t\t\"sanitized_subject_line\": \"quick-fix-the-tier-selector-14143\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 21 Apr 2023 17:21:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f643abdad9592eed91689c38a3b67ad25b7cf10c\",\n",
      "\t\t\"parent\": \"8d60edcfcb371423f9b731bfdb8579eda5f7c4da\",\n",
      "\t\t\"subject\": \"SQL planning: Consider subqueries in fewer scenarios. (#14123)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-planning-Consider-subqueries-in-fewer-scenarios.-14123\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL planning: Consider subqueries in fewer scenarios.  Further adjusts logic in DruidRules that was previously adjusted in #13902. The reason for the original change was that the comment \\\"Subquery must be a groupBy, so stage must be >= AGGREGATE\\\" was no longer accurate. Subqueries do not need to be groupBy anymore; they can really be any type of query. If I recall correctly, the change was needed for certain window queries to be able to plan on top of Scan queries.  However, this impacts performance negatively, because it causes many additional outer-query scenarios to be considered, which is expensive.  So, this patch updates the matching logic to consider fewer scenarios. The skipped scenarios are ones where we expect that, for one reason or another, it isn't necessary to consider a subquery.  * Remove unnecessary escaping.  * Fix test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 21 Apr 2023 08:32:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8d60edcfcb371423f9b731bfdb8579eda5f7c4da\",\n",
      "\t\t\"parent\": \"e7ae825e0cdd5a6b6726df504d870ac66a090438\",\n",
      "\t\t\"subject\": \"Updating segment map function for QueryDataSource to ensure group by \\u2026 (#14112)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updating-segment-map-function-for-QueryDataSource-to-ensure-group-by-14112\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Updating segment map function for QueryDataSource to ensure group by of group by of join data source gets into proper segment map function path  * Adding unit tests for the failed case  * There you go coverage bot, be happy now\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Apr 2023 13:22:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e7ae825e0cdd5a6b6726df504d870ac66a090438\",\n",
      "\t\t\"parent\": \"895abd89295db62c80593feb4e428363b2ba7158\",\n",
      "\t\t\"subject\": \"Web console: better end of (MSQ) query segment loading UX (#14120)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-better-end-of-MSQ-query-segment-loading-UX-14120\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* better end of query segment loading UX  * fix snapshot  * handle case when MSQ query returns results directly  * add ip address column icon  * better icons  * add variance icon  * better summary\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Apr 2023 10:26:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"895abd89295db62c80593feb4e428363b2ba7158\",\n",
      "\t\t\"parent\": \"4fffee17761286996a8c43154b72db4bcaafb16d\",\n",
      "\t\t\"subject\": \"Refresh DruidLeaderClient cache selectively for non-200 responses (#14092)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refresh-DruidLeaderClient-cache-selectively-for-non-200-responses-14092\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refresh DruidLeaderClient cache for non-200 responses  * Change local variable name to avoid confusion  * Implicit retries for 503 and 504  * Remove unused imports  * Use argumentmatcher instead of Mockito for #any in test  * Remove flag to disable retry for 503/504  * Remove unused import from test  * Add log line for internal retry  ---------  Co-authored-by: Abhishek Singh Chouhan <abhishek.chouhan@salesforce.com>\",\n",
      "\t\t\"author_name\": \"Abhishek Singh Chouhan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Apr 2023 01:46:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4fffee17761286996a8c43154b72db4bcaafb16d\",\n",
      "\t\t\"parent\": \"e8674e2a60aed3b223809bbcb124d132634c19f8\",\n",
      "\t\t\"subject\": \"Web console: better lookup 404 detection (#14108)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-better-lookup-404-detection-14108\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* better lookup 404 detection  * update snapshot\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 19 Apr 2023 09:27:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e8674e2a60aed3b223809bbcb124d132634c19f8\",\n",
      "\t\t\"parent\": \"9436ee8a63b6ccfd668c45c5304154f09a9f9919\",\n",
      "\t\t\"subject\": \"fix npe with gs uri having underscores (#14107)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-npe-with-gs-uri-having-underscores-14107\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix npe with gs uri having underscores  * compile fix\",\n",
      "\t\t\"author_name\": \"Parag Jain\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 19 Apr 2023 11:26:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9436ee8a63b6ccfd668c45c5304154f09a9f9919\",\n",
      "\t\t\"parent\": \"04da0102cbe93ab0e494ce8f8402e2f3abe34d68\",\n",
      "\t\t\"subject\": \"Nicer error message for CSV with no properties. (#14093)\",\n",
      "\t\t\"sanitized_subject_line\": \"Nicer-error-message-for-CSV-with-no-properties.-14093\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Nicer error message for CSV with no properties.  * Take two.  * Adjustments from review, and test fixes.  * Fix test.  * Fix static check.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Apr 2023 12:52:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"04da0102cbe93ab0e494ce8f8402e2f3abe34d68\",\n",
      "\t\t\"parent\": \"a7d5c64aeb7c5d70935e5ed797c8312af17264db\",\n",
      "\t\t\"subject\": \"KillTask should return empty inputSource resources (#14106)\",\n",
      "\t\t\"sanitized_subject_line\": \"KillTask-should-return-empty-inputSource-resources-14106\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  This pr fixes a few bugs found with the inputSource security feature.  1. `KillUnusedSegmentsTask` previously had no definition for the `getInputSourceResources`, which caused an unsupportedOperationException to be thrown when this task type was submitted with the inputSource security feature enabled. This task type should not require any input source specific resources, so returning an empty set for this task type now.  2. Fixed a bug where when the input source type security feature is enabled, all of the input source type specific resources used where authenticated against:  `{\\\"resource\\\": {\\\"name\\\": \\\"EXTERNAL\\\", \\\"type\\\": \\\"{INPUT_SOURCE_TYPE}\\\"}, \\\"action\\\": \\\"READ\\\"}`  When they should be instead authenticated against:  `{\\\"resource\\\": {\\\"name\\\": \\\"{INPUT_SOURCE_TYPE}\\\", \\\"type\\\": \\\"EXTERNAL\\\"}, \\\"action\\\": \\\"READ\\\"}`  3. fixed bug where supervisor tasks were not authenticated against the specific input source types used, if input source security feature was enabled.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Apr 2023 15:27:16 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7d5c64aeb7c5d70935e5ed797c8312af17264db\",\n",
      "\t\t\"parent\": \"8eb854c845f8eb2d272e3f2c6046e5a146118aa1\",\n",
      "\t\t\"subject\": \"Move MSQ temporary storage to a runtime parameter instead of being configured from query context (#14061)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-MSQ-temporary-storage-to-a-runtime-parameter-instead-of-being-configured-from-query-context-14061\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"*      Adds new run time parameter druid.indexer.task.tmpStorageBytesPerTask. This sets a limit for the amount of temporary storage disk space used by tasks. This limit is currently only respected by MSQ tasks. *   Removes query context parameters intermediateSuperSorterStorageMaxLocalBytes and composedIntermediateSuperSorterStorageEnabled. Composed intermediate super sorter (which was enabled by composedIntermediateSuperSorterStorageEnabled) is now enabled automatically if durableShuffleStorage is set to true. intermediateSuperSorterStorageMaxLocalBytes is calculated from the limit set by the run time parameter druid.indexer.task.tmpStorageBytesPerTask.  \",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Apr 2023 16:56:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8eb854c845f8eb2d272e3f2c6046e5a146118aa1\",\n",
      "\t\t\"parent\": \"086b2b8efe392fb4aea5436d6b95b01c6b16111d\",\n",
      "\t\t\"subject\": \"Remove maxResultsSize config property from S3OutputConfig (#14101)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-maxResultsSize-config-property-from-S3OutputConfig-14101\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* \\\"maxResultsSize\\\" has been removed from the S3OutputConfig and a default \\\"chunkSize\\\" of 100MiB is now present. This change primarily affects users who wish to use durable storage for MSQ jobs. \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Apr 2023 14:25:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"086b2b8efe392fb4aea5436d6b95b01c6b16111d\",\n",
      "\t\t\"parent\": \"f6a0888bc07396a4afab91f5cb576793e26275d2\",\n",
      "\t\t\"subject\": \"Log merge and push timings for PartialGenericSegmentMergeTask (#14089)\",\n",
      "\t\t\"sanitized_subject_line\": \"Log-merge-and-push-timings-for-PartialGenericSegmentMergeTask-14089\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Apr 2023 11:51:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f6a0888bc07396a4afab91f5cb576793e26275d2\",\n",
      "\t\t\"parent\": \"e7d2e8b914bf89a780490de109b8b7850b0e141f\",\n",
      "\t\t\"subject\": \"document arrays in sql (#12549)\",\n",
      "\t\t\"sanitized_subject_line\": \"document-arrays-in-sql-12549\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* document arrays in sql  * adjustments  * Update docs/querying/sql-array-functions.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/querying/sql-data-types.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/querying/sql-data-types.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/querying/sql-array-functions.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/querying/sql-array-functions.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update sql-array-functions.md  * fix stuff  * fix spelling  ---------  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 19:08:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e7d2e8b914bf89a780490de109b8b7850b0e141f\",\n",
      "\t\t\"parent\": \"c98c66558f7d5ad48edde681ba5192130268b24a\",\n",
      "\t\t\"subject\": \"fix bug filtering nested columns with expression filters (#14096)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-filtering-nested-columns-with-expression-filters-14096\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 14:21:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c98c66558f7d5ad48edde681ba5192130268b24a\",\n",
      "\t\t\"parent\": \"be6745f75ba437bcd0aec15217ce69955ebd8603\",\n",
      "\t\t\"subject\": \"Include statement attributes in `EXPLAIN PLAN` output (#14074)\",\n",
      "\t\t\"sanitized_subject_line\": \"Include-statement-attributes-in-EXPLAIN-PLAN-output-14074\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit adds attributes that contain metadata information about the query in the EXPLAIN PLAN output. The attributes currently contain two items: - `statementTyp`: SELECT, INSERT or REPLACE - `targetDataSource`: provides the target datasource name for DML statements  It is added to both the legacy and native query plan outputs.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 21:00:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"be6745f75ba437bcd0aec15217ce69955ebd8603\",\n",
      "\t\t\"parent\": \"facd82b4935d8d5313d93737a6de8bd8b7248f7b\",\n",
      "\t\t\"subject\": \"Adding more logs for sequential merge. (#14097)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-more-logs-for-sequential-merge.-14097\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 18:01:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"facd82b4935d8d5313d93737a6de8bd8b7248f7b\",\n",
      "\t\t\"parent\": \"1bd63948a10b21b12ca6f67241f53d5d95da6dd3\",\n",
      "\t\t\"subject\": \"Add HLLC tests for empty strings that don't pass. (#14085)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-HLLC-tests-for-empty-strings-that-don-t-pass.-14085\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"I believe the test case illustrates the cause of the problem in #13950.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 15:46:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1bd63948a10b21b12ca6f67241f53d5d95da6dd3\",\n",
      "\t\t\"parent\": \"eb797512a02777d0b48ef0911223af4469c34b5e\",\n",
      "\t\t\"subject\": \"Update asf-release-process-guide.md (#14080)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-asf-release-process-guide.md-14080\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"update release guide to include steps to ensure web-console tests that have docs links are updated correctly for the release branch\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 10:12:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb797512a02777d0b48ef0911223af4469c34b5e\",\n",
      "\t\t\"parent\": \"8affcaa7eb9c57f7ed4b463e0ebfb171fbbafc4d\",\n",
      "\t\t\"subject\": \"Fix MSQSelectTest. (#14099)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-MSQSelectTest.-14099\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"A logical conflict between #14046 and #14048 caused testJoinWithLookup to fail. This patch fixes it.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Apr 2023 01:15:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8affcaa7eb9c57f7ed4b463e0ebfb171fbbafc4d\",\n",
      "\t\t\"parent\": \"a8eb3f2f57f5109e169bff043d16e7dd2c406c0b\",\n",
      "\t\t\"subject\": \"Increase timeout for call to get worker capacity (#14095)\",\n",
      "\t\t\"sanitized_subject_line\": \"Increase-timeout-for-call-to-get-worker-capacity-14095\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 16 Apr 2023 21:24:13 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8eb3f2f57f5109e169bff043d16e7dd2c406c0b\",\n",
      "\t\t\"parent\": \"eeed5ed7e2885262f1456f291054951c626e453f\",\n",
      "\t\t\"subject\": \"SQL: Fix natural comparator selection for groupBy. (#14075)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Fix-natural-comparator-selection-for-groupBy.-14075\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Fix natural comparator selection for groupBy.  DruidQuery.computeSorting had some unique logic for finding natural comparators for SQL types. It should be using getStringComparatorForRelDataType instead.  One good effect here is that the comparator for BOOLEAN is now NUMERIC rather than LEXICOGRAPHIC. The test case illustrates this.  * Remove msqCompatible, for now.  * Fix test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Apr 2023 07:14:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eeed5ed7e2885262f1456f291054951c626e453f\",\n",
      "\t\t\"parent\": \"0884a22c4107dcb6868ade3c807fd5760336cd8c\",\n",
      "\t\t\"subject\": \"MSQ: Use the same result coercion routines as the regular SQL endpoint. (#14046)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Use-the-same-result-coercion-routines-as-the-regular-SQL-endpoint.-14046\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Use the same result coercion routines as the regular SQL endpoint.  The main changes are to move NativeQueryMaker.coerce to SqlResults, and to formally make the list of sqlTypeNames from the MSQ results reports use SqlTypeNames.  - Change the default to MSQ-compatible rather than MSQ-incompatible.   The explicit marker function is now \\\"notMsqCompatible()\\\".  \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Apr 2023 06:56:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0884a22c4107dcb6868ade3c807fd5760336cd8c\",\n",
      "\t\t\"parent\": \"bdc547709489adedb00263a7ca04a5cfc15eca90\",\n",
      "\t\t\"subject\": \"MSQ: Support for querying lookup and inline data directly. (#14048)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Support-for-querying-lookup-and-inline-data-directly.-14048\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Support for querying lookup and inline data directly.  Main changes:  1) Add of LookupInputSpec and DataSourcePlan.forLookup.  2) Add InlineInputSpec, and modify of DataSourcePlan.forInline to use    this instead of an ExternalInputSpec with JSON. This allows the inline    data to act as the right-hand side of a join, if needed.  Supporting changes:  1) Modify JoinDataSource's leftFilter validation to be a little less    strict: it's now OK with leftFilter being attached to any concrete    leaf (no children) datasource, rather than requiring it be a table.    This allows MSQ to create JoinDataSource with InputNumberDataSource    as the base.  2) Add SegmentWranglerModule to CliIndexer, CliPeon. This allows them to    query lookups and inline data directly.  * Updates based on CI.  * Additional tests.  * Style fix.  * Remove unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Apr 2023 14:04:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bdc547709489adedb00263a7ca04a5cfc15eca90\",\n",
      "\t\t\"parent\": \"e3c160f2f2a6a3a19f571ddaf18f0c998fdf42f5\",\n",
      "\t\t\"subject\": \"Adding missed s3 retry handling in storage connector. (#14086)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-missed-s3-retry-handling-in-storage-connector.-14086\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Apr 2023 17:21:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e3c160f2f2a6a3a19f571ddaf18f0c998fdf42f5\",\n",
      "\t\t\"parent\": \"6c9b7b6efdcdc26210276951598f732cc6cd7f0e\",\n",
      "\t\t\"subject\": \"Add start_time column to sys.servers  (#13358)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-start_time-column-to-sys.servers-13358\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Adds a new column start_time to sys.servers that captures the time at which the server was added to the cluster.\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Apr 2023 15:23:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c9b7b6efdcdc26210276951598f732cc6cd7f0e\",\n",
      "\t\t\"parent\": \"aaa6cc18836553e90f5d8111ecb2f793925199b8\",\n",
      "\t\t\"subject\": \"msq: add durable storage info (#14035)\",\n",
      "\t\t\"sanitized_subject_line\": \"msq-add-durable-storage-info-14035\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* msq: add durable storage info  * fix duplicate row  * Apply suggestions from code review  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>  ---------  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Apr 2023 13:28:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"aaa6cc18836553e90f5d8111ecb2f793925199b8\",\n",
      "\t\t\"parent\": \"179e2e8108b79b2b1a2dfe364765c467bc5996e5\",\n",
      "\t\t\"subject\": \"Make the tasks run with only a single directory (#14063)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-the-tasks-run-with-only-a-single-directory-14063\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make the tasks run with only a single directory  There was a change that tried to get indexing to run on multiple disks It made a bunch of changes to how tasks run, effectively hiding the \\\"safe\\\" directory for tasks to write files into from the task code itself making it extremely difficult to do anything correctly inside of a task.  This change reverts those changes inside of the tasks and makes it so that only the task runners are the ones that make decisions about which mount points should be used for storing task-related files.  It adds the config druid.worker.baseTaskDirs which can be used by the task runners to know which directories they should schedule tasks inside of. The TaskConfig remains the authoritative source of configuration for where and how an individual task should be operating.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Apr 2023 00:45:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"179e2e8108b79b2b1a2dfe364765c467bc5996e5\",\n",
      "\t\t\"parent\": \"d2f82f8dd624d15c7fd5b26ca710d6751bf78291\",\n",
      "\t\t\"subject\": \"adjust useSchemaDiscovery to also include the behavior of includeAllDimensions to support partial schema declaration without having to set two flags (#14076)\",\n",
      "\t\t\"sanitized_subject_line\": \"adjust-useSchemaDiscovery-to-also-include-the-behavior-of-includeAllDimensions-to-support-partial-schema-declaration-without-having-to-set-two-flags-14076\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Apr 2023 23:12:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d2f82f8dd624d15c7fd5b26ca710d6751bf78291\",\n",
      "\t\t\"parent\": \"81074411a99aadd8a899ceae7d8d12f2de347ac6\",\n",
      "\t\t\"subject\": \"Make GCP initialization truly lazy (#14077)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-GCP-initialization-truly-lazy-14077\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The GCP initialization pulls credentials for talking to GCP.  We want that to only happen when fully required and thus want the GCP-related objects lazily instantiated.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Apr 2023 23:10:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"81074411a99aadd8a899ceae7d8d12f2de347ac6\",\n",
      "\t\t\"parent\": \"f86ea5cbc4e0046cd6c8792436dae35955d3c6f7\",\n",
      "\t\t\"subject\": \"MSQ: Support multiple result columns with the same name. (#14025)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Support-multiple-result-columns-with-the-same-name.-14025\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Support multiple result columns with the same name.  This is allowed in SQL, and is supported by the regular SQL endpoint. We retain a validation that INSERT ... SELECT does not allow multiple columns with the same name, because column names in segments must be unique. \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Apr 2023 11:09:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f86ea5cbc4e0046cd6c8792436dae35955d3c6f7\",\n",
      "\t\t\"parent\": \"9ed8beca5e800301912c42364a208dbc93f629ae\",\n",
      "\t\t\"subject\": \"Separate web-checks from static-checks to improve build time (#14071)\",\n",
      "\t\t\"sanitized_subject_line\": \"Separate-web-checks-from-static-checks-to-improve-build-time-14071\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Moves web-checks to separate job \",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Apr 2023 20:17:03 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9ed8beca5e800301912c42364a208dbc93f629ae\",\n",
      "\t\t\"parent\": \"966cae1c942eb7e549b359d2d3f08412ec21a62c\",\n",
      "\t\t\"subject\": \"bug fixes and add support for boolean inputs to classic long dimension indexer (#14069)\",\n",
      "\t\t\"sanitized_subject_line\": \"bug-fixes-and-add-support-for-boolean-inputs-to-classic-long-dimension-indexer-14069\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * adds support for boolean inputs to the classic long dimension indexer, which plays nice with LONG being the semi official boolean type in Druid, and even nicer when druid.expressions.useStrictBooleans is set to true, since the sampler when using the new 'auto' schema when 'useSchemaDiscovery' is specified on the dimensions spec will call the type out as LONG * fix bugs with sampler response and new schema discovery stuff incorrectly using classic 'json' type for the logical schema instead of the new 'auto' type\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 20:49:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"966cae1c942eb7e549b359d2d3f08412ec21a62c\",\n",
      "\t\t\"parent\": \"3a7e4efdd6e12344c9d54eb853af7b13b5fee612\",\n",
      "\t\t\"subject\": \"Fix GHA CI branch trigger patterns (#14067)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-GHA-CI-branch-trigger-patterns-14067\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix matching pattern on release branches  * test\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 20:43:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3a7e4efdd6e12344c9d54eb853af7b13b5fee612\",\n",
      "\t\t\"parent\": \"29652bd2460768dad9eb3c51a9995f988528b136\",\n",
      "\t\t\"subject\": \"Docs: updating Kafka input format docs (#14049)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-updating-Kafka-input-format-docs-14049\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* updating Kafka input format docs  * typo  * spellcheck  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  ---------  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 20:06:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"29652bd2460768dad9eb3c51a9995f988528b136\",\n",
      "\t\t\"parent\": \"5ce1b0903ef4bf6917f16a1daf78373ed005d1fa\",\n",
      "\t\t\"subject\": \"fix NPE that can happen when merging all null nested v4 format columns (#14068)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-NPE-that-can-happen-when-merging-all-null-nested-v4-format-columns-14068\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 19:04:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ce1b0903ef4bf6917f16a1daf78373ed005d1fa\",\n",
      "\t\t\"parent\": \"89bdbdc3ed94cf2d7d5d8655488da179ffbace8c\",\n",
      "\t\t\"subject\": \"Add basic security functions to druidapi (follow up to #14009) (#14055)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-basic-security-functions-to-druidapi-follow-up-to-14009-14055\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Paul Rogers <progers@apache.org> \",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 10:55:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"89bdbdc3ed94cf2d7d5d8655488da179ffbace8c\",\n",
      "\t\t\"parent\": \"d61bd7f8f16c3f25ba4f81c5573edb1d7c504770\",\n",
      "\t\t\"subject\": \"Input source security feature should work for MSQ tasks (#14056)\",\n",
      "\t\t\"sanitized_subject_line\": \"Input-source-security-feature-should-work-for-MSQ-tasks-14056\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  Previously msq controller and worker tasks did not have implementations for the `getInputSourceResources()` method. This causes the submission of these tasks to fail if the following auth config is enabled:  `druid.auth.enableInputSourceSecurity=true`  Added implementations of this method for these tasks that return an empty set of input sources. This means that for these task types, if `druid.auth.enableInputSourceSecurity=true` config is used, the input source types will be properly computed and authorized in the SQL layer, but not if the equivalent controller / worker tasks are submitted to the task endpoint.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Apr 2023 11:36:15 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d61bd7f8f16c3f25ba4f81c5573edb1d7c504770\",\n",
      "\t\t\"parent\": \"00d777d848cd95941c994541f54637eadd585f32\",\n",
      "\t\t\"subject\": \"fix bug in nested v4 format merger from refactoring (#14053)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-in-nested-v4-format-merger-from-refactoring-14053\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 20:38:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"00d777d848cd95941c994541f54637eadd585f32\",\n",
      "\t\t\"parent\": \"2e87b5a901f69029bd3eccb9c23ebd9fdbe01dec\",\n",
      "\t\t\"subject\": \"Fix race condition in KubernetesTaskRunner between shutdown and getKnownTasks (#14030)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-race-condition-in-KubernetesTaskRunner-between-shutdown-and-getKnownTasks-14030\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix issues with null pointers on jobResponse  * fix unit tests  * Update extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/DruidKubernetesPeonClient.java  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>  * nullable  * fix error message  * Use jobs for known tasks instead of pods  * Remove log lines  * remove log lines  * PR change requests  * revert wait change  ---------  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 13:27:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2e87b5a901f69029bd3eccb9c23ebd9fdbe01dec\",\n",
      "\t\t\"parent\": \"cb302e1bd1092048875919d640bb65916c4ac796\",\n",
      "\t\t\"subject\": \"Input source security sql layer can handle input source with multiple types (#14050)\",\n",
      "\t\t\"sanitized_subject_line\": \"Input-source-security-sql-layer-can-handle-input-source-with-multiple-types-14050\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  This change allows for input sources used during MSQ ingestion to be authorized for multiple input source types, instead of just 1. Such an input source that allows for multiple types is the CombiningInputSource.  Also fixed bug that caused some input source specific functions to be authorized against the permissions  ` [     new ResourceAction(new Resource(ResourceType.EXTERNAL, ResourceType.EXTERNAL), Action.READ),     new ResourceAction(new Resource(ResourceType.EXTERNAL, {input_source_type}), Action.READ) ] `  when the inputSource based authorization feature is enabled, when it should instead be authorized against  ` [     new ResourceAction(new Resource(ResourceType.EXTERNAL, {input_source_type}), Action.READ) ] `\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 09:48:57 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb302e1bd1092048875919d640bb65916c4ac796\",\n",
      "\t\t\"parent\": \"1aef72aa7e8a89272084f8f4d2f81e0c038e769b\",\n",
      "\t\t\"subject\": \"Use apache-jar-resource-bundle:1.5 instead of 1.5-SNAPSHOT (#14054)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-apache-jar-resource-bundle-1.5-instead-of-1.5-SNAPSHOT-14054\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 18:55:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1aef72aa7e8a89272084f8f4d2f81e0c038e769b\",\n",
      "\t\t\"parent\": \"871209830108008cd59e87adb58d11349600a8dd\",\n",
      "\t\t\"subject\": \"Bump up the version in pom to 27.0.0 in preparation of release (#14051)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-up-the-version-in-pom-to-27.0.0-in-preparation-of-release-14051\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 14:56:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"871209830108008cd59e87adb58d11349600a8dd\",\n",
      "\t\t\"parent\": \"d52bc333aa63064871ced8326460b834fa6bfced\",\n",
      "\t\t\"subject\": \"Fixing overlord unable to become a leader when syncing the lock from metadata store. (#14038)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-overlord-unable-to-become-a-leader-when-syncing-the-lock-from-metadata-store.-14038\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 12:37:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d52bc333aa63064871ced8326460b834fa6bfced\",\n",
      "\t\t\"parent\": \"166cb6203b115dc9cc279f429a6696cbebe18151\",\n",
      "\t\t\"subject\": \"Frames: Ensure nulls are read as default values when appropriate. (#14020)\",\n",
      "\t\t\"sanitized_subject_line\": \"Frames-Ensure-nulls-are-read-as-default-values-when-appropriate.-14020\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Frames: Ensure nulls are read as default values when appropriate.  Fixes a bug where LongFieldWriter didn't write a properly transformed zero when writing out a null. This had no meaningful effect in SQL-compatible null handling mode, because the field would get treated as a null anyway. But it does have an effect in default-value mode: it would cause Long.MIN_VALUE to get read out instead of zero.  Also adds NullHandling checks to the various frame-based column selectors, allowing reading of nullable frames by servers in default-value mode.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Apr 2023 05:28:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"166cb6203b115dc9cc279f429a6696cbebe18151\",\n",
      "\t\t\"parent\": \"a769f1465223c608d8457bf6a9e991ad4ce69569\",\n",
      "\t\t\"subject\": \"Remove unnecessary python topic. Style changes to quickstart. (#13647)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-unnecessary-python-topic.-Style-changes-to-quickstart.-13647\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Apr 2023 09:55:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a769f1465223c608d8457bf6a9e991ad4ce69569\",\n",
      "\t\t\"parent\": \"5ee4ecee6216c9fd93c0bb7dad1645c8fa44a77d\",\n",
      "\t\t\"subject\": \"fix compile with java 8 (#14045)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-compile-with-java-8-14045\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Apr 2023 07:01:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ee4ecee6216c9fd93c0bb7dad1645c8fa44a77d\",\n",
      "\t\t\"parent\": \"f41468fd466ab239d3373755fba28c0d4dbdb4b5\",\n",
      "\t\t\"subject\": \"Web console: use new sampler features (#14017)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-use-new-sampler-features-14017\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use new sampler features  * supprot kafka format  * update DQT, fix tests  * prefer non numeric formats  * fix input format step  * boost SQL data loader  * delete dimension in auto discover mode  * inline example specs  * feedback updates  * yeet the format into valueFormat when switching to kafka  * kafka format is now a toggle  * even better form layout  * rename\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Apr 2023 06:28:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f41468fd466ab239d3373755fba28c0d4dbdb4b5\",\n",
      "\t\t\"parent\": \"f47b05a98cc3ec748bef6958fceac4ac3f91064e\",\n",
      "\t\t\"subject\": \"fix off by one error in FrontCodedIndexedWriter and FrontCodedIntArrayIndexedWriter getCardinality method (#14047)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-off-by-one-error-in-FrontCodedIndexedWriter-and-FrontCodedIntArrayIndexedWriter-getCardinality-method-14047\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix off by one error in FrontCodedIndexedWriter and FrontCodedIntArrayIndexedWriter getCardinality method\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Apr 2023 03:11:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f47b05a98cc3ec748bef6958fceac4ac3f91064e\",\n",
      "\t\t\"parent\": \"1b75b2d3d60e5415dc00dc6415fcd620064e706f\",\n",
      "\t\t\"subject\": \"Hyphenate multi value string for consistency. Fixup extra space in javadoc. (#14043)\",\n",
      "\t\t\"sanitized_subject_line\": \"Hyphenate-multi-value-string-for-consistency.-Fixup-extra-space-in-javadoc.-14043\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Apr 2023 11:46:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1b75b2d3d60e5415dc00dc6415fcd620064e706f\",\n",
      "\t\t\"parent\": \"b4157e32aecb7a0ea5930ea1efc4586431c0ffbf\",\n",
      "\t\t\"subject\": \"revert .idea/misc.xml changes (#14044)\",\n",
      "\t\t\"sanitized_subject_line\": \"revert-.idea-misc.xml-changes-14044\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 17:45:03 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b4157e32aecb7a0ea5930ea1efc4586431c0ffbf\",\n",
      "\t\t\"parent\": \"1c2744b31e9cb3d9eabb248fa69292919f26a29b\",\n",
      "\t\t\"subject\": \"Update api.md (#13436)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-api.md-13436\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update api.md  I have created changes in api call of python according to latest version of requests 2.28.1 library. Along with this there are some irregularities between use of <your-instance> and <hostname> so I have tried to fix that also.  * Update api.md  made some changes in declaring USER and PASSWORD\",\n",
      "\t\t\"author_name\": \"Suraj Sanjay Kadam\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 15:05:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c2744b31e9cb3d9eabb248fa69292919f26a29b\",\n",
      "\t\t\"parent\": \"5c0221375c8dfa4c3509eb9e1b6864941dfe84c7\",\n",
      "\t\t\"subject\": \"Fix querying sql (#14026)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-querying-sql-14026\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 14:50:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5c0221375c8dfa4c3509eb9e1b6864941dfe84c7\",\n",
      "\t\t\"parent\": \"92912a6a2b5cbea282137151dfa0314b97568988\",\n",
      "\t\t\"subject\": \" Allow for Input source security in native task layer (#14003)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-for-Input-source-security-in-native-task-layer-14003\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes #13837.  ### Description  This change allows for input source type security in the native task layer.  To enable this feature, the user must set the following property to true:  `druid.auth.enableInputSourceSecurity=true`  The default value for this property is false, which will continue the existing functionality of needing authorization to write to the respective datasource.  When this config is enabled, the users will be required to be authorized for the following resource action, in addition to write permission on the respective datasource.  `new ResourceAction(new Resource(ResourceType.EXTERNAL, {INPUT_SOURCE_TYPE}, Action.READ`  where `{INPUT_SOURCE_TYPE}` is the type of the input source being used;, http, inline, s3, etc..  Only tasks that provide a non-default implementation of the `getInputSourceResources` method can be submitted when config `druid.auth.enableInputSourceSecurity=true` is set. Otherwise, a 400 error will be thrown.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 13:13:09 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"92912a6a2b5cbea282137151dfa0314b97568988\",\n",
      "\t\t\"parent\": \"b11c0bc249de96ae4151595e1ff22001f2468fa5\",\n",
      "\t\t\"subject\": \"JOIN or UNNEST queries over tombstone segment can fail (#14021)\",\n",
      "\t\t\"sanitized_subject_line\": \"JOIN-or-UNNEST-queries-over-tombstone-segment-can-fail-14021\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Join,Unnest queries over tombstone segment can fail\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 16:55:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b11c0bc249de96ae4151595e1ff22001f2468fa5\",\n",
      "\t\t\"parent\": \"030ed911d4073843dc76a655e6fc8066b310af46\",\n",
      "\t\t\"subject\": \"smarter nested column index utilization (#13977)\",\n",
      "\t\t\"sanitized_subject_line\": \"smarter-nested-column-index-utilization-13977\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* smarter nested column index utilization changes: * adds skipValueRangeIndexScale and skipValuePredicateIndexScale to ColumnConfig (e.g. DruidProcessingConfig) available as system config via druid.processing.indexes.skipValueRangeIndexScale and druid.processing.indexes.skipValuePredicateIndexScale * NestedColumnIndexSupplier uses skipValueRangeIndexScale and skipValuePredicateIndexScale to multiply by the total number of rows to be processed to determine the threshold at which we should no longer consider using bitmap indexes because it will be too many operations * Default values for skipValueRangeIndexScale and skipValuePredicateIndexScale have been initially set to 0.08, but are separate to allow independent tuning * these are not documented on purpose yet because they are kind of hard to explain, the mainly exist to help conduct larger scale experiments than the jmh benchmarks used to derive the initial set of values * these changes provide a pretty sweet performance boost for filter processing on nested columns \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Apr 2023 04:09:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"030ed911d4073843dc76a655e6fc8066b310af46\",\n",
      "\t\t\"parent\": \"b98eed8fb83e3868fdd88c6edff696bf0290cf15\",\n",
      "\t\t\"subject\": \"Temporarily revert extended table functions for Druid 26 (#14019)\",\n",
      "\t\t\"sanitized_subject_line\": \"Temporarily-revert-extended-table-functions-for-Druid-26-14019\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 21:09:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b98eed8fb83e3868fdd88c6edff696bf0290cf15\",\n",
      "\t\t\"parent\": \"5810e650d43d6195a88994372c7aedc8cf5622ab\",\n",
      "\t\t\"subject\": \"Revert quoting lookup fix. (#14034)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-quoting-lookup-fix.-14034\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Revert \\\"Add ANSI_QUOTES propety to DBI init in lookups. (#13826)\\\"  This reverts commit 9e9976001c5692732be4b7e28d79886e0d6859a9.  * Revert \\\"Quote and escape literals in JDBC lookup to allow reserved identifiers. (#13632)\\\"  This reverts commit 41fdf6eafbf3ff4bb67909ba15a2eaeb648dd036.  * fix typo.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 20:52:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5810e650d43d6195a88994372c7aedc8cf5622ab\",\n",
      "\t\t\"parent\": \"ccf48245d730f430881305e54907e3782a251b3b\",\n",
      "\t\t\"subject\": \"K8s mm less fixes (#14028)\",\n",
      "\t\t\"sanitized_subject_line\": \"K8s-mm-less-fixes-14028\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Update Fabric8 version and allow metrics monitors to be overriden\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 22:23:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ccf48245d730f430881305e54907e3782a251b3b\",\n",
      "\t\t\"parent\": \"319f99db05aefb8f232dfbf265b38ca9541fef4c\",\n",
      "\t\t\"subject\": \"Update documentation for Kafka Supervisor IdleConfig (#14032)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-documentation-for-Kafka-Supervisor-IdleConfig-14032\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 21:55:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"319f99db05aefb8f232dfbf265b38ca9541fef4c\",\n",
      "\t\t\"parent\": \"e6a11707cba7284783860fc1155877676cfae1f0\",\n",
      "\t\t\"subject\": \"Always use file sizes when determining batch ingest splits (#13955)\",\n",
      "\t\t\"sanitized_subject_line\": \"Always-use-file-sizes-when-determining-batch-ingest-splits-13955\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Always use file sizes when determining batch ingest splits.  Main changes:  1) Update CloudObjectInputSource and its subclasses (S3, GCS,    Azure, Aliyun OSS) to use SplitHintSpecs in all cases. Previously, they    were only used for prefixes, not uris or objects.  2) Update ExternalInputSpecSlicer (MSQ) to consider file size. Previously,    file size was ignored; all files were treated as equal weight when    determining splits.  A side effect of these changes is that we'll make additional network calls to find the sizes of objects when users specify URIs or objects as opposed to prefixes. IMO, this is worth it because it's the only way to respect the user's split hint and task assignment settings.  Secondary changes:  1) S3, Aliyun OSS: Use getObjectMetadata instead of listObjects to get    metadata for a single object. This is a simpler call that is also    expected to be less expensive.  2) Azure: Fix a bug where getBlobLength did not populate blob    reference attributes, and therefore would not actually retrieve the    blob length.  3) MSQ: Align dynamic slicing logic between ExternalInputSpecSlicer and    TableInputSpecSlicer.  4) MSQ: Adjust WorkerInputs to ensure there is always at least one    worker, even if it has a nil slice.  * Add msqCompatible to testGroupByWithImpossibleTimeFilter.  * Fix tests.  * Add additional tests.  * Remove unused stuff.  * Remove more unused stuff.  * Adjust thresholds.  * Remove irrelevant test.  * Fix comments.  * Fix bug.  * Updates.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 08:54:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e6a11707cba7284783860fc1155877676cfae1f0\",\n",
      "\t\t\"parent\": \"1c8a18467744445a6a2c05bb43ff935618baecc6\",\n",
      "\t\t\"subject\": \"Adding query stack fault to MSQ to capture native query errors. (#13926)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-query-stack-fault-to-MSQ-to-capture-native-query-errors.-13926\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add a new fault \\\"QueryRuntimeError\\\" to MSQ engine to capture native query errors.  * Fixed bug in MSQ fault tolerance where worker were being retried if `UnexpectedMultiValueDimensionException` was thrown. * An exception from the query runtime with `org.apache.druid.query` as the package name is thrown as a QueryRuntimeError\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 16:29:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c8a18467744445a6a2c05bb43ff935618baecc6\",\n",
      "\t\t\"parent\": \"012b49d5e5588d4ac2a8f588100d5c844727a05e\",\n",
      "\t\t\"subject\": \"add null safety checks for DiscoveryDruidNode services for more resilient http server and task views (#13930)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-null-safety-checks-for-DiscoveryDruidNode-services-for-more-resilient-http-server-and-task-views-13930\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add null safety checks for DiscoveryDruidNode services for more resilient http server and task vi\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 02:45:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"012b49d5e5588d4ac2a8f588100d5c844727a05e\",\n",
      "\t\t\"parent\": \"d21babc5b831a90b904e499f4435cd60d168e99a\",\n",
      "\t\t\"subject\": \"Fix the order of aggregator finalization in GroupByPostShuffleFrameProcessor (MSQ) (#14022)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-order-of-aggregator-finalization-in-GroupByPostShuffleFrameProcessor-MSQ-14022\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix the order in which finalization is done  * add comment explaining the change  * null handling case\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Apr 2023 11:04:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d21babc5b831a90b904e499f4435cd60d168e99a\",\n",
      "\t\t\"parent\": \"f60f377e5f67221f8a4a34163b257ecffece60d7\",\n",
      "\t\t\"subject\": \"remix nested columns (#14014)\",\n",
      "\t\t\"sanitized_subject_line\": \"remix-nested-columns-14014\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * introduce ColumnFormat to separate physical storage format from logical type. ColumnFormat is now used instead of ColumnCapabilities to get column handlers for segment creation * introduce new 'auto' type indexer and merger which produces a new common nested format of columns, which is the next logical iteration of the nested column stuff. Essentially this is an automatic type column indexer that produces the most appropriate column for the given inputs, making either STRING, ARRAY<STRING>, LONG, ARRAY<LONG>, DOUBLE, ARRAY<DOUBLE>, or COMPLEX<json>. * revert NestedDataColumnIndexer, NestedDataColumnMerger, NestedDataColumnSerializer to their version pre #13803 behavior (v4) for backwards compatibility * fix a bug in RoaringBitmapSerdeFactory if anything actually ever wrote out an empty bitmap using toBytes and then later tried to read it (the nerve!) \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 17:51:59 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f60f377e5f67221f8a4a34163b257ecffece60d7\",\n",
      "\t\t\"parent\": \"7e572eef086cd47607d680e607954e293fecf9c4\",\n",
      "\t\t\"subject\": \"Fix issues with null pointers on jobResponse (#14010)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-issues-with-null-pointers-on-jobResponse-14010\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix issues with null pointers on jobResponse  * fix unit tests  * Update extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/DruidKubernetesPeonClient.java  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>  * nullable  * fix error message  ---------  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 17:48:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7e572eef086cd47607d680e607954e293fecf9c4\",\n",
      "\t\t\"parent\": \"232491eea47c261ee881b6beb2a3feccc311b81d\",\n",
      "\t\t\"subject\": \"docs: sql unnest and cleanup unnest datasource (#13736)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-sql-unnest-and-cleanup-unnest-datasource-13736\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net> Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Paul Rogers <paul-rogers@users.noreply.github.com> Co-authored-by: Jill Osborne <jill.osborne@imply.io> Co-authored-by: Anshu Makkar <83963638+anshu-makkar@users.noreply.github.com> Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com> Co-authored-by: Elliott Freis <108356317+imply-elliott@users.noreply.github.com> Co-authored-by: Nicholas Lippis <nick.lippis@imply.io> Co-authored-by: Rohan Garg <7731512+rohangarg@users.noreply.github.com> Co-authored-by: Karan Kumar <karankumar1100@gmail.com> Co-authored-by: Vadim Ogievetsky <vadim@ogievetsky.com> Co-authored-by: Gian Merlino <gianmerlino@gmail.com> Co-authored-by: Clint Wylie <cwylie@apache.org> Co-authored-by: Adarsh Sanjeev <adarshsanjeev@gmail.com> Co-authored-by: Laksh Singla <lakshsingla@gmail.com> \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 13:07:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"232491eea47c261ee881b6beb2a3feccc311b81d\",\n",
      "\t\t\"parent\": \"ab91768ddfa87fe2764c7504ed807966f9abf423\",\n",
      "\t\t\"subject\": \"Document our conventions for writing messages (#13916)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-our-conventions-for-writing-messages-13916\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Document our conventions for writing messages\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Apr 2023 21:30:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ab91768ddfa87fe2764c7504ed807966f9abf423\",\n",
      "\t\t\"parent\": \"6c33ef8b150e6cb6f20b76c78ff03f76a9ca40ab\",\n",
      "\t\t\"subject\": \"Fix broken shields (#14015)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-broken-shields-14015\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 09:41:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c33ef8b150e6cb6f20b76c78ff03f76a9ca40ab\",\n",
      "\t\t\"parent\": \"5a9c13293b7906d82176cc13c368002e36e02fdb\",\n",
      "\t\t\"subject\": \"Improve entries (#14016)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-entries-14016\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 09:40:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5a9c13293b7906d82176cc13c368002e36e02fdb\",\n",
      "\t\t\"parent\": \"ca94f7146f50900aeab2e520bec032ad3ded4368\",\n",
      "\t\t\"subject\": \"remove duplicate trigger on Cron Job ITs workflow (#14013)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-duplicate-trigger-on-Cron-Job-ITs-workflow-14013\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Apr 2023 09:39:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca94f7146f50900aeab2e520bec032ad3ded4368\",\n",
      "\t\t\"parent\": \"4560b9d8aaee34bc4da14cae8ffc4f4e35c96f81\",\n",
      "\t\t\"subject\": \"Planning correctly for order by queries on time which previously thre\\u2026 (#13965)\",\n",
      "\t\t\"sanitized_subject_line\": \"Planning-correctly-for-order-by-queries-on-time-which-previously-thre-13965\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Planning correctly for order by queries on time which previously threw a planning error * Updating toDruidQueryForExplaining on a query data source if there is a window on the partial query\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Apr 2023 18:30:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4560b9d8aaee34bc4da14cae8ffc4f4e35c96f81\",\n",
      "\t\t\"parent\": \"217b0f6832c819b6c2b264418038b86049769ad8\",\n",
      "\t\t\"subject\": \"New error message for task deletion (#14008)\",\n",
      "\t\t\"sanitized_subject_line\": \"New-error-message-for-task-deletion-14008\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* New error message  * Add unit test\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Apr 2023 14:26:09 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"217b0f6832c819b6c2b264418038b86049769ad8\",\n",
      "\t\t\"parent\": \"518698a9520a52bfb0cc1118f53df536f09aaf44\",\n",
      "\t\t\"subject\": \"Eagerly fetching remote s3 files leading to out of disk (OOD) (#13981)\",\n",
      "\t\t\"sanitized_subject_line\": \"Eagerly-fetching-remote-s3-files-leading-to-out-of-disk-OOD-13981\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Eagerly fetching remote s3 files leading to OOD. \",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Apr 2023 14:10:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"518698a9520a52bfb0cc1118f53df536f09aaf44\",\n",
      "\t\t\"parent\": \"981662e9f407093162d5649c9e8a223c131d8c78\",\n",
      "\t\t\"subject\": \"lower segment heap footprint and fix bug with expression type coercion (#14002)\",\n",
      "\t\t\"sanitized_subject_line\": \"lower-segment-heap-footprint-and-fix-bug-with-expression-type-coercion-14002\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 31 Mar 2023 13:53:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"981662e9f407093162d5649c9e8a223c131d8c78\",\n",
      "\t\t\"parent\": \"e3211e3be050b8c52fdd718b32007e8f502408b8\",\n",
      "\t\t\"subject\": \"Web console: add a nice UI for overlord dynamic configs and improve the docs (#13993)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-add-a-nice-UI-for-overlord-dynamic-configs-and-improve-the-docs-13993\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* in progress  * better form  * doc updates  * doc changes  * add inline docs  * fix tests  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/configuration/index.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * final fixes  * fix case  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * fix overflow  * fix spelling  ---------  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com> Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 31 Mar 2023 10:12:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e3211e3be050b8c52fdd718b32007e8f502408b8\",\n",
      "\t\t\"parent\": \"51f3db2ce672b82ab27b846d56b62af4de5fc41a\",\n",
      "\t\t\"subject\": \"actually backwards compatible frontCoded string encoding strategy (#13996)\",\n",
      "\t\t\"sanitized_subject_line\": \"actually-backwards-compatible-frontCoded-string-encoding-strategy-13996\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 31 Mar 2023 02:24:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"51f3db2ce672b82ab27b846d56b62af4de5fc41a\",\n",
      "\t\t\"parent\": \"1eeecf5fb2909e561d0ec23941ce8755760476ba\",\n",
      "\t\t\"subject\": \"Fix peon errors when executing tasks in ipv6(#13972) (#13995)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-peon-errors-when-executing-tasks-in-ipv6-13972-13995\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"soullkk\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 31 Mar 2023 09:18:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1eeecf5fb2909e561d0ec23941ce8755760476ba\",\n",
      "\t\t\"parent\": \"eb3120740227f10f6d198ee614e32ba7aacd810d\",\n",
      "\t\t\"subject\": \"Fixing regression issues on unnest (#13976)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-regression-issues-on-unnest-13976\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* select sum(c) on an unnested column now does not return 'Type mismatch' error and works properly * Making sure an inner join query works properly * Having on unnested column with a group by now works correctly * count(*) on an unnested query now works correctly\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 31 Mar 2023 09:06:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb3120740227f10f6d198ee614e32ba7aacd810d\",\n",
      "\t\t\"parent\": \"47face9ca92a50290e9d98c7a84e5648c5417894\",\n",
      "\t\t\"subject\": \"Using MinIO to run S3DeepStorage ITs (#13997)\",\n",
      "\t\t\"sanitized_subject_line\": \"Using-MinIO-to-run-S3DeepStorage-ITs-13997\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Using MinIO to S3DeepStorage ITs  * Adding S3DeepStorageTest to github actions revised ITs \",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 30 Mar 2023 12:15:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47face9ca92a50290e9d98c7a84e5648c5417894\",\n",
      "\t\t\"parent\": \"61a35262ec0afac578fd0a39f87a695791644225\",\n",
      "\t\t\"subject\": \"Handle null values in BrokerServerView.serverAddedSegment (#13980)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-null-values-in-BrokerServerView.serverAddedSegment-13980\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Due to race conditions, the BrokerServerView may sometimes try to add a segment to a server which has already been removed from the inventory. This results in an NPE and keeps the BrokerServerView from processing all change requests.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 30 Mar 2023 16:19:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"61a35262ec0afac578fd0a39f87a695791644225\",\n",
      "\t\t\"parent\": \"44abe2b96f97b5e0d4e630809ae318d32f7f3351\",\n",
      "\t\t\"subject\": \"Kubernetes task runner live reports (#13986)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kubernetes-task-runner-live-reports-13986\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Implement Live Reports for the KubernetesTaskRunner\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 30 Mar 2023 10:30:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44abe2b96f97b5e0d4e630809ae318d32f7f3351\",\n",
      "\t\t\"parent\": \"3bb67721f718d54d80f8b2690f9897d8cdc98ee4\",\n",
      "\t\t\"subject\": \"Fix bug in k8s task runner in handling deleted jobs (#14001)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bug-in-k8s-task-runner-in-handling-deleted-jobs-14001\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"With the KubernetesTaskRunner, if a task is manually shutdown via the web console while running or the corresponding k8s job is manually deleted, the thread responsible for overseeing the task gets stuck in a loop because the fabric8 client sends one event to it that the job is null when the job is deleted, but this doesn't pass the condition.  This means that the thread is stuck waiting on a fabric8 event (the job being successful) that will never come up until maxTaskDuration (default 4 hours). If a user of the extension is trying to use a limited taskqueue maxSize, this can cause problems as the k8s executor pool is unable to pick up additional tasks (since threads are stuck waiting on the old tasks that have already been deleted).\",\n",
      "\t\t\"author_name\": \"George Shiqi Wu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 30 Mar 2023 10:09:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3bb67721f718d54d80f8b2690f9897d8cdc98ee4\",\n",
      "\t\t\"parent\": \"abb7133153be7f7f638e2f83e3f2d9339737efdd\",\n",
      "\t\t\"subject\": \"Allow for Input source security in SQL layer (#13989)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-for-Input-source-security-in-SQL-layer-13989\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This change introduces the concept of input source type security model, proposed in #13837.. With this change, this feature is only available at the SQL layer, but we will expand to native layer in a follow up PR.  To enable this feature, the user must set the following property to true:  druid.auth.enableInputSourceSecurity=true  The default value for this property is false, which will continue the existing functionality of having the usage all external sources being authorized against the hardcoded resource action  new ResourceAction(new Resource(ResourceType.EXTERNAL, ResourceType.EXTERNAL), Action.READ  When this config is enabled, the users will be required to be authorized for the following resource action  new ResourceAction(new Resource(ResourceType.EXTERNAL, {INPUT_SOURCE_TYPE}, Action.READ  where {INPUT_SOURCE_TYPE} is the type of the input source being used;, http, inline, s3, etc..  Documentation has not been added for the feature as it is not complete at the moment, as we still need to enable this for the native layer in a follow up pr.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 22:15:33 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"abb7133153be7f7f638e2f83e3f2d9339737efdd\",\n",
      "\t\t\"parent\": \"f7158871727e0b98d41b6927a2caf71e6eedc5ca\",\n",
      "\t\t\"subject\": \"Web console: use EXTEND syntax (#13985)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-use-EXTEND-syntax-13985\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use EXTEND syntax  * update licenses  * update demo queries  * updated snapshots  * add join algorithm selector  * dismiss\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 16:19:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7158871727e0b98d41b6927a2caf71e6eedc5ca\",\n",
      "\t\t\"parent\": \"e4c5122a60367c1e6f814ab9bec8c64c0629f128\",\n",
      "\t\t\"subject\": \"Debug docker logs on ITs failure. (#13978)\",\n",
      "\t\t\"sanitized_subject_line\": \"Debug-docker-logs-on-ITs-failure.-13978\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 09:06:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e4c5122a60367c1e6f814ab9bec8c64c0629f128\",\n",
      "\t\t\"parent\": \"ccdf30e39960f710e5bf8fc110be787a0937784f\",\n",
      "\t\t\"subject\": \"Fixing checkstyle (#14000)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-checkstyle-14000\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 20:21:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ccdf30e39960f710e5bf8fc110be787a0937784f\",\n",
      "\t\t\"parent\": \"8dce3ca4d594ddc498c1372d4d6cef3c6c3ed056\",\n",
      "\t\t\"subject\": \"Bump Joda-Time version for current DateTimeZone data (#13999)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-Joda-Time-version-for-current-DateTimeZone-data-13999\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 20:15:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8dce3ca4d594ddc498c1372d4d6cef3c6c3ed056\",\n",
      "\t\t\"parent\": \"3c096c01a2c4554b6f107627fb55755b4f2a6cb0\",\n",
      "\t\t\"subject\": \"OOM fix for running MSQ jobs with `intermediateSuperSorterStorageMaxLocalBytes` set (#13974)\",\n",
      "\t\t\"sanitized_subject_line\": \"OOM-fix-for-running-MSQ-jobs-with-intermediateSuperSorterStorageMaxLocalBytes-set-13974\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"While using intermediateSuperSorterStorageMaxLocalBytes the super sorter was retaining references of the memory allocator.  The fix clears the current outputChannel when close() is called on the ComposingWritableFrameChannel.java \",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 18:00:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c096c01a2c4554b6f107627fb55755b4f2a6cb0\",\n",
      "\t\t\"parent\": \"488f1d83634e002c52ad9b7ff8c4cbb00efb4937\",\n",
      "\t\t\"subject\": \"cache mvn dependencies across tests without building (#13962)\",\n",
      "\t\t\"sanitized_subject_line\": \"cache-mvn-dependencies-across-tests-without-building-13962\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 16:27:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"488f1d83634e002c52ad9b7ff8c4cbb00efb4937\",\n",
      "\t\t\"parent\": \"2219e68fa3c602eaad8f5ba84acc36f8e2cabebc\",\n",
      "\t\t\"subject\": \"Do not print error message if pod not found when getting task location (#13971)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-print-error-message-if-pod-not-found-when-getting-task-location-13971\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Do not print error message if pod not found when getting task location\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Mar 2023 13:27:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2219e68fa3c602eaad8f5ba84acc36f8e2cabebc\",\n",
      "\t\t\"parent\": \"76fe26d4ba2cd73ded87be4b5708030aec6624d1\",\n",
      "\t\t\"subject\": \"add backwards compat mode for frontCoded stringEncodingStrategy (#13988)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-backwards-compat-mode-for-frontCoded-stringEncodingStrategy-13988\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Mar 2023 14:44:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"76fe26d4ba2cd73ded87be4b5708030aec6624d1\",\n",
      "\t\t\"parent\": \"2f986752859557ff4715f443dc176e5dd86f16d2\",\n",
      "\t\t\"subject\": \"Fix typos, add tests for http() function (#13954)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-typos-add-tests-for-http-function-13954\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Mar 2023 14:41:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f986752859557ff4715f443dc176e5dd86f16d2\",\n",
      "\t\t\"parent\": \"c2fe6a4956de416ce7e91fa82847dd4219ffd50a\",\n",
      "\t\t\"subject\": \"Tuple sketch SQL support (#13887)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tuple-sketch-SQL-support-13887\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR is a follow-up to #13819 so that the Tuple sketch functionality can be used in SQL for both ingestion using Multi-Stage Queries (MSQ) and also for analytic queries against Tuple sketch columns.\",\n",
      "\t\t\"author_name\": \"frankgrimes97\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Mar 2023 18:47:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c2fe6a4956de416ce7e91fa82847dd4219ffd50a\",\n",
      "\t\t\"parent\": \"e8e808257336c2c4eb07915bb457024a5d3c8749\",\n",
      "\t\t\"subject\": \"Reworking s3 connector with various improvements (#13960)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reworking-s3-connector-with-various-improvements-13960\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Reworking s3 connector with 1. Adding retries 2. Adding max fetch size 3. Using s3Utils for most of the api's 4. Fixing bugs in DurableStorageCleaner 5. Moving to Iterator for listDir call \",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Mar 2023 17:05:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e8e808257336c2c4eb07915bb457024a5d3c8749\",\n",
      "\t\t\"parent\": \"d5b1b5bc8e751b8a45b2a2bf5a02ee2018968a9f\",\n",
      "\t\t\"subject\": \"Update OIDCConfig with scope information  (#13973)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-OIDCConfig-with-scope-information-13973\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Allow users to provide custom scope through OIDC configuration\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Mar 2023 14:50:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d5b1b5bc8e751b8a45b2a2bf5a02ee2018968a9f\",\n",
      "\t\t\"parent\": \"062d72b67eccbb754fe74c7328cd06e0026fe5bf\",\n",
      "\t\t\"subject\": \"nested columns + arrays = array columns! (#13803)\",\n",
      "\t\t\"sanitized_subject_line\": \"nested-columns-arrays-array-columns-13803\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"array columns! changes: * add support for storing nested arrays of string, long, and double values as specialized nested columns instead of breaking them into separate element columns * nested column type mimic behavior means that columns ingested with only root arrays of primitive values will be ARRAY typed columns * neat test refactor stuff * add v4 segment test * add array element indexes * add tests for unnest and array columns * fix unnest column value selector cursor handling of null and empty arrays\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Mar 2023 12:42:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"062d72b67eccbb754fe74c7328cd06e0026fe5bf\",\n",
      "\t\t\"parent\": \"daff7fe73b880b84c86ea425a5a98514a50542a8\",\n",
      "\t\t\"subject\": \"Add timeout to TaskStartTimeoutFault. (#13970)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-timeout-to-TaskStartTimeoutFault.-13970\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add timeout to TaskStartTimeoutFault.  Makes the error message a bit more useful.  * Update docs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Mar 2023 23:37:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"daff7fe73b880b84c86ea425a5a98514a50542a8\",\n",
      "\t\t\"parent\": \"13ffeb50bacd995e99090b502ea441f8634d8369\",\n",
      "\t\t\"subject\": \"Document how to report security issues (#13886)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-how-to-report-security-issues-13886\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Document how to report security issues on the security overview page, so we can link this page from the homepage. That should make all the other important security information easier to find as well.\",\n",
      "\t\t\"author_name\": \"Arnout Engelen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Mar 2023 11:26:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"13ffeb50bacd995e99090b502ea441f8634d8369\",\n",
      "\t\t\"parent\": \"19db32d6b4ba6986075acc5566f3ce9c97561211\",\n",
      "\t\t\"subject\": \"should retry when failed to pause realtime task (#11515)\",\n",
      "\t\t\"sanitized_subject_line\": \"should-retry-when-failed-to-pause-realtime-task-11515\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"kaijianding\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 25 Mar 2023 19:03:13 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"19db32d6b4ba6986075acc5566f3ce9c97561211\",\n",
      "\t\t\"parent\": \"598eaad7e1ceac983ac0fef7766d0455f57eda82\",\n",
      "\t\t\"subject\": \"Add JWT authenticator support for validating ID Tokens (#13242)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-JWT-authenticator-support-for-validating-ID-Tokens-13242\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Expands the OIDC based auth in Druid by adding a JWT Authenticator that validates ID Tokens associated with a request. The existing pac4j authenticator works for authenticating web users while accessing the console, whereas this authenticator is for validating Druid API requests made by Direct clients. Services already supporting OIDC can attach their ID tokens to the Druid requests under the Authorization request header.\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 25 Mar 2023 18:41:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"598eaad7e1ceac983ac0fef7766d0455f57eda82\",\n",
      "\t\t\"parent\": \"549018d07648fdedacd0d132cd6b07a4f8bbbfee\",\n",
      "\t\t\"subject\": \"Fix HSTS for middle manager (#13975)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-HSTS-for-middle-manager-13975\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fix HSTS for middle manager\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 25 Mar 2023 14:01:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"549018d07648fdedacd0d132cd6b07a4f8bbbfee\",\n",
      "\t\t\"parent\": \"de27c7d3c12386491b3b5903fa64015cee0b01b1\",\n",
      "\t\t\"subject\": \"Revert \\\"Update docs.\\\"\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Update-docs\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit de27c7d3c12386491b3b5903fa64015cee0b01b1. \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"Gian Merlino\",\n",
      "\t\t\"date\": \"Fri, 24 Mar 2023 17:16:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de27c7d3c12386491b3b5903fa64015cee0b01b1\",\n",
      "\t\t\"parent\": \"8a72544bd2cd7b2af7e12ccf88def6db46fcd356\",\n",
      "\t\t\"subject\": \"Update docs.\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-docs\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"Gian Merlino\",\n",
      "\t\t\"date\": \"Fri, 24 Mar 2023 17:15:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8a72544bd2cd7b2af7e12ccf88def6db46fcd356\",\n",
      "\t\t\"parent\": \"976d39281fa8903850432abac85f1bcb067dd867\",\n",
      "\t\t\"subject\": \"Hook up pod template adapter (#13966)\",\n",
      "\t\t\"sanitized_subject_line\": \"Hook-up-pod-template-adapter-13966\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Hook up PodTemplateTaskAdapter  * Make task adapter TYPE parameters final  * Rename adapters types  * Include specified adapter name in exception message  * Documentation for sidecarSupport deprecation  * Fix order  * Set TASK_ID as environment variable in PodTemplateTaskAdapter (#13969)  * Update docs/development/extensions-contrib/k8s-jobs.md  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>  * Hook up PodTemplateTaskAdapter  * Make task adapter TYPE parameters final  * Rename adapters types  * Include specified adapter name in exception message  * Documentation for sidecarSupport deprecation  * Fix order  * fix spelling errors  ---------  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Mar 2023 12:13:46 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"976d39281fa8903850432abac85f1bcb067dd867\",\n",
      "\t\t\"parent\": \"36df2495e135a12efea3d3b4765e960753d497fa\",\n",
      "\t\t\"subject\": \"Fix some broken links in docs (#13968)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-some-broken-links-in-docs-13968\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Mar 2023 10:48:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36df2495e135a12efea3d3b4765e960753d497fa\",\n",
      "\t\t\"parent\": \"139a058ba712cbc6547ab403cfbf5636884cb7e0\",\n",
      "\t\t\"subject\": \"Set TASK_ID as environment variable in PodTemplateTaskAdapter (#13969)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-TASK_ID-as-environment-variable-in-PodTemplateTaskAdapter-13969\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Mar 2023 16:45:01 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"139a058ba712cbc6547ab403cfbf5636884cb7e0\",\n",
      "\t\t\"parent\": \"c52d15d65d592411d698f97c0e5f88a30194d76a\",\n",
      "\t\t\"subject\": \"Use sonatype maven central for plugin repositories (#13961)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-sonatype-maven-central-for-plugin-repositories-13961\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Change search order of maven repositories  * Update pom.xml\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Mar 2023 15:35:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c52d15d65d592411d698f97c0e5f88a30194d76a\",\n",
      "\t\t\"parent\": \"da42ee5bfa04f9996fb0ccd9aba1c2265194bb38\",\n",
      "\t\t\"subject\": \"Fixing security vulnerability check errors (#13956)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-security-vulnerability-check-errors-13956\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing security vulnerability check errors  * Updating javax.el to jakarta.el  * Adding cron job trigger on changes to suppressions file\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Mar 2023 11:10:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"da42ee5bfa04f9996fb0ccd9aba1c2265194bb38\",\n",
      "\t\t\"parent\": \"2ad133c06e01c2f6af8d930b6bdea2a6ad1c6ea3\",\n",
      "\t\t\"subject\": \"Added TYPE(native) data type for external tables (#13958)\",\n",
      "\t\t\"sanitized_subject_line\": \"Added-TYPE-native-data-type-for-external-tables-13958\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 21:43:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2ad133c06e01c2f6af8d930b6bdea2a6ad1c6ea3\",\n",
      "\t\t\"parent\": \"8d125b7c7ffe74c32c0e1495aca84b7318285d98\",\n",
      "\t\t\"subject\": \"Unnest changes for moving the filter on right side of correlate to inside the unnest datasource (#13934)\",\n",
      "\t\t\"sanitized_subject_line\": \"Unnest-changes-for-moving-the-filter-on-right-side-of-correlate-to-inside-the-unnest-datasource-13934\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactoring and bug fixes on top of unnest. The filter now is passed inside the unnest cursors. Added tests for scenarios such as 1. filter on unnested column which involves a left filter rewrite 2. filter on unnested virtual column which pushes the filter to the right only and involves no rewrite 3. not filters 4. SQL functions applied on top of unnested column 5. null present in first row of the column to be unnested\",\n",
      "\t\t\"author_name\": \"Soumyava\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 18:24:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8d125b7c7ffe74c32c0e1495aca84b7318285d98\",\n",
      "\t\t\"parent\": \"d81d13b9ba5b81ed098230dd5fbf24f39ea5710f\",\n",
      "\t\t\"subject\": \"Web console: segment writing progress indication (#13929)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-segment-writing-progress-indication-13929\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add segment writing progress indication  * update with more metrics  * add push metric\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 16:34:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d81d13b9ba5b81ed098230dd5fbf24f39ea5710f\",\n",
      "\t\t\"parent\": \"086eb26b74bdb1ee124e32deacbf5d8f1fe6c0dd\",\n",
      "\t\t\"subject\": \"Pod template task adapter (#13896)\",\n",
      "\t\t\"sanitized_subject_line\": \"Pod-template-task-adapter-13896\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Pod template task adapter  * Use getBaseTaskDirPaths  * Remove unused task from getEnv  * Use Optional.ifPresent() instead of Optional.map()  * Pass absolute path  * Don't pass task to getEnv  * Assert the correct adapter is created  * Javadocs and Comments  * Add exception message to assertions\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 14:20:24 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"086eb26b74bdb1ee124e32deacbf5d8f1fe6c0dd\",\n",
      "\t\t\"parent\": \"7bab40749523bd98886b980fc66814e88b5e9f98\",\n",
      "\t\t\"subject\": \"fix join and unnest planning to ensure that duplicate join prefixes are not used (#13943)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-join-and-unnest-planning-to-ensure-that-duplicate-join-prefixes-are-not-used-13943\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix join and unnest planning to ensure that duplicate join prefixes are not used  * wont somebody please think of the children\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 12:53:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7bab40749523bd98886b980fc66814e88b5e9f98\",\n",
      "\t\t\"parent\": \"f4392a31556fa66b770c7dd66dc1427fdfe5746d\",\n",
      "\t\t\"subject\": \"Add segment generator counters to MSQ reports (#13909)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-segment-generator-counters-to-MSQ-reports-13909\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add segment generator counters to reports  * Remove unneeded annotation  * Fix checkstyle and coverage  * Add persist and merged as new metrics  * Address review comments  * Fix checkstyle  * Create metrics class to handle updating counters  * Address review comments  * Add rowsPushed as a new metrics\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 09:17:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f4392a31556fa66b770c7dd66dc1427fdfe5746d\",\n",
      "\t\t\"parent\": \"b7752a909c7ac6e51f6b1571f3a07471beccc3c9\",\n",
      "\t\t\"subject\": \"expression transform improvements and fixes (#13947)\",\n",
      "\t\t\"sanitized_subject_line\": \"expression-transform-improvements-and-fixes-13947\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * fixes inconsistent handling of byte[] values between ExprEval.bestEffortOf and ExprEval.ofType, which could cause byte[] values to end up as java toString values instead of base64 encoded strings in ingest time transforms * improved ExpressionTransform binding to re-use ExprEval.bestEffortOf when evaluating a binding instead of throwing it away * improved ExpressionTransform array handling, added RowFunction.evalDimension that returns List<String> to back Row.getDimension and remove the automatic coercing of array types that would typically happen to expression transforms unless using Row.getDimension * added some tests for ExpressionTransform with array inputs * improved ExpressionPostAggregator to use partial type information from decoration * migrate some test uses of InputBindings.forMap to use other methods\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Mar 2023 23:26:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b7752a909c7ac6e51f6b1571f3a07471beccc3c9\",\n",
      "\t\t\"parent\": \"ede9903ff4752f643716ad82bb20ecfe60a559f9\",\n",
      "\t\t\"subject\": \"Enable round-robin segment assignment and batch segment allocation by default (#13942)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-round-robin-segment-assignment-and-batch-segment-allocation-by-default-13942\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Set `useRoundRobinSegmentAssignment` in coordinator dynamic config to `true` by default. - Set `batchSegmentAllocation` in `TaskLockConfig` (used in Overlord runtime properties) to `true` by default. \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Mar 2023 08:20:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ede9903ff4752f643716ad82bb20ecfe60a559f9\",\n",
      "\t\t\"parent\": \"1c7a03a47be652853a9991f79716f69e0ad39bd4\",\n",
      "\t\t\"subject\": \"pip install for Python Druid API (#13938)\",\n",
      "\t\t\"sanitized_subject_line\": \"pip-install-for-Python-Druid-API-13938\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Broken test appears unrelated to this PR  * make druidapi pip installable  * include druidapi in prerequisites  * add license to setup.py  * updates from Paul's review  * note about editable install  * Apply suggestions from code review  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * update install instructions  * found unrelated typos  * standardize install cmd with pip  ---------  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Mar 2023 11:37:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c7a03a47be652853a9991f79716f69e0ad39bd4\",\n",
      "\t\t\"parent\": \"4f9528540630c36a5624b07e719bc5e53ab07d60\",\n",
      "\t\t\"subject\": \"Lower default maxRowsInMemory for realtime ingestion. (#13939)\",\n",
      "\t\t\"sanitized_subject_line\": \"Lower-default-maxRowsInMemory-for-realtime-ingestion.-13939\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Lower default maxRowsInMemory for realtime ingestion.  The thinking here is that for best ingestion throughput, we want intermediate persists to be as big as possible without using up all available memory. So, we rely mainly on maxBytesInMemory. The default maxRowsInMemory (1 million) is really just a safety: in case we have a large number of very small rows, we don't want to get overwhelmed by per-row overheads.  However, maximum ingestion throughput isn't necessarily the primary goal for realtime ingestion. Query performance is also important. And because query performance is not as good on the in-memory dataset, it's helpful to keep it from growing too large. 150k seems like a reasonable balance here. It means that for a typical 5 million row segment, we won't trigger more than 33 persists due to this limit, which is a reasonable number of persists.  * Update tests.  * Update server/src/main/java/org/apache/druid/segment/indexing/RealtimeTuningConfig.java  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Fix test.  * Fix link.  ---------  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Mar 2023 10:36:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4f9528540630c36a5624b07e719bc5e53ab07d60\",\n",
      "\t\t\"parent\": \"617c325c70bf33e4e9e7ae8016c8f2b777869526\",\n",
      "\t\t\"subject\": \"Correct nested columns JSON example (#13953)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correct-nested-columns-JSON-example-13953\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Mar 2023 09:17:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"617c325c70bf33e4e9e7ae8016c8f2b777869526\",\n",
      "\t\t\"parent\": \"143fdcfacfbd578399a4b845562eb7e8eeac96b0\",\n",
      "\t\t\"subject\": \"Make zk connection retries configurable (#13913)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-zk-connection-retries-configurable-13913\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* This makes the zookeeper connection retry count configurable. This is presently hardcoded to 29 tries which ends up taking a long time for the druid node to shutdown in case of ZK connectivity loss. Having a shorter retry count helps k8s deployments to fail fast. In situations where the underlying k8s node loses network connectivity or is no longer able to talk to zookeeper, failing fast can trigger pod restarts which can then reassign the pod to a healthy k8s node. Existing behavior is preserved, but users can override this property if needed.\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Mar 2023 14:45:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"143fdcfacfbd578399a4b845562eb7e8eeac96b0\",\n",
      "\t\t\"parent\": \"1c250a0bc00b5d2722e7d6fc2795facce799bec6\",\n",
      "\t\t\"subject\": \"Change test name so it triggers in CI (#13844)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-test-name-so-it-triggers-in-CI-13844\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"As the name of the class did not end or start with \\\"Test\\\", CalciteSelectQueryMSQTest was not triggered in CI. This PR renames the test.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 20 Mar 2023 15:55:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c250a0bc00b5d2722e7d6fc2795facce799bec6\",\n",
      "\t\t\"parent\": \"38adac4369d6f483dbc18caead34f6518576e091\",\n",
      "\t\t\"subject\": \"Fix error in cron job ITs workflow  (#13945)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-error-in-cron-job-ITs-workflow-13945\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Mar 2023 17:29:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"38adac4369d6f483dbc18caead34f6518576e091\",\n",
      "\t\t\"parent\": \"bf13156b55a378bd14932b6407205de745aa779f\",\n",
      "\t\t\"subject\": \"Dart sass (#13937)\",\n",
      "\t\t\"sanitized_subject_line\": \"Dart-sass-13937\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Run npx saas-migrator division  * Switch to dart sass  * Upgrade blueprint  * Remove deprecated import syntax  * Prettify  * Snapshots\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 12:44:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bf13156b55a378bd14932b6407205de745aa779f\",\n",
      "\t\t\"parent\": \"67df1324eeffa24ebec0844ef091c673a8653e6a\",\n",
      "\t\t\"subject\": \"Regression bug fix where ever LimitFrameProcessor's were used. (#13941)\",\n",
      "\t\t\"sanitized_subject_line\": \"Regression-bug-fix-where-ever-LimitFrameProcessor-s-were-used.-13941\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 09:18:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"67df1324eeffa24ebec0844ef091c673a8653e6a\",\n",
      "\t\t\"parent\": \"da197c92730a62417d69b2e913b3d2a5fead1f0b\",\n",
      "\t\t\"subject\": \"Undocumenting certain context parameter in MSQ.  (#13928)\",\n",
      "\t\t\"sanitized_subject_line\": \"Undocumenting-certain-context-parameter-in-MSQ.-13928\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Removing intermediateSuperSorterStorageMaxLocalBytes, maxInputBytesPerWorker, composedIntermediateSuperSorterStorageEnabled, clusterStatisticsMergeMode from docs  * Adding documentation in the context class.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 17:56:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"da197c92730a62417d69b2e913b3d2a5fead1f0b\",\n",
      "\t\t\"parent\": \"6837289cb043fdf57375ad7911fb68a2d2a84276\",\n",
      "\t\t\"subject\": \"Migrate existing jdk11 ITs to cron job (#13918)\",\n",
      "\t\t\"sanitized_subject_line\": \"Migrate-existing-jdk11-ITs-to-cron-job-13918\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This cron job runs on the latest commit of the master branch by default daily at 3:00 AM UTC.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 15:30:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6837289cb043fdf57375ad7911fb68a2d2a84276\",\n",
      "\t\t\"parent\": \"c7d864d3bccf82601c757f44c859eaeae34cfc1d\",\n",
      "\t\t\"subject\": \"Fixes parquet uint_32 datatype conversion (#13935)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixes-parquet-uint_32-datatype-conversion-13935\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"After parquet ingestion, uint_32 parquet datatypes are stored as null values in the dataSource. This PR fixes this conversion bug.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 15:27:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c7d864d3bccf82601c757f44c859eaeae34cfc1d\",\n",
      "\t\t\"parent\": \"65a663adbb8f1fd39c3bcc029a96f5a650a6928d\",\n",
      "\t\t\"subject\": \"Update container creation in AzureTestUtil.java (#13911)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-container-creation-in-AzureTestUtil.java-13911\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* 1. Handling deletion/creation of container created during the previously run test in AzureTestUtil.java. 2. Adding/updating log messages and comments in Azure and GCS deep storage tests. \",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Mar 2023 11:04:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65a663adbb8f1fd39c3bcc029a96f5a650a6928d\",\n",
      "\t\t\"parent\": \"cee2dfd768eb257820e4019986be0a98fa62b44a\",\n",
      "\t\t\"subject\": \"docs: clarify Java precision (#13671)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-clarify-Java-precision-13671\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Mar 2023 11:43:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cee2dfd768eb257820e4019986be0a98fa62b44a\",\n",
      "\t\t\"parent\": \"46766d245ca235bc86a2535109bab2e9264bfcf3\",\n",
      "\t\t\"subject\": \"Upgrade ZK from 3.5.9 to 3.5.10 to avoid data inconsistency risk (#13715)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-ZK-from-3.5.9-to-3.5.10-to-avoid-data-inconsistency-risk-13715\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Mar 2023 19:21:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"46766d245ca235bc86a2535109bab2e9264bfcf3\",\n",
      "\t\t\"parent\": \"ed57c5c8539bcd61a50cca6a337761307fd8e540\",\n",
      "\t\t\"subject\": \"Replace deprecated substr with slice (#13822)\",\n",
      "\t\t\"sanitized_subject_line\": \"Replace-deprecated-substr-with-slice-13822\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Andreas Maechler\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Mar 2023 03:57:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ed57c5c8539bcd61a50cca6a337761307fd8e540\",\n",
      "\t\t\"parent\": \"7ce3371730b3895207e2f7729abb713b05ab7eec\",\n",
      "\t\t\"subject\": \"better FrontCodedIndexed (#13854)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-FrontCodedIndexed-13854\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adds new implementation of 'frontCoded' string encoding strategy, which writes out a v1 FrontCodedIndexed which stores buckets on a prefix of the previous value instead of the first value in the bucket \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Mar 2023 18:14:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7ce3371730b3895207e2f7729abb713b05ab7eec\",\n",
      "\t\t\"parent\": \"a7ba3616668d55c807a1a01434e50d1b44b6d61a\",\n",
      "\t\t\"subject\": \"Fixing a github workflow to resolve conflicts and use the correct tag for jdk (#13933)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-a-github-workflow-to-resolve-conflicts-and-use-the-correct-tag-for-jdk-13933\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Mar 2023 16:06:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7ba3616668d55c807a1a01434e50d1b44b6d61a\",\n",
      "\t\t\"parent\": \"4493275d88d8a73ed1766ee07954d95c55dda862\",\n",
      "\t\t\"subject\": \"Refactoring and bug fixes on top of unnest. The allowList now is not passed \\u2026 (#13922)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactoring-and-bug-fixes-on-top-of-unnest.-The-allowList-now-is-not-passed-13922\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactoring and bug fixes on top of unnest. The filter now is passed inside the unnest cursors. Added tests for scenarios such as 1. filter on unnested column which involves a left filter rewrite 2. filter on unnested virtual column which pushes the filter to the right only and involves no rewrite 3. not filters 4. SQL functions applied on top of unnested column 5. null present in first row of the column to be unnested \",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Mar 2023 16:05:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4493275d88d8a73ed1766ee07954d95c55dda862\",\n",
      "\t\t\"parent\": \"29b6bf0942f12c1c6921eaf8d7f1e390a4c9d21c\",\n",
      "\t\t\"subject\": \"Use Maven central repo rather than Apache (#13921)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-Maven-central-repo-rather-than-Apache-13921\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use Maven central repo rather than Apache  * Disable snapshots\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Mar 2023 10:49:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"29b6bf0942f12c1c6921eaf8d7f1e390a4c9d21c\",\n",
      "\t\t\"parent\": \"8a1dc2f51cb64c9a187e88741105a045671a34be\",\n",
      "\t\t\"subject\": \"Removing the forbidden check on getOrDefault due to java8 incompatibility. (#13920)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removing-the-forbidden-check-on-getOrDefault-due-to-java8-incompatibility.-13920\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 11 Mar 2023 09:49:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8a1dc2f51cb64c9a187e88741105a045671a34be\",\n",
      "\t\t\"parent\": \"44547614aebab030aa660728f9e032991c4a54cc\",\n",
      "\t\t\"subject\": \"We want to tag the container based on the build jdk version, not the runtime version (#13917)\",\n",
      "\t\t\"sanitized_subject_line\": \"We-want-to-tag-the-container-based-on-the-build-jdk-version-not-the-runtime-version-13917\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 11:35:33 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44547614aebab030aa660728f9e032991c4a54cc\",\n",
      "\t\t\"parent\": \"67be70e82ecc229107c6582b4ff3d03ec2f0c081\",\n",
      "\t\t\"subject\": \"Report engine as a dimension for sqlQuery metrics (#13906)\",\n",
      "\t\t\"sanitized_subject_line\": \"Report-engine-as-a-dimension-for-sqlQuery-metrics-13906\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Report engine as a dimension for sqlQuery metrics  * docs\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 11:23:57 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"67be70e82ecc229107c6582b4ff3d03ec2f0c081\",\n",
      "\t\t\"parent\": \"4b1ffbc452831178dccd38456ed9b2cdf2521d13\",\n",
      "\t\t\"subject\": \"Removing the forbidden check until we find a fix for java 8 to unblock builds. (#13910)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removing-the-forbidden-check-until-we-find-a-fix-for-java-8-to-unblock-builds.-13910\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 21:37:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4b1ffbc452831178dccd38456ed9b2cdf2521d13\",\n",
      "\t\t\"parent\": \"64b67c22c440cf6d1bf00fc1ae6f233d45edece8\",\n",
      "\t\t\"subject\": \"Various changes and fixes to UNNEST. (#13892)\",\n",
      "\t\t\"sanitized_subject_line\": \"Various-changes-and-fixes-to-UNNEST.-13892\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Various changes and fixes to UNNEST.  Native changes:  1) UnnestDataSource: Replace \\\"column\\\" and \\\"outputName\\\" with \\\"virtualColumn\\\".    This enables pushing expressions into the datasource. This in turn    allows us to do the next thing...  2) UnnestStorageAdapter: Logically apply query-level filters and virtual    columns after the unnest operation. (Physically, filters are pulled up,    when possible.) This is beneficial because it allows filters and    virtual columns to reference the unnested column, and because it is    consistent with how the join datasource works.  3) Various documentation updates, including declaring \\\"unnest\\\" as an    experimental feature for now.  SQL changes:  1) Rename DruidUnnestRel (& Rule) to DruidUnnestRel (& Rule). The rel    is simplified: it only handles the UNNEST part of a correlated join.    Constant UNNESTs are handled with regular inline rels.  2) Rework DruidCorrelateUnnestRule to focus on pulling Projects from    the left side up above the Correlate. New test testUnnestTwice verifies    that this works even when two UNNESTs are stacked on the same table.  3) Include ProjectCorrelateTransposeRule from Calcite to encourage    pushing mappings down below the left-hand side of the Correlate.  4) Add a new CorrelateFilterLTransposeRule and CorrelateFilterRTransposeRule    to handle pulling Filters up above the Correlate. New tests    testUnnestWithFiltersOutside and testUnnestTwiceWithFilters verify    this behavior.  5) Require a context feature flag for SQL UNNEST, since it's undocumented.    As part of this, also cleaned up how we handle feature flags in SQL.    They're now hooked into EngineFeatures, which is useful because not    all engines support all features. \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 16:42:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"64b67c22c440cf6d1bf00fc1ae6f233d45edece8\",\n",
      "\t\t\"parent\": \"29b519a7a7ba83721cdd21b2c5f80f0e6e62dda8\",\n",
      "\t\t\"subject\": \"add latest version of druid operator to integeration tests (#13883)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-latest-version-of-druid-operator-to-integeration-tests-13883\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add latest version of druid operator to integeration tests  * Update integration-tests/k8s/tiny-cluster.yaml\",\n",
      "\t\t\"author_name\": \"AdheipSingh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 16:11:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"29b519a7a7ba83721cdd21b2c5f80f0e6e62dda8\",\n",
      "\t\t\"parent\": \"6b90a320cf737264da551069c843692a32424509\",\n",
      "\t\t\"subject\": \"Add ability to add config files when using druid on Kubernetes (#13795)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-ability-to-add-config-files-when-using-druid-on-Kubernetes-13795\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"You can now add additional configuration files to be copied to the final conf directory on startup when running in a containerized environment. Useful for running on Kubernetes and needing to add more files with a config map. To specify the path where the configMap is mounted, utilize the DRUID_ADDITIONAL_CONF_DIR environment variable.\",\n",
      "\t\t\"author_name\": \"EylonLevy\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 14:52:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6b90a320cf737264da551069c843692a32424509\",\n",
      "\t\t\"parent\": \"c16d9da35ae87a111a19728354b09a3b4610a107\",\n",
      "\t\t\"subject\": \"Add back function signature for compat (#13914)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-back-function-signature-for-compat-13914\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add back function signature for compat  * Suppress IntelliJ Error\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Mar 2023 21:06:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c16d9da35ae87a111a19728354b09a3b4610a107\",\n",
      "\t\t\"parent\": \"5b0b3a9b2c08fd988a1967d760eaf9b2b819b1b6\",\n",
      "\t\t\"subject\": \"Improve documentation for tombstone generation and minor improvement (#13907)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-documentation-for-tombstone-generation-and-minor-improvement-13907\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* As a follow up to #13893, this PR improves the comments added along with examples for the code, as well as adds handling for an edge case where the generated tombstone boundaries were overshooting the bounds of MIN_TIME (or MAX_TIME).\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 06:59:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5b0b3a9b2c08fd988a1967d760eaf9b2b819b1b6\",\n",
      "\t\t\"parent\": \"bf39b4d313277be9e1dc91a6fe9d2749759ebb34\",\n",
      "\t\t\"subject\": \"Add a readOnly() method for PartitionedOutputChannel (#13755)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-readOnly-method-for-PartitionedOutputChannel-13755\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"With SuperSorter using the PartitionedOutputChannels for sorting, it might OOM on inputs of reasonable size because the channel consists of both the writable frame channel and the frame allocator, both of which are not required once the output channel has been written to. This change adds a readOnly to the output channel which contains only the readable channel, due to which unnecessary memory references to the writable channel and the memory allocator are lost once the output channel has been written to, preventing the OOM.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Mar 2023 06:58:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bf39b4d313277be9e1dc91a6fe9d2749759ebb34\",\n",
      "\t\t\"parent\": \"fe9d0c46d535445b407c00cf1cfafb00438fbc06\",\n",
      "\t\t\"subject\": \"Window planning: use collation traits, improve subquery logic. (#13902)\",\n",
      "\t\t\"sanitized_subject_line\": \"Window-planning-use-collation-traits-improve-subquery-logic.-13902\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Window planning: use collation traits, improve subquery logic.  SQL changes:  1) Attach RelCollation (sorting) trait to any PartialDruidQuery    that ends in AGGREGATE or AGGREGATE_PROJECT. This allows planning to    take advantage of the fact that Druid sorts by dimensions when    doing aggregations.  2) Windowing: inspect RelCollation trait from input, and insert naiveSort    if, and only if, necessary.  3) Windowing: add support for Project after Window, when the Project    is a simple mapping. Helps eliminate subqueries.  4) DruidRules: update logic for considering subqueries to reflect that    subqueries are not required to be GroupBys, and that we have a bunch    of new Stages now. With all of this evolution that has happened, the    old logic didn't quite make sense.  Native changes:  1) Use merge sort (stable) rather than quicksort when sorting    RowsAndColumns. Makes it easier to write test cases for plans that    involve re-sorting the data.  * Changes from review.  * Mark the bad test as failing.  * Additional update.  * Fix failingTest.  * Fix tests.  * Mark a var final.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Mar 2023 15:48:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fe9d0c46d535445b407c00cf1cfafb00438fbc06\",\n",
      "\t\t\"parent\": \"48ac5ce50b0c87ac0c6b0bc85470b176dbefe5fb\",\n",
      "\t\t\"subject\": \"Improve memory efficiency of WrappedRoaringBitmap. (#13889)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-memory-efficiency-of-WrappedRoaringBitmap.-13889\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve memory efficiency of WrappedRoaringBitmap.  Two changes:  1) Use an int[] for sizes 4 or below. 2) Remove the boolean compressRunOnSerialization. Doesn't save much    space, but it does save a little, and it isn't adding a ton of value    to have it be configurable. It was originally configurable in case    anything broke when enabling it, but it's been a while and nothing    has broken.  * Slight adjustment.  * Adjust for inspection.  * Updates.  * Update snaps.  * Update test.  * Adjust test.  * Fix snaps.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Mar 2023 15:48:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48ac5ce50b0c87ac0c6b0bc85470b176dbefe5fb\",\n",
      "\t\t\"parent\": \"90d8f67e3dfec80db52e5dac43d278ef90aa47f9\",\n",
      "\t\t\"subject\": \"use native nvl expression for SQL NVL and 2 argument COALESCE (#13897)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-native-nvl-expression-for-SQL-NVL-and-2-argument-COALESCE-13897\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use custom case operator conversion instead of direct operator conversion, to produce native nvl expression for SQL NVL and 2 argument COALESCE, and add optimization for certain case filters from coalesce and nvl statements\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Mar 2023 05:46:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90d8f67e3dfec80db52e5dac43d278ef90aa47f9\",\n",
      "\t\t\"parent\": \"dc67296e9d0adfb65f31a96d2653e0eb3bd40f1e\",\n",
      "\t\t\"subject\": \"Avoid creating new RelDataTypeFactory during SQL planning. (#13904)\",\n",
      "\t\t\"sanitized_subject_line\": \"Avoid-creating-new-RelDataTypeFactory-during-SQL-planning.-13904\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Avoid creating new RelDataTypeFactory during SQL planning.  Reduces unnecessary CPU cycles.  * Fix.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 21:55:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dc67296e9d0adfb65f31a96d2653e0eb3bd40f1e\",\n",
      "\t\t\"parent\": \"c7f4bb50563ec2ca64154c26bf3e6c427a2e1b91\",\n",
      "\t\t\"subject\": \"Fix for OOM in the Tombstone generating logic in MSQ (#13893)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-for-OOM-in-the-Tombstone-generating-logic-in-MSQ-13893\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"fix OOMs using a different logic for generating tombstones  ---------  Co-authored-by: Paul Rogers <paul-rogers@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 21:38:08 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c7f4bb50563ec2ca64154c26bf3e6c427a2e1b91\",\n",
      "\t\t\"parent\": \"82f7a5647571ab38659739e0fce806e3f0cfb688\",\n",
      "\t\t\"subject\": \"fix KafkaInputFormat when used with Sampler API (#13900)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-KafkaInputFormat-when-used-with-Sampler-API-13900\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix KafkaInputFormat when used with Sampler API  * handle key format sampling the same as value format sampling\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 16:23:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"82f7a5647571ab38659739e0fce806e3f0cfb688\",\n",
      "\t\t\"parent\": \"f0fb094cc7f164646c22271fb73cc359c5282fc5\",\n",
      "\t\t\"subject\": \"Sort-merge join and hash shuffles for MSQ. (#13506)\",\n",
      "\t\t\"sanitized_subject_line\": \"Sort-merge-join-and-hash-shuffles-for-MSQ.-13506\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Sort-merge join and hash shuffles for MSQ.  The main changes are in the processing, multi-stage-query, and sql modules.  processing module:  1) Rename SortColumn to KeyColumn, replace boolean descending with KeyOrder.    This makes it nicer to model hash keys, which use KeyOrder.NONE.  2) Add nullability checkers to the FieldReader interface, and an    \\\"isPartiallyNullKey\\\" method to FrameComparisonWidget. The join    processor uses this to detect null keys.  3) Add WritableFrameChannel.isClosed and OutputChannel.isReadableChannelReady    so callers can tell which OutputChannels are ready for reading and which    aren't.  4) Specialize FrameProcessors.makeCursor to return FrameCursor, a random-access    implementation. The join processor uses this to rewind when it needs to    replay a set of rows with a particular key.  5) Add MemoryAllocatorFactory, which is embedded inside FrameWriterFactory    instead of a particular MemoryAllocator. This allows FrameWriterFactory    to be shared in more scenarios.  multi-stage-query module:  1) ShuffleSpec: Add hash-based shuffles. New enum ShuffleKind helps callers    figure out what kind of shuffle is happening. The change from SortColumn    to KeyColumn allows ClusterBy to be used for both hash-based and sort-based    shuffling.  2) WorkerImpl: Add ability to handle hash-based shuffles. Refactor the logic    to be more readable by moving the work-order-running code to the inner    class RunWorkOrder, and the shuffle-pipeline-building code to the inner    class ShufflePipelineBuilder.  3) Add SortMergeJoinFrameProcessor and factory.  4) WorkerMemoryParameters: Adjust logic to reserve space for output frames    for hash partitioning. (We need one frame per partition.)  sql module:  1) Add sqlJoinAlgorithm context parameter; can be \\\"broadcast\\\" or    \\\"sortMerge\\\". With native, it must always be \\\"broadcast\\\", or it's a    validation error. MSQ supports both. Default is \\\"broadcast\\\" in    both engines.  2) Validate that MSQs do not use broadcast join with RIGHT or FULL join,    as results are not correct for broadcast join with those types. Allow    this in native for two reasons: legacy (the docs caution against it,    but it's always been allowed), and the fact that it actually *does*    generate correct results in native when the join is processed on the    Broker. It is much less likely that MSQ will plan in such a way that    generates correct results.  3) Remove subquery penalty in DruidJoinQueryRel when using sort-merge    join, because subqueries are always required, so there's no reason    to penalize them.  4) Move previously-disabled join reordering and manipulation rules to    FANCY_JOIN_RULES, and enable them when using sort-merge join. Helps    get to better plans where projections and filters are pushed down.  * Work around compiler problem.  * Updates from static analysis.  * Fix @param tag.  * Fix declared exception.  * Fix spelling.  * Minor adjustments.  * wip  * Merge fixups  * fixes  * Fix CalciteSelectQueryMSQTest  * Empty keys are sortable.  * Address comments from code review. Rename mux -> mix.  * Restore inspection config.  * Restore original doc.  * Reorder imports.  * Adjustments  * Fix.  * Fix imports.  * Adjustments from review.  * Update header.  * Adjust docs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 14:19:39 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f0fb094cc7f164646c22271fb73cc359c5282fc5\",\n",
      "\t\t\"parent\": \"68db39d08adbdadc095ec5cd8cdc54a93f007b00\",\n",
      "\t\t\"subject\": \"Fix start-druid for indexers. (#13891)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-start-druid-for-indexers.-13891\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"There was an unused parameter causing the unpack to fail.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 10:32:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"68db39d08adbdadc095ec5cd8cdc54a93f007b00\",\n",
      "\t\t\"parent\": \"52bd9e6adb203f279680fb0edf6e939436bf8982\",\n",
      "\t\t\"subject\": \"fix ci (#13901)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-ci-13901\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR is #13899 plus spotbugs fix to fix the failures introduced by #13815\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Mar 2023 16:55:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"52bd9e6adb203f279680fb0edf6e939436bf8982\",\n",
      "\t\t\"parent\": \"ef827561762f4c39adca51c1a1f3e39cbcde8a8f\",\n",
      "\t\t\"subject\": \"Improved error message when topic name changes within same supervisor (#13815)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improved-error-message-when-topic-name-changes-within-same-supervisor-13815\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Improved error message when topic name changes within same supervisor  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Mar 2023 18:10:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ef827561762f4c39adca51c1a1f3e39cbcde8a8f\",\n",
      "\t\t\"parent\": \"faac43eabe86ce1641ee379a75113ccda0e66518\",\n",
      "\t\t\"subject\": \"Add validation for aggregations on __time (#13793)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-validation-for-aggregations-on-__time-13793\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add validation for aggregations on __time \",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Mar 2023 17:16:36 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"faac43eabe86ce1641ee379a75113ccda0e66518\",\n",
      "\t\t\"parent\": \"3924f0eff4e0a9990896f88ce2ed46d180f7b7eb\",\n",
      "\t\t\"subject\": \"Use base task dir in kubernetes task runner (#13880)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-base-task-dir-in-kubernetes-task-runner-13880\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use TaskConfig to get task dir in KubernetesTaskRunner  * Use the first path specified in baseTaskDirPaths instead of deprecated baseTaskDirPath  * Use getBaseTaskDirPaths in generate command\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Mar 2023 15:30:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3924f0eff4e0a9990896f88ce2ed46d180f7b7eb\",\n",
      "\t\t\"parent\": \"ca4df8594115ea8e7f6def5100f6f92966ed319b\",\n",
      "\t\t\"subject\": \"use Calcites.getColumnTypeForRelDataType for SQL CAST operator conversion (#13890)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-Calcites.getColumnTypeForRelDataType-for-SQL-CAST-operator-conversion-13890\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use Calcites.getColumnTypeForRelDataType for SQL CAST operator conversion  * fix comment  * intervals are strings but also longs\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Mar 2023 13:12:15 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca4df8594115ea8e7f6def5100f6f92966ed319b\",\n",
      "\t\t\"parent\": \"fcfb7b8ff63edf0c4f7925baeb664d3c17dc8919\",\n",
      "\t\t\"subject\": \"fix SQL in segment card (#13895)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-SQL-in-segment-card-13895\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Mar 2023 13:08:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fcfb7b8ff63edf0c4f7925baeb664d3c17dc8919\",\n",
      "\t\t\"parent\": \"38b6373bf78165c1ed95198d2e0cffecfc6eb06f\",\n",
      "\t\t\"subject\": \"Add warning comments to Granularity.getIterable. (#13888)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-warning-comments-to-Granularity.getIterable.-13888\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This function is notorious for causing memory exhaustion and excessive CPU usage; so much so that it was valuable to work around it in the SQL planner in #13206. Hopefully, a warning comment will encourage developers to stay away and come up with solutions that do not involve computing all possible buckets.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 22:57:10 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"38b6373bf78165c1ed95198d2e0cffecfc6eb06f\",\n",
      "\t\t\"parent\": \"cd4ad5123a2f3c5826cbe82d2b2709dfdeda9c34\",\n",
      "\t\t\"subject\": \"Web console: Compaction history dialog (#13861)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Compaction-history-dialog-13861\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* initial renames  * add comaction history diff  * final fixes  * update snapshots  * use maps  * update test\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 11:52:25 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cd4ad5123a2f3c5826cbe82d2b2709dfdeda9c34\",\n",
      "\t\t\"parent\": \"94cfabea1822eaadb9b36e700645d729a57a250e\",\n",
      "\t\t\"subject\": \"Stream Kubernetes Job Logs (#13869)\",\n",
      "\t\t\"sanitized_subject_line\": \"Stream-Kubernetes-Job-Logs-13869\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Streams Kubernetes job logs from the Kubernetes client to a file on the machine instead of reading the logs into memory and then writing to a file.\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 19:52:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"94cfabea1822eaadb9b36e700645d729a57a250e\",\n",
      "\t\t\"parent\": \"65c395494252f7a2dd52eead82fd7c7481afdc3d\",\n",
      "\t\t\"subject\": \"Suggested memory calculation in case NOT_ENOUGH_MEMORY_FAULT is thrown. (#13846)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suggested-memory-calculation-in-case-NOT_ENOUGH_MEMORY_FAULT-is-thrown.-13846\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Suggested memory calculation in case NOT_ENOUGH_MEMORY_FAULT is thrown.  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 18:00:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65c395494252f7a2dd52eead82fd7c7481afdc3d\",\n",
      "\t\t\"parent\": \"f33898ed6d81099a9b73531093e36200bb77f188\",\n",
      "\t\t\"subject\": \"Adding forbidden api for Properties#get() and Properties#getOrDefault() (#13882)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-forbidden-api-for-Properties-get-and-Properties-getOrDefault-13882\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Properties#getOrDefault method does not check the default map for values where as Properties#getProperty() does.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 10:42:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f33898ed6d81099a9b73531093e36200bb77f188\",\n",
      "\t\t\"parent\": \"a580aca551f70c6d0f410a1230b76a1fe492f83e\",\n",
      "\t\t\"subject\": \"Fix durable storage cleanup (#13853)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-durable-storage-cleanup-13853\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Mar 2023 09:49:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a580aca551f70c6d0f410a1230b76a1fe492f83e\",\n",
      "\t\t\"parent\": \"b68180fc44d7e385c7f026b9b2be368283737f35\",\n",
      "\t\t\"subject\": \"Python Druid API for use in notebooks (#13787)\",\n",
      "\t\t\"sanitized_subject_line\": \"Python-Druid-API-for-use-in-notebooks-13787\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Python Druid API for use in notebooks  Revises existing notebooks and readme to reference the new API.  Notebook to explain the new API.  Split README into a console version and a notebook version to work around lack of a nice display for md files.  Update the REST API notebook to use simpler Requests calls  Converted the SQL tutorial to use the Python library  README file, converted to using properties  ---------  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Mar 2023 18:25:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b68180fc44d7e385c7f026b9b2be368283737f35\",\n",
      "\t\t\"parent\": \"7123681adaeb98cc614c63410af883cc42f93785\",\n",
      "\t\t\"subject\": \"use getProperty in MSQDurableStorageModule (#13881)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-getProperty-in-MSQDurableStorageModule-13881\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Mar 2023 11:56:43 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7123681adaeb98cc614c63410af883cc42f93785\",\n",
      "\t\t\"parent\": \"d93fdb2632bb9b870c2637915120153baae41771\",\n",
      "\t\t\"subject\": \"Allow druid-kubernetes-overlord-extensions to be loaded in any druid service (#13872)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-druid-kubernetes-overlord-extensions-to-be-loaded-in-any-druid-service-13872\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Allow druid-kubernetes-overlord-extensions to be loaded in any druid service \",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Mar 2023 23:53:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d93fdb2632bb9b870c2637915120153baae41771\",\n",
      "\t\t\"parent\": \"81356f76673b7b6a81dd038c11b16f7958eb4889\",\n",
      "\t\t\"subject\": \"Bump CycloneDX module to address POM errors (#13878)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-CycloneDX-module-to-address-POM-errors-13878\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump CycloneDX module to address POM errors  * Including web-console in the PR  ---------  Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Mar 2023 15:39:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"81356f76673b7b6a81dd038c11b16f7958eb4889\",\n",
      "\t\t\"parent\": \"a10e4150d59925b116c5da0fa18dedc8ea561e90\",\n",
      "\t\t\"subject\": \"do not run non sql compatible tests for all jdk flavours (#13875)\",\n",
      "\t\t\"sanitized_subject_line\": \"do-not-run-non-sql-compatible-tests-for-all-jdk-flavours-13875\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Mar 2023 11:26:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a10e4150d59925b116c5da0fa18dedc8ea561e90\",\n",
      "\t\t\"parent\": \"b4b354b658ed3d3f8e9280984b74e5683ed752f3\",\n",
      "\t\t\"subject\": \"Add Post Aggregators for Tuple Sketches (#13819)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Post-Aggregators-for-Tuple-Sketches-13819\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"You can now do the following operations with TupleSketches in Post Aggregation Step  Get the Sketch Output as Base64 String Provide a constant Tuple Sketch in post-aggregation step that can be used in Set Operations Get the Estimated Value(Sum) of Summary/Metrics Objects associated with Tuple Sketch\",\n",
      "\t\t\"author_name\": \"Anshu Makkar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Mar 2023 09:32:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b4b354b658ed3d3f8e9280984b74e5683ed752f3\",\n",
      "\t\t\"parent\": \"26c5cac41af0fb755736e9d40390b59fc56c8fea\",\n",
      "\t\t\"subject\": \"docs: fix html nits (#13835)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-html-nits-13835\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 11:19:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"26c5cac41af0fb755736e9d40390b59fc56c8fea\",\n",
      "\t\t\"parent\": \"7103cb4b9df56f8ecc4a27672d34dc21da58b812\",\n",
      "\t\t\"subject\": \"Fix a link problem (#13876)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-a-link-problem-13876\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 09:09:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7103cb4b9df56f8ecc4a27672d34dc21da58b812\",\n",
      "\t\t\"parent\": \"1aae37f7d688c1bdd67fd27babd80f949ad30fb8\",\n",
      "\t\t\"subject\": \"Removes FiniteFirehoseFactory and its implementations (#12852)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removes-FiniteFirehoseFactory-and-its-implementations-12852\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The FiniteFirehoseFactory and InputRowParser classes were deprecated in 0.17.0 (#8823) in favor of InputSource & InputFormat. This PR removes the FiniteFirehoseFactory and all its implementations along with classes solely used by them like Fetcher (Used by PrefetchableTextFilesFirehoseFactory). Refactors classes including tests using FiniteFirehoseFactory to use InputSource instead. Removing InputRowParser may not be as trivial as many classes that aren't deprecated depends on it (with no alternatives), like EventReceiverFirehoseFactory. Hence FirehoseFactory, EventReceiverFirehoseFactory, and Firehose are marked deprecated.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 18:07:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1aae37f7d688c1bdd67fd27babd80f949ad30fb8\",\n",
      "\t\t\"parent\": \"775f89c75b46c31f4a2880a254fce829edbc924f\",\n",
      "\t\t\"subject\": \"Fix expectedSingleiContainerOutput.yaml spelling (#13870)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-expectedSingleiContainerOutput.yaml-spelling-13870\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 00:07:15 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"775f89c75b46c31f4a2880a254fce829edbc924f\",\n",
      "\t\t\"parent\": \"38ac71ee5614afe2a6bb527c18b97f0165933869\",\n",
      "\t\t\"subject\": \"Include workaround for CycloneDX is causing POM build errors to web-console as well (#13874)\",\n",
      "\t\t\"sanitized_subject_line\": \"Include-workaround-for-CycloneDX-is-causing-POM-build-errors-to-web-console-as-well-13874\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 00:06:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"38ac71ee5614afe2a6bb527c18b97f0165933869\",\n",
      "\t\t\"parent\": \"d32dc1b0c9317bc973ad41b19609766a05dd32c7\",\n",
      "\t\t\"subject\": \"one version of mockito is more than enough (#13871)\",\n",
      "\t\t\"sanitized_subject_line\": \"one-version-of-mockito-is-more-than-enough-13871\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Mar 2023 23:27:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d32dc1b0c9317bc973ad41b19609766a05dd32c7\",\n",
      "\t\t\"parent\": \"d046cee3e43bcf895eb7c13d0c8b413141734fbf\",\n",
      "\t\t\"subject\": \"Remove K8sOverlordConfig.java (#13866)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-K8sOverlordConfig.java-13866\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nicholas Lippis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Mar 2023 09:43:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d046cee3e43bcf895eb7c13d0c8b413141734fbf\",\n",
      "\t\t\"parent\": \"b26f1b4a5ded113926572f6ad164a85451057512\",\n",
      "\t\t\"subject\": \"Workaround for CycloneDX is causing POM build errors (#13867)\",\n",
      "\t\t\"sanitized_subject_line\": \"Workaround-for-CycloneDX-is-causing-POM-build-errors-13867\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Mar 2023 16:47:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b26f1b4a5ded113926572f6ad164a85451057512\",\n",
      "\t\t\"parent\": \"ca68fd93a6e7b547d8a52277c31ad96ea743f1c0\",\n",
      "\t\t\"subject\": \"Update datasources.md: Fix Documentation. (#13865)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-datasources.md-Fix-Documentation.-13865\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixed documentation to clarify that union query cant be run over query datasources.\",\n",
      "\t\t\"author_name\": \"Apoorv Gupta\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Mar 2023 20:29:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca68fd93a6e7b547d8a52277c31ad96ea743f1c0\",\n",
      "\t\t\"parent\": \"6cf754b0e0cd0ae28025439d6272ac174ae857ae\",\n",
      "\t\t\"subject\": \"Generate tombstones when running MSQ's replace (#13706)\",\n",
      "\t\t\"sanitized_subject_line\": \"Generate-tombstones-when-running-MSQ-s-replace-13706\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"*When running REPLACE queries, the segments which contain no data are dropped (marked as unused). This PR aims to generate tombstones in place of segments which contain no data to mark their deletion, as is the behavior with the native ingestion.  This will cause InsertCannotReplaceExistingSegmentFault to be removed since it was generated if the interval to be marked unused didn't fully overlap one of the existing segments to replace. \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Mar 2023 12:01:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6cf754b0e0cd0ae28025439d6272ac174ae857ae\",\n",
      "\t\t\"parent\": \"faf602108bfec548ed99c9db60c8a641c20ccd1c\",\n",
      "\t\t\"subject\": \"move numeric null value coercion out of expression processing engine (#13809)\",\n",
      "\t\t\"sanitized_subject_line\": \"move-numeric-null-value-coercion-out-of-expression-processing-engine-13809\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* move numeric null value coercion out of expression processing engine * add ExprEval.valueOrDefault() to allow consumers to automatically coerce to default values * rename Expr.buildVectorized as Expr.asVectorProcessor more consistent naming with Function and ApplyFunction; javadocs for some stuff \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 18:10:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"faf602108bfec548ed99c9db60c8a641c20ccd1c\",\n",
      "\t\t\"parent\": \"22e516fd53a879c28bb20ebbd0516f37709fa851\",\n",
      "\t\t\"subject\": \"We never want to restore caches that aren't an exact match to the commit SHA (#13863)\",\n",
      "\t\t\"sanitized_subject_line\": \"We-never-want-to-restore-caches-that-aren-t-an-exact-match-to-the-commit-SHA-13863\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 13:59:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"22e516fd53a879c28bb20ebbd0516f37709fa851\",\n",
      "\t\t\"parent\": \"1d8fff4096e9058a7de3232564385593e17fd6cd\",\n",
      "\t\t\"subject\": \"Update kubernetes.md (#13858)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-kubernetes.md-13858\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AdheipSingh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 11:20:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d8fff4096e9058a7de3232564385593e17fd6cd\",\n",
      "\t\t\"parent\": \"13721f5998c76a06a70e47b2dbda6b0618610110\",\n",
      "\t\t\"subject\": \"sampler + type detection = bff (#13711)\",\n",
      "\t\t\"sanitized_subject_line\": \"sampler-type-detection-bff-13711\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* sampler + type detection = bff * split logical and physical dimensions, tidy up\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 04:14:30 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"13721f5998c76a06a70e47b2dbda6b0618610110\",\n",
      "\t\t\"parent\": \"12f62e2c42e0fffcac446eca62ff700ecc78581d\",\n",
      "\t\t\"subject\": \"upgrade druid query toolkit (#13848)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-druid-query-toolkit-13848\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 14:34:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"12f62e2c42e0fffcac446eca62ff700ecc78581d\",\n",
      "\t\t\"parent\": \"aeb1187a7d08db704bda098e8844fa456fd1af68\",\n",
      "\t\t\"subject\": \"Clarify doc of ingest/handoff/time metric (#13856)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clarify-doc-of-ingest-handoff-time-metric-13856\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Feb 2023 10:37:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"aeb1187a7d08db704bda098e8844fa456fd1af68\",\n",
      "\t\t\"parent\": \"e2461c21c49945835ec752f26e05a4b89942a9b0\",\n",
      "\t\t\"subject\": \"Fix NPE in KinesisSupervisor#setupRecordSupplier. (#13859)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-NPE-in-KinesisSupervisor-setupRecordSupplier.-13859\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix NPE in KinesisSupervisor#setupRecordSupplier.  PR #13539 refactored record supplier creation and introduced a bug: this method would throw NPE when recordsPerFetch was not provided by the user. recordsPerFetch isn't needed in this context at all, since the supervisor-side supplier doesn't fetch records. So this patch sets it to zero.  * Remove unused imports.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Feb 2023 19:55:28 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e2461c21c49945835ec752f26e05a4b89942a9b0\",\n",
      "\t\t\"parent\": \"6f7f391762c906c8065f0d7ef50239e1d1813152\",\n",
      "\t\t\"subject\": \"fix flaky BatchIndex IT failures. (#13855)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-flaky-BatchIndex-IT-failures.-13855\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Feb 2023 17:23:14 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f7f391762c906c8065f0d7ef50239e1d1813152\",\n",
      "\t\t\"parent\": \"31c7de1087a7b0ce096aed78fd472d1e8821892c\",\n",
      "\t\t\"subject\": \"Remove unused imports. (#13860)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-unused-imports.-13860\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Crept in during #13842. Possibly logical conflict with another PR.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Feb 2023 15:14:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31c7de1087a7b0ce096aed78fd472d1e8821892c\",\n",
      "\t\t\"parent\": \"48f4330100e73be5dbf85c3002eaf0d4e5224e63\",\n",
      "\t\t\"subject\": \"Make CompactionSearchPolicy injectable (#13842)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-CompactionSearchPolicy-injectable-13842\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make CompactionSearchPolicy injectable  A small refactoring that makes the search policy for compaction injectable.  Future changes can introduce new search policies that can be configured and injected so that operators can choose which search policy is best suited for their cluster.  This will also allow us to de-couple the scheduling of compaction jobs from the CompactSegments duty, allowing the co-ordinator to schedule compaction jobs faster than the duty lifecycle.  This PR is made so that it easy to review the future changes.  * fix tests\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 27 Feb 2023 07:57:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48f4330100e73be5dbf85c3002eaf0d4e5224e63\",\n",
      "\t\t\"parent\": \"54da38b50845a99a43ff41f7cbbe2a4496ea81c9\",\n",
      "\t\t\"subject\": \"Make leader redirection work when both plainText and TLS ports are set (#13847)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-leader-redirection-work-when-both-plainText-and-TLS-ports-are-set-13847\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"When both plainText and TLS ports are set in druid, the redirection to a different leader node can fail. This is caused by how we compare a redirect path and the leader locations registered with a druid node. While the registered location has both plainText and TLS port set, the redirect path only has one port since it's a URI.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 26 Feb 2023 21:23:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"54da38b50845a99a43ff41f7cbbe2a4496ea81c9\",\n",
      "\t\t\"parent\": \"6bb5effa7bb1c7a31cff270818d035bdfb7a7883\",\n",
      "\t\t\"subject\": \"Add missing license for jakarta.activation against module druid-avro-extensions (#13845)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-missing-license-for-jakarta.activation-against-module-druid-avro-extensions-13845\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 26 Feb 2023 17:06:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6bb5effa7bb1c7a31cff270818d035bdfb7a7883\",\n",
      "\t\t\"parent\": \"e46379ba7a3b7e3b57aee8b4ed1e7e593885c8a0\",\n",
      "\t\t\"subject\": \"Better logging for MSQ worker task (#13790)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-logging-for-MSQ-worker-task-13790\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding more logs to MSQ worker implementation which makes it easier to debug.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 26 Feb 2023 03:24:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e46379ba7a3b7e3b57aee8b4ed1e7e593885c8a0\",\n",
      "\t\t\"parent\": \"d74d6824ecf04a32a0f84478ac8935d8cebe2301\",\n",
      "\t\t\"subject\": \"Docs: Update name of the metadata tables (#13734)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Update-name-of-the-metadata-tables-13734\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update name of the metadata tables  * emend spelling file  * fix spelling  ---------  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 13:57:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d74d6824ecf04a32a0f84478ac8935d8cebe2301\",\n",
      "\t\t\"parent\": \"e4e6c7ed013a60fb49d18dd737c3142350927735\",\n",
      "\t\t\"subject\": \"update LDAP endpoint (#13839)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-LDAP-endpoint-13839\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Current DOC at step https://druid.apache.org/docs/latest/operations/auth-ldap.html#add-an-ldap-user-to-druid-and-assign-a-role Example request to add the LDAP user myuser to Druid: curl -i -v  -H \\\"Content-Type: application/json\\\" -u internal -X POST http://localhost:8081/druid-ext/basic-security/authentication/db/ldap/users/myuser  Example request to assign the myuser user to the queryRole role: curl -i -v  -H \\\"Content-Type: application/json\\\" -u internal -X POST http://localhost:8081/druid-ext/basic-security/authentication/db/ldap/users/myuser/roles/queryRole  Expected: Example request to add the LDAP user myuser to Druid: curl -i -v  -H \\\"Content-Type: application/json\\\" -u internal -X POST http://localhost:8081/druid-ext/basic-security/authorization/db/ldapauth/users/myuser  Example request to assign the myuser user to the queryRole role curl -i -v  -H \\\"Content-Type: application/json\\\" -u internal -X POST http://localhost:8081/druid-ext/basic-security/authorization/db/ldapauth/users/myuser/roles/queryRole\",\n",
      "\t\t\"author_name\": \"tejasparbat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 13:55:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e4e6c7ed013a60fb49d18dd737c3142350927735\",\n",
      "\t\t\"parent\": \"70f9052f1de116c34a4b5b02c4a2b31ee018c036\",\n",
      "\t\t\"subject\": \"make completions smarter (#13830)\",\n",
      "\t\t\"sanitized_subject_line\": \"make-completions-smarter-13830\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 10:17:10 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"70f9052f1de116c34a4b5b02c4a2b31ee018c036\",\n",
      "\t\t\"parent\": \"471cb82af3d02ebcd212eb2e09d7e9abe1950fd3\",\n",
      "\t\t\"subject\": \"docs: update correct config base on server spec (#13832)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-update-correct-config-base-on-server-spec-13832\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Winn Minn <winn.minn@grabtaxi.com>\",\n",
      "\t\t\"author_name\": \"Win Min Soe\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 08:50:47 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"471cb82af3d02ebcd212eb2e09d7e9abe1950fd3\",\n",
      "\t\t\"parent\": \"f7a5fcf30fffb0ecce52130e6bf617aa20f67a4d\",\n",
      "\t\t\"subject\": \"Use built-in java rather than spending time to install (#13834)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-built-in-java-rather-than-spending-time-to-install-13834\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 08:50:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7a5fcf30fffb0ecce52130e6bf617aa20f67a4d\",\n",
      "\t\t\"parent\": \"786172947eaaa9296d318318d11cb86055fa3e9f\",\n",
      "\t\t\"subject\": \"helm: Add serviceAccounts, rbac, and small fixes (#13747)\",\n",
      "\t\t\"sanitized_subject_line\": \"helm-Add-serviceAccounts-rbac-and-small-fixes-13747\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Update suggested segment-cache path, Allow for per-service serviceAccounts in druid helm chart and finer-grained RBAC, and add a default annotation to historical statefulset.\",\n",
      "\t\t\"author_name\": \"Jason Witkowski\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 11:42:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"786172947eaaa9296d318318d11cb86055fa3e9f\",\n",
      "\t\t\"parent\": \"79f04e71a1ef1a181dcf7f5a3d69ff76858446b9\",\n",
      "\t\t\"subject\": \"Skip tests when there are markdown only changes. (#13836)\",\n",
      "\t\t\"sanitized_subject_line\": \"Skip-tests-when-there-are-markdown-only-changes.-13836\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 11:39:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"79f04e71a1ef1a181dcf7f5a3d69ff76858446b9\",\n",
      "\t\t\"parent\": \"17a3cd0b68de0e2e24573104df145a0ae5755537\",\n",
      "\t\t\"subject\": \"Hadoop based batch ingestion support range partition (#13303)\",\n",
      "\t\t\"sanitized_subject_line\": \"Hadoop-based-batch-ingestion-support-range-partition-13303\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This pr implements range partitioning for hadoop-based ingestion. For detail about multi dimension range partition can be seen #11848.\",\n",
      "\t\t\"author_name\": \"hqx871\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 11:38:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"17a3cd0b68de0e2e24573104df145a0ae5755537\",\n",
      "\t\t\"parent\": \"66034dd8bcd324bbdf51431e06d94fb4ebf0a75f\",\n",
      "\t\t\"subject\": \"Remove the additional backtick that's causing a SA issue. (#13838)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-the-additional-backtick-that-s-causing-a-SA-issue.-13838\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Feb 2023 09:01:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"66034dd8bcd324bbdf51431e06d94fb4ebf0a75f\",\n",
      "\t\t\"parent\": \"914eebb4b747b5847ba6e9e1e559b6fbbee72ff2\",\n",
      "\t\t\"subject\": \"Update default for finalize in query-context.md (#13763)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-default-for-finalize-in-query-context.md-13763\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  ---------  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"benkrug\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Feb 2023 12:35:36 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"914eebb4b747b5847ba6e9e1e559b6fbbee72ff2\",\n",
      "\t\t\"parent\": \"1595653e6f7ea7d4b6b3fac3a896f0b64745844b\",\n",
      "\t\t\"subject\": \"Wire up the catalog resolver (#13788)\",\n",
      "\t\t\"sanitized_subject_line\": \"Wire-up-the-catalog-resolver-13788\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Introduces the catalog resolver interface Wires the resolver up to the planner factory Refactors planner factory\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Feb 2023 11:42:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1595653e6f7ea7d4b6b3fac3a896f0b64745844b\",\n",
      "\t\t\"parent\": \"aceeac91d4f46f834ceab78a59d4d51b19ac768f\",\n",
      "\t\t\"subject\": \"docs: add a link for the Druid SQL tutorial  (#13468)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-a-link-for-the-Druid-SQL-tutorial-13468\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs: add juptyer API tutorial for API and jupyter tutorial index (#3)  (cherry picked from commit aeb8d9e3390fa26d9c533dce0862295b80c58583)  * update prereqs and fix jupyterlab name  * Removing notebook since 13345 has it  13345 should be merged first  * update contributing instructions  * docs: link to the  Druid SQL tutorial  * Add link to partitioning  * fix merge conflict  * Saving  * Update docs/tutorials/tutorial-jupyter-index.md  * Remove partitioning  ---------  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com> Co-authored-by: brian.le <brian.le@imply.io> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Feb 2023 09:36:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"aceeac91d4f46f834ceab78a59d4d51b19ac768f\",\n",
      "\t\t\"parent\": \"d2dbb8b2c02b3de9c7049d03bd59b03839aa209b\",\n",
      "\t\t\"subject\": \"Fix MSQ IT test (#13808)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-MSQ-IT-test-13808\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Feb 2023 08:14:46 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d2dbb8b2c02b3de9c7049d03bd59b03839aa209b\",\n",
      "\t\t\"parent\": \"3a67a43c8ae5f740d7fd4c312310c6e58d1e369d\",\n",
      "\t\t\"subject\": \"Fix infinite checkpointing between tasks and overlord (#13825)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-infinite-checkpointing-between-tasks-and-overlord-13825\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"If the intermediate handoff period is less than the task duration and there is no new data in the input topic, task will continuously checkpoint the same offsets again and again. This PR fixes that bug by resetting the checkpoint time even when the task receives the same end offset request again.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Feb 2023 19:25:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3a67a43c8ae5f740d7fd4c312310c6e58d1e369d\",\n",
      "\t\t\"parent\": \"07883e311eaeb6f6b442ec92ecb4027948c17b49\",\n",
      "\t\t\"subject\": \"Add method SegmentTimeline.addSegments (#13831)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-method-SegmentTimeline.addSegments-13831\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 23:58:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"07883e311eaeb6f6b442ec92ecb4027948c17b49\",\n",
      "\t\t\"parent\": \"665dee43bfbf00285a757b5fdd352db93b5788ce\",\n",
      "\t\t\"subject\": \"doc: fix unnecessary link (#13785)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-fix-unnecessary-link-13785\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"CI errors look unrelated to this change.\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 17:34:46 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"665dee43bfbf00285a757b5fdd352db93b5788ce\",\n",
      "\t\t\"parent\": \"9e9976001c5692732be4b7e28d79886e0d6859a9\",\n",
      "\t\t\"subject\": \"Revert \\\"Operator conversion deny list (#13766)\\\" (#13829)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Operator-conversion-deny-list-13766-13829\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit 38e620aa4cd5c85ef651a37c7f7cd9beb6d60920.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 15:14:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e9976001c5692732be4b7e28d79886e0d6859a9\",\n",
      "\t\t\"parent\": \"8595271b556f92a67483dee7fa976d2c343f4e6d\",\n",
      "\t\t\"subject\": \"Add ANSI_QUOTES propety to DBI init in lookups. (#13826)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-ANSI_QUOTES-propety-to-DBI-init-in-lookups.-13826\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 15:13:22 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8595271b556f92a67483dee7fa976d2c343f4e6d\",\n",
      "\t\t\"parent\": \"5dadbdf4d051a6843c87a05948cade84eb042a40\",\n",
      "\t\t\"subject\": \"Fixup typos in integration-test README. (#13828)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixup-typos-in-integration-test-README.-13828\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 15:12:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5dadbdf4d051a6843c87a05948cade84eb042a40\",\n",
      "\t\t\"parent\": \"c6b1576fc17bd9bf53d58fdb7249d1bcffff07d9\",\n",
      "\t\t\"subject\": \"Generate the IT docker-compose.yaml files (#13669)\",\n",
      "\t\t\"sanitized_subject_line\": \"Generate-the-IT-docker-compose.yaml-files-13669\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Generate IT docker-compose.sh files  Generates test-specific docker-compose.sh files using a simple Python template script. \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 15:03:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c6b1576fc17bd9bf53d58fdb7249d1bcffff07d9\",\n",
      "\t\t\"parent\": \"614205f3bcd366315432fe7bb12c9fdb7f68987c\",\n",
      "\t\t\"subject\": \"Update clean-metadata-store.md (#13131)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-clean-metadata-store.md-13131\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> \",\n",
      "\t\t\"author_name\": \"benkrug\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 12:53:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"614205f3bcd366315432fe7bb12c9fdb7f68987c\",\n",
      "\t\t\"parent\": \"46eafa57e199e72893e998a4c7619991df47ea2c\",\n",
      "\t\t\"subject\": \"fix some intellij inspections in druid-processing (#13823)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-some-intellij-inspections-in-druid-processing-13823\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"fix some intellij inspections in druid-processing\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Feb 2023 09:02:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"46eafa57e199e72893e998a4c7619991df47ea2c\",\n",
      "\t\t\"parent\": \"e788f1ae6b4245fd3dd3b005d45843b2489edda0\",\n",
      "\t\t\"subject\": \"Improve client change counter management in HTTP Server View (#13010)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-client-change-counter-management-in-HTTP-Server-View-13010\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Avoid calling resolveWaitingFutures if there are no changes made  * Avoid telling HTTP serveview client to reset counter when their counter is valid\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 20 Feb 2023 17:32:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e788f1ae6b4245fd3dd3b005d45843b2489edda0\",\n",
      "\t\t\"parent\": \"882ae9f002d5f0c845e4a03d633a1959737066dc\",\n",
      "\t\t\"subject\": \"Add option to run standard & revised ITs manually on PRs (#13814)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-option-to-run-standard-revised-ITs-manually-on-PRs-13814\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Create the docker image in case of maven dependencies cache restore failure too as env.sh file is removed on maven rebuild. Increase java heap size for security IT failing with error\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 20 Feb 2023 16:15:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"882ae9f002d5f0c845e4a03d633a1959737066dc\",\n",
      "\t\t\"parent\": \"85d36be0853b6eaa5f2f94be3028a91291ed56b3\",\n",
      "\t\t\"subject\": \"Speed up composite key joins on IndexedTable. (#13516)\",\n",
      "\t\t\"sanitized_subject_line\": \"Speed-up-composite-key-joins-on-IndexedTable.-13516\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Speed up composite key joins on IndexedTable.  Prior to this patch, IndexedTable indexes are sorted IntList. This works great when we have a single-column join key: we simply retrieve the list and we know what rows match. However, when we have a composite key, we need to merge the sorted lists. This is inefficient when one is very dense and others are very sparse.  This patch switches from sorted IntList to IntSortedSet, and changes to the following intersection algorithm:  1) Initialize the intersection set to the smallest matching set from the    various parts of the composite key.  2) For each element in that smallest set, check other sets for that element.    If any do *not* include it, then remove the element from the intersection    set.  This way, complexity scales with the size of the smallest set, not the largest one.  * RangeIntSet stuff.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 22:01:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"85d36be0853b6eaa5f2f94be3028a91291ed56b3\",\n",
      "\t\t\"parent\": \"08b5951cc53c4fe474a129500c62a6adad78337f\",\n",
      "\t\t\"subject\": \"Information schema now uses numeric column types (#13777)\",\n",
      "\t\t\"sanitized_subject_line\": \"Information-schema-now-uses-numeric-column-types-13777\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Change to use SQL schemas to allow null numeric columns  * Updated docs\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 14:39:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"08b5951cc53c4fe474a129500c62a6adad78337f\",\n",
      "\t\t\"parent\": \"8d03ace1b4d7d24b6c978f273d2bc593c6abf995\",\n",
      "\t\t\"subject\": \"merge druid-core, extendedset, and druid-hll into druid-processing to simplify everything (#13698)\",\n",
      "\t\t\"sanitized_subject_line\": \"merge-druid-core-extendedset-and-druid-hll-into-druid-processing-to-simplify-everything-13698\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* merge druid-core, extendedset, and druid-hll into druid-processing to simplify everything * fix poms and license stuff * mockito is evil * allow reset of JvmUtils RuntimeInfo if tests used static injection to override \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 14:27:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8d03ace1b4d7d24b6c978f273d2bc593c6abf995\",\n",
      "\t\t\"parent\": \"bc8b710b7ec78d5e92d58f97b56e8e0611e154a0\",\n",
      "\t\t\"subject\": \"Use K3S instead of minikube for integration tests (#13782)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-K3S-instead-of-minikube-for-integration-tests-13782\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We are seeing failures on GHA while using minikube so switching to K3S instead. \",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 23:06:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bc8b710b7ec78d5e92d58f97b56e8e0611e154a0\",\n",
      "\t\t\"parent\": \"ddae7974c2c1113ec63ccb4d1b43c48f23b28a8a\",\n",
      "\t\t\"subject\": \"Fix broken link (#13767)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-broken-link-13767\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 09:02:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ddae7974c2c1113ec63ccb4d1b43c48f23b28a8a\",\n",
      "\t\t\"parent\": \"add2081f7c6d42f2845078044cd09b7cc6298339\",\n",
      "\t\t\"subject\": \"Don't run UTs, ITs when there are only docs, helm and console changes.  (#13812)\",\n",
      "\t\t\"sanitized_subject_line\": \"Don-t-run-UTs-ITs-when-there-are-only-docs-helm-and-console-changes.-13812\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Don't run UTs, ITs for docs, helm and console changes  * Test  * right place  * Revert test  * Remove ITs from ignore list  * Update unit-and-integration-tests-unified.yml  * Update unit-and-integration-tests-unified.yml\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Feb 2023 09:56:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"add2081f7c6d42f2845078044cd09b7cc6298339\",\n",
      "\t\t\"parent\": \"1ca0edb8c9545b451ecc235ced5ea0188cbbf7d3\",\n",
      "\t\t\"subject\": \"gha: add auto labeler for doc prs (#13791)\",\n",
      "\t\t\"sanitized_subject_line\": \"gha-add-auto-labeler-for-doc-prs-13791\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This adds an autolabeler GitHub action that will label any changes to the docs directories (docs and the Jupyter nb directory) as Area - Documentation.  The GHA will also remove the label if the PR changes and no longer touches files in those directories.  \",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Feb 2023 12:05:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1ca0edb8c9545b451ecc235ced5ea0188cbbf7d3\",\n",
      "\t\t\"parent\": \"460d8b8a2aca59b4712a1e7579055585b5b6a063\",\n",
      "\t\t\"subject\": \"Web console: Fixes query cancel NPE and more (#13786)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Fixes-query-cancel-NPE-and-more-13786\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add null icon  * empty string table cell  * enable views only if they will work  * make sure method exists  * use SQL compatible nulls for e2e tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 15:02:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"460d8b8a2aca59b4712a1e7579055585b5b6a063\",\n",
      "\t\t\"parent\": \"e5ecb4d6aa6b6bc77c8d21e117c8e266079ad74e\",\n",
      "\t\t\"subject\": \"Add license header to template file (#13811)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-license-header-to-template-file-13811\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 04:12:15 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e5ecb4d6aa6b6bc77c8d21e117c8e266079ad74e\",\n",
      "\t\t\"parent\": \"333196d20717c9109665f717731c333939af4e7a\",\n",
      "\t\t\"subject\": \"Flip boolean logic so the test description makes sense (#13805)\",\n",
      "\t\t\"sanitized_subject_line\": \"Flip-boolean-logic-so-the-test-description-makes-sense-13805\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.local>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 16:07:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"333196d20717c9109665f717731c333939af4e7a\",\n",
      "\t\t\"parent\": \"e8330e95f59d24ef2882ba4670dc0ad746b6cf34\",\n",
      "\t\t\"subject\": \"Code cleanup & message improvements (#13778)\",\n",
      "\t\t\"sanitized_subject_line\": \"Code-cleanup-message-improvements-13778\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Misc cleanup edits  Correct spacing Add type parameters Add toString() methods to formats so tests compare correctly IT doc revisions Error message edits Display UT query results when tests fail  * Edit  * Build fix  * Build fixes\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 15:22:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e8330e95f59d24ef2882ba4670dc0ad746b6cf34\",\n",
      "\t\t\"parent\": \"355cdbeb86faf71d30066c036f75652c3e926b69\",\n",
      "\t\t\"subject\": \"Update Apache Kafka dependencies to 3.4.0 (#13802)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Apache-Kafka-dependencies-to-3.4.0-13802\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Release notes: - https://downloads.apache.org/kafka/3.4.0/RELEASE_NOTES.html\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 15:15:13 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"355cdbeb86faf71d30066c036f75652c3e926b69\",\n",
      "\t\t\"parent\": \"9ffaba9c7fc72495e1b65ffad67270af230bf6c0\",\n",
      "\t\t\"subject\": \"helm: Fix PDB apiVersion to allow K8s 1.25+ deployment (#13783)\",\n",
      "\t\t\"sanitized_subject_line\": \"helm-Fix-PDB-apiVersion-to-allow-K8s-1.25-deployment-13783\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jason Witkowski\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 11:24:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9ffaba9c7fc72495e1b65ffad67270af230bf6c0\",\n",
      "\t\t\"parent\": \"f67abf2e99c6ffe3f4f11256a3a170796ef4bae0\",\n",
      "\t\t\"subject\": \"Fix MySQL drivers setup for Revised ITs (#13800)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-MySQL-drivers-setup-for-Revised-ITs-13800\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* download both mysql drivers and use org.mariadb.jdbc.Driver for now  * use com.mysql.jdbc.Driver\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Feb 2023 11:03:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f67abf2e99c6ffe3f4f11256a3a170796ef4bae0\",\n",
      "\t\t\"parent\": \"f3e19f69bbf14a978afc8cd347fbe04df92e6ef8\",\n",
      "\t\t\"subject\": \"Better logs for query errors (#13776)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-logs-for-query-errors-13776\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Better logs for query errors  * checkstyle\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Feb 2023 15:55:58 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f3e19f69bbf14a978afc8cd347fbe04df92e6ef8\",\n",
      "\t\t\"parent\": \"c1f283fd314f61950fa240f7cf31eed251173518\",\n",
      "\t\t\"subject\": \"Support prometheus emitter (#13531)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-prometheus-emitter-13531\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"modify helm chart to support scraping from prometheus automatically\",\n",
      "\t\t\"author_name\": \"\\uc11c\\uc7ac\\uad8c(Data Platform)\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Feb 2023 15:40:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1f283fd314f61950fa240f7cf31eed251173518\",\n",
      "\t\t\"parent\": \"fa4cab405fae1cc986306f865508e9e04c577d8c\",\n",
      "\t\t\"subject\": \"Better sidecar support (#13655)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-sidecar-support-13655\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Better sidecar support  * remove un-thrown exception from test  * Druid you are such a stickler about spelling :)  * Only require the primaryContainerName, no need to exclude containers\",\n",
      "\t\t\"author_name\": \"Churro\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Feb 2023 10:56:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fa4cab405fae1cc986306f865508e9e04c577d8c\",\n",
      "\t\t\"parent\": \"842ee554de0556f190ed4bdc042d3ee6f54a210d\",\n",
      "\t\t\"subject\": \"fix bug with sql planner when virtual column capabilities are null (#13797)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-with-sql-planner-when-virtual-column-capabilities-are-null-13797\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Feb 2023 18:27:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"842ee554de0556f190ed4bdc042d3ee6f54a210d\",\n",
      "\t\t\"parent\": \"306997be872067ddcb99557746a5e04736640774\",\n",
      "\t\t\"subject\": \"Refinements to input-source specific table functions (#13780)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refinements-to-input-source-specific-table-functions-13780\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Refinements to table functions  Fixes various bugs Improves the structure of the table function classes Adds unit and integration tests\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Feb 2023 16:21:27 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"306997be872067ddcb99557746a5e04736640774\",\n",
      "\t\t\"parent\": \"f09f83697df5daa5dd52c6f930d12c0c68233776\",\n",
      "\t\t\"subject\": \"Add Perl 5 to druid requirements (#13708)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Perl-5-to-druid-requirements-13708\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Without perl 5 I was unable to start druid using the instructions in the quickstart guide. I'm not certain what versions it might require, but the one that I got working was perl 5  > This is perl 5, version 36, subversion 0 (v5.36.0) built for x86_64-linux-thread-multi\",\n",
      "\t\t\"author_name\": \"Guy \\u2600\\ufe0f Moore\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Feb 2023 13:34:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f09f83697df5daa5dd52c6f930d12c0c68233776\",\n",
      "\t\t\"parent\": \"38e620aa4cd5c85ef651a37c7f7cd9beb6d60920\",\n",
      "\t\t\"subject\": \"fix array_agg to work with complex types and bugs with expression aggregator complex array handling (#13781)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-array_agg-to-work-with-complex-types-and-bugs-with-expression-aggregator-complex-array-handling-13781\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix array_agg to work with complex types and bugs with expression aggregator complex array handling * more consistent handling of array expressions, numeric arrays more consistently honor druid.generic.useDefaultValueForNull, fix array_ordinal sql output type\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 12 Feb 2023 22:01:39 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"38e620aa4cd5c85ef651a37c7f7cd9beb6d60920\",\n",
      "\t\t\"parent\": \"477bc424d93ad5302049e2545988a06f24372983\",\n",
      "\t\t\"subject\": \"Operator conversion deny list (#13766)\",\n",
      "\t\t\"sanitized_subject_line\": \"Operator-conversion-deny-list-13766\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  This change adds a new config property `druid.sql.planner.operatorConversion.denyList`, which allows a user to specify any operator conversions that they wish to disallow. A user may want to do this for a number of reasons, including security concerns. The default value of this property is the empty list `[]`, which does not disallow any operator conversions.  An example usage of this property is `druid.sql.planner.operatorConversion.denyList=[\\\"extern\\\"]`, which disallows the usage of the `extern` operator conversion. If the property is configured this way, and a user of the Druid cluster tries to submit a query that uses the `extern` function, such as the example given [here](https://druid.apache.org/docs/latest/multi-stage-query/examples.html#insert-with-no-rollup), a response with http response code `400` is returned with en error body similar to the following:  ``` {   \\\"taskId\\\": \\\"4ec5b0b6-fa9b-4c3a-827d-2308294e9985\\\",   \\\"state\\\": \\\"FAILED\\\",   \\\"error\\\": {     \\\"error\\\": \\\"Plan validation failed\\\",     \\\"errorMessage\\\": \\\"org.apache.calcite.runtime.CalciteContextException: From line 28, column 5 to line 32, column 5: No match found for function signature EXTERN(<CHARACTER>, <CHARACTER>, <CHARACTER>)\\\",     \\\"errorClass\\\": \\\"org.apache.calcite.tools.ValidationException\\\",     \\\"host\\\": null   } } ```\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Feb 2023 09:59:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"477bc424d93ad5302049e2545988a06f24372983\",\n",
      "\t\t\"parent\": \"752964390e1c74446d14f136f5e73508cbf715fd\",\n",
      "\t\t\"subject\": \"Fix GHA tests cache hit miss scenario (#13772)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-GHA-tests-cache-hit-miss-scenario-13772\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* rebuild maven project or docker image in case of cache hit miss * rebuild maven project in case of docker cache hit miss too * fix docker-restore cache hit fail issue\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Feb 2023 08:57:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"752964390e1c74446d14f136f5e73508cbf715fd\",\n",
      "\t\t\"parent\": \"d7b95988d7caf2f5df9a104154f31778be0abc8c\",\n",
      "\t\t\"subject\": \"remove Travis CI (#13789)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-Travis-CI-13789\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Feb 2023 01:46:56 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7b95988d7caf2f5df9a104154f31778be0abc8c\",\n",
      "\t\t\"parent\": \"ffeda72abb40d8e849a95a6ccc1a76a870e45dd0\",\n",
      "\t\t\"subject\": \"Add missing documentation for constant post-aggregator (#13664)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-missing-documentation-for-constant-post-aggregator-13664\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Thanks @anshu-makkar , I was waiting for CI to complete yesterday. Failures seem unrelated, so merging.\",\n",
      "\t\t\"author_name\": \"Anshu Makkar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Feb 2023 08:53:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffeda72abb40d8e849a95a6ccc1a76a870e45dd0\",\n",
      "\t\t\"parent\": \"58d9720b0029f45c53c8b39c07141a1302c6e97d\",\n",
      "\t\t\"subject\": \"fix filtering nested field virtual column when used with non nested column input (#13779)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-filtering-nested-field-virtual-column-when-used-with-non-nested-column-input-13779\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix filtering nested field virtual column when used with non nested column input\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Feb 2023 03:16:38 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58d9720b0029f45c53c8b39c07141a1302c6e97d\",\n",
      "\t\t\"parent\": \"714ac07b524fcdc4d5a81a8f58af91ed03c78be3\",\n",
      "\t\t\"subject\": \"docs: notebook only for SQL tutorial (#13465)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-notebook-only-for-SQL-tutorial-13465\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"CI Failures seem unrelated to docs  * docs: notebook only for SQL tutorial  * Update logical operators section  * Fix typo  * Adopt review suggestions  * Update examples/quickstart/jupyter-notebooks/sql-tutorial.ipynb  * Update examples, add link to keywords  * Update after review  * Update per review comments  * Add links\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 20:04:53 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"714ac07b524fcdc4d5a81a8f58af91ed03c78be3\",\n",
      "\t\t\"parent\": \"d7a15be9bc29dfa3863dce76a8b93770a62cab7f\",\n",
      "\t\t\"subject\": \"Allow users to add additional metadata to ingestion metrics (#13760)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-users-to-add-additional-metadata-to-ingestion-metrics-13760\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Allow users to add additional metadata to ingestion metrics  When submitting an ingestion spec, users may pass a map of metadata in the ingestion spec config that will be added to ingestion metrics.  This will make it possible for operators to tag metrics with other metadata that doesn't necessarily line up with the existing tags like taskId.  Druid clusters that ingest these metrics can take advantage of the nested data columns feature to process this additional metadata.  * rename to tags  * docs  * tests  * fix test  * make code cov happy  * checkstyle\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 18:07:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7a15be9bc29dfa3863dce76a8b93770a62cab7f\",\n",
      "\t\t\"parent\": \"34c04daa9f731c0d3230062d9977fd67dd42a6f0\",\n",
      "\t\t\"subject\": \"Add assertions for counters from reports (#13726)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-assertions-for-counters-from-reports-13726\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Adds assertions for counters to MSQ unit tests\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 16:33:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"34c04daa9f731c0d3230062d9977fd67dd42a6f0\",\n",
      "\t\t\"parent\": \"d925ebdc9e12b5bb176c0bd05d58f86c1d5acafe\",\n",
      "\t\t\"subject\": \"Fix infinite iteration in http sync monitoring (#13731)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-infinite-iteration-in-http-sync-monitoring-13731\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix infinite iteration in http task runner  * Fix infinite iteration in http server view  * Add tests\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 15:14:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d925ebdc9e12b5bb176c0bd05d58f86c1d5acafe\",\n",
      "\t\t\"parent\": \"0cf1fc3d552ed105036664ed7aad58c14d8cc7b9\",\n",
      "\t\t\"subject\": \"Bump app version in Helm Chart from 0.23.0 to 24.0.0 (#13341)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-app-version-in-Helm-Chart-from-0.23.0-to-24.0.0-13341\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: zemin <zemin.piao@adyen.com>\",\n",
      "\t\t\"author_name\": \"jamon\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 11:48:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0cf1fc3d552ed105036664ed7aad58c14d8cc7b9\",\n",
      "\t\t\"parent\": \"5934d5fffee0aebf82f04b693a07a45c95a9798a\",\n",
      "\t\t\"subject\": \"Indexing on multiple disks (#13476)\",\n",
      "\t\t\"sanitized_subject_line\": \"Indexing-on-multiple-disks-13476\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Initial commit  * Simple UTs  * Parameterize tests  * Parameterized tests for k8s task runner  * Fix restore bug  * Refactor TaskStorageDirTracker  * Change CliPeon args \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 11:31:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5934d5fffee0aebf82f04b693a07a45c95a9798a\",\n",
      "\t\t\"parent\": \"f684df4c22ce723c35e95307a748388dfe4e54f5\",\n",
      "\t\t\"subject\": \"helm: Stop helm chart from failing if zkHosts is not set (#13746)\",\n",
      "\t\t\"sanitized_subject_line\": \"helm-Stop-helm-chart-from-failing-if-zkHosts-is-not-set-13746\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jason Witkowski\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Feb 2023 10:43:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f684df4c22ce723c35e95307a748388dfe4e54f5\",\n",
      "\t\t\"parent\": \"dcdae84888f71f92c808ed2b238f42cc64bda9a6\",\n",
      "\t\t\"subject\": \"Use an HllSketchHolder object to enable optimized merge (#13737)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-an-HllSketchHolder-object-to-enable-optimized-merge-13737\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use an HllSketchHolder object to enable optimized merge  HllSketchAggregatorFactory.combine had been implemented using a pure pair-wise, \\\"make a union -> add 2 things to union -> get sketch\\\" algorithm.  This algorithm does 2 things that was CPU  1) The Union object always builds an HLL_8 sketch regardless of the   target type.  This means that when the target type is not HLL_8, we   spent CPU cycles converting to HLL_8 and back over and over again 2) By throwing away the Union object and converting back to the   HllSketch only to build another Union object, we do lots and lots   of copy+conversions of the HllSketch  This change introduces an HllSketchHolder object which can hold onto a Union object and delay conversion back into an HllSketch until it is actually needed.  This follows the same pattern as the SketchHolder object for theta sketches. \",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Feb 2023 13:57:48 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dcdae84888f71f92c808ed2b238f42cc64bda9a6\",\n",
      "\t\t\"parent\": \"a0f8889f2316b57592e2e43c28aacfa2b92cd1ab\",\n",
      "\t\t\"subject\": \"Add server view initialization metrics (#13716)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-server-view-initialization-metrics-13716\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add server view init metrics  * Test coverage  * Rename metrics\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Feb 2023 20:02:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a0f8889f2316b57592e2e43c28aacfa2b92cd1ab\",\n",
      "\t\t\"parent\": \"b33962cab7809a750e7af5c0e0b6fdf009b347b3\",\n",
      "\t\t\"subject\": \"Robust handling and management of S3 streams for MSQ shuffle storage (#13741)\",\n",
      "\t\t\"sanitized_subject_line\": \"Robust-handling-and-management-of-S3-streams-for-MSQ-shuffle-storage-13741\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Feb 2023 14:17:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b33962cab7809a750e7af5c0e0b6fdf009b347b3\",\n",
      "\t\t\"parent\": \"2d3bee85457851aa96d4d0ed937a19d17113d83c\",\n",
      "\t\t\"subject\": \"Upgrade typescript and other dependencies (#13762)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-typescript-and-other-dependencies-13762\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump zustand, licenses  * Bump TypeScript, Eslint, use type imports  * Switch to react-shallow-renderer from enzyme  * Update ts-loader\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 23:12:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d3bee85457851aa96d4d0ed937a19d17113d83c\",\n",
      "\t\t\"parent\": \"9c5b61e114a6da4f1e8149ea0f1014aebc5f55db\",\n",
      "\t\t\"subject\": \"various nested column (and other) fixes (#13732)\",\n",
      "\t\t\"sanitized_subject_line\": \"various-nested-column-and-other-fixes-13732\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * modified druid schema column type compution to special case COMPLEX<json> handling to choose COMPLEX<json> if any column in any segment is COMPLEX<json> * NestedFieldVirtualColumn can now work correctly on any type of column, returning either a column selector if a root path, or nil selector if not * fixed a random bug with NilVectorSelector when using a vector size larger than the default and druid.generic.useDefaultValueForNull=false would have the nulls vector set to all false instead of true * fixed an overly aggressive check in ExprEval.ofType when handling complex types which would try to treat any string as base64 without gracefully falling back if it was not in fact base64 encoded, along with special handling for complex<json> * added ExpressionVectorSelectors.castValueSelectorToObject and ExpressionVectorSelectors.castObjectSelectorToNumeric as convience methods to cast vector selectors using cast expressions without the trouble of constructing an expression. the polymorphic nature of the non-vectorized engine (and significantly larger overhead of non-vectorized expression processing) made adding similar methods for non-vectorized selectors less attractive and so have not been added at this time * fix inconsistency between nested column indexer and serializer in handling values (coerce non primitive and non arrays of primitives using asString) * ExprEval best effort mode now handles byte[] as string * added test for ExprEval.bestEffortOf, and add missing conversion cases that tests uncovered * more tests more better\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 19:48:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9c5b61e114a6da4f1e8149ea0f1014aebc5f55db\",\n",
      "\t\t\"parent\": \"f28c06515b8ac1c2c3592a5d601ecd5df66c94de\",\n",
      "\t\t\"subject\": \"Fallback virtual column (#13739)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fallback-virtual-column-13739\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fallback virtual column  This virtual columns enables falling back to another column if the original column doesn't exist.  This is useful when doing column migrations and you have some old data with column X, new data with column Y and you want to use Y if it exists, X otherwise so that you can run a consistent query against all of the data.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 19:36:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f28c06515b8ac1c2c3592a5d601ecd5df66c94de\",\n",
      "\t\t\"parent\": \"9100a61bf61ba2b9b018e5ec8f7be178eff22243\",\n",
      "\t\t\"subject\": \"Auto-detect docker-compose (#13754)\",\n",
      "\t\t\"sanitized_subject_line\": \"Auto-detect-docker-compose-13754\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 21:29:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9100a61bf61ba2b9b018e5ec8f7be178eff22243\",\n",
      "\t\t\"parent\": \"c5835c29a142861741cd546e26c7132df9b3698b\",\n",
      "\t\t\"subject\": \"Fix NPE in postCleanupStage if stage doesn't exist (#13742)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-NPE-in-postCleanupStage-if-stage-doesn-t-exist-13742\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"With fault tolerance enabled in MSQ, not all the work orders might be populated if the worker is restarted. In case it gets the request for cleaning up the stage which is not present in the worker's map, it can throw an NPE. Added a check to ensure that the stage is present in the map before cleaning it up, or else logging it as a warning.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 19:13:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c5835c29a142861741cd546e26c7132df9b3698b\",\n",
      "\t\t\"parent\": \"e16639121f576b06ee4f66824def9ce3a7f24533\",\n",
      "\t\t\"subject\": \"Use durable super sorter intermediate storage only with composable storage (#13748)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-durable-super-sorter-intermediate-storage-only-with-composable-storage-13748\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* This enables usage of durable storage connector only in case the composable storage feature is enabled. \",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Feb 2023 18:59:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e16639121f576b06ee4f66824def9ce3a7f24533\",\n",
      "\t\t\"parent\": \"c06631037db3c7a4fa76c7ca3980e6655480c04a\",\n",
      "\t\t\"subject\": \"Local pathing for tests (#13753)\",\n",
      "\t\t\"sanitized_subject_line\": \"Local-pathing-for-tests-13753\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Feb 2023 20:11:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c06631037db3c7a4fa76c7ca3980e6655480c04a\",\n",
      "\t\t\"parent\": \"bea18dc9e432994c64811a5077fa45c51cb71ca5\",\n",
      "\t\t\"subject\": \"Moving to SHA based cache key (#13751)\",\n",
      "\t\t\"sanitized_subject_line\": \"Moving-to-SHA-based-cache-key-13751\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Elliott Freis <elliottfreis@Elliott-Freis.earth.dynamic.blacklight.net>\",\n",
      "\t\t\"author_name\": \"Elliott Freis\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Feb 2023 15:49:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bea18dc9e432994c64811a5077fa45c51cb71ca5\",\n",
      "\t\t\"parent\": \"758024877058b31c1025073a9041c15ef99c3857\",\n",
      "\t\t\"subject\": \"Update basic auth examples (#13750)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-basic-auth-examples-13750\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Feb 2023 14:45:48 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"758024877058b31c1025073a9041c15ef99c3857\",\n",
      "\t\t\"parent\": \"f022a9f2469d36666a98087f577d19d52fb06223\",\n",
      "\t\t\"subject\": \"Update api.md (#13727)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-api.md-13727\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Added missing '/status' in HTTP status request\",\n",
      "\t\t\"author_name\": \"drudi-at-coffee\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Feb 2023 10:43:22 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f022a9f2469d36666a98087f577d19d52fb06223\",\n",
      "\t\t\"parent\": \"6cb842e76e2605ed6c4c53279b1a49d67c471d97\",\n",
      "\t\t\"subject\": \"When a task fails and doesn't throw an exception, report it correctly\\u2026 (#13668)\",\n",
      "\t\t\"sanitized_subject_line\": \"When-a-task-fails-and-doesn-t-throw-an-exception-report-it-correctly-13668\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* When a task fails and doesn't throw an exception, report it correctly in mm-less druid  * Removing unthrown exception from test\",\n",
      "\t\t\"author_name\": \"Churro\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Feb 2023 09:04:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6cb842e76e2605ed6c4c53279b1a49d67c471d97\",\n",
      "\t\t\"parent\": \"440212c5f991faa3450c77a93c3af847836f5e6e\",\n",
      "\t\t\"subject\": \"update snapshots if cache restore failed otherwise run test normally (not all test mvn dependencies are downloaded during build phase due to skipTests) (#13740)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-snapshots-if-cache-restore-failed-otherwise-run-test-normally-not-all-test-mvn-dependencies-are-downloaded-during-build-phase-due-to-skipTests-13740\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Feb 2023 08:09:56 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"440212c5f991faa3450c77a93c3af847836f5e6e\",\n",
      "\t\t\"parent\": \"7c188d80b848416b5ac4fed17373b41c39d819b8\",\n",
      "\t\t\"subject\": \"Fix GHA workflow maven build erroring incase of version updates (#13735)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-GHA-workflow-maven-build-erroring-incase-of-version-updates-13735\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* build maven sequentially  * run mvn tests in offline mode after retrieving cache\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 20:32:57 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7c188d80b848416b5ac4fed17373b41c39d819b8\",\n",
      "\t\t\"parent\": \"33efd5ab1d06d406a0f91fe33c89b5be9652a2ea\",\n",
      "\t\t\"subject\": \"Make batch segment allocation logs less noisy (#13725)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-batch-segment-allocation-logs-less-noisy-13725\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Feb 2023 09:54:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"33efd5ab1d06d406a0f91fe33c89b5be9652a2ea\",\n",
      "\t\t\"parent\": \"f629643c50aee2708030ac6071f29cff1db487bf\",\n",
      "\t\t\"subject\": \"docs: Refresh the update data tutorial (#13641)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-Refresh-the-update-data-tutorial-13641\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Merging regardless of nit since topic is in better shape.  * refresh the update data tutorial  * Apply suggestions from code review  Co-authored-by: Jill Osborne <jill.osborne@imply.io>  ---------  Co-authored-by: Jill Osborne <jill.osborne@imply.io>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 18:18:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f629643c50aee2708030ac6071f29cff1db487bf\",\n",
      "\t\t\"parent\": \"7f830b20d76b7c5c2d7541d632f3b1c005251ade\",\n",
      "\t\t\"subject\": \"Fix value of lookup sync period in docs (#13695)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-value-of-lookup-sync-period-in-docs-13695\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix lookup docs  * Fix spelling  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  ---------  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 18:12:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f830b20d76b7c5c2d7541d632f3b1c005251ade\",\n",
      "\t\t\"parent\": \"cfc3115a5957ce8663fc27429a4494034d259a73\",\n",
      "\t\t\"subject\": \"fixed init commands for both mysql and postgresql (#13713)\",\n",
      "\t\t\"sanitized_subject_line\": \"fixed-init-commands-for-both-mysql-and-postgresql-13713\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sergio Ferragut\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 18:07:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cfc3115a5957ce8663fc27429a4494034d259a73\",\n",
      "\t\t\"parent\": \"76e79c7db7dfebfc04efbbed148ff9d7e717f48d\",\n",
      "\t\t\"subject\": \"Compaction history returns empty list instead of 404 when not found (#13730)\",\n",
      "\t\t\"sanitized_subject_line\": \"Compaction-history-returns-empty-list-instead-of-404-when-not-found-13730\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Compaction history returns empty list instead of 404 when not found  * checkstyle\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 17:44:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"76e79c7db7dfebfc04efbbed148ff9d7e717f48d\",\n",
      "\t\t\"parent\": \"74ff848ce54cd389bdae6153322ba8cbc32d5cb2\",\n",
      "\t\t\"subject\": \"Suppress CVEs (#13733)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVEs-13733\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 04:18:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"74ff848ce54cd389bdae6153322ba8cbc32d5cb2\",\n",
      "\t\t\"parent\": \"c95a26cae3ecafca430326ae8302fefda59b9fbd\",\n",
      "\t\t\"subject\": \"Fixing  incorrect filtering of nulls in an array when ingesting for JSON and Avro (#13712)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-incorrect-filtering-of-nulls-in-an-array-when-ingesting-for-JSON-and-Avro-13712\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 04:15:08 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c95a26cae3ecafca430326ae8302fefda59b9fbd\",\n",
      "\t\t\"parent\": \"7a3bd89a854c73879ccdc51ce35071f81109b24c\",\n",
      "\t\t\"subject\": \"Migrate ITs from Travis to GHA (#13681)\",\n",
      "\t\t\"sanitized_subject_line\": \"Migrate-ITs-from-Travis-to-GHA-13681\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 03:31:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7a3bd89a854c73879ccdc51ce35071f81109b24c\",\n",
      "\t\t\"parent\": \"ec1e6ac8407066fe0f21835c733e1fb15b7d3b0c\",\n",
      "\t\t\"subject\": \"Dimension dictionary reduce locking (#13710)\",\n",
      "\t\t\"sanitized_subject_line\": \"Dimension-dictionary-reduce-locking-13710\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* perf: introduce benchmark for StringDimensionIndexer  jdk11 -- Benchmark                                                       Mode  Cnt      Score     Error  Units StringDimensionIndexerProcessBenchmark.parallelReadWrite                 avgt   10  30471.552 \\u00b1  456.716  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelReader  avgt   10  18069.863 \\u00b1  327.923  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelWriter  avgt   10  67676.617 \\u00b1 2351.311  us/op StringDimensionIndexerProcessBenchmark.soloReader                        avgt   10   1048.079 \\u00b1    1.120  us/op StringDimensionIndexerProcessBenchmark.soloWriter                        avgt   10   4629.769 \\u00b1   29.353  us/op  * perf: switch DimensionDictionary to StampedLock  jdk11 - Benchmark                                                        Mode  Cnt      Score      Error  Units StringDimensionIndexerProcessBenchmark.parallelReadWrite                 avgt   10  37958.372 \\u00b1 1685.206  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelReader  avgt   10  31192.232 \\u00b1 2755.365  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelWriter  avgt   10  58256.791 \\u00b1 1998.220  us/op StringDimensionIndexerProcessBenchmark.soloReader                        avgt   10   1079.440 \\u00b1    1.753  us/op StringDimensionIndexerProcessBenchmark.soloWriter                        avgt   10   4585.690 \\u00b1   13.225  us/op  * perf: use optimistic locking in DimensionDictionary  jdk11 - Benchmark                                                        Mode  Cnt      Score     Error  Units StringDimensionIndexerProcessBenchmark.parallelReadWrite                 avgt   10   6212.366 \\u00b1 162.684  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelReader  avgt   10   1807.235 \\u00b1 109.339  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelWriter  avgt   10  19427.759 \\u00b1 611.692  us/op StringDimensionIndexerProcessBenchmark.soloReader                        avgt   10    194.370 \\u00b1   1.050  us/op StringDimensionIndexerProcessBenchmark.soloWriter                        avgt   10   2871.423 \\u00b1  14.426  us/op  * perf: refactor DimensionDictionary null handling to need less locks  jdk11 - Benchmark                                                        Mode  Cnt      Score      Error  Units StringDimensionIndexerProcessBenchmark.parallelReadWrite                 avgt   10   6591.619 \\u00b1  470.497  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelReader  avgt   10   1387.338 \\u00b1  144.587  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelWriter  avgt   10  22204.462 \\u00b1 1620.806  us/op StringDimensionIndexerProcessBenchmark.soloReader                        avgt   10    204.911 \\u00b1    0.459  us/op StringDimensionIndexerProcessBenchmark.soloWriter                        avgt   10   2935.376 \\u00b1   12.639  us/op  * perf: refactor DimensionDictionary add handling to do a little less work  jdk11 - Benchmark                                                        Mode  Cnt      Score    Error  Units StringDimensionIndexerProcessBenchmark.parallelReadWrite                 avgt   10   2914.859 \\u00b1 22.519  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelReader  avgt   10    508.010 \\u00b1 14.675  us/op StringDimensionIndexerProcessBenchmark.parallelReadWrite:parallelWriter  avgt   10  10135.408 \\u00b1 82.745  us/op StringDimensionIndexerProcessBenchmark.soloReader                        avgt   10    205.415 \\u00b1  0.158  us/op StringDimensionIndexerProcessBenchmark.soloWriter                        avgt   10   3098.743 \\u00b1 23.603  us/op\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Feb 2023 02:59:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ec1e6ac8407066fe0f21835c733e1fb15b7d3b0c\",\n",
      "\t\t\"parent\": \"1beef30bb29af94156e8cd96407c23eeece2de3a\",\n",
      "\t\t\"subject\": \"fix nested column handling of null and \\\"null\\\" (#13714)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-nested-column-handling-of-null-and-null-13714\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix nested column handling of null and \\\"null\\\" * fix issue merging nested column value dictionaries that could incorrect lose dictionary values\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 Jan 2023 20:59:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1beef30bb29af94156e8cd96407c23eeece2de3a\",\n",
      "\t\t\"parent\": \"51dfde02840017092486fb75be2b16566aff6a19\",\n",
      "\t\t\"subject\": \"Support  postaggregation function  as in Math.pow() (#13703)  (#13704)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-postaggregation-function-as-in-Math.pow-13703-13704\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Support postaggregation function as in Math.pow()\",\n",
      "\t\t\"author_name\": \"Tijo Thomas\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 Jan 2023 22:55:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"51dfde02840017092486fb75be2b16566aff6a19\",\n",
      "\t\t\"parent\": \"698670c88e3993be971d5c7dda5fed281e32f6de\",\n",
      "\t\t\"subject\": \"Add maxInputBytesPerWorker as query context parameter (#13707)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-maxInputBytesPerWorker-as-query-context-parameter-13707\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add maxInputBytesPerWorker as query context parameter  * Move documenation to msq specific docs  * Update tests  * Spacing  * Address review comments  * Fix test  * Update docs/multi-stage-query/reference.md  * Correct spelling mistake  ---------  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 Jan 2023 20:55:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"698670c88e3993be971d5c7dda5fed281e32f6de\",\n",
      "\t\t\"parent\": \"356b0e37cfa95506174a8536684c3ae4420ee197\",\n",
      "\t\t\"subject\": \"update core Apache Kafka dependencies to 3.3.2 (#13717)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-core-Apache-Kafka-dependencies-to-3.3.2-13717\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Release notes: - https://downloads.apache.org/kafka/3.3.2/RELEASE_NOTES.html\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 27 Jan 2023 21:00:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"356b0e37cfa95506174a8536684c3ae4420ee197\",\n",
      "\t\t\"parent\": \"3b62d7929c6a291acfd1b76383ddeda1e044c414\",\n",
      "\t\t\"subject\": \"Tutorial: Query view (#13565)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tutorial-Query-view-13565\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Tutorial: Query view  * Removed duplicate file  * Update tutorial-sql-query-view.md  * Update tutorial-sql-query-view.md  * Update tutorial-sql-query-view.md  * Updated after review  * Update docs/tutorials/tutorial-sql-query-view.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update tutorial-sql-query-view.md  Update title  * Update sidebars.json  fix merge conflict w/ sidebar  * address spelling ci  ---------  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 27 Jan 2023 14:29:43 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3b62d7929c6a291acfd1b76383ddeda1e044c414\",\n",
      "\t\t\"parent\": \"6164c420a15f7970b9fa6e1882893ad5e9fcaf48\",\n",
      "\t\t\"subject\": \"Web console: Data loader should allow for multiline JSON messages in kafka (#13709)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Data-loader-should-allow-for-multiline-JSON-messages-in-kafka-13709\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* stricter  * data loader should allow for mulit-line json  * add await  * kinesis also\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 Jan 2023 21:23:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6164c420a15f7970b9fa6e1882893ad5e9fcaf48\",\n",
      "\t\t\"parent\": \"9021161c8cc1fcff801b62574abb134c944418e9\",\n",
      "\t\t\"subject\": \"Create update.md (#13451)\",\n",
      "\t\t\"sanitized_subject_line\": \"Create-update.md-13451\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Create update.md  Important Line highlighted  * Update docs/data-management/update.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"sairam devarashetty\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 Jan 2023 16:23:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9021161c8cc1fcff801b62574abb134c944418e9\",\n",
      "\t\t\"parent\": \"17c0167248035b7ff37d1b9407c13395276fda25\",\n",
      "\t\t\"subject\": \"doc: fix markdown spacing (#13683)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-fix-markdown-spacing-13683\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* doc: fix markdown spacing  * fix spacing\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 Jan 2023 16:22:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"17c0167248035b7ff37d1b9407c13395276fda25\",\n",
      "\t\t\"parent\": \"00cee329bde326bde8ef2071b1ffc1970c5c328c\",\n",
      "\t\t\"subject\": \"Additional native query tests for unnest datasource (#13554)\",\n",
      "\t\t\"sanitized_subject_line\": \"Additional-native-query-tests-for-unnest-datasource-13554\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Native tests for the unnest datasource.\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 Jan 2023 15:57:52 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"00cee329bde326bde8ef2071b1ffc1970c5c328c\",\n",
      "\t\t\"parent\": \"706b8a02270e68090ebcdd67a170df0007454bd2\",\n",
      "\t\t\"subject\": \"pitfall when using combining input source (#13639)\",\n",
      "\t\t\"sanitized_subject_line\": \"pitfall-when-using-combining-input-source-13639\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 Jan 2023 12:50:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"706b8a02270e68090ebcdd67a170df0007454bd2\",\n",
      "\t\t\"parent\": \"016c881795c03fc6a107f46243ffc71854088e53\",\n",
      "\t\t\"subject\": \"Adjust Operators to be Pausable (#13694)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adjust-Operators-to-be-Pausable-13694\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adjust Operators to be Pausable  This enables \\\"merge\\\" style operations that combine multiple streams.  This change includes a naive implementation of one such merge operator just to provide concrete evidence that the refactoring is effective.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 Jan 2023 20:52:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"016c881795c03fc6a107f46243ffc71854088e53\",\n",
      "\t\t\"parent\": \"90d445536da54fdd48631feea73eff63fb6d476f\",\n",
      "\t\t\"subject\": \"Add API to return automatic compaction config history (#13699)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-API-to-return-automatic-compaction-config-history-13699\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add a new API to return the history of changes to automatic compaction config history to make it easy for users to see what changes have been made to their auto-compaction config.  The API is scoped per dataSource to allow users to triage issues with an individual dataSource. The API responds with a list of configs when there is a change to either the settings that impact all auto-compaction configs on a cluster or the dataSource in question.\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 Jan 2023 13:23:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90d445536da54fdd48631feea73eff63fb6d476f\",\n",
      "\t\t\"parent\": \"f76acccff2b897f930b8971465f0ddf90385f99b\",\n",
      "\t\t\"subject\": \"SQL version of unnest native druid function (#13576)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-version-of-unnest-native-druid-function-13576\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* adds the SQL component of the native unnest functionality in Druid to unnest SQL queries on a table dimension, virtual column or a constant array and convert them into native Druid queries * unnest in SQL is implemented as a combination of Correlate (the comma join part) and Uncollect (the unnest part)\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 Jan 2023 12:53:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f76acccff2b897f930b8971465f0ddf90385f99b\",\n",
      "\t\t\"parent\": \"a516eb1a412f8d718d30bb62e7bc27f322d35197\",\n",
      "\t\t\"subject\": \"Allow using composed storage for SuperSorter intermediate data (#13368)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-using-composed-storage-for-SuperSorter-intermediate-data-13368\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 24 Jan 2023 01:02:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a516eb1a412f8d718d30bb62e7bc27f322d35197\",\n",
      "\t\t\"parent\": \"fb26a1093d11f0574dbb905ac0d39c8eb3777312\",\n",
      "\t\t\"subject\": \"Port Calcite's tests to run with MSQ  (#13625)\",\n",
      "\t\t\"sanitized_subject_line\": \"Port-Calcite-s-tests-to-run-with-MSQ-13625\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL test framework extensions  * Capture planner artifacts: logical plan, etc. * Planner test builder validates the logical plan * Validation for the SQL resut schema (we already have   validation for the Druid row signature) * Better Guice integration: properties, reuse Guice modules * Avoid need for hand-coded expr, macro tables * Retire some of the test-specific query component creation * Fix query log hook race condition  Co-authored-by: Paul Rogers <progers@apache.org>\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 Jan 2023 08:51:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fb26a1093d11f0574dbb905ac0d39c8eb3777312\",\n",
      "\t\t\"parent\": \"1582d74f375bf97a26fbc3327c97f96906ab247d\",\n",
      "\t\t\"subject\": \"discover nested columns when using nested column indexer for schemaless ingestion (#13672)\",\n",
      "\t\t\"sanitized_subject_line\": \"discover-nested-columns-when-using-nested-column-indexer-for-schemaless-ingestion-13672\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* discover nested columns when using nested column indexer for schemaless * move useNestedColumnIndexerForSchemaDiscovery from AppendableIndexSpec to DimensionsSpec \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 18 Jan 2023 12:57:28 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1582d74f375bf97a26fbc3327c97f96906ab247d\",\n",
      "\t\t\"parent\": \"fa493f1ebca6b5fab3f1b0f4046e7a6f78511645\",\n",
      "\t\t\"subject\": \"Fix Parquet Reader for schema-less ingestion need to read all columns (#13689)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Parquet-Reader-for-schema-less-ingestion-need-to-read-all-columns-13689\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix stuff  * address comments\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 18 Jan 2023 12:52:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fa493f1ebca6b5fab3f1b0f4046e7a6f78511645\",\n",
      "\t\t\"parent\": \"7a54524076b99b0f6dc2456dccf7ef151ecc7f59\",\n",
      "\t\t\"subject\": \"Convert from DRUID_INTEGRATION_TEST_INDEXER to USE_INDEXER (#13684)\",\n",
      "\t\t\"sanitized_subject_line\": \"Convert-from-DRUID_INTEGRATION_TEST_INDEXER-to-USE_INDEXER-13684\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The old ITs use DRUID_INTEGRATION_TEST_INDEXER. The new ones use the USE_INDEXER env var passed in from the build environment.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 18 Jan 2023 08:51:42 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7a54524076b99b0f6dc2456dccf7ef151ecc7f59\",\n",
      "\t\t\"parent\": \"44374f91bc77aa6e6a486559ac30540de14b1aff\",\n",
      "\t\t\"subject\": \"install node on runners (#13690)\",\n",
      "\t\t\"sanitized_subject_line\": \"install-node-on-runners-13690\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 18 Jan 2023 16:19:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44374f91bc77aa6e6a486559ac30540de14b1aff\",\n",
      "\t\t\"parent\": \"22630b0aabbaf683748b65a698ccbf966e1a54a4\",\n",
      "\t\t\"subject\": \"Fix broken links to Oracle JDK docs (#13687)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-broken-links-to-Oracle-JDK-docs-13687\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix broken link for SSLContext java doc  * Update tls-support.md  * Update tls-support.md  * Update tls-support.md  * Update simple-client-sslcontext.md\",\n",
      "\t\t\"author_name\": \"Eyal Yurman\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 18 Jan 2023 14:46:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"22630b0aabbaf683748b65a698ccbf966e1a54a4\",\n",
      "\t\t\"parent\": \"59dfe7bed395adb8064b26220bc606c6d28adba7\",\n",
      "\t\t\"subject\": \"Much improved table functions (#13627)\",\n",
      "\t\t\"sanitized_subject_line\": \"Much-improved-table-functions-13627\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Much improved table functions  * Revises properties, definitions in the catalog * Adds a \\\"table function\\\" abstraction to model such functions * Specific functions for HTTP, inline, local and S3. * Extended SQL types in the catalog * Restructure external table definitions to use table functions * EXTEND syntax for Druid's extern table function * Support for array-valued table function parameters * Support for array-valued SQL query parameters * Much new documentation\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 Jan 2023 08:41:57 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"59dfe7bed395adb8064b26220bc606c6d28adba7\",\n",
      "\t\t\"parent\": \"cc89c661d0aebf95bb85f01bfbedf76251e2f307\",\n",
      "\t\t\"subject\": \"Add new probe delay configurations into Helm Chart doc (#12997)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-new-probe-delay-configurations-into-Helm-Chart-doc-12997\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 Jan 2023 22:06:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc89c661d0aebf95bb85f01bfbedf76251e2f307\",\n",
      "\t\t\"parent\": \"7ff3722cb95bfa14c92b822118c1453a3a3c6fcd\",\n",
      "\t\t\"subject\": \"Move the tips section in PR template into comments block (#13676)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-the-tips-section-in-PR-template-into-comments-block-13676\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 Jan 2023 17:01:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7ff3722cb95bfa14c92b822118c1453a3a3c6fcd\",\n",
      "\t\t\"parent\": \"ed623d626f5e821d9056e745bc3b8f344ea91784\",\n",
      "\t\t\"subject\": \"Swap LazySingleton for Singleton (#13673)\",\n",
      "\t\t\"sanitized_subject_line\": \"Swap-LazySingleton-for-Singleton-13673\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Swap LazySingleton for Singleton * Initialize WebserverTestUtils properly\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 15 Jan 2023 21:38:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ed623d626f5e821d9056e745bc3b8f344ea91784\",\n",
      "\t\t\"parent\": \"566fc990e43991784ffcc9ffa64d763650842f36\",\n",
      "\t\t\"subject\": \"Support both Indexer and MiddleManager in ITs (#13660)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-both-Indexer-and-MiddleManager-in-ITs-13660\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Support both indexer and MM in ITs  Support for the DRUID_INTEGRATION_TEST_INDEXER variable Conditional client cluster configuration Cleanup of OVERRIDE_ENV file handling Enforce setting of test-specific env vars Cleanup of unused bits \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 14 Jan 2023 14:34:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"566fc990e43991784ffcc9ffa64d763650842f36\",\n",
      "\t\t\"parent\": \"4368b3a071719b50e8341626d967b8ae77caa786\",\n",
      "\t\t\"subject\": \"Semantic Implementations for ArrayListRAC (#13652)\",\n",
      "\t\t\"sanitized_subject_line\": \"Semantic-Implementations-for-ArrayListRAC-13652\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Semantic Implementations for ArrayListRAC  This adds implementations of semantic interfaces to optimize (eliminate object creation) the window processing on top of an ArrayListSegment.  Tests are also added to cover the interplay between the semantic interfaces that are expected for this use case\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 13 Jan 2023 19:42:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4368b3a071719b50e8341626d967b8ae77caa786\",\n",
      "\t\t\"parent\": \"182c4fad299fca4864010fa7a07aa30c1f4dd9c5\",\n",
      "\t\t\"subject\": \"Migrate jdk8 unit tests from Travis to GHA (#13518)\",\n",
      "\t\t\"sanitized_subject_line\": \"Migrate-jdk8-unit-tests-from-Travis-to-GHA-13518\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* migrate UTs form Travis to GHA  * update permissions  * rename file  * set fetch depth to 1  * debugs remote branches  * test with github.ref variable  * fetch github.base_ref for diff  * nit  * test git diff  * run tests  * test code coverage failure scenario  * nit  * nit  * revert code changes  * revert code changes  * Setup diff-test-coverage before tests  * build distribution module at end in packaging check  * nit  * remove redundant steps in static-checks workflow  * drop jdk8 unit tests from Travis\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 13 Jan 2023 14:46:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"182c4fad299fca4864010fa7a07aa30c1f4dd9c5\",\n",
      "\t\t\"parent\": \"b5b740bbbb4be5f5e1bb5cf0cd9118137913c76c\",\n",
      "\t\t\"subject\": \"Kinesis: More robust default fetch settings. (#13539)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kinesis-More-robust-default-fetch-settings.-13539\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Kinesis: More robust default fetch settings.  1) Default recordsPerFetch and recordBufferSize based on available memory    rather than using hardcoded numbers. For this, we need an estimate    of record size. Use 10 KB for regular records and 1 MB for aggregated    records. With 1 GB heaps, 2 processors per task, and nonaggregated    records, recordBufferSize comes out to the same as the old    default (10000), and recordsPerFetch comes out slightly lower (1250    instead of 4000).  2) Default maxRecordsPerPoll based on whether records are aggregated    or not (100 if not aggregated, 1 if aggregated). Prior default was 100.  3) Default fetchThreads based on processors divided by task count on    Indexers, rather than overall processor count.  4) Additionally clean up the serialized JSON a bit by adding various    JsonInclude annotations.  * Updates for tests.  * Additional important verify.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 13 Jan 2023 11:03:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b5b740bbbb4be5f5e1bb5cf0cd9118137913c76c\",\n",
      "\t\t\"parent\": \"93dc01b6c5827b694c5f573b2c103ccdb7e00db0\",\n",
      "\t\t\"subject\": \"allow using nested column indexer for schema discovery (#13653)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-using-nested-column-indexer-for-schema-discovery-13653\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* single typed \\\"root\\\" only nested columns now mimic \\\"regular\\\" columns of those types * incremental index can now use nested column indexer instead of string indexer for discovered columns\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 12 Jan 2023 18:31:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"93dc01b6c5827b694c5f573b2c103ccdb7e00db0\",\n",
      "\t\t\"parent\": \"cb16a7f6a942c2a070832420d3962a2dce6cfdc4\",\n",
      "\t\t\"subject\": \"fix broken table missing new line (#13666)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-broken-table-missing-new-line-13666\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 12 Jan 2023 15:29:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb16a7f6a942c2a070832420d3962a2dce6cfdc4\",\n",
      "\t\t\"parent\": \"0a486c3bcfe9d6e59eb456934f659d9ec9ab231c\",\n",
      "\t\t\"subject\": \"Fix behaviour of downsampling buckets to a single key (#13663)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-behaviour-of-downsampling-buckets-to-a-single-key-13663\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 12 Jan 2023 21:24:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0a486c3bcfe9d6e59eb456934f659d9ec9ab231c\",\n",
      "\t\t\"parent\": \"afb3d917772123ccc4ee46ac8bdb06b9ab00cdf3\",\n",
      "\t\t\"subject\": \"Update forbidden apis with fixed executor (#13633)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-forbidden-apis-with-fixed-executor-13633\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update forbidden apis with fixed executor\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 12 Jan 2023 15:34:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"afb3d917772123ccc4ee46ac8bdb06b9ab00cdf3\",\n",
      "\t\t\"parent\": \"7f54ebbf478b9a2122edcc4bee4815ae86831927\",\n",
      "\t\t\"subject\": \"Add unit test for complex column grouping (#13650)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-unit-test-for-complex-column-grouping-13650\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add unit test for complex column grouping  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 12 Jan 2023 15:25:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f54ebbf478b9a2122edcc4bee4815ae86831927\",\n",
      "\t\t\"parent\": \"f97bcc69d3384ce4a1310a719f965b33565ed41a\",\n",
      "\t\t\"subject\": \"Fix Parquet Parser missing column when reading parquet file  (#13612)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Parquet-Parser-missing-column-when-reading-parquet-file-13612\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix parquet reader  * fix checkstyle  * fix bug  * fix inspection  * refactor  * fix checkstyle  * fix checkstyle  * fix checkstyle  * fix checkstyle  * add test  * fix checkstyle  * fix tests  * add IT  * add IT  * add more tests  * fix checkstyle  * fix stuff  * fix stuff  * add more tests  * add more tests\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 Jan 2023 20:08:48 -1000\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f97bcc69d3384ce4a1310a719f965b33565ed41a\",\n",
      "\t\t\"parent\": \"a83d1cdf268aea882ac4b87e8e658373706e94ac\",\n",
      "\t\t\"subject\": \"Docs: reword single server page (#13659)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-reword-single-server-page-13659\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* reword single server page  * fix typo  * Update docs/operations/single-server.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * spelling  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 Jan 2023 21:12:52 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a83d1cdf268aea882ac4b87e8e658373706e94ac\",\n",
      "\t\t\"parent\": \"5ef689fc3ffd91a00c4f8bc08ed4c7a8287eb52c\",\n",
      "\t\t\"subject\": \"fix var name (#13657)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-var-name-13657\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 Jan 2023 21:15:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ef689fc3ffd91a00c4f8bc08ed4c7a8287eb52c\",\n",
      "\t\t\"parent\": \"56076d33fbb02ead4cd317758106db6546723597\",\n",
      "\t\t\"subject\": \"Cloud deep storage tests in new IT framework (S3, GCS, Azure) (#13535)\",\n",
      "\t\t\"sanitized_subject_line\": \"Cloud-deep-storage-tests-in-new-IT-framework-S3-GCS-Azure-13535\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ s3 deep storage tests  * Fix license check  * Getting config values from env variables  * Added  s3TestUtils  * Merged AbstractITSQLBasedIngestionTest with AbstractITBatchIndexTest  * Fixing license issues  * Fixing checkstyle errors  * Fix spotbug errors  * Update s3util name in other files  * GCS and Azure deep storage tests  * Fix license and checkstyle errors  * Fix dependency error  * fix intellij check errors  * Copy credentials file in all containers  * Refactor and gcs file upload fix  * Fixing dependency check errors and codeQL warnings  * Fixing checkstyle errors  * Fixing intellij inspection errors  * Removing unrequired exceptions  * Addressing comments\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 Jan 2023 09:43:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"56076d33fbb02ead4cd317758106db6546723597\",\n",
      "\t\t\"parent\": \"17936e2920df5c0f5c819b80403330c5e689cd6c\",\n",
      "\t\t\"subject\": \"Worker retry for MSQ task (#13353)\",\n",
      "\t\t\"sanitized_subject_line\": \"Worker-retry-for-MSQ-task-13353\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Initial commit.  * Fixing error message in retry exceeded exception  * Cleaning up some code  * Adding some test cases.  * Adding java docs.  * Finishing up state test cases.  * Adding some more java docs and fixing spot bugs, intellij inspections  * Fixing intellij inspections and added tests  * Documenting error codes  * Migrate current integration batch tests to equivalent MSQ tests (#13374)  * Migrate current integration batch tests to equivalent MSQ tests using new IT framework  * Fix build issues  * Trigger Build  * Adding more tests and addressing comments  * fixBuildIssues  * fix dependency issues  * Parameterized the test and addressed comments  * Addressing comments  * fixing checkstyle errors  * Adressing comments  * Adding ITTest which kills the worker abruptly  * Review comments phase one  * Adding doc changes  * Adjusting for single threaded execution.  * Adding Sequential Merge PR state handling  * Merge things  * Fixing checkstyle.  * Adding new context param for fault tolerance. Adding stale task handling in sketchFetcher. Adding UT's.  * Merge things  * Merge things  * Adding parameterized tests Created separate module for faultToleranceTests  * Adding missed files  * Review comments and fixing tests.  * Documentation things.  * Fixing IT  * Controller impl fix.  * Fixing racy WorkerSketchFetcherTest.java exception handling.  Co-authored-by: abhagraw <99210446+abhagraw@users.noreply.github.com> Co-authored-by: Karan Kumar <cryptoe@karans-mbp.lan>\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 Jan 2023 07:38:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"17936e2920df5c0f5c819b80403330c5e689cd6c\",\n",
      "\t\t\"parent\": \"2503095296b5a5f95c8d0fddc4e0ba88aa5db149\",\n",
      "\t\t\"subject\": \"Add an option to enable HSTS in druid services (#13489)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-an-option-to-enable-HSTS-in-druid-services-13489\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add an option to enable HSTS  * Fix code and add docs  * Deduplicate headers  * unused import  * Fix spelling\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 Jan 2023 22:31:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2503095296b5a5f95c8d0fddc4e0ba88aa5db149\",\n",
      "\t\t\"parent\": \"74a76c74b111d3f6dafbbb0b41926ca9aa6f7bed\",\n",
      "\t\t\"subject\": \"Publish SBOM artifacts (#13648)\",\n",
      "\t\t\"sanitized_subject_line\": \"Publish-SBOM-artifacts-13648\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Dongjoon Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 Jan 2023 16:08:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"74a76c74b111d3f6dafbbb0b41926ca9aa6f7bed\",\n",
      "\t\t\"parent\": \"41fdf6eafbf3ff4bb67909ba15a2eaeb648dd036\",\n",
      "\t\t\"subject\": \"Updating dependency check version (#13649)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updating-dependency-check-version-13649\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 Jan 2023 14:43:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"41fdf6eafbf3ff4bb67909ba15a2eaeb648dd036\",\n",
      "\t\t\"parent\": \"62a105ee65af2911303ef9ba30c411c1444a8bac\",\n",
      "\t\t\"subject\": \"Quote and escape literals in JDBC lookup to allow reserved identifiers. (#13632)\",\n",
      "\t\t\"sanitized_subject_line\": \"Quote-and-escape-literals-in-JDBC-lookup-to-allow-reserved-identifiers.-13632\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Quote and escape table, key and column names.  * fix typo.  * More select statements.  * Derby lookup tests create quoted identifiers so it's compatible.  * Use Stringutils.replace() utility.  * quote the filter string.  * Squish doubly quote usage into a single function.  * Add parameterized test with reserved identifiers.  * few changes.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 Jan 2023 12:11:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"62a105ee65af2911303ef9ba30c411c1444a8bac\",\n",
      "\t\t\"parent\": \"a800dae87a2bfb397cf8ac2edd8967ab72f05c6a\",\n",
      "\t\t\"subject\": \"Add context to HadoopIngestionSpec (#13624)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-context-to-HadoopIngestionSpec-13624\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add context to HadoopIngestionSpec  * fix alert\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 9 Jan 2023 14:37:02 -1000\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a800dae87a2bfb397cf8ac2edd8967ab72f05c6a\",\n",
      "\t\t\"parent\": \"6bbf4266b2140ddf7b4a4a1ab79919fb6724e52d\",\n",
      "\t\t\"subject\": \"doc: List Protobuf as a supported format (#13640)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-List-Protobuf-as-a-supported-format-13640\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 6 Jan 2023 15:09:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6bbf4266b2140ddf7b4a4a1ab79919fb6724e52d\",\n",
      "\t\t\"parent\": \"f1821a7c18bf938882114e8435dfda696affe871\",\n",
      "\t\t\"subject\": \"docs: documentation for unnest datasource (#13479)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-documentation-for-unnest-datasource-13479\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 6 Jan 2023 11:41:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f1821a7c18bf938882114e8435dfda696affe871\",\n",
      "\t\t\"parent\": \"4ee4d99b8df95974722140eeb7d8de7ffc64c788\",\n",
      "\t\t\"subject\": \"Add Sort Operator for Window Functions (#13619)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Sort-Operator-for-Window-Functions-13619\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Addition of NaiveSortMaker and Default implementation  Add the NaiveSortMaker which makes a sorter object and a default implementation of the interface.  This also allows us to plan multiple different window  definitions on the same query.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 6 Jan 2023 00:27:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ee4d99b8df95974722140eeb7d8de7ffc64c788\",\n",
      "\t\t\"parent\": \"fdc8aa283340054d94b3fde593a82aed5b2ba0f4\",\n",
      "\t\t\"subject\": \"better error reporting (#13636)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-error-reporting-13636\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 5 Jan 2023 20:00:33 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fdc8aa283340054d94b3fde593a82aed5b2ba0f4\",\n",
      "\t\t\"parent\": \"a8ecc48ffe9a2b04cac7b7b14a5300028e8bf13d\",\n",
      "\t\t\"subject\": \"better show totals when grouping (#13631)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-show-totals-when-grouping-13631\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 5 Jan 2023 18:06:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8ecc48ffe9a2b04cac7b7b14a5300028e8bf13d\",\n",
      "\t\t\"parent\": \"7a7874a952bd5b1a39b08f1f33ce395cc1452286\",\n",
      "\t\t\"subject\": \"Validate response headers and fix exception logging (#13609)\",\n",
      "\t\t\"sanitized_subject_line\": \"Validate-response-headers-and-fix-exception-logging-13609\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Validate response headers and fix exception logging  A class of QueryException were throwing away their causes making it really hard to determine what's going wrong when something goes wrong in the SQL planner specifically.  Fix that and adjust tests  to do more validation of response headers as well.  We allow 404s and 307s to be returned even without  authorization validated, but others get converted to 403\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 5 Jan 2023 14:15:15 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7a7874a952bd5b1a39b08f1f33ce395cc1452286\",\n",
      "\t\t\"parent\": \"365474ff1d0518cb5d91a7bc7096dabef463cb34\",\n",
      "\t\t\"subject\": \"Update docker-compose to use druid 24.0.1 (#13623)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-docker-compose-to-use-druid-24.0.1-13623\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Varachit W\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 4 Jan 2023 18:46:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"365474ff1d0518cb5d91a7bc7096dabef463cb34\",\n",
      "\t\t\"parent\": \"200c547d02bcccc07de2a82789fd42969c99bbeb\",\n",
      "\t\t\"subject\": \"New IT Framework - InputSource and InputFormat Tests (#13597)\",\n",
      "\t\t\"sanitized_subject_line\": \"New-IT-Framework-InputSource-and-InputFormat-Tests-13597\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* New IT Framework - InputSource and InputFormat Tests  * Fixing checkstyle errors  * Updating InputSource setup  * Updating queries to use druid DB  * Making metadata setup queries to be idempotent  * Restore intellij files\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 4 Jan 2023 10:40:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"200c547d02bcccc07de2a82789fd42969c99bbeb\",\n",
      "\t\t\"parent\": \"36e67655966815a79151bf94a4bb912362564946\",\n",
      "\t\t\"subject\": \"Include info about Hadoop 3 artifacts in release guide (#13594)\",\n",
      "\t\t\"sanitized_subject_line\": \"Include-info-about-Hadoop-3-artifacts-in-release-guide-13594\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update release guide for hadoop3  * Update instructions to verify checksum and signature  * Update email lists\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 Jan 2023 13:53:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36e67655966815a79151bf94a4bb912362564946\",\n",
      "\t\t\"parent\": \"313d937236efa242bc7b3ae144b50405a0499761\",\n",
      "\t\t\"subject\": \"Fix flaky test (#13603)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-test-13603\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 Jan 2023 13:52:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"313d937236efa242bc7b3ae144b50405a0499761\",\n",
      "\t\t\"parent\": \"8773d619a2c8be49f52d22483242e0c9a653f200\",\n",
      "\t\t\"subject\": \"Switch operators to a push-style API (#13600)\",\n",
      "\t\t\"sanitized_subject_line\": \"Switch-operators-to-a-push-style-API-13600\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Switch operators to a push-style API  This API generates nice stack-traces of processing for Operators.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Dec 2022 22:01:55 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8773d619a2c8be49f52d22483242e0c9a653f200\",\n",
      "\t\t\"parent\": \"78ae0b75338016dd02245eeb83715c521daad41d\",\n",
      "\t\t\"subject\": \"Web console: tidy up stage UI (#13615)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-tidy-up-stage-UI-13615\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* show the right info  * sort indicator  * nicer marker  * move error icon\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Dec 2022 12:52:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"78ae0b75338016dd02245eeb83715c521daad41d\",\n",
      "\t\t\"parent\": \"af05cfa78c10d3b801413b78b5064ef7fda5aa13\",\n",
      "\t\t\"subject\": \"Upgrade to netty 4.1.86.Final to address CVEs (#13604)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-to-netty-4.1.86.Final-to-address-CVEs-13604\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit addresses the following CVEs: - CVE-2021-43797 - CVE-2022-41881 \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Dec 2022 01:44:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"af05cfa78c10d3b801413b78b5064ef7fda5aa13\",\n",
      "\t\t\"parent\": \"0d97e658b2ef65903cf7484b5fdaf115631d0304\",\n",
      "\t\t\"subject\": \"Fix shutdown in httpRemote task runner (#13558)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-shutdown-in-httpRemote-task-runner-13558\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix shutdown in httpRemote task runner  * Add UT\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Dec 2022 14:50:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0d97e658b2ef65903cf7484b5fdaf115631d0304\",\n",
      "\t\t\"parent\": \"7b92b851684d4bc816ec701bcef8b22ad57ba095\",\n",
      "\t\t\"subject\": \"Docs: Update quickstart instructions (#13611)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Update-quickstart-instructions-13611\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Remove specification of a Druid version in the quickstart, because the previous step instructs downloading the latest version anyway. - Mention usage of memory parameter in the quickstart\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Dec 2022 11:51:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7b92b851684d4bc816ec701bcef8b22ad57ba095\",\n",
      "\t\t\"parent\": \"fd63e5a5142b458616157ce857f2c1eeae3eac2a\",\n",
      "\t\t\"subject\": \"Unify DummyRequest with MockHttpServletRequest (#13602)\",\n",
      "\t\t\"sanitized_subject_line\": \"Unify-DummyRequest-with-MockHttpServletRequest-13602\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We had 2 different classes both creating fake instances of an HttpServletRequest, this makes it to that we only have one in a common location\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Dec 2022 20:15:08 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd63e5a5142b458616157ce857f2c1eeae3eac2a\",\n",
      "\t\t\"parent\": \"df5576853513b0394644f9af9f28a6badaa2de44\",\n",
      "\t\t\"subject\": \"fix issue with jdbc and query metrics (#13608)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-jdbc-and-query-metrics-13608\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issue with metrics emitting and jdbc results by getting yielder from query processing thread  * more better\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Dec 2022 19:32:53 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"df5576853513b0394644f9af9f28a6badaa2de44\",\n",
      "\t\t\"parent\": \"6c44dd817547fd87ed408cc5be2fc7fc6d8d10d5\",\n",
      "\t\t\"subject\": \"Add CodeQL workflow (#13477)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-CodeQL-workflow-13477\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* workflower: Add CodeQL workflow  * add modified CodeQL build config\",\n",
      "\t\t\"author_name\": \"Peter St\\u00f6ckli\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Dec 2022 09:24:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c44dd817547fd87ed408cc5be2fc7fc6d8d10d5\",\n",
      "\t\t\"parent\": \"c1e2656644ab728a8bff466b178ee5094205b2ae\",\n",
      "\t\t\"subject\": \"perf: core/TextReader for faster json ingestion (#13545)\",\n",
      "\t\t\"sanitized_subject_line\": \"perf-core-TextReader-for-faster-json-ingestion-13545\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* perf: provide a custom utf8 specific buffered line iterator (benchmark)  Benchmark                         Mode  Cnt     Score     Error  Units JsonLineReaderBenchmark.baseline  avgt   15  3459.871 \\u00b1 106.175  us/op  * perf: provide a custom utf8 specific buffered line iterator  Benchmark                         Mode  Cnt     Score    Error  Units JsonLineReaderBenchmark.baseline  avgt   15  3022.053 \\u00b1 51.286  us/op  * perf: provide a custom utf8 specific buffered line iterator (more tests)  * perf: provide a custom utf8 specific buffered line iterator (pr feedback)  Ensure field visibility is as limited as possible  Null check for buffer in constructor  * perf: provide a custom utf8 specific buffered line iterator (pr feedback)  Remove additional 'finished' variable.  * perf: provide a custom utf8 specific buffered line iterator (more tests and bugfix)\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Dec 2022 23:12:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1e2656644ab728a8bff466b178ee5094205b2ae\",\n",
      "\t\t\"parent\": \"0efd0879a83191ac550cded6122451ba4bf91194\",\n",
      "\t\t\"subject\": \"Fix scope of dependencies in protobuf-extensions pom (#13593)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-scope-of-dependencies-in-protobuf-extensions-pom-13593\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Dec 2022 13:56:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0efd0879a83191ac550cded6122451ba4bf91194\",\n",
      "\t\t\"parent\": \"07597c687d205f2fa3b0bdf0ca310eb8844ad2bf\",\n",
      "\t\t\"subject\": \"Unify the handling of HTTP between SQL and Native (#13564)\",\n",
      "\t\t\"sanitized_subject_line\": \"Unify-the-handling-of-HTTP-between-SQL-and-Native-13564\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Unify the handling of HTTP between SQL and Native  The SqlResource and QueryResource have been using independent logic for things like error handling and response context stuff.  This became abundantly clear and painful during a change I was making for Window Functions, so I unified them into using the same code for walking the response and serializing it.  Things are still not perfectly unified (it would be the absolute best if the SqlResource just took SQL, planned it and then delegated the query run entirely to the QueryResource), but this refactor doesn't take that fully on.  The new code leverages async query processing from our jetty container, the different interaction model with the Resource means that a lot of tests had to be adjusted to align with the async query model.  The semantics of the tests remain the same with one exception: the SqlResource used to not log requests that failed authorization checks, now it does.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Dec 2022 00:25:33 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"07597c687d205f2fa3b0bdf0ca310eb8844ad2bf\",\n",
      "\t\t\"parent\": \"ee890965f493a2752711c78459455d5acb895d9a\",\n",
      "\t\t\"subject\": \"Docs: Remove large data file (#13595)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Remove-large-data-file-13595\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Dec 2022 13:14:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee890965f493a2752711c78459455d5acb895d9a\",\n",
      "\t\t\"parent\": \"09d8b1644768bd3f8ccf14b9552439a0a3f59bee\",\n",
      "\t\t\"subject\": \"LocalInputSource: Serialize File paths without forcing resolution. (#13534)\",\n",
      "\t\t\"sanitized_subject_line\": \"LocalInputSource-Serialize-File-paths-without-forcing-resolution.-13534\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* LocalInputSource: Serialize File paths without forcing resolution.  Fixes #13359.  * Add one more javadoc.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Dec 2022 11:47:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"09d8b1644768bd3f8ccf14b9552439a0a3f59bee\",\n",
      "\t\t\"parent\": \"e34e56295faa51dac4faa5117c2e34528dd8f39c\",\n",
      "\t\t\"subject\": \"Document shouldFinalize for sketches that have the parameter (#13524)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-shouldFinalize-for-sketches-that-have-the-parameter-13524\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Dec 2022 10:48:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e34e56295faa51dac4faa5117c2e34528dd8f39c\",\n",
      "\t\t\"parent\": \"e23abc710aa2882be9d350b97d2290b8e163691c\",\n",
      "\t\t\"subject\": \"Suppress CVE-2022-1278, CVE-2022-2048, CVE-2022-3509, CVE-2022-40152 (#13590)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVE-2022-1278-CVE-2022-2048-CVE-2022-3509-CVE-2022-40152-13590\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Dec 2022 20:09:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e23abc710aa2882be9d350b97d2290b8e163691c\",\n",
      "\t\t\"parent\": \"639decdf2eb4b59152a52c188dae97716d746e75\",\n",
      "\t\t\"subject\": \"Web console: default max workers to cluster capacity and simplify live reports (#13577)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-default-max-workers-to-cluster-capacity-and-simplify-live-reports-13577\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* step  * better capacity  * start with capacity  * more compressed stats display  * better rule editor  * fix SQL data loader also  * update snapshots  * new line  * better formatting\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 15:13:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"639decdf2eb4b59152a52c188dae97716d746e75\",\n",
      "\t\t\"parent\": \"d9c27d6102a5e8f6dbc7500bac8d2eedc00baae4\",\n",
      "\t\t\"subject\": \"fix preview droping out of MSQ mode (#13586)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-preview-droping-out-of-MSQ-mode-13586\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 15:13:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d9c27d6102a5e8f6dbc7500bac8d2eedc00baae4\",\n",
      "\t\t\"parent\": \"1cc9bc9af9ca7c5697a2e8d6fbd4e0cc1164da5c\",\n",
      "\t\t\"subject\": \"docs: add index page and related stuff for jupyter tutorials (#13342)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-add-index-page-and-related-stuff-for-jupyter-tutorials-13342\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 13:33:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1cc9bc9af9ca7c5697a2e8d6fbd4e0cc1164da5c\",\n",
      "\t\t\"parent\": \"f42722e62725c3829c295fa815c6e48aac1e0600\",\n",
      "\t\t\"subject\": \"Suppress CVE-2022-45685 and CVE-2022-45693 from jettison-1.3 (#13585)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVE-2022-45685-and-CVE-2022-45693-from-jettison-1.3-13585\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 22:56:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f42722e62725c3829c295fa815c6e48aac1e0600\",\n",
      "\t\t\"parent\": \"d9e5245ff0222d8f0b0650e6a1e220bacd4714a2\",\n",
      "\t\t\"subject\": \"Set monotonically increasing worker capacity in start-druid-main (#13581)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-monotonically-increasing-worker-capacity-in-start-druid-main-13581\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit updates the task memory allocation logic. - min task count is 2 and max task count is number of cpus on the machine - task count increases wrt total task memory - task memory increases from 512m to 2g\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 15:34:30 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d9e5245ff0222d8f0b0650e6a1e220bacd4714a2\",\n",
      "\t\t\"parent\": \"9ae7a36ccd05ec464942b0d0ae3d25578ac55e38\",\n",
      "\t\t\"subject\": \"allow string dimension indexer to handle byte[] as base64 strings (#13573)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-string-dimension-indexer-to-handle-byte-as-base64-strings-13573\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR expands `StringDimensionIndexer` to handle conversion of `byte[]` to base64 encoded strings, rather than the current behavior of calling java `toString`.   This issue was uncovered by a regression of sorts introduced by #13519, which updated the protobuf extension to directly convert stuff to java types, resulting in `bytes` typed values being converted as `byte[]` instead of a base64 string which the previous JSON based conversion created. While outputting `byte[]` is more consistent with other input formats, and preferable when the bytes can be consumed directly (such as complex types serde), when fed to a `StringDimensionIndexer`, it resulted in an ugly java `toString` because `processRowValsToUnsortedEncodedKeyComponent` is fed the output of `row.getRaw(..)`. Converting `byte[]` to a base64 string within `StringDimensionIndexer` is consistent with the behavior of calling `row.getDimension(..)` which does do this coercion (and why many tests on binary types appeared to be doing the expected thing).  I added some protobuf `bytes` tests, but they don't really hit the new `StringDimensionIndexer` behavior because they operate on the `InputRow` directly, and call `getDimension` to validate stuff. The parser based version still uses the old conversion mechanisms, so when not using a flattener incorrectly calls `toString` on the `ByteString`. I have encoded this behavior in the test for now, if we either update the parser to use the new flattener or just .. remove parsers we can remove this test stuff.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 14:50:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9ae7a36ccd05ec464942b0d0ae3d25578ac55e38\",\n",
      "\t\t\"parent\": \"7f3c117e3ab0971dd52180ac99d4da6cc092b598\",\n",
      "\t\t\"subject\": \"improve nested column storage format for broader compatibility (#13568)\",\n",
      "\t\t\"sanitized_subject_line\": \"improve-nested-column-storage-format-for-broader-compatibility-13568\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* bump nested column format version changes: * nested field files are now named by their position in field paths list, rather than directly by the path itself. this fixes issues with valid json properties with commas and newlines breaking the csv file meta.smoosh * update StructuredDataProcessor to deal in NestedPathPart to be consistent with other abstract path handling rather than building JQ syntax strings directly * add v3 format segment and test \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 15:39:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f3c117e3ab0971dd52180ac99d4da6cc092b598\",\n",
      "\t\t\"parent\": \"668d1fad6be616fe3c6b78feb74aef698896b520\",\n",
      "\t\t\"subject\": \"SQL: Improve docs around casts. (#13466)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Improve-docs-around-casts.-13466\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Main change: clarify that the \\\"default value\\\" for casts only applies if druid.generic.useDefaultValueForNull = true.  Secondary change: adjust a bunch of wording from future to present tense.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 15:01:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"668d1fad6be616fe3c6b78feb74aef698896b520\",\n",
      "\t\t\"parent\": \"d6949b1b79df67e6a031ceb074461585e48b1d27\",\n",
      "\t\t\"subject\": \"docs: notebook only for API tutorial (#13345)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-notebook-only-for-API-tutorial-13345\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs: notebook for API tutorial  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * address the other comments  * typo  * add commentary to outputs  * address feedback from will  * delete unnecessary comment  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 13:16:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d6949b1b79df67e6a031ceb074461585e48b1d27\",\n",
      "\t\t\"parent\": \"431a1195cae61edac03e6ed5aaeb73c736bd0ea5\",\n",
      "\t\t\"subject\": \"Track input processedBytes with MSQ ingestion (#13559)\",\n",
      "\t\t\"sanitized_subject_line\": \"Track-input-processedBytes-with-MSQ-ingestion-13559\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Follow up to #13520  Bytes processed are currently tracked for intermediate stages in MSQ ingestion. This patch adds the capability to track the bytes processed by an MSQ controller task while reading from an external input source or a segment source.  Changes: - Track `processedBytes` for every `InputSource` read in `ExternalInputSliceReader` - Update `ChannelCounters` with the above obtained `processedBytes` when incrementing the input file count. - Update task report structure in docs  The total input processed bytes can be obtained by summing the `processedBytes` as follows:  totalBytes = 0 for every root stage (i.e. a stage which does not have another stage as an input):     for every worker in that stage:         for every input channel: (i.e. channels with prefix \\\"input\\\", e.g. \\\"input0\\\", \\\"input1\\\", etc.)             totalBytes += processedBytes \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Dec 2022 02:20:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"431a1195cae61edac03e6ed5aaeb73c736bd0ea5\",\n",
      "\t\t\"parent\": \"49cbfdff83c3666f8cc029b683b1747e452b7975\",\n",
      "\t\t\"subject\": \"Suppress CVE-2022-1471 from snakeyaml (#13557)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVE-2022-1471-from-snakeyaml-13557\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Upgrade kube client to 17.0.0  * Remove snakeyaml CVE suppression  * Update licenses.yaml  * Revert changes and suppress cve\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 21:39:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"49cbfdff83c3666f8cc029b683b1747e452b7975\",\n",
      "\t\t\"parent\": \"97bc0220c7a2b437581af55d9e3267c37ea46b1b\",\n",
      "\t\t\"subject\": \"Fix cool nested column bug caused by not properly validating that global id is present in global dictionary before lookup up local id (#13561)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-cool-nested-column-bug-caused-by-not-properly-validating-that-global-id-is-present-in-global-dictionary-before-lookup-up-local-id-13561\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit fixes a bug with nested column \\\"value set\\\" indexes caused by not properly validating that the globalId looked up for value is present in the global dictionary prior to looking it up in the local dictionary, which when \\\"adjusting\\\" the global ids for value type can cause incorrect selection of value indexes.  To use an example of a variant typed nested column with 3 values `[\\\"1\\\", null, -2]`. The string dictionary is `[null, \\\"1\\\"]`, the long dictionary is `[-2]` and our local dictionary is `[0, 1, 2]`.  The code for variant typed indexes checks if the value is present in all global dictionaries and returns indexes for all matches. So in this case, we first lookup \\\"1\\\" in the string dictionary, find it at global id 1, all is good. Now, we check the long dictionary for `1`, which due to  `-(insertionpoint + 1)` gives us `-(1 + 2) = -2`. Since the global id space is actually stacked dictionaries, global ids for long and double values must be \\\"adjusted\\\" by the size of string dictionary, and size of string + size of long for doubles.  Prior to this patch we were not checking that the globalId is 0 or larger, we then immediately looked up the `localDictionary.indexOf(-2 + adjustLong) = localDictionary.indexOf(-2 + 2) = localDictionary.indexOf(0)` ... which is an actual value contained in the dictionary! The fix is to skip the longs completely since there were no global matches.  On to doubles, `-(insertionPoint + 1)` gives us `-(0 + 1) = -1`. The double adjust value is '3' since 2 strings and 1 long, so `localDictionary.indexOf(-1 + 3)` = `localDictionary.indexOf(2)`  which is also a real value in our local dictionary that is definitely not '1'.  So in this one case, looking for '1' incorrectly ended up matching every row.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 17:00:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"97bc0220c7a2b437581af55d9e3267c37ea46b1b\",\n",
      "\t\t\"parent\": \"2b605aa9cf987ccb8e9ace04f71214aa6b508ec4\",\n",
      "\t\t\"subject\": \"Update task memory computation in start-druid (#13563)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-task-memory-computation-in-start-druid-13563\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: * Use 80% of memory specified for running services (versus 50% earlier). * Tasks get either 512m / 1024m or 2048m now (versus 512m or 2048m earlier).  * Add direct memory for router.\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 11:06:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b605aa9cf987ccb8e9ace04f71214aa6b508ec4\",\n",
      "\t\t\"parent\": \"089d8da5610453549fc9c305046f0b7397500b47\",\n",
      "\t\t\"subject\": \"Multiple fixes for the MSQ stats merging piece which (#13463)\",\n",
      "\t\t\"sanitized_subject_line\": \"Multiple-fixes-for-the-MSQ-stats-merging-piece-which-13463\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add validation checks to worker chat handler apis  * Merge things and polishing the error messages.  * Minor error message change  * Fixing race and adding some tests  * Fixing controller fetching stats from wrong workers. Fixing race Changing default mode to Parallel Adding logging. Fixing exceptions not propagated properly.  * Changing to kernel worker count  * Added a better logic to figure out assigned worker for a stage.  * Nits  * Moving to existing kernel methods  * Adding more coverage  Co-authored-by: cryptoe <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Dec 2022 09:35:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"089d8da5610453549fc9c305046f0b7397500b47\",\n",
      "\t\t\"parent\": \"2729e252951884998ab816b2d20940debdd5107d\",\n",
      "\t\t\"subject\": \"Support Framing for Window Aggregations (#13514)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-Framing-for-Window-Aggregations-13514\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support Framing for Window Aggregations  This adds support for framing  over ROWS for window aggregations.  Still not implemented as yet: 1. RANGE frames 2. Multiple different frames in the same query 3. Frames on last/first functions\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Dec 2022 18:04:39 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2729e252951884998ab816b2d20940debdd5107d\",\n",
      "\t\t\"parent\": \"35c983a3510b357880cd1c4d2407d4296d054511\",\n",
      "\t\t\"subject\": \"Link to java docs (#13478)\",\n",
      "\t\t\"sanitized_subject_line\": \"Link-to-java-docs-13478\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add link to page about selecting a JRE  * add link to script also  * simplify text\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Dec 2022 11:45:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"35c983a3510b357880cd1c4d2407d4296d054511\",\n",
      "\t\t\"parent\": \"58a3acc2c4c5d5d22098e15f7ff25d6e9baa8541\",\n",
      "\t\t\"subject\": \"Use template file for adding table functions grammar (#13553)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-template-file-for-adding-table-functions-grammar-13553\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Dec 2022 21:52:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58a3acc2c4c5d5d22098e15f7ff25d6e9baa8541\",\n",
      "\t\t\"parent\": \"7682b0b6b185e4879ba202b0b777fa655e3d4f59\",\n",
      "\t\t\"subject\": \"Add InputStats to track bytes processed by a task (#13520)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-InputStats-to-track-bytes-processed-by-a-task-13520\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit adds a new class `InputStats` to track the total bytes processed by a task. The field `processedBytes` is published in task reports along with other row stats.  Major changes: - Add class `InputStats` to track processed bytes - Add method `InputSourceReader.read(InputStats)` to read input rows while counting bytes. > Since we need to count the bytes, we could not just have a wrapper around `InputSourceReader` or `InputEntityReader` (the way `CountableInputSourceReader` does) because the `InputSourceReader` only deals with `InputRow`s and the byte information is already lost. - Classic batch: Use the new `InputSourceReader.read(inputStats)` in `AbstractBatchIndexTask` - Streaming: Increment `processedBytes` in `StreamChunkParser`. This does not use the new `InputSourceReader.read(inputStats)` method. - Extend `InputStats` with `RowIngestionMeters` so that bytes can be exposed in task reports  Other changes: - Update tests to verify the value of `processedBytes` - Rename `MutableRowIngestionMeters` to `SimpleRowIngestionMeters` and remove duplicate class - Replace `CacheTestSegmentCacheManager` with `NoopSegmentCacheManager` - Refactor `KafkaIndexTaskTest` and `KinesisIndexTaskTest` \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Dec 2022 18:54:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7682b0b6b185e4879ba202b0b777fa655e3d4f59\",\n",
      "\t\t\"parent\": \"de5a4bafcbad7c05abd9ca528ab157e6a121dbbf\",\n",
      "\t\t\"subject\": \"Analysis refactor (#13501)\",\n",
      "\t\t\"sanitized_subject_line\": \"Analysis-refactor-13501\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Refactor DataSource to have a getAnalysis method()  This removes various parts of the code where while loops and instanceof checks were being used to walk through the structure of DataSource objects in order to build a DataSourceAnalysis.  Instead we just ask the DataSource for its analysis and allow the stack to rebuild whatever structure existed.\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Dec 2022 17:35:44 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de5a4bafcbad7c05abd9ca528ab157e6a121dbbf\",\n",
      "\t\t\"parent\": \"8e386072e963e7933942eca91d5f32140b80e4c9\",\n",
      "\t\t\"subject\": \"Zero-copy local deep storage. (#13394)\",\n",
      "\t\t\"sanitized_subject_line\": \"Zero-copy-local-deep-storage.-13394\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Zero-copy local deep storage.  This is useful for local deep storage, since it reduces disk usage and makes Historicals able to load segments instantaneously.  Two changes:  1) Introduce \\\"druid.storage.zip\\\" parameter for local storage, which defaults    to false. This changes default behavior from writing an index.zip to writing    a regular directory. This is safe to do even during a rolling update, because    the older code actually already handled unzipped directories being present    on local deep storage.  2) In LocalDataSegmentPuller and LocalDataSegmentPusher, use hard links    instead of copies when possible. (Generally this is possible when the    source and destination directory are on the same filesystem.) \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Dec 2022 17:28:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8e386072e963e7933942eca91d5f32140b80e4c9\",\n",
      "\t\t\"parent\": \"5a3d79a5d5612eb91aa6d8df57024aa60fc457ff\",\n",
      "\t\t\"subject\": \"Druid automated quickstart: zookeeper in service list (#13550)\",\n",
      "\t\t\"sanitized_subject_line\": \"Druid-automated-quickstart-zookeeper-in-service-list-13550\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Dec 2022 10:29:43 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5a3d79a5d5612eb91aa6d8df57024aa60fc457ff\",\n",
      "\t\t\"parent\": \"7002ecd303984c15f31cc04e600bd6d53dd27ab8\",\n",
      "\t\t\"subject\": \"Removing unused exec service. (#13541)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removing-unused-exec-service.-13541\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Dec 2022 14:39:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7002ecd303984c15f31cc04e600bd6d53dd27ab8\",\n",
      "\t\t\"parent\": \"4ebdfe226dc91a29384cf932633b727137a89f78\",\n",
      "\t\t\"subject\": \"add protobuf flattener, direct to plain java conversion for faster flattening (#13519)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-protobuf-flattener-direct-to-plain-java-conversion-for-faster-flattening-13519\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add protobuf flattener, direct to plain java conversion for faster flattening, nested column tests\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Dec 2022 12:24:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ebdfe226dc91a29384cf932633b727137a89f78\",\n",
      "\t\t\"parent\": \"55814888f54ebd6a909c60cc0638bf4ea306349f\",\n",
      "\t\t\"subject\": \"Druid automated quickstart (#13365)\",\n",
      "\t\t\"sanitized_subject_line\": \"Druid-automated-quickstart-13365\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Druid automated quickstart  * remove conf/druid/single-server/quickstart/_common/historical/jvm.config  * Minor changes in python script  * Add lower bound memory for some services  * Additional runtime properties for services  * Update supervise script to accept command arguments, corresponding changes in druid-quickstart.py  * File end newline  * Limit the ability to start multiple instances of a service, documentation changes  * simplify script arguments  * restore changes in medium profile  * run-druid refactor  * compute and pass middle manager runtime properties to run-druid supervise script changes to process java opts array use argparse, leave free memory, logging  * Remove extra quotes from mm task javaopts array  * Update logic to compute minimum memory  * simplify run-druid  * remove debug options from run-druid  * resolve the config_path provided  * comment out service specific runtime properties which are computed in the code  * simplify run-druid  * clean up docs, naming changes  * Throw ValueError exception on illegal state  * update docs  * rename args, compute_only -> compute, run_zk -> zk  * update help documentation  * update help documentation  * move task memory computation into separate method  * Add validation checks  * remove print  * Add validations  * remove start-druid bash script, rename start-druid-main  * Include tasks in lower bound memory calculation  * Fix test  * 256m instead of 256g  * caffeine cache uses 5% of heap  * ensure min task count is 2, task count is monotonic  * update configs and documentation for runtime props in conf/druid/single-server/quickstart  * Update docs  * Specify memory argument for each profile in single-server.md  * Update middleManager runtime.properties  * Move quickstart configs to conf/druid/base, add bash launch script, support python2  * Update supervise script  * rename base config directory to auto  * rename python script, changes to pass repeated args to supervise  * remove exmaples/conf/druid/base dir  * add docs  * restore changes in conf dir  * update start-druid-auto  * remove hashref for commands in supervise script  * start-druid-main java_opts array is comma separated  * update entry point script name in python script  * Update help docs  * documentation changes  * docs changes  * update docs  * add support for running indexer  * update supported services list  * update help  * Update python.md  * remove dir  * update .spelling  * Remove dependency on psutil and pathlib  * update docs  * Update get_physical_memory method  * Update help docs  * update docs  * update method to get physical memory on python  * udpate spelling  * update .spelling  * minor change  * Minor change  * memory comptuation for indexer  * update start-druid  * Update python.md  * Update single-server.md  * Update python.md  * run python3 --version to check if python is installed  * Update supervise script  * start-druid: echo message if python not found  * update anchor text  * minor change  * Update condition in supervise script  * JVM not jvm in docs\",\n",
      "\t\t\"author_name\": \"Rishabh Singh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Dec 2022 11:04:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"55814888f54ebd6a909c60cc0638bf4ea306349f\",\n",
      "\t\t\"parent\": \"013a12e86f9292ae58a77c933437aa72653575bb\",\n",
      "\t\t\"subject\": \"MSQ: Only look at sqlInsertSegmentGranularity on the outer query. (#13537)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Only-look-at-sqlInsertSegmentGranularity-on-the-outer-query.-13537\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The planner sets sqlInsertSegmentGranularity in its context when using PARTITIONED BY, which sets it on every native query in the stack (as all native queries for a SQL query typically have the same context). QueryKit would interpret that as a request to configure bucketing for all native queries. This isn't useful, as bucketing is only used for the penultimate stage in INSERT / REPLACE.  So, this patch modifies QueryKit to only look at sqlInsertSegmentGranularity on the outermost query.  As an additional change, this patch switches the static ObjectMapper to use the processwide ObjectMapper for deserializing Granularities. Saves an ObjectMapper instance, and ensures that if there are any special serdes registered for Granularity, we'll pick them up.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Dec 2022 20:48:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"013a12e86f9292ae58a77c933437aa72653575bb\",\n",
      "\t\t\"parent\": \"d8e27eaab49d4c91dbec5e7e68a8a89bcb02b141\",\n",
      "\t\t\"subject\": \"Enhanced MSQ table functions (#13360)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enhanced-MSQ-table-functions-13360\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Enhanced MSQ table functions * HTTP, LOCALFILES and INLINE table functions powered by catalog metadata. * Documentation\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Dec 2022 13:56:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d8e27eaab49d4c91dbec5e7e68a8a89bcb02b141\",\n",
      "\t\t\"parent\": \"91ef9872ecaaf29d67bf28f1e40adcefc55e806e\",\n",
      "\t\t\"subject\": \"update error anchors (#13527)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-error-anchors-13527\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Dec 2022 13:18:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"91ef9872ecaaf29d67bf28f1e40adcefc55e806e\",\n",
      "\t\t\"parent\": \"d85fb8cc4ecef574f1c032d09a2f2e1f61f6b1c3\",\n",
      "\t\t\"subject\": \"MSQ: Improve TooManyBuckets error message, improve error docs. (#13525)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Improve-TooManyBuckets-error-message-improve-error-docs.-13525\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"1) Edited the TooManyBuckets error message to mention PARTITIONED BY    instead of segmentGranularity.  2) Added error-code-specific anchors in the docs.  3) Add information to various error codes in the docs about common    causes and solutions.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Dec 2022 13:18:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d85fb8cc4ecef574f1c032d09a2f2e1f61f6b1c3\",\n",
      "\t\t\"parent\": \"fbf76ad8f544c44e7f1443d8ed4e53a17388237e\",\n",
      "\t\t\"subject\": \"Web console: improve compaction status display (#13523)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-improve-compaction-status-display-13523\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* improve compaction status display  * even more accurate  * fix snapshot\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Dec 2022 21:03:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fbf76ad8f544c44e7f1443d8ed4e53a17388237e\",\n",
      "\t\t\"parent\": \"69951273b8ef51ac1fa5fc08aa1ef74298514756\",\n",
      "\t\t\"subject\": \"Remove stray reference to fix OOM while merging sketches (#13475)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-stray-reference-to-fix-OOM-while-merging-sketches-13475\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove stray reference to fix OOM while merging sketches  * Update future to add result from executor service  * Update tests and address review comments  * Address review comments  * Moved mock  * Close threadpool on teardown  * Remove worker task cancel\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Dec 2022 07:17:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"69951273b8ef51ac1fa5fc08aa1ef74298514756\",\n",
      "\t\t\"parent\": \"b56855b837b73644c080f5305b2726b4518e10f5\",\n",
      "\t\t\"subject\": \"Fix typo in metric name (#13521)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-typo-in-metric-name-13521\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Dec 2022 06:41:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b56855b837b73644c080f5305b2726b4518e10f5\",\n",
      "\t\t\"parent\": \"9679f6a9b5c84a7618529f1739a6256e04c9da56\",\n",
      "\t\t\"subject\": \"Update to native ingestion doc (#13482)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-to-native-ingestion-doc-13482\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update to native ingestion doc  * Update docs/ingestion/native-batch.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update native-batch.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Dec 2022 15:08:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9679f6a9b5c84a7618529f1739a6256e04c9da56\",\n",
      "\t\t\"parent\": \"c7229fc7871d6068bb488ce398ba8c1632f7151f\",\n",
      "\t\t\"subject\": \"Web console: add arrayOfDoublesSketch and other small fixes (#13486)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-add-arrayOfDoublesSketch-and-other-small-fixes-13486\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add padding and keywords  * add arrayOfDoubles  * Update docs/development/extensions-core/datasketches-tuple.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/datasketches-tuple.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/datasketches-tuple.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/datasketches-tuple.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/datasketches-tuple.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * partiton int  * fix docs  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Dec 2022 21:21:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c7229fc7871d6068bb488ce398ba8c1632f7151f\",\n",
      "\t\t\"parent\": \"b25cf216d58ba93a884c89b37c1c42d0accd00ee\",\n",
      "\t\t\"subject\": \"Limit max batch size for segment allocation, add docs (#13503)\",\n",
      "\t\t\"sanitized_subject_line\": \"Limit-max-batch-size-for-segment-allocation-add-docs-13503\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Limit max batch size in `SegmentAllocationQueue` to 500 - Rename `batchAllocationMaxWaitTime` to `batchAllocationWaitTime` since the actual wait time may exceed this configured value. - Replace usage of `SegmentInsertAction` in `TaskToolbox` with `SegmentTransactionalInsertAction`\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Dec 2022 10:07:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b25cf216d58ba93a884c89b37c1c42d0accd00ee\",\n",
      "\t\t\"parent\": \"37d8833125b21f2baae02a1316dc56926e24ac16\",\n",
      "\t\t\"subject\": \"Better error message when theta_sketch_intersect is used on scalar expression (#13508)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-error-message-when-theta_sketch_intersect-is-used-on-scalar-expression-13508\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Dec 2022 09:35:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37d8833125b21f2baae02a1316dc56926e24ac16\",\n",
      "\t\t\"parent\": \"83261f9641a750b121dbbb13b1cf53dd0c40f126\",\n",
      "\t\t\"subject\": \"fix bug with broker parallel merge metrics emitting, add wall time, fast/slow partition time metrics (#13420)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-with-broker-parallel-merge-metrics-emitting-add-wall-time-fast-slow-partition-time-metrics-13420\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Dec 2022 17:50:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"83261f9641a750b121dbbb13b1cf53dd0c40f126\",\n",
      "\t\t\"parent\": \"cf472162a6cde2808df90e158cb1acfb7418f8bb\",\n",
      "\t\t\"subject\": \"Starting on Window Functions (#13458)\",\n",
      "\t\t\"sanitized_subject_line\": \"Starting-on-Window-Functions-13458\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Processors for Window Processing  This is an initial take on how to use Processors for Window Processing.  A Processor is an interface that transforms RowsAndColumns objects. RowsAndColumns objects are essentially combinations of rows and columns.  The intention is that these Processors are the start of a set of operators that more closely resemble what DB engineers would be accustomed to seeing.  * Wire up windowed processors with a query type that can run them end-to-end.  This code can be used to actually run a query, so yay!  * Wire up windowed processors with a query type that can run them end-to-end.  This code can be used to actually run a query, so yay!  * Some SQL tests for window functions. Added wikipedia  data to the indexes available to the SQL queries and tests validating the windowing functionality as it exists now.  Co-authored-by: Gian Merlino <gianmerlino@gmail.com>\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Dec 2022 15:54:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cf472162a6cde2808df90e158cb1acfb7418f8bb\",\n",
      "\t\t\"parent\": \"136322d13b68f1e14552ea606ac70101ff6af400\",\n",
      "\t\t\"subject\": \"fix issue with jetty graceful shutdown of data servers when druid.serverview.type=http (#13499)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-jetty-graceful-shutdown-of-data-servers-when-druid.serverview.type-http-13499\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issue with http server inventory view blocking data node http server shutdown with long polling  * adjust  * fix test inspections\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Dec 2022 15:52:44 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"136322d13b68f1e14552ea606ac70101ff6af400\",\n",
      "\t\t\"parent\": \"fda0a1aadde9d640cd4f9ff448a74ee5d2149d2a\",\n",
      "\t\t\"subject\": \"clean install before license checks (#13502)\",\n",
      "\t\t\"sanitized_subject_line\": \"clean-install-before-license-checks-13502\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 22:38:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fda0a1aadde9d640cd4f9ff448a74ee5d2149d2a\",\n",
      "\t\t\"parent\": \"658a9c2d350e3ecb334cd7afc6faa29cd087091e\",\n",
      "\t\t\"subject\": \"Set chatAsync default to true. (#13491)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-chatAsync-default-to-true.-13491\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This functionality was originally added in #13354.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 20:53:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"658a9c2d350e3ecb334cd7afc6faa29cd087091e\",\n",
      "\t\t\"parent\": \"65945a686fa3ca950c18cf43d4fc5a91e572fa82\",\n",
      "\t\t\"subject\": \"Early stop on failed start (Alternative to #13087) (#13258)\",\n",
      "\t\t\"sanitized_subject_line\": \"Early-stop-on-failed-start-Alternative-to-13087-13258\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make halt configurable. Don't halt in tests\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 21:05:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65945a686fa3ca950c18cf43d4fc5a91e572fa82\",\n",
      "\t\t\"parent\": \"10bec54acc92ae109db6fee8e60bdcc641f2b36d\",\n",
      "\t\t\"subject\": \"Docs: Update docs for coordinator dynamic config (#13494)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Update-docs-for-coordinator-dynamic-config-13494\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update docs for useBatchedSegmentSampler  * Update docs for round robin assigment\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 16:53:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"10bec54acc92ae109db6fee8e60bdcc641f2b36d\",\n",
      "\t\t\"parent\": \"45a8fa280c1f34f0401cfa43e1d38240d7d41f91\",\n",
      "\t\t\"subject\": \"Switching emitter. This will allow for a per feed emitter designation. (#13363)\",\n",
      "\t\t\"sanitized_subject_line\": \"Switching-emitter.-This-will-allow-for-a-per-feed-emitter-designation.-13363\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Switching emitter. This will allow for a per feed emitter designation.  This will work by looking at an event's feed and direct it to a specific emitter. If no specific feed is specified for a feed. The emitter can direct the event to a default emitter.  * fix checkstyle issues and make docs for switching emitter use basic event feeds  * fix broken docs, add test, and guard against misconfigurations  * add module test add switching emitter module test  * fix broken SwitchingEmitterModuleTest  * add apache license to top of test  * fix checkstyle issues  * address comments by adding javadocs, removing a todo, and making druid docs more clear\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 16:04:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45a8fa280c1f34f0401cfa43e1d38240d7d41f91\",\n",
      "\t\t\"parent\": \"91774196285ea51b823883394ef1bfe8f2417892\",\n",
      "\t\t\"subject\": \"Add SegmentAllocationQueue to batch SegmentAllocateActions (#13369)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-SegmentAllocationQueue-to-batch-SegmentAllocateActions-13369\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In a cluster with a large number of streaming tasks (~1000), SegmentAllocateActions  on the overlord can often take very long intervals of time to finish thus causing spikes  in the `task/action/run/time`. This may result in lag building up while a task waits for a segment to get allocated.  The root causes are: - large number of metadata calls made to the segments and pending segments tables - `giant` lock held in `TaskLockbox.tryLock()` to acquire task locks and allocate segments  Since the contention typically arises when several tasks of the same datasource try to allocate segments for the same interval/granularity, the allocation run times can be improved by batching the requests together.  Changes - Add flags    - `druid.indexer.tasklock.batchSegmentAllocation` (default `false`)    - `druid.indexer.tasklock.batchAllocationMaxWaitTime` (in millis) (default `1000`) - Add methods `canPerformAsync` and `performAsync` to `TaskAction` - Submit each allocate action to a `SegmentAllocationQueue`, and add to correct batch - Process batch after `batchAllocationMaxWaitTime` - Acquire `giant` lock just once per batch in `TaskLockbox` - Reduce metadata calls by batching statements together and updating query filters - Except for batching, retain the whole behaviour (order of steps, retries, etc.) - Respond to leadership changes and fail items in queue when not leader - Emit batch and request level metrics \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 5 Dec 2022 14:00:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"91774196285ea51b823883394ef1bfe8f2417892\",\n",
      "\t\t\"parent\": \"78c1a2bd665411f7adc93b67e1a3d3995c931f29\",\n",
      "\t\t\"subject\": \"Unnest functionality for Druid (#13268)\",\n",
      "\t\t\"sanitized_subject_line\": \"Unnest-functionality-for-Druid-13268\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Moving all unnest cursor code atop refactored code for unnest  * Updating unnest cursor  * Removing dedup and fixing up some null checks  * AllowList changes  * Fixing some NPEs  * Using bitset for allowlist  * Updating the initialization only when cursor is in non-done state  * Updating code to skip rows not in allow list  * Adding a flag for cases when first element is not in allowed list  * Updating for a null in allowList  * Splitting unnest cursor into 2 subclasses  * Intercepting some apis with columnName for new unnested column  * Adding test cases and renaming some stuff  * checkstyle fixes  * Moving to an interface for Unnest  * handling null rows in a dimension  * Updating cursors after comments part-1  * Addressing comments and adding some more tests  * Reverting a change to ScanQueryRunner and improving a comment  * removing an unused function  * Updating cursors after comments part 2  * One last fix for review comments  * Making some functions private, deleting some comments, adding a test for unnest of unnest with allowList  * Adding an exception for a case  * Closure for unnest data source  * Adding some javadocs  * One minor change in makeDimSelector of columnarCursor  * Updating an error message  * Update processing/src/main/java/org/apache/druid/segment/DimensionUnnestCursor.java  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>  * Unnesting on virtual columns was missing an object array, adding that to support virtual columns unnesting  * Updating exceptions to use UOE  * Renamed files, added column capability test on adapter, return statement and made unnest datasource not cacheable for the time being  * Handling for null values in dim selector  * Fixing a NPE for null row  * Updating capabilities  * Updating capabilities  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Dec 2022 18:48:25 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"78c1a2bd665411f7adc93b67e1a3d3995c931f29\",\n",
      "\t\t\"parent\": \"b76ff16d00b8a77539af18a36ab940fe31a5817b\",\n",
      "\t\t\"subject\": \"Remove limit from timeseries (#13457)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-limit-from-timeseries-13457\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"CI build failures seem unrelated to docs\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Dec 2022 12:19:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b76ff16d00b8a77539af18a36ab940fe31a5817b\",\n",
      "\t\t\"parent\": \"30498c1f98346050a9121bae113ace4fd4059302\",\n",
      "\t\t\"subject\": \"SQL test framework extensions (#13426)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-test-framework-extensions-13426\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"SQL test framework extensions  * Capture planner artifacts: logical plan, etc. * Planner test builder validates the logical plan * Validation for the SQL resut schema (we already have   validation for the Druid row signature) * Better Guice integration: properties, reuse Guice modules * Avoid need for hand-coded expr, macro tables * Retire some of the test-specific query component creation * Fix query log hook race condition \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Dec 2022 09:11:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"30498c1f98346050a9121bae113ace4fd4059302\",\n",
      "\t\t\"parent\": \"138a6de5074e787788d682eb5522775558c9e6a7\",\n",
      "\t\t\"subject\": \"Update gha & travis checks (#13412)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-gha-travis-checks-13412\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update static-checks GHA to run sequentially remove static-checks from travis.yml move docs, web-console, packaging checks from travis to GHA  * nit  * nit  * groups all checks, runs on 8, 11, 17 jdks  * nit  * adds license info  * update permissions on scripts folder  * nit  * nit  * fix packaging check  * changes naming, cleans repo before license checks  * simulate failure  * bump up license checks  * test license checks failure  * test license checks failure  * test license checks failure  * verify gha script run exit code  * fail fast in case of shell script  * verified fail fast in case of shell script\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Dec 2022 15:06:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"138a6de5074e787788d682eb5522775558c9e6a7\",\n",
      "\t\t\"parent\": \"cc307e4c29a8c73a4253667db02170809fd5c7ff\",\n",
      "\t\t\"subject\": \"Update nested columns docs (#13461)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-nested-columns-docs-13461\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update nested columns docs  (cherry picked from commit 04206c5179e0eb46a30d4113c7332daee46c390d)  * Update nested-columns.md  (cherry picked from commit 8085ee7217d90e0e3f133985a52ec2e0b0552992)\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Dec 2022 10:47:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc307e4c29a8c73a4253667db02170809fd5c7ff\",\n",
      "\t\t\"parent\": \"f6f625ee088e955af01974c3850e095d7d52496a\",\n",
      "\t\t\"subject\": \"Fix needless task shutdown on leader switch (#13411)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-needless-task-shutdown-on-leader-switch-13411\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix needless task shutdown on leader switch  * Add unit test  * Fix style  * Fix UTs\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Dec 2022 18:31:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f6f625ee088e955af01974c3850e095d7d52496a\",\n",
      "\t\t\"parent\": \"8395273099e82da9cbc1d8b25ed6971fc0085624\",\n",
      "\t\t\"subject\": \"MSQ Reindex IT (#13433)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Reindex-IT-13433\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ Reindex IT  * Fixing checkstyle errors  * Addressing comments  * Addressing comments\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Dec 2022 12:13:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8395273099e82da9cbc1d8b25ed6971fc0085624\",\n",
      "\t\t\"parent\": \"2f3b97194fb579d33bd6063c3d3c2bba1bb6f84f\",\n",
      "\t\t\"subject\": \"Add unit tests for MSQ ingestion faults (#13439)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-unit-tests-for-MSQ-ingestion-faults-13439\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add unit tests for MSQ ingestion faults  * Resolve build failure  * Move test to MSQFaultTest  * Rename test\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Dec 2022 10:11:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f3b97194fb579d33bd6063c3d3c2bba1bb6f84f\",\n",
      "\t\t\"parent\": \"2fdcfffe40cb400db4015fd4ae37478b4779512e\",\n",
      "\t\t\"subject\": \"Fix harcoded version in pom file (#13460)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-harcoded-version-in-pom-file-13460\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Dec 2022 10:10:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2fdcfffe40cb400db4015fd4ae37478b4779512e\",\n",
      "\t\t\"parent\": \"cc2e4a80ff485a15a9bba1ea94bcf0915a35b264\",\n",
      "\t\t\"subject\": \"don't render duration if aggregated (#13455)\",\n",
      "\t\t\"sanitized_subject_line\": \"don-t-render-duration-if-aggregated-13455\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 19:21:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc2e4a80ff485a15a9bba1ea94bcf0915a35b264\",\n",
      "\t\t\"parent\": \"6ba35f6d59357587187d648bb23a8229cd7493a2\",\n",
      "\t\t\"subject\": \"doc: add a basic JDBC tutorial (#13343)\",\n",
      "\t\t\"sanitized_subject_line\": \"doc-add-a-basic-JDBC-tutorial-13343\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* initial commit for jdbc tutorial  (cherry picked from commit 04c4adad71e5436b76c3425fe369df03aaaf0acb)  * add commentary  * address comments from charles  * add query context to example  * fix typo  * add links  * Apply suggestions from code review  Co-authored-by: Frank Chen <frankchen@apache.org>  * fix datatype  * address feedback  * add parameterize to spelling file. the past tense version was already there  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 16:25:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ba35f6d59357587187d648bb23a8229cd7493a2\",\n",
      "\t\t\"parent\": \"af164cbc100185f33388759df9e866b468925c58\",\n",
      "\t\t\"subject\": \"update org.bouncycastle:bcprov-jdk15on 1.68 to 1.69 (#13440)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-org.bouncycastle-bcprov-jdk15on-1.68-to-1.69-13440\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"xiaokang\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 21:57:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"af164cbc100185f33388759df9e866b468925c58\",\n",
      "\t\t\"parent\": \"8ff1b2d5d41752ade0f915d4dac6f5d9b6f45542\",\n",
      "\t\t\"subject\": \"Fix an issue with WorkerSketchFetcher not terminating on shutdown (#13459)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-an-issue-with-WorkerSketchFetcher-not-terminating-on-shutdown-13459\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix an issue with WorkerSketchFetcher not terminating on shutdown  * Change threadpool name\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 21:02:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ff1b2d5d41752ade0f915d4dac6f5d9b6f45542\",\n",
      "\t\t\"parent\": \"291ded22d5510148b39b113e7d0a492ba905d787\",\n",
      "\t\t\"subject\": \"Revert \\\"Add filter in cloud object input source for backward compatibility (#13437)\\\" (#13450)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Add-filter-in-cloud-object-input-source-for-backward-compatibility-13437-13450\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit b12e5f300e7c2795ba3d9c7ef17fb64f4925b9c0.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 16:33:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"291ded22d5510148b39b113e7d0a492ba905d787\",\n",
      "\t\t\"parent\": \"50963edcae70150f13520b619f167512d951a71b\",\n",
      "\t\t\"subject\": \"Update experimental features doc (#13452)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-experimental-features-doc-13452\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 30 Nov 2022 16:14:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"50963edcae70150f13520b619f167512d951a71b\",\n",
      "\t\t\"parent\": \"5c520e0cf92fec6a336ff71d1eb36ddbd9503066\",\n",
      "\t\t\"subject\": \"Fix compile error in MSQSelectTest. (#13456)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-compile-error-in-MSQSelectTest.-13456\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 15:51:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5c520e0cf92fec6a336ff71d1eb36ddbd9503066\",\n",
      "\t\t\"parent\": \"79df11c16cd2fd1c6a9867855c42768a079917ff\",\n",
      "\t\t\"subject\": \"Update LDAP configuration docs (#13245)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-LDAP-configuration-docs-13245\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update LDAP configuration docs  * Updated after review  * Update auth-ldap.md  Updated.  * Update auth-ldap.md  * Updated spelling file  * Update docs/operations/auth-ldap.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/auth-ldap.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/auth-ldap.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update auth-ldap.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 09:26:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"79df11c16cd2fd1c6a9867855c42768a079917ff\",\n",
      "\t\t\"parent\": \"4ed6255bdf213b15577d645a36e0e341a16e8d9d\",\n",
      "\t\t\"subject\": \"Improve unit test coverage for MSQ (#13398)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-unit-test-coverage-for-MSQ-13398\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add faults tests for the multi stage query  * add too many parttiions fault  * add toomanyinputfilesfault  * programmatically generate the file  * refactor  * Trigger Build\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 17:27:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ed6255bdf213b15577d645a36e0e341a16e8d9d\",\n",
      "\t\t\"parent\": \"edd076ca696e3ebcb45c4b0219440a50add9e13a\",\n",
      "\t\t\"subject\": \"Convert errors based on implicit type conversion in multi value arrays to parse exception in MSQ (#13366)\",\n",
      "\t\t\"sanitized_subject_line\": \"Convert-errors-based-on-implicit-type-conversion-in-multi-value-arrays-to-parse-exception-in-MSQ-13366\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* initial commit  * fix test  * push the json changes  * reduce the area of the try..catch  * Trigger Build  * review\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 17:19:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"edd076ca696e3ebcb45c4b0219440a50add9e13a\",\n",
      "\t\t\"parent\": \"100a2aa4a234f8c0dd84d34a9819484fb55b9bf6\",\n",
      "\t\t\"subject\": \"Remove duplicate FrameRowTooLargeException.java (#13441)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-duplicate-FrameRowTooLargeException.java-13441\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Removing duplicate FrameRowTooLargeException.java  * Fixing intellij inspection\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 08:46:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"100a2aa4a234f8c0dd84d34a9819484fb55b9bf6\",\n",
      "\t\t\"parent\": \"d8f4353c43ccc2578b2c58488e10ff8dfb38b6c5\",\n",
      "\t\t\"subject\": \"Update and document experimental features (#13348)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-and-document-experimental-features-13348\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update and document experimental features * Updated * Update experimental-features.md * Update docs/development/experimental-features.md Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com> * Updated after review * Updated * Update materialized-view.md * Update experimental-features.md Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Nov 2022 08:01:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d8f4353c43ccc2578b2c58488e10ff8dfb38b6c5\",\n",
      "\t\t\"parent\": \"37b8d4861c928a9b9e5cbde74df7f8a8a5562e45\",\n",
      "\t\t\"subject\": \"Web console: be more robust to aux queries failing and improve kill tasks (#13431)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-be-more-robust-to-aux-queries-failing-and-improve-kill-tasks-13431\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* be more robust to aux queries failing  * feedback fixes  * remove empty block  * fix spelling  * remove killAllDataSources from the console\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 16:50:38 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37b8d4861c928a9b9e5cbde74df7f8a8a5562e45\",\n",
      "\t\t\"parent\": \"4b58f5f23c2a1d23bb9dcb90ff13916659539ee3\",\n",
      "\t\t\"subject\": \"fix issues with nested data conversion (#13407)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issues-with-nested-data-conversion-13407\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 12:29:43 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4b58f5f23c2a1d23bb9dcb90ff13916659539ee3\",\n",
      "\t\t\"parent\": \"a2d5e335f338fd58a84950633bbc3232210091c9\",\n",
      "\t\t\"subject\": \"fix KafkaInputFormat with nested columns by delegating to underlying inputRow map instead of eagerly copying (#13406)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-KafkaInputFormat-with-nested-columns-by-delegating-to-underlying-inputRow-map-instead-of-eagerly-copying-13406\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 12:28:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a2d5e335f338fd58a84950633bbc3232210091c9\",\n",
      "\t\t\"parent\": \"b12e5f300e7c2795ba3d9c7ef17fb64f4925b9c0\",\n",
      "\t\t\"subject\": \"Web console: Index spec dialog (#13425)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Index-spec-dialog-13425\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add index spec dialog  * add sanpshot\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 11:40:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b12e5f300e7c2795ba3d9c7ef17fb64f4925b9c0\",\n",
      "\t\t\"parent\": \"58c896ea0b7c9896ed1cada416e872e5dfee7ff3\",\n",
      "\t\t\"subject\": \"Add filter in cloud object input source for backward compatibility (#13437)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-filter-in-cloud-object-input-source-for-backward-compatibility-13437\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"https://github.com/apache/druid/pull/13027 PR replaces `filter` parameter with `objectGlob` in ingestion input source. However, this will cause existing ingestion jobs to fail if they are using a filter already. This PR adds old filter functionality alongside objectGlob to preserve backward compatibility.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 23:04:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58c896ea0b7c9896ed1cada416e872e5dfee7ff3\",\n",
      "\t\t\"parent\": \"656b6cdf62a66aac6ff8fb7b7823d6f056b37d13\",\n",
      "\t\t\"subject\": \"ServiceClient: More robust redirect handling. (#13413)\",\n",
      "\t\t\"sanitized_subject_line\": \"ServiceClient-More-robust-redirect-handling.-13413\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Detects self-redirects, redirect loops, long redirect chains, and redirects to unknown servers. Treat all of these cases as an unavailable service, retrying if the retry policy allows it.  Previously, some of these cases would lead to a prompt, unretryable error. This caused clients contacting an Overlord during a leader change to fail with error messages like:  org.apache.druid.rpc.RpcException: Service [overlord] redirected too many times  Additionally, a slight refactor of callbacks in ServiceClientImpl improves readability of the flow through onSuccess. \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 22:24:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"656b6cdf62a66aac6ff8fb7b7823d6f056b37d13\",\n",
      "\t\t\"parent\": \"db7c29c6f9e39ccd482b3f5374e40ae31bfb7d0e\",\n",
      "\t\t\"subject\": \"Add MetricsVerifier to simplify verification of metric values in tests (#13442)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-MetricsVerifier-to-simplify-verification-of-metric-values-in-tests-13442\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 19:32:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"db7c29c6f9e39ccd482b3f5374e40ae31bfb7d0e\",\n",
      "\t\t\"parent\": \"b091b32f21f22cdb8daa48de06d18116d76f6780\",\n",
      "\t\t\"subject\": \"Correction to firehose migration doc (#13423)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correction-to-firehose-migration-doc-13423\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Nov 2022 10:24:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b091b32f21f22cdb8daa48de06d18116d76f6780\",\n",
      "\t\t\"parent\": \"16385c71011aaf7568345657491d4350c26438ea\",\n",
      "\t\t\"subject\": \"Fixes reindexing bug with filter on long column (#13386)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixes-reindexing-bug-with-filter-on-long-column-13386\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fixes BlockLayoutColumnarLongs close method to nullify internal buffer.  * fixes other BlockLayoutColumnar supplier close methods to nullify internal buffers.  * fix spotbugs\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 25 Nov 2022 19:22:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"16385c71011aaf7568345657491d4350c26438ea\",\n",
      "\t\t\"parent\": \"f524c68f08eb58047064e8234d320b51e83499ce\",\n",
      "\t\t\"subject\": \"Bump minimatch and replace in /web-console (#13396)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-minimatch-and-replace-in-web-console-13396\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [minimatch](https://github.com/isaacs/minimatch) to 3.0.5 and updates ancestor dependency [replace](https://github.com/ALMaclaine/replace). These dependencies need to be updated together.   Updates `minimatch` from 3.0.4 to 3.0.5 - [Release notes](https://github.com/isaacs/minimatch/releases) - [Commits](https://github.com/isaacs/minimatch/compare/v3.0.4...v3.0.5)  Updates `replace` from 1.2.1 to 1.2.2 - [Release notes](https://github.com/ALMaclaine/replace/releases) - [Commits](https://github.com/ALMaclaine/replace/commits)  --- updated-dependencies: - dependency-name: minimatch   dependency-type: indirect - dependency-name: replace   dependency-type: direct:development ...  Signed-off-by: dependabot[bot] <support@github.com>  Signed-off-by: dependabot[bot] <support@github.com> Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Nov 2022 12:16:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f524c68f08eb58047064e8234d320b51e83499ce\",\n",
      "\t\t\"parent\": \"c26b18c953e33b3bc886695e45836182357b593e\",\n",
      "\t\t\"subject\": \"Add mechanism for 'safe' memory reads for complex types (#13361)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-mechanism-for-safe-memory-reads-for-complex-types-13361\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* we can read where we want to we can leave your bounds behind 'cause if the memory is not there we really don't care and we'll crash this process of mine \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Nov 2022 00:25:22 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c26b18c953e33b3bc886695e45836182357b593e\",\n",
      "\t\t\"parent\": \"be4914dcd9bea9e56f8c8ef5c966eb34b84739a1\",\n",
      "\t\t\"subject\": \"Port CVE suppressions from 24.0.1 (#13415)\",\n",
      "\t\t\"sanitized_subject_line\": \"Port-CVE-suppressions-from-24.0.1-13415\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Suppress jackson-databind CVE-2022-42003 and CVE-2022-42004 (cherry picked from commit 1f4d892c9a2dbc3ce6df1481fd4c6d242ba0ea8d) * Suppress CVEs (cherry picked from commit ed55baa8fa7d7f914a0addabb072d9ed47e1cd9f) * Suppress vulnerabilities from druid-website package (cherry picked from commit c0fb364f8049d53cd704e414e2ffeab6c49b012e) * Add more suppressions for website package (cherry picked from commit 9bba569ebd52c5480bf4219c420ed78eb053701f)\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Nov 2022 11:35:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"be4914dcd9bea9e56f8c8ef5c966eb34b84739a1\",\n",
      "\t\t\"parent\": \"7cf761cee42dae8c21e415b7ce3fd4191f199a38\",\n",
      "\t\t\"subject\": \"fix off by one error in nested column range index (#13405)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-off-by-one-error-in-nested-column-range-index-13405\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Nov 2022 12:46:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7cf761cee42dae8c21e415b7ce3fd4191f199a38\",\n",
      "\t\t\"parent\": \"c6054b7cb78a9aaed0763465730434d2c9d6f6c9\",\n",
      "\t\t\"subject\": \"Prepare master branch for next release, 26.0.0 (#13401)\",\n",
      "\t\t\"sanitized_subject_line\": \"Prepare-master-branch-for-next-release-26.0.0-13401\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Prepare master branch for next release, 26.0.0  * Use docker image for druid 24.0.1  * Fix version in druid-it-cases pom.xml\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Nov 2022 15:31:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c6054b7cb78a9aaed0763465730434d2c9d6f6c9\",\n",
      "\t\t\"parent\": \"280a0f7158eba2a5a5bf2ab0a9fd0ccc00656fcb\",\n",
      "\t\t\"subject\": \"Attach IO error to parse error when we can't contact Avro schema registry. (#13403)\",\n",
      "\t\t\"sanitized_subject_line\": \"Attach-IO-error-to-parse-error-when-we-can-t-contact-Avro-schema-registry.-13403\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Attach IO error to parse error when we can't contact Avro schema registry.  The change in #12080 lost the original exception context. This patch adds it back.  * Add hamcrest-core.  * Fix format string.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 22:20:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"280a0f7158eba2a5a5bf2ab0a9fd0ccc00656fcb\",\n",
      "\t\t\"parent\": \"fe34ecc5e35d5091c3ca6c9043d6eac0db1dba56\",\n",
      "\t\t\"subject\": \"Add sequential sketch merging to MSQ (#13205)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-sequential-sketch-merging-to-MSQ-13205\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add sketch fetching framework  * Refactor code to support sequential merge  * Update worker sketch fetcher  * Refactor sketch fetcher  * Refactor sketch fetcher  * Add context parameter and threshold to trigger sequential merge  * Fix test  * Add integration test for non sequential merge  * Address review comments  * Address review comments  * Address review comments  * Resolve maxRetainedBytes  * Add new classes  * Renamed key statistics information class  * Rename fetchStatisticsSnapshotForTimeChunk function  * Address review comments  * Address review comments  * Update documentation and add comments  * Resolve build issues  * Resolve build issues  * Change worker APIs to async  * Address review comments  * Resolve build issues  * Add null time check  * Update integration tests  * Address review comments  * Add log messages and comments  * Resolve build issues  * Add unit tests  * Add unit tests  * Fix timing issue in tests\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Nov 2022 09:56:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fe34ecc5e35d5091c3ca6c9043d6eac0db1dba56\",\n",
      "\t\t\"parent\": \"68018a808fff8d04e5875ec366b7d3a7a0a16d9e\",\n",
      "\t\t\"subject\": \"add ability to make inputFormat part of the example datasets (#13402)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-ability-to-make-inputFormat-part-of-the-example-datasets-13402\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 12:50:44 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"68018a808fff8d04e5875ec366b7d3a7a0a16d9e\",\n",
      "\t\t\"parent\": \"133054bf27dd680fb281e440a7a9123d6e7818c5\",\n",
      "\t\t\"subject\": \"Firehose migration doc (#12981)\",\n",
      "\t\t\"sanitized_subject_line\": \"Firehose-migration-doc-12981\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Firehose migration doc  * Update migrate-from-firehose-ingestion.md  * Updated with review comments and suggestions  * Update migrate-from-firehose-ingestion.md  * Update migrate-from-firehose-ingestion.md  * Update migrate-from-firehose-ingestion.md\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 11:17:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"133054bf27dd680fb281e440a7a9123d6e7818c5\",\n",
      "\t\t\"parent\": \"bfffbabb56b654ca5cd4a6b5f33c537940431f38\",\n",
      "\t\t\"subject\": \"Make batched segment sampling the default, minor cleanup of coordinator config (#13391)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-batched-segment-sampling-the-default-minor-cleanup-of-coordinator-config-13391\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The batch segment sampling performs significantly better than the older method of sampling if there are a large number of used segments. It also avoids duplicates.  Changes: - Make batch segment sampling the default - Deprecate the property `useBatchedSegmentSampler` - Remove unused coordinator config `druid.coordinator.loadqueuepeon.repeatDelay` - Cleanup `KillUnusedSegments` - Simplify `KillUnusedSegmentsTest`, add better tests, remove redundant tests\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 20:31:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bfffbabb56b654ca5cd4a6b5f33c537940431f38\",\n",
      "\t\t\"parent\": \"f037776fd8028b52ebd5ecfaf7bc336abda8ab0d\",\n",
      "\t\t\"subject\": \"Async task client for SeekableStreamSupervisors. (#13354)\",\n",
      "\t\t\"sanitized_subject_line\": \"Async-task-client-for-SeekableStreamSupervisors.-13354\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Main changes: 1) Convert SeekableStreamIndexTaskClient to an interface, move old code    to SeekableStreamIndexTaskClientSyncImpl, and add new implementation    SeekableStreamIndexTaskClientAsyncImpl that uses ServiceClient. 2) Add \\\"chatAsync\\\" parameter to seekable stream supervisors that causes    the supervisor to use an async task client. 3) In SeekableStreamSupervisor.discoverTasks, adjust logic to avoid making    blocking RPC calls in workerExec threads. 4) In SeekableStreamSupervisor generally, switch from Futures.successfulAsList    to FutureUtils.coalesce, so we can better capture the errors that occurred    with contacting individual tasks.  Other, related changes: 1) Add ServiceRetryPolicy.retryNotAvailable, which controls whether    ServiceClient retries unavailable services. Useful since we do not    want to retry calls unavailable tasks within the service client. (The    supervisor does its own higher-level retries.) 2) Add FutureUtils.transformAsync, a more lambda friendly version of    Futures.transform(f, AsyncFunction). 3) Add FutureUtils.coalesce. Similar to Futures.successfulAsList, but    returns Either instead of using null on error. 4) Add JacksonUtils.readValue overloads for JavaType and TypeReference.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 19:20:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f037776fd8028b52ebd5ecfaf7bc336abda8ab0d\",\n",
      "\t\t\"parent\": \"b8ca03d28323350968846f4a2aa090c95b7d1fcd\",\n",
      "\t\t\"subject\": \"MSQ: Launch initial tasks faster. (#13393)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Launch-initial-tasks-faster.-13393\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Notify the mainLoop thread to skip a sleep when the desired task count changes.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 19:11:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b8ca03d28323350968846f4a2aa090c95b7d1fcd\",\n",
      "\t\t\"parent\": \"de566eb0dbe70e68b8161aa80713fa88b467260d\",\n",
      "\t\t\"subject\": \"SeekableStreamSupervisor: Unique type name for GracefulShutdownNotice. (#13399)\",\n",
      "\t\t\"sanitized_subject_line\": \"SeekableStreamSupervisor-Unique-type-name-for-GracefulShutdownNotice.-13399\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Allows GracefulShutdownNotice to be differentiated from ShutdownNotice.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 19:10:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de566eb0dbe70e68b8161aa80713fa88b467260d\",\n",
      "\t\t\"parent\": \"6c3f688a66775c26bb33630766b0badf6c004541\",\n",
      "\t\t\"subject\": \"Fix shared lock acquisition criteria (#13390)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-shared-lock-acquisition-criteria-13390\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, a shared lock is acquired only when all other locks are also shared locks.  This commit updates the behaviour and acquires a shared lock only if all locks of equal or higher priority are either shared locks or are already revoked. The lock type of locks with lower priority does not matter as they can be revoked.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 15:31:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c3f688a66775c26bb33630766b0badf6c004541\",\n",
      "\t\t\"parent\": \"c61313f4c4a396364aa19d63e68429c1a0cb277a\",\n",
      "\t\t\"subject\": \"cron stage failure should always send a failure notification (#13397)\",\n",
      "\t\t\"sanitized_subject_line\": \"cron-stage-failure-should-always-send-a-failure-notification-13397\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 14:38:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c61313f4c4a396364aa19d63e68429c1a0cb277a\",\n",
      "\t\t\"parent\": \"fa3ab27a71ab9829404319d515b3d09718c25789\",\n",
      "\t\t\"subject\": \"Quieter streaming supervisors. (#13392)\",\n",
      "\t\t\"sanitized_subject_line\": \"Quieter-streaming-supervisors.-13392\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Eliminates two common sources of noise with Kafka supervisors that have large numbers of tasks and partitions:  1) Log the report at DEBUG rather than INFO level at each run cycle.    It can get quite large, and can be retrieved via API when needed.  2) Use log4j2.xml to quiet down the org.apache.kafka.clients.consumer.internals    package. Avoids a log message per-partition per-minute as part of seeking    to the latest offset in the reporting thread. In the tasks, where this    sort of logging might be more useful, we have another log message with    the same information: \\\"Seeking partition[%s] to[%s]\\\".\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 20 Nov 2022 23:53:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fa3ab27a71ab9829404319d515b3d09718c25789\",\n",
      "\t\t\"parent\": \"fd239305d9eacf50a10b90d73d30fa392eca01d3\",\n",
      "\t\t\"subject\": \"Bump apache curator from 5.3.0 to 5.4.0 (#13295)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-apache-curator-from-5.3.0-to-5.4.0-13295\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Follow up to #12939. As noted in that PR there are a few fixes in 5.4.0 that should make running on Kubernetes more reliable. Notably: - https://issues.apache.org/jira/browse/CURATOR-538 - https://issues.apache.org/jira/browse/CURATOR-649\",\n",
      "\t\t\"author_name\": \"Adam Peck\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 11:23:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd239305d9eacf50a10b90d73d30fa392eca01d3\",\n",
      "\t\t\"parent\": \"5172d76a6720a217c321e90b9294435ca60242ea\",\n",
      "\t\t\"subject\": \"Update metrics doc (#13316)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-metrics-doc-13316\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - used inline code-style to format dimension names - removed unnecessary punctuation\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 09:43:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5172d76a6720a217c321e90b9294435ca60242ea\",\n",
      "\t\t\"parent\": \"a860baf4965cb46f35ba3b38e1651fa5838da1b3\",\n",
      "\t\t\"subject\": \"Migrate current integration batch tests to equivalent MSQ tests (#13374)\",\n",
      "\t\t\"sanitized_subject_line\": \"Migrate-current-integration-batch-tests-to-equivalent-MSQ-tests-13374\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Migrate current integration batch tests to equivalent MSQ tests using new IT framework  * Fix build issues  * Trigger Build  * Adding more tests and addressing comments  * fixBuildIssues  * fix dependency issues  * Parameterized the test and addressed comments  * Addressing comments  * fixing checkstyle errors  * Adressing comments\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 21 Nov 2022 09:12:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a860baf4965cb46f35ba3b38e1651fa5838da1b3\",\n",
      "\t\t\"parent\": \"08fa0383b9c61822de6a9ac50b7b56aecded2012\",\n",
      "\t\t\"subject\": \"Updated docs on front coding (#13387)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updated-docs-on-front-coding-13387\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 19 Nov 2022 00:01:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"08fa0383b9c61822de6a9ac50b7b56aecded2012\",\n",
      "\t\t\"parent\": \"c628947c31698df7761a757611305aeebf814132\",\n",
      "\t\t\"subject\": \"add supported indexSpec options (#13388)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-supported-indexSpec-options-13388\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 19 Nov 2022 00:00:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c628947c31698df7761a757611305aeebf814132\",\n",
      "\t\t\"parent\": \"a3d45f60862ef0c641e69edb2288b311f55f1b31\",\n",
      "\t\t\"subject\": \"Web console: streaming json input format specifics (#13381)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-streaming-json-input-format-specifics-13381\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* streaming json input format specifics  * goodies\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Nov 2022 14:15:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3d45f60862ef0c641e69edb2288b311f55f1b31\",\n",
      "\t\t\"parent\": \"5b625cea96450f284ad273b5619fb1e2eeaea42d\",\n",
      "\t\t\"subject\": \"treat user cancelation seriously (#13376)\",\n",
      "\t\t\"sanitized_subject_line\": \"treat-user-cancelation-seriously-13376\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Nov 2022 14:04:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5b625cea96450f284ad273b5619fb1e2eeaea42d\",\n",
      "\t\t\"parent\": \"092e769dd84d2f3b051d35b4b64b8fd4f00ac788\",\n",
      "\t\t\"subject\": \"Improve performance for ReadableInputStreamFrameChannel (#13373)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-performance-for-ReadableInputStreamFrameChannel-13373\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve performance for ReadableInputStreamFrameChannel  * Fix race condition leading to unnecessary sleep\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Nov 2022 18:26:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"092e769dd84d2f3b051d35b4b64b8fd4f00ac788\",\n",
      "\t\t\"parent\": \"6ccf31490e5b08a2b9333f54df370eb5e841c708\",\n",
      "\t\t\"subject\": \"JvmMonitor: Report jvm/gc/cpu in nanos. (#13383)\",\n",
      "\t\t\"sanitized_subject_line\": \"JvmMonitor-Report-jvm-gc-cpu-in-nanos.-13383\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Our documentation says we report this in nanos, and we actually did prior to #12481. This patch restores the prior behavior.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Nov 2022 12:33:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ccf31490e5b08a2b9333f54df370eb5e841c708\",\n",
      "\t\t\"parent\": \"7f4e386509855a2646f7aeb4ecee97145f5437ca\",\n",
      "\t\t\"subject\": \"Allow injection of node-role set to all non base modules (#13371)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-injection-of-node-role-set-to-all-non-base-modules-13371\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Nov 2022 12:12:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f4e386509855a2646f7aeb4ecee97145f5437ca\",\n",
      "\t\t\"parent\": \"8c9ffcfe37f5cc3b80dce3bb57be82d3813f8ffa\",\n",
      "\t\t\"subject\": \"add missing vector object selector for multi-value string columns, refactor some stuff (#13379)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-missing-vector-object-selector-for-multi-value-string-columns-refactor-some-stuff-13379\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add vector object selector for multi-value string columns, refactor some stuff  * use for nested columns too  * add test  * inspections\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Nov 2022 21:08:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8c9ffcfe37f5cc3b80dce3bb57be82d3813f8ffa\",\n",
      "\t\t\"parent\": \"bf10ff73a83defda18befb06b8cab1472dead10b\",\n",
      "\t\t\"subject\": \"nested column support for ORC (#13375)\",\n",
      "\t\t\"sanitized_subject_line\": \"nested-column-support-for-ORC-13375\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* nested column support for ORC  * more test\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Nov 2022 21:08:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bf10ff73a83defda18befb06b8cab1472dead10b\",\n",
      "\t\t\"parent\": \"6b9344cd39017174013f757c274e0d9c8e6671b7\",\n",
      "\t\t\"subject\": \"Fixes Kafka Supervisor Lag Report (#13380)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixes-Kafka-Supervisor-Lag-Report-13380\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes inclusion of all stream partitions in all tasks.  The PR (Adds Idle feature to `SeekableStreamSupervisor` for inactive stream) - https://github.com/apache/druid/pull/13144 updates the resulting lag calculation map in `KafkaSupervisor` to include all the latest partitions from the stream to set the idle state accordingly rather than the previous way of lag calculation only for the partitions actively being read from the stream. This led to an explosion of metrics in lag reports in cases where 1000s of tasks per supervisor are present.  Changes: - Add a new method to generate lags for only those partitions a single task is actively reading from while updating the Supervisor reports.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Nov 2022 22:24:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6b9344cd39017174013f757c274e0d9c8e6671b7\",\n",
      "\t\t\"parent\": \"8e9e46b519163713c72e00478759f727a411bf7b\",\n",
      "\t\t\"subject\": \"Persist legacy LatestPairs for now (#13378)\",\n",
      "\t\t\"sanitized_subject_line\": \"Persist-legacy-LatestPairs-for-now-13378\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We added compression to the latest/first pair storage, but the code change was forcing new things to be persisted with the new format, meaning that any segment created with the new code cannot be read by the old code.  Instead, we need to default to creating the old format and then remove that default in a future version.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Nov 2022 21:37:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8e9e46b519163713c72e00478759f727a411bf7b\",\n",
      "\t\t\"parent\": \"78d0b0abce2b27b88a53790684d81530a2318fc9\",\n",
      "\t\t\"subject\": \"Add static-checks Github Action (#13347)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-static-checks-Github-Action-13347\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adds static-checks github action  * bug fixes  * bug fixes  * adds maven install step  * update permissions on scripts folder  * fix license check errors  * attempt for parallelization  * fix concurrency  * fix naming  * remove intellij inspections to add in different CI pipeline  * minimize naming, add new lines  * setting hadoop profile through matrix  * also runs on push triggers to master and release branches  * changes on review\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Nov 2022 17:20:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"78d0b0abce2b27b88a53790684d81530a2318fc9\",\n",
      "\t\t\"parent\": \"71b133f3ff1ba9c547f94ddeed63d72e14419e94\",\n",
      "\t\t\"subject\": \" Add string comparison methods to StringUtils, fix dictionary comparisons. (#13364)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-string-comparison-methods-to-StringUtils-fix-dictionary-comparisons.-13364\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add string comparison methods to StringUtils, fix dictionary comparisons.  There are various places in Druid code where we assume that String.compareTo is consistent with Unicode code-point ordering. Sadly this is not the case.  To help deal with this, this patch introduces the following helpers:  1) compareUnicode: Compares two Strings in Unicode code-point order. 2) compareUtf8: Compares two UTF-8 byte arrays in Unicode code-point order.    Equivalent to comparison as unsigned bytes. 3) compareUtf8UsingJavaStringOrdering: Compares two UTF-8 byte arrays, or    ByteBuffers, in a manner consistent with String.compareTo.  There is no helper for comparing two Strings in a manner consistent with String.compareTo, because for that we can use compareTo directly.  The patch also fixes an inconsistency between the String and UTF-8 dictionary GenericIndexed flavors of string-typed columns: they were formerly using incompatible comparators.  * Adjust test.  * FrontCodedIndexed updates.  * Add test.  * Fix comments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Nov 2022 07:15:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"71b133f3ff1ba9c547f94ddeed63d72e14419e94\",\n",
      "\t\t\"parent\": \"61a7199f2b7f4356217f9affe5b231339e79f3f8\",\n",
      "\t\t\"subject\": \"Add `RoundRobinServerSelector` to speed up segment assignments (#13367)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-RoundRobinServerSelector-to-speed-up-segment-assignments-13367\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Segment assignments can take very long due to the strategy cost computation for a large number of segments. This commit allows segment assignments to be done in a round-robin fashion within a tier. Only segment balancing takes cost-based decisions to move segments around.  Changes - Add dynamic config `useRoundRobinSegmentAssignment` with default value false - Add `RoundRobinServerSelector`. This does not implement the `BalancerStrategy` as it does not conform to that contract and may also be used in conjunction with a strategy (round-robin for `RunRules` and a cost strategy for `BalanceSegments`) - Drops are still cost-based even when round-robin assignment is enabled.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Nov 2022 20:05:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"61a7199f2b7f4356217f9affe5b231339e79f3f8\",\n",
      "\t\t\"parent\": \"9e938b5a6f5dacf22012fb89556fb44298b5eede\",\n",
      "\t\t\"subject\": \"Bump loader-utils from 1.4.0 to 1.4.2 in /web-console (#13372)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-loader-utils-from-1.4.0-to-1.4.2-in-web-console-13372\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [loader-utils](https://github.com/webpack/loader-utils) from 1.4.0 to 1.4.2. - [Release notes](https://github.com/webpack/loader-utils/releases) - [Changelog](https://github.com/webpack/loader-utils/blob/v1.4.2/CHANGELOG.md) - [Commits](https://github.com/webpack/loader-utils/compare/v1.4.0...v1.4.2)  --- updated-dependencies: - dependency-name: loader-utils   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Signed-off-by: dependabot[bot] <support@github.com> Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Nov 2022 20:00:33 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e938b5a6f5dacf22012fb89556fb44298b5eede\",\n",
      "\t\t\"parent\": \"309cae7b65e65628f3b277808717a0c7e0bdaccf\",\n",
      "\t\t\"subject\": \"Add a limit to the number of columns in the CLUSTERED BY clause (#13352)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-limit-to-the-number-of-columns-in-the-CLUSTERED-BY-clause-13352\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add clustered by limit  * change semantics, add docs  * add fault class to the module  * add test  * unambiguate test\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Nov 2022 22:05:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"309cae7b65e65628f3b277808717a0c7e0bdaccf\",\n",
      "\t\t\"parent\": \"1231ce3b75b4ae13ecf012da480df4d7e09702cc\",\n",
      "\t\t\"subject\": \"nested column support for Parquet and Avro (#13325)\",\n",
      "\t\t\"sanitized_subject_line\": \"nested-column-support-for-Parquet-and-Avro-13325\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* nested column support for Parquet and Avro  * style\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Nov 2022 16:09:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1231ce3b75b4ae13ecf012da480df4d7e09702cc\",\n",
      "\t\t\"parent\": \"a3edda3b634d00942f8729930dd45e2dd6b2eaff\",\n",
      "\t\t\"subject\": \"dump-segment tool support for examining nested columns (#13356)\",\n",
      "\t\t\"sanitized_subject_line\": \"dump-segment-tool-support-for-examining-nested-columns-13356\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add nested mode to dump segment tool to dump nested columns  * docs  * more test  * fix it\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Nov 2022 16:08:47 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3edda3b634d00942f8729930dd45e2dd6b2eaff\",\n",
      "\t\t\"parent\": \"81d005f267484ce883fa3d9beb76e75995412f94\",\n",
      "\t\t\"subject\": \"Modify quantile sketches to add byte[] directly (#13351)\",\n",
      "\t\t\"sanitized_subject_line\": \"Modify-quantile-sketches-to-add-byte-directly-13351\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Modify quantile sketchs to add byte[] directly  * Rename class and add test\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Nov 2022 00:24:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"81d005f267484ce883fa3d9beb76e75995412f94\",\n",
      "\t\t\"parent\": \"b0db2a87d82a49d64f61b72c0066a13904928e69\",\n",
      "\t\t\"subject\": \"Druid Catalog basics (#13165)\",\n",
      "\t\t\"sanitized_subject_line\": \"Druid-Catalog-basics-13165\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Druid catalog basics  Catalog object model for tables, columns Druid metadata DB storage (as an extension) REST API to update the catalog (as an extension) Integration tests Model only: no planner integration yet\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 12 Nov 2022 15:30:22 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b0db2a87d82a49d64f61b72c0066a13904928e69\",\n",
      "\t\t\"parent\": \"3e172d44abef43a25409260b51a797a1cef5f958\",\n",
      "\t\t\"subject\": \"Update Kafka ingestion tutorial (#13261)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Kafka-ingestion-tutorial-13261\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update Kafka ingestion tutorial  * Update tutorial-kafka.md  Updated location of sample data file  * Added sample data file  * Update tutorial-kafka.md  * Add sample data file  * Update tutorial-kafka.md  Updated sample file location in curl commands  * Update and reuploading sample data files  * Updated spelling file  * Delete .spelling  * Added spelling file  * Update docs/tutorials/tutorial-kafka.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-kafka.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Updated after review  * Update tutorial-kafka.md  * Updated  * Update tutorial-kafka.md  * Update tutorial-kafka.md  * Update tutorial-kafka.md  * Updated sample data file and command  * Add files via upload  * Delete kttm-nested-data.json.tgz  * Delete kttm-nested-data.json.tgz  * Add files via upload  * Update tutorial-kafka.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Nov 2022 14:47:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3e172d44abef43a25409260b51a797a1cef5f958\",\n",
      "\t\t\"parent\": \"47dd4ed2e767d98730940eb697375cf7bc62ed97\",\n",
      "\t\t\"subject\": \"Bind DurableStorageCleaner only on the Overlord nodes (#13355)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bind-DurableStorageCleaner-only-on-the-Overlord-nodes-13355\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Nov 2022 21:56:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47dd4ed2e767d98730940eb697375cf7bc62ed97\",\n",
      "\t\t\"parent\": \"e78f648023466ff3edd8482d6b67c211c5ade0e5\",\n",
      "\t\t\"subject\": \"Added experimental feature text for front coding feature (#13349)\",\n",
      "\t\t\"sanitized_subject_line\": \"Added-experimental-feature-text-for-front-coding-feature-13349\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Nov 2022 02:06:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e78f648023466ff3edd8482d6b67c211c5ade0e5\",\n",
      "\t\t\"parent\": \"56d5c9780d6c09d6844136a6c678e3b417388bfe\",\n",
      "\t\t\"subject\": \"SeekableStreamSupervisor: Don't enqueue duplicate notices. (#13334)\",\n",
      "\t\t\"sanitized_subject_line\": \"SeekableStreamSupervisor-Don-t-enqueue-duplicate-notices.-13334\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SeekableStreamSupervisor: Don't enqueue duplicate notices.  Similar goal to #12018, but more aggressive. Don't enqueue a notice at all if it is equal to one currently in the queue.  * Adjustments from review.  * Update indexing-service/src/test/java/org/apache/druid/indexing/overlord/supervisor/NoticesQueueTest.java  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Nov 2022 01:54:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"56d5c9780d6c09d6844136a6c678e3b417388bfe\",\n",
      "\t\t\"parent\": \"77478f25fb3d33c032b26a1dbcb9ad485a417ea2\",\n",
      "\t\t\"subject\": \"Use standard library to correctly glob and stop at the correct folder structure when filtering cloud objects (#13027)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-standard-library-to-correctly-glob-and-stop-at-the-correct-folder-structure-when-filtering-cloud-objects-13027\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use standard library to correctly glob and stop at the correct folder structure when filtering cloud objects.  Removed:  import org.apache.commons.io.FilenameUtils;  Add:  import java.nio.file.FileSystems; import java.nio.file.PathMatcher; import java.nio.file.Paths;  * Forgot to update CloudObjectInputSource as well.  * Fix tests.  * Removed unused exceptions.  * Able to reduced user mistakes, by removing the protocol and the bucket on filter.  * add 1 more test.  * add comment on filterWithoutProtocolAndBucket  * Fix lint issue.  * Fix another lint issue.  * Replace all mention of filter -> objectGlob per convo here:  https://github.com/apache/druid/pull/13027#issuecomment-1266410707  * fix 1 bad constructor.  * Fix the documentation.  * Don\\u2019t do anything clever with the object path.  * Remove unused imports.  * Fix spelling error.  * Fix incorrect search and replace.  * Addressing Gian\\u2019s comment.  * add filename on .spelling  * Fix documentation.  * fix documentation again  Co-authored-by: Didip Kerabat <didip@apple.com>\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 23:46:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"77478f25fb3d33c032b26a1dbcb9ad485a417ea2\",\n",
      "\t\t\"parent\": \"03175a2b8d50e1121d7b1937ec61ceabec2ea43f\",\n",
      "\t\t\"subject\": \"Add taskActionType dimension to task/action/run/time. (#13333)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-taskActionType-dimension-to-task-action-run-time.-13333\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add taskActionType dimension to task/action/run/time.  * Spelling.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Nov 2022 12:00:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"03175a2b8d50e1121d7b1937ec61ceabec2ea43f\",\n",
      "\t\t\"parent\": \"fb23e38aa716d5f57c4f89352c3e3da5a10ac502\",\n",
      "\t\t\"subject\": \"Add missing MSQ error code fields to docs (#13308)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-missing-MSQ-error-code-fields-to-docs-13308\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix typo  * Fix some spacing  * Add missing fields  * Cleanup table spacing  * Remove durable storage docs again  Thanks Brian for pointing out previous discussions.  * Update docs/multi-stage-query/reference.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Mark codes as code  * And even more codes as code  * Another set of spaces  * Combine `ColumnTypeNotSupported`  Thanks Karan.  * More whitespaces and typos  * Add spelling and fix links  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Andreas Maechler\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 21:03:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fb23e38aa716d5f57c4f89352c3e3da5a10ac502\",\n",
      "\t\t\"parent\": \"c2210c4e098a90999678ed05807f7cd59f149362\",\n",
      "\t\t\"subject\": \"Fix messageGap emission (#13346)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-messageGap-emission-13346\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix messageGap emission  * Do not emit messageGap after stopping reading events  * Refactoring  * Fix tests\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 17:50:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c2210c4e098a90999678ed05807f7cd59f149362\",\n",
      "\t\t\"parent\": \"44f29030dddb33f34fda8baba9ce1018c4225053\",\n",
      "\t\t\"subject\": \"Update ingestion spec doc (#13329)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ingestion-spec-doc-13329\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update ingestion spec doc  * Updated  * Updated  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  * Updated  * Updated  Co-authored-by: Clint Wylie <cjwylie@gmail.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 02:54:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44f29030dddb33f34fda8baba9ce1018c4225053\",\n",
      "\t\t\"parent\": \"27215d1ff13ffc06d58fe06a59e2b4c32c1afc75\",\n",
      "\t\t\"subject\": \"fix flaky RemoteTaskRunnerTest.testRunPendingTaskFailToAssignTask with ugly Thread.sleep (#13344)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-flaky-RemoteTaskRunnerTest.testRunPendingTaskFailToAssignTask-with-ugly-Thread.sleep-13344\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 14:28:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"27215d1ff13ffc06d58fe06a59e2b4c32c1afc75\",\n",
      "\t\t\"parent\": \"965e41538edabb487f961f466272b18ab0b71da3\",\n",
      "\t\t\"subject\": \"fix complex_decode_base64 function, add SQL bindings (#13332)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-complex_decode_base64-function-add-SQL-bindings-13332\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix complex_decode_base64 function, add SQL bindings  * more permissive\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 23:40:25 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"965e41538edabb487f961f466272b18ab0b71da3\",\n",
      "\t\t\"parent\": \"0512ae49223bcd0f646b95738c95f331018a00b7\",\n",
      "\t\t\"subject\": \"Update nested columns doc (#13314)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-nested-columns-doc-13314\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Updated nested columns doc  * Update nested-columns.md  * Update nested-columns.md\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 09:53:28 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0512ae49223bcd0f646b95738c95f331018a00b7\",\n",
      "\t\t\"parent\": \"00400428635e5678ec3b608111a48683bad70ad7\",\n",
      "\t\t\"subject\": \"Optimize metadata calls in SeekableStreamSupervisor (#13328)\",\n",
      "\t\t\"sanitized_subject_line\": \"Optimize-metadata-calls-in-SeekableStreamSupervisor-13328\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Optimize metadata calls  * Modify isTaskCurrent  * Fix tests  * Refactoring\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Nov 2022 07:22:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"00400428635e5678ec3b608111a48683bad70ad7\",\n",
      "\t\t\"parent\": \"3e2bb4cf10a18395ed65a9be9ad11fbb315170f1\",\n",
      "\t\t\"subject\": \"HttpPostEmitter back off send() busy-loop (#12102)\",\n",
      "\t\t\"sanitized_subject_line\": \"HttpPostEmitter-back-off-send-busy-loop-12102\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* HttpPostEmitter back off send() busy-loop  The HttpPostEmitter gets in a loop until the flush timeout can be triggered, OR until some new events arrive that reset the minimum batch fill timeout delay. As a tactical fix, this introduces a simple backoff delay to the send loop to prevent spamming logs.  * Update core/src/main/java/org/apache/druid/java/util/emitter/core/HttpPostEmitter.java  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 14:32:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3e2bb4cf10a18395ed65a9be9ad11fbb315170f1\",\n",
      "\t\t\"parent\": \"a2013e656678146094f6c9039471d3933c81313f\",\n",
      "\t\t\"subject\": \"fix front-coded bucket size handling, better validation (#13335)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-front-coded-bucket-size-handling-better-validation-13335\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix front-coded bucket size handling, better validation  * Update FrontCodedIndexedTest.java\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 13:33:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a2013e656678146094f6c9039471d3933c81313f\",\n",
      "\t\t\"parent\": \"b7a513fe092da85e091bbe81f0cf7b9e2eafb844\",\n",
      "\t\t\"subject\": \"Enhance streaming ingestion metrics (#13331)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enhance-streaming-ingestion-metrics-13331\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Add a metric for partition-wise kafka/kinesis lag for streaming ingestion. - Emit lag metrics for streaming ingestion when supervisor is not suspended and state is in {RUNNING, IDLE, UNHEALTHY_TASKS, UNHEALTHY_SUPERVISOR} - Document metrics\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 23:44:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b7a513fe092da85e091bbe81f0cf7b9e2eafb844\",\n",
      "\t\t\"parent\": \"d242a9314b8a4979e5233f1b3d4ac76267bdc4e1\",\n",
      "\t\t\"subject\": \"Add a OverlordHelper that cleans up durable storage objects in MSQ (#13269)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-OverlordHelper-that-cleans-up-durable-storage-objects-in-MSQ-13269\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* scratch  * s3 ls fix, add docs  * add documentation, update method name  * Add tests, address commits, change default value of the helper  * fix test  * update the default value of config, remove initial delay config  * Trigger Build  * update class  * add more tests  * docs update  * spellcheck  * remove ioe from the signature  * add back dmmy constructor for initialization  * fix guice bindings, intellij inspections\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 17:23:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d242a9314b8a4979e5233f1b3d4ac76267bdc4e1\",\n",
      "\t\t\"parent\": \"7e600d2c6336078a11756c472f69a506cf60357b\",\n",
      "\t\t\"subject\": \"Adds license and security vulnerabilities checks for Hadoop3 build (#13270)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adds-license-and-security-vulnerabilities-checks-for-Hadoop3-build-13270\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* adds license and security vulnerabilities check for Hadoop3 builds  * spacing  * fixes bugs  * updates check_test_suite.py to always run license checks with Hadoop3  * nit  * run analyze dependencies, analyze hadoop 3 dependencies  * run tests  * revert analyze dependencies, analyze hadoop 3 dependencies addition in check_test_suite.py  * fixes bug  * revert code change\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Nov 2022 14:50:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7e600d2c6336078a11756c472f69a506cf60357b\",\n",
      "\t\t\"parent\": \"9f7fd57a692f307f733311d3ce4efda84769f752\",\n",
      "\t\t\"subject\": \"Enhancements to the Calcite test framework (#13283)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enhancements-to-the-Calcite-test-framework-13283\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Enhancements to the Calcite test framework * Standardize \\\"Unauthorized\\\" messages * Additional test framework extension points * Resolved joinable factory dependency issue\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 14:28:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9f7fd57a692f307f733311d3ce4efda84769f752\",\n",
      "\t\t\"parent\": \"ff8e0c3397c3677b85e521f141ffcc650094ca91\",\n",
      "\t\t\"subject\": \"Improve fetch of pending segments from metadata store (#13310)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-fetch-of-pending-segments-from-metadata-store-13310\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Deserialize only when needed  * Update query to fetch pending segments  * Revert unneeded changes  * Fix query\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 05:46:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ff8e0c3397c3677b85e521f141ffcc650094ca91\",\n",
      "\t\t\"parent\": \"594545da55e3502269a0275e2140ad95d0aa56a5\",\n",
      "\t\t\"subject\": \"Fix issues with caching cost strategy (#13321)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-issues-with-caching-cost-strategy-13321\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"`cachingCost` strategy has some discrepancies when compared to cost strategy. This commit addresses two of these by retaining the same behaviour as the `cost` strategy when computing the cost of moving a segment to a server: - subtract the self cost of a segment if it is being served by the target server - subtract the cost of segments that are marked to be dropped  Other changes: - Add tests to verify fixed strategy. These tests would fail without the fixes made to `CachingCostStrategy.computeCost()` - Fix the definition of the segment related metrics in the docs. - Fix some docs issues introduced in #13181\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 16:11:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"594545da55e3502269a0275e2140ad95d0aa56a5\",\n",
      "\t\t\"parent\": \"9a684af3c9d93009a4c2a6a23a0fa29be2f81ee2\",\n",
      "\t\t\"subject\": \"Adds cluster level idleConfig setting for supervisor (#13311)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adds-cluster-level-idleConfig-setting-for-supervisor-13311\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* adds cluster level idleConfig  * updates docs  * refactoring  * spelling nit  * nit  * nit  * refactoring\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 14:54:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9a684af3c9d93009a4c2a6a23a0fa29be2f81ee2\",\n",
      "\t\t\"parent\": \"a28b8c26745cc9656ce4aa3e0301f6ebd8ed76f4\",\n",
      "\t\t\"subject\": \"Fixing the K8s task runner to work with MSQ (#13305)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-the-K8s-task-runner-to-work-with-MSQ-13305\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing the K8s task runner to work with MSQ  * Sorry incomplete PR  Co-authored-by: Rahul Gidwani <r_gidwani@apple.com>\",\n",
      "\t\t\"author_name\": \"Churro\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 14:41:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a28b8c26745cc9656ce4aa3e0301f6ebd8ed76f4\",\n",
      "\t\t\"parent\": \"48528a0c9858f06c0daf7dc88cc9cecfe88a3654\",\n",
      "\t\t\"subject\": \"Improve rowkey object size estimate (#13319)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-rowkey-object-size-estimate-13319\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve rowkey object size estimate  * Address review comments  * Update comment  * Fix test\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 10:12:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48528a0c9858f06c0daf7dc88cc9cecfe88a3654\",\n",
      "\t\t\"parent\": \"f6aca21e8203c003e6467d0112840a63223bc859\",\n",
      "\t\t\"subject\": \"MSQ: Fix task lock checking during publish, fix lock priority. (#13282)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Fix-task-lock-checking-during-publish-fix-lock-priority.-13282\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Fix task lock checking during publish, fix lock priority.  Fixes two issues:  1) ControllerImpl did not properly check the return value of    SegmentTransactionalInsertAction when doing a REPLACE. This could cause    it to not realize that its locks were preempted.  2) Task lock priority was the default of 0. It should be the higher    batch default of 50. The low priority made it possible for MSQ tasks    to be preempted by compaction tasks, which is not desired.  * Restructuring, add docs.  * Add performSegmentPublish tests.  * Fix tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Nov 2022 09:27:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f6aca21e8203c003e6467d0112840a63223bc859\",\n",
      "\t\t\"parent\": \"d1a4de022a8570e906dd4eafa26e0519dd68e98c\",\n",
      "\t\t\"subject\": \"Web console: update DQT to version 0.17 (#13323)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-update-DQT-to-version-0.17-13323\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update to DQT 17  * update licenses  * after npm i\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 17:47:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d1a4de022a8570e906dd4eafa26e0519dd68e98c\",\n",
      "\t\t\"parent\": \"a9b39fc29ddb34b3ac32bc9198b52ba86d8de2b8\",\n",
      "\t\t\"subject\": \"Update retention rules doc (#13181)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-retention-rules-doc-13181\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update retention rules doc  * Update rule-configuration.md  * Updated  * Updated  * Updated  * Updated  * Update rule-configuration.md  * Update rule-configuration.md\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 14:47:33 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a9b39fc29ddb34b3ac32bc9198b52ba86d8de2b8\",\n",
      "\t\t\"parent\": \"a738ac9ad77194e66ff48d4253664649f78925b8\",\n",
      "\t\t\"subject\": \"Try converting all inner joins to filters (#13201)\",\n",
      "\t\t\"sanitized_subject_line\": \"Try-converting-all-inner-joins-to-filters-13201\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 23:19:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a738ac9ad77194e66ff48d4253664649f78925b8\",\n",
      "\t\t\"parent\": \"b1eaf7a21f3e414c3ad4732175b3143de16a2010\",\n",
      "\t\t\"subject\": \"Improve task pause logging and metrics for streaming ingestion (#13313)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-task-pause-logging-and-metrics-for-streaming-ingestion-13313\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve task pause logging and metrics for streaming ingestion  * Add metrics doc  * Fix spelling\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 21:33:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b1eaf7a21f3e414c3ad4732175b3143de16a2010\",\n",
      "\t\t\"parent\": \"47c32a9d929ac25df14647a971e3dd396a06a277\",\n",
      "\t\t\"subject\": \"MSQ should load even if node roles are not set (#13318)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-should-load-even-if-node-roles-are-not-set-13318\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 21:11:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47c32a9d929ac25df14647a971e3dd396a06a277\",\n",
      "\t\t\"parent\": \"650840ddaf741ade156d259a20f3119b4550ed12\",\n",
      "\t\t\"subject\": \"Skip ALL granularity compaction  (#13304)\",\n",
      "\t\t\"sanitized_subject_line\": \"Skip-ALL-granularity-compaction-13304\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Skip autocompaction for datasources with ETERNITY segments\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 17:55:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"650840ddaf741ade156d259a20f3119b4550ed12\",\n",
      "\t\t\"parent\": \"227b57dd8e1afed9c6696ae7780b8d222f6798bb\",\n",
      "\t\t\"subject\": \"Add segment handoff time metric (#13238)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-segment-handoff-time-metric-13238\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add segment handoff time metric  * Remove monitors on scheduler stop  * Add warning log for slow handoff  * Remove monitor when scheduler stops\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 17:49:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"227b57dd8e1afed9c6696ae7780b8d222f6798bb\",\n",
      "\t\t\"parent\": \"9423aa9163ce60f9572e9042c0dcb370fe81770f\",\n",
      "\t\t\"subject\": \"Compaction: Fetch segments one at a time on main task; skip when possible. (#13280)\",\n",
      "\t\t\"sanitized_subject_line\": \"Compaction-Fetch-segments-one-at-a-time-on-main-task-skip-when-possible.-13280\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Compaction: Fetch segments one at a time on main task; skip when possible.  Compact tasks include the ability to fetch existing segments and determine reasonable defaults for granularitySpec, dimensionsSpec, and metricsSpec. This is a useful feature that makes compact tasks work well even when the user running the compaction does not have a clear idea of what they want the compacted segments to be like.  However, this comes at a cost: it takes time, and disk space, to do all of these fetches. This patch improves the situation in two ways:  1) When segments do need to be fetched, download them one at a time and    delete them when we're done. This still takes time, but minimizes the    required disk space.  2) Don't fetch segments on the main compact task when they aren't needed.    If the user provides a full granularitySpec, dimensionsSpec, and    metricsSpec, we can skip it.  * Adjustments.  * Changes from code review.  * Fix logic for determining rollup.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 14:50:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9423aa9163ce60f9572e9042c0dcb370fe81770f\",\n",
      "\t\t\"parent\": \"081508f1aa45de3d44e65cb1a5f7169bc36dccb5\",\n",
      "\t\t\"subject\": \"MSQ: Consider PARTITION_STATS_MAX_BYTES in WorkerMemoryParameters. (#13274)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Consider-PARTITION_STATS_MAX_BYTES-in-WorkerMemoryParameters.-13274\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ: Consider PARTITION_STATS_MAX_BYTES in WorkerMemoryParameters.  This consideration is important, because otherwise we can run out of memory due to large statistics-tracking objects.  * Improved calculations.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Nov 2022 14:27:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"081508f1aa45de3d44e65cb1a5f7169bc36dccb5\",\n",
      "\t\t\"parent\": \"a17ffdfc5d82c8cf60dfb91015f69142e427d76f\",\n",
      "\t\t\"subject\": \"Bump commons-text from 1.9 to 1.10.0 in /extensions-contrib/kubernetes-overlord-extensions (#13299)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-commons-text-from-1.9-to-1.10.0-in-extensions-contrib-kubernetes-overlord-extensions-13299\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump commons-text in /extensions-contrib/kubernetes-overlord-extensions  Bumps commons-text from 1.9 to 1.10.0.  --- updated-dependencies: - dependency-name: org.apache.commons:commons-text   dependency-type: direct:production ...  Signed-off-by: dependabot[bot] <support@github.com>  * Cleanup pom  Signed-off-by: dependabot[bot] <support@github.com> Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com> Co-authored-by: Frank Chen <frank.chen021@outlook.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 5 Nov 2022 15:21:39 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a17ffdfc5d82c8cf60dfb91015f69142e427d76f\",\n",
      "\t\t\"parent\": \"d8329195f7eac03d0443f6bfeab88bfb6f135000\",\n",
      "\t\t\"subject\": \" Fix flaky test method in KafkaSupervisorTest (#13315)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-test-method-in-KafkaSupervisorTest-13315\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 5 Nov 2022 10:31:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d8329195f7eac03d0443f6bfeab88bfb6f135000\",\n",
      "\t\t\"parent\": \"e60e305ddb71131133fdea994cc0f2d619b22fd9\",\n",
      "\t\t\"subject\": \"fix bug when front-coded index has only the null value (#13309)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-when-front-coded-index-has-only-the-null-value-13309\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Nov 2022 05:26:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e60e305ddb71131133fdea994cc0f2d619b22fd9\",\n",
      "\t\t\"parent\": \"848570d8db3cd34f7179e292c91dbfd69ee216f4\",\n",
      "\t\t\"subject\": \"fix issue with parquet list conversion of nullable lists with complex nullable elements (#13294)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-parquet-list-conversion-of-nullable-lists-with-complex-nullable-elements-13294\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issue with parquet list conversion of nullable lists with complex nullable elements  * pom stuff  * fix style  * adjustments\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Nov 2022 05:25:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"848570d8db3cd34f7179e292c91dbfd69ee216f4\",\n",
      "\t\t\"parent\": \"2fdaa2fcabc7ceb91568ce1e6b1fcede2da7602c\",\n",
      "\t\t\"subject\": \"Suppressing package-lock.json?d3-color vulnerability (#13301)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppressing-package-lock.json-d3-color-vulnerability-13301\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Nov 2022 11:47:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2fdaa2fcabc7ceb91568ce1e6b1fcede2da7602c\",\n",
      "\t\t\"parent\": \"2a757b64e89b9f0f983df9c001bd90b3f8d1f743\",\n",
      "\t\t\"subject\": \"Make RecordSupplierInputSource respect sampler timeout when stream is empty (#13296)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-RecordSupplierInputSource-respect-sampler-timeout-when-stream-is-empty-13296\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make RecordSupplierInputSource respect sampler timeout when stream is empty  * Rename timeout param, make it nullable, add timeout test\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 17:45:35 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2a757b64e89b9f0f983df9c001bd90b3f8d1f743\",\n",
      "\t\t\"parent\": \"c875f4bd0402d49c57d56068537b8babc52386d1\",\n",
      "\t\t\"subject\": \"Update Curator in licenses.yaml. (#13306)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Curator-in-licenses.yaml.-13306\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 15:42:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c875f4bd0402d49c57d56068537b8babc52386d1\",\n",
      "\t\t\"parent\": \"8f90589ce538a96b04830c377220a3e7e1adbd2b\",\n",
      "\t\t\"subject\": \"Upgrade curator to 5.4.0 (#13302)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-curator-to-5.4.0-13302\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 11:26:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8f90589ce538a96b04830c377220a3e7e1adbd2b\",\n",
      "\t\t\"parent\": \"d1877e41ec74e649cbbb8f2ce1121e00fbad68d7\",\n",
      "\t\t\"subject\": \"Always return sketches from DS_HLL, DS_THETA, DS_QUANTILES_SKETCH. (#13247)\",\n",
      "\t\t\"sanitized_subject_line\": \"Always-return-sketches-from-DS_HLL-DS_THETA-DS_QUANTILES_SKETCH.-13247\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Always return sketches from DS_HLL, DS_THETA, DS_QUANTILES_SKETCH.  These aggregation functions are documented as creating sketches. However, they are planned into native aggregators that include finalization logic to convert the sketch to a number of some sort. This creates an inconsistency: the functions sometimes return sketches, and sometimes return numbers, depending on where they lie in the native query plan.  This patch changes these SQL aggregators to _never_ finalize, by using the \\\"shouldFinalize\\\" feature of the native aggregators. It already existed for theta sketches. This patch adds the feature for hll and quantiles sketches.  As to impact, Druid finalizes aggregators in two cases:  - When they appear in the outer level of a query (not a subquery). - When they are used as input to an expression or finalizing-field-access   post-aggregator (not any other kind of post-aggregator).  With this patch, the functions will no longer be finalized in these cases.  The second item is not likely to matter much. The SQL functions all declare return type OTHER, which would be usable as an input to any other function that makes sense and that would be planned into an expression.  So, the main effect of this patch is the first item. To provide backwards compatibility with anyone that was depending on the old behavior, the patch adds a \\\"sqlFinalizeOuterSketches\\\" query context parameter that restores the old behavior.  Other changes:  1) Move various argument-checking logic from runtime to planning time in    DoublesSketchListArgBaseOperatorConversion, by adding an OperandTypeChecker.  2) Add various JsonIgnores to the sketches to simplify their JSON representations.  3) Allow chaining of ExpressionPostAggregators and other PostAggregators    in the SQL layer.  4) Avoid unnecessary FieldAccessPostAggregator wrapping in the SQL layer,    now that expressions can operate on complex inputs.  5) Adjust return type to thetaSketch (instead of OTHER) in    ThetaSketchSetBaseOperatorConversion.  * Fix benchmark class.  * Fix compilation error.  * Fix ThetaSketchSqlAggregatorTest.  * Hopefully fix ITAutoCompactionTest.  * Adjustment to ITAutoCompactionTest.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 09:43:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d1877e41ec74e649cbbb8f2ce1121e00fbad68d7\",\n",
      "\t\t\"parent\": \"c5fcc03bdfd50f2624ba0a3d39f0d5e5e856deef\",\n",
      "\t\t\"subject\": \"Use lookup memory footprint in MSQ memory computations. (#13271)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-lookup-memory-footprint-in-MSQ-memory-computations.-13271\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use lookup memory footprint in MSQ memory computations.  Two main changes:  1) Add estimateHeapFootprint to LookupExtractor.  2) Use this in MSQ's IndexerWorkerContext when determining the total    amount of available memory. It's taken off the top.  This prevents MSQ tasks from running out of memory when there are lookups defined in the cluster.  * Updates from code review.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 07:36:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c5fcc03bdfd50f2624ba0a3d39f0d5e5e856deef\",\n",
      "\t\t\"parent\": \"ccc55ef8991716bc721b9ee0ab75c19a78a763a2\",\n",
      "\t\t\"subject\": \"PrometheusEmitter NullPointerException fix (#13286)\",\n",
      "\t\t\"sanitized_subject_line\": \"PrometheusEmitter-NullPointerException-fix-13286\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* PrometheusEmitter NullPointerException fix  * Improved null value judgment in pushMetric  * Delete meaningless judgments about namespace  * Delete unnecessary @Nullable above namespace attribute\",\n",
      "\t\t\"author_name\": \"DENNIS\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 18:50:27 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ccc55ef8991716bc721b9ee0ab75c19a78a763a2\",\n",
      "\t\t\"parent\": \"ae638e338c4ec7a7d76eefaff7b4bacbd6fed084\",\n",
      "\t\t\"subject\": \"Mask SQL String in the MSQTaskQueryMaker for secrets (#13231)\",\n",
      "\t\t\"sanitized_subject_line\": \"Mask-SQL-String-in-the-MSQTaskQueryMaker-for-secrets-13231\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add test  * add masking code  * fix test  * oops  * refactor json usage  * refactor, variable update  * add test cases  * Trigger Build  * add comment to the regex  * address review comment\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 15:27:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ae638e338c4ec7a7d76eefaff7b4bacbd6fed084\",\n",
      "\t\t\"parent\": \"7cb21cb9685b6641c52e2a51e9707fcbcb7f6903\",\n",
      "\t\t\"subject\": \"docs(msq): update insert vs replace for dimension-based segment pruning (#13228)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-msq-update-insert-vs-replace-for-dimension-based-segment-pruning-13228\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs(msq): update insert vs replace to mention dimension-based segment pruning  * make suggested changes\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 14:17:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7cb21cb9685b6641c52e2a51e9707fcbcb7f6903\",\n",
      "\t\t\"parent\": \"018f9847819dee9b2750e1f0cd3a546edb7737f0\",\n",
      "\t\t\"subject\": \"Use worker number instead of task id in MSQ for communication to/from workers. (#13062)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-worker-number-instead-of-task-id-in-MSQ-for-communication-to-from-workers.-13062\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Conversion from taskId to workerNumber in the workerClient  * storage connector changes, suffix file when finish writing to it  * Fix tests  * Trigger Build  * convert IntFunction to a dedicated interface  * first review round  * use a dummy file to indicate success  * fetch the first filename from the list in case of multiple files  * tests working, fix semantic issue with ls  * change how the success flag works  * comments, checkstyle, method rename  * fix test  * forbiddenapis fix  * Trigger Build  * change the writer  * dead store fix  * Review comments  * revert changes  * review  * review comments  * Update extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/DurableStorageInputChannelFactory.java  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>  * Update extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/DurableStorageInputChannelFactory.java  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>  * update error messages  * better error messages  * fix checkstyle  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Nov 2022 10:25:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"018f9847819dee9b2750e1f0cd3a546edb7737f0\",\n",
      "\t\t\"parent\": \"e5ad24ff9f1ea0169ca492283da84e6f1563a754\",\n",
      "\t\t\"subject\": \"fix nested column range index range computation (#13297)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-nested-column-range-index-range-computation-13297\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix nested column range index range computation  * simplify, add missing bounds check for FixedIndexed\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Nov 2022 21:37:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e5ad24ff9f1ea0169ca492283da84e6f1563a754\",\n",
      "\t\t\"parent\": \"176934e849d50a2360f50db7771c1775110308f3\",\n",
      "\t\t\"subject\": \"Support for middle manager less druid, tasks launch as k8s jobs (#13156)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-for-middle-manager-less-druid-tasks-launch-as-k8s-jobs-13156\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support for middle manager less druid, tasks launch as k8s jobs  * Fixing forking task runner test  * Test cleanup, dependency cleanup, intellij inspections cleanup  * Changes per PR review  Add configuration option to disable http/https proxy for the k8s client Update the docs to provide more detail about sidecar support  * Removing un-needed log lines  * Small changes per PR review  * Upon task completion we callback to the overlord to update the status / locaiton, for slower k8s clusters, this reduces locking time significantly  * Merge conflict fix  * Fixing tests and docs  * update tiny-cluster.yaml   changed `enableTaskLevelLogPush` to `encapsulatedTask`  * Apply suggestions from code review  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>  * Minor changes per PR request  * Cleanup, adding test to AbstractTask  * Add comment in peon.sh  * Bumping code coverage  * More tests to make code coverage happy  * Doh a duplicate dependnecy  * Integration test setup is weird for k8s, will do this in a different PR  * Reverting back all integration test changes, will do in anotbher PR  * use StringUtils.base64 instead of Base64  * Jdk is nasty, if i compress in jdk 11 in jdk 17 the decompressed result is different  Co-authored-by: Rahul Gidwani <r_gidwani@apple.com> Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Dr. Sizzles\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Nov 2022 19:44:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"176934e849d50a2360f50db7771c1775110308f3\",\n",
      "\t\t\"parent\": \"fd7864ae33ba8afe56d660c2b6d84ec5b498d321\",\n",
      "\t\t\"subject\": \"Web console: expose in the UI that a query is stuck waiting for task slots (#13291)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-expose-in-the-UI-that-a-query-is-stuck-waiting-for-task-slots-13291\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add pending info  * update tests  * fixes after review\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Nov 2022 09:40:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd7864ae33ba8afe56d660c2b6d84ec5b498d321\",\n",
      "\t\t\"parent\": \"0d03ce435fdf648430646cebea71ccdae2540dac\",\n",
      "\t\t\"subject\": \"Improve run time of coordinator duty MarkAsUnusedOvershadowedSegments (#13287)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-run-time-of-coordinator-duty-MarkAsUnusedOvershadowedSegments-13287\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In clusters with a large number of segments, the duty `MarkAsUnusedOvershadowedSegments` can take a long very long time to finish. This is because of the costly invocation of  `timeline.isOvershadowed` which is done for every used segment in every coordinator run.  Changes - Use `DataSourceSnapshot.getOvershadowedSegments` to get all overshadowed segments - Iterate over this set instead of all used segments to identify segments that can be marked as unused - Mark segments as unused in the DB in batches rather than one at a time - Refactor: Add class `SegmentTimeline` for ease of use and readability while using a `VersionedIntervalTimeline` of segments.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Nov 2022 20:19:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0d03ce435fdf648430646cebea71ccdae2540dac\",\n",
      "\t\t\"parent\": \"675fd982fb5ca274b057495a90563ecc248ad823\",\n",
      "\t\t\"subject\": \"introduce a \\\"tree\\\" type to the flattenSpec (#12177)\",\n",
      "\t\t\"sanitized_subject_line\": \"introduce-a-tree-type-to-the-flattenSpec-12177\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* introduce a \\\"tree\\\" type to the flattenSpec  * feedback - rename exprs to nodes, use CollectionsUtils.isNullOrEmpty for guard  * feedback - expand docs to more clearly capture limitations of \\\"tree\\\" flattenSpec  * feedback - fix for typo on docs  * introduce a comment to explain defensive copy, tweak null handling  * fix: part of rebase  * mark ObjectFlatteners.FlattenerMaker as an ExtensionPoint and provide default for new tree type  * fix: objectflattener restore previous behavior to call getRootField for root type  * docs: ingestion/data-formats add note that ORC only supports path expressions  * chore: linter remove unused import  * fix: use correct newer form for empty DimensionsSpec in FlattenJSONBenchmark\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Nov 2022 14:49:30 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"675fd982fb5ca274b057495a90563ecc248ad823\",\n",
      "\t\t\"parent\": \"e1ff3ca28904913cb2cd3876f7ef232531b7c4ba\",\n",
      "\t\t\"subject\": \"Correct task status returned by controller (#13288)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correct-task-status-returned-by-controller-13288\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Correct worker status returned by controller  * Address review comments\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 31 Oct 2022 15:18:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e1ff3ca28904913cb2cd3876f7ef232531b7c4ba\",\n",
      "\t\t\"parent\": \"e40c7f2a67f18c10dc308dd614aecd0c3444cbf2\",\n",
      "\t\t\"subject\": \"Resume streaming tasks on Overlord switch (#13223)\",\n",
      "\t\t\"sanitized_subject_line\": \"Resume-streaming-tasks-on-Overlord-switch-13223\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Resume streaming tasks on Overlord switch  * Refactoring and better messages  * Better docs  * Add unit test  * Fix tests' setup  * Update indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Better logs  * Fix test again  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 29 Oct 2022 09:38:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e40c7f2a67f18c10dc308dd614aecd0c3444cbf2\",\n",
      "\t\t\"parent\": \"d851985cf5b0faf8e6630c3011dc80288e959f28\",\n",
      "\t\t\"subject\": \"Update data loader parse screen help text (#13241)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-data-loader-parse-screen-help-text-13241\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Margaret Brewster <margaretbrewster@Maggie-Brewster.local>\",\n",
      "\t\t\"author_name\": \"Margaret Brewster\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 29 Oct 2022 11:51:37 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d851985cf5b0faf8e6630c3011dc80288e959f28\",\n",
      "\t\t\"parent\": \"4f0145fb8506257f6531cce04b5dee8354a1a1a1\",\n",
      "\t\t\"subject\": \"MSQ: Add support for indexSpec. (#13275)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Add-support-for-indexSpec.-13275\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 14:27:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4f0145fb8506257f6531cce04b5dee8354a1a1a1\",\n",
      "\t\t\"parent\": \"5429b9d76440c5e4fd7433e3cac3821dd0ca1e9b\",\n",
      "\t\t\"subject\": \"MSQ: Use long instead of double for estimatedRetainedBytes. (#13272)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Use-long-instead-of-double-for-estimatedRetainedBytes.-13272\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes a problem where, due to the inexactness of floating-point math, we would potentially drift while tracking retained byte counts and run into assertion failures in assertRetainedByteCountsAreTrackedCorrectly.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 08:31:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5429b9d76440c5e4fd7433e3cac3821dd0ca1e9b\",\n",
      "\t\t\"parent\": \"9cbda66d96797a69b6fcdd7c0cc9cf20a7a5d5b7\",\n",
      "\t\t\"subject\": \"RTR: Dedupe items in getKnownTasks. (#13273)\",\n",
      "\t\t\"sanitized_subject_line\": \"RTR-Dedupe-items-in-getKnownTasks.-13273\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes a problem where the tasks API in OverlordResource would complain about duplicate keys in the map it's building.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 08:31:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9cbda66d96797a69b6fcdd7c0cc9cf20a7a5d5b7\",\n",
      "\t\t\"parent\": \"de7ef81dff02175bad35177dc745534b40468960\",\n",
      "\t\t\"subject\": \"Remove skip ignorable shards (#13221)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-skip-ignorable-shards-13221\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Revert \\\"Improve kinesis task assignment after resharding (#12235)\\\"  This reverts commit 1ec57cb935bd0b04d3123dfbb26a962a984422c7.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 16:19:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de7ef81dff02175bad35177dc745534b40468960\",\n",
      "\t\t\"parent\": \"32020247d12dd5776b83342848dd4a54cb339a9b\",\n",
      "\t\t\"subject\": \"helm: add Kubernetes discovery support (#13262)\",\n",
      "\t\t\"sanitized_subject_line\": \"helm-add-Kubernetes-discovery-support-13262\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The K8 discovery mechanism, enabled by the druid-kubernetes-extension, relies on each pod advertising its name and namespace on the env variables POD_NAME and POD_NAMESPACE [1]. Add env variables to all deployments/statefulsets.  [1] https://druid.apache.org/docs/latest/development/extensions-core/kubernetes.html  Signed-off-by: Alejandro del Castillo <alejandro.delcastillo@ni.com>  Signed-off-by: Alejandro del Castillo <alejandro.delcastillo@ni.com>\",\n",
      "\t\t\"author_name\": \"Alejandro del Castillo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 15:09:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"32020247d12dd5776b83342848dd4a54cb339a9b\",\n",
      "\t\t\"parent\": \"4775427e2c77840c19e1d2458b7e0bb0d01e76d8\",\n",
      "\t\t\"subject\": \"Web console: Update dqt to a version that adds quotes by default (#13243)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Update-dqt-to-a-version-that-adds-quotes-by-default-13243\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update dqt  * auto quote by default\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 01:06:45 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4775427e2c77840c19e1d2458b7e0bb0d01e76d8\",\n",
      "\t\t\"parent\": \"49e54a0ec67b6227c5de2c37bac949eef4866905\",\n",
      "\t\t\"subject\": \"Add task start status to worker report (#13263)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-task-start-status-to-worker-report-13263\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add task start status to worker report  * Address review comments  * Address review comments  * Update documentation  * Update spelling checks\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 12:00:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"49e54a0ec67b6227c5de2c37bac949eef4866905\",\n",
      "\t\t\"parent\": \"22c140251a685993023ad2067fb47c05921f8429\",\n",
      "\t\t\"subject\": \"Docs: Update inputSegmentSizeBytes description (#13266)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Update-inputSegmentSizeBytes-description-13266\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 28 Oct 2022 09:33:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"22c140251a685993023ad2067fb47c05921f8429\",\n",
      "\t\t\"parent\": \"acb9cb022711f7c9aa3158aec0f79869fa6a7469\",\n",
      "\t\t\"subject\": \"Removed unused planner context parameter (#13249)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removed-unused-planner-context-parameter-13249\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Removed unused planner context parameter \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Oct 2022 17:59:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"acb9cb022711f7c9aa3158aec0f79869fa6a7469\",\n",
      "\t\t\"parent\": \"affc522b9f8227a42631e55bc9ad833ee57fc3a0\",\n",
      "\t\t\"subject\": \"fix thread safety issue with nested column global dictionaries (#13265)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-thread-safety-issue-with-nested-column-global-dictionaries-13265\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix thread safety issue with nested column global dictionaries  * missing float  * clarify javadocs thread safety\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Oct 2022 17:58:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"affc522b9f8227a42631e55bc9ad833ee57fc3a0\",\n",
      "\t\t\"parent\": \"72c16097ac6c04915f0137a1a37fed19f597799b\",\n",
      "\t\t\"subject\": \"Refactoring the data source before unnest (#13085)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactoring-the-data-source-before-unnest-13085\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* First set of changes for framework  * Second set of changes to move segment map function to data source  * Minot change to server manager  * Removing the createSegmentMapFunction from JoinableFactoryWrapper and moving to JoinDataSource  * Checkstyle fixes  * Patching Eric's fix for injection  * Checkstyle and fixing some CI issues  * Fixing code inspections and some failed tests and one injector for test in avatica  * Another set of changes for CI...almost there  * Equals and hashcode part update  * Fixing injector from Eric + refactoring for broadcastJoinHelper  * Updating second injector. Might revert later if better way found  * Fixing guice issue in JoinableFactory  * Addressing review comments part 1  * Temp changes refactoring  * Revert \\\"Temp changes refactoring\\\"  This reverts commit 9da42a9ef05bbeefddfc62b4019227fd7c975f93.  * temp  * Temp discussions  * Refactoring temp  * Refatoring the query rewrite to refer to a datasource  * Refactoring getCacheKey by moving it inside data source  * Nullable annotation check in injector  * Addressing some comments, removing 2 analysis.isJoin() checks and correcting the benchmark files  * Minor changes for refactoring  * Addressing reviews part 1  * Refactoring part 2 with new test cases for broadcast join  * Set for nullables  * removing instance of checks  * Storing nullables in guice to avoid checking on reruns  * Fixing a test case and removing an irrelevant line  * Addressing the atomic reference review comments\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Oct 2022 15:58:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"72c16097ac6c04915f0137a1a37fed19f597799b\",\n",
      "\t\t\"parent\": \"77e4246598428ae501096b10e6b4d6438206e297\",\n",
      "\t\t\"subject\": \"Fix Apache Commons Text  CVE-2022-42889 (#13226)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Apache-Commons-Text-CVE-2022-42889-13226\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix Apache Commons Text  CVE-2022-42889  Fix Apache Commons Text  CVE-2022-42889  https://nvd.nist.gov/vuln/detail/CVE-2022-42889  * Update license  Co-authored-by: Frank Chen <frank.chen021@outlook.com>\",\n",
      "\t\t\"author_name\": \"chi-chi weng\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 26 Oct 2022 10:04:32 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"77e4246598428ae501096b10e6b4d6438206e297\",\n",
      "\t\t\"parent\": \"2b0d873c7e4bf244fce12c45e381d00a61a277e2\",\n",
      "\t\t\"subject\": \"add support for 'front coded' string dictionaries for smaller string columns (#12277)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-support-for-front-coded-string-dictionaries-for-smaller-string-columns-12277\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add FrontCodedIndexed for delta string encoding  * now for actual segments  * fix indexOf  * fixes and thread safety  * add bucket size 4, which seems generally better  * fixes  * fixes maybe  * update indexes to latest interfaces  * utf8 support  * adjust  * oops  * oops  * refactor, better, faster  * more test  * fixes  * revert  * adjustments  * fix prefixing  * more chill  * sql nested benchmark too  * refactor  * more comments and javadocs  * better get  * remove base class  * fix  * hot rod  * adjust comments  * faster still  * minor adjustments  * spatial index support  * spotbugs  * add isSorted to Indexed to strengthen indexOf contract if set, improve javadocs, add docs  * fix docs  * push into constructor  * use base buffer instead of copy  * oops\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Oct 2022 18:05:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b0d873c7e4bf244fce12c45e381d00a61a277e2\",\n",
      "\t\t\"parent\": \"1e39bc65ccfb8e149330d7e873c274251ceed84a\",\n",
      "\t\t\"subject\": \"Fix two sources of SQL statement leaks. (#13259)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-two-sources-of-SQL-statement-leaks.-13259\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix two sources of SQL statement leaks.  1) SqlTaskResource and DruidJdbcResultSet leaked statements 100% of the    time, since they call stmt.plan(), which adds statements to    SqlLifecycleManager, and they do not explicitly remove them.  2) SqlResource leaked statements if yielder.close() threw an exception.    (And also would not emit metrics, since in that case it failed to    call stmt.close as well.)  * Only closeQuietly is needed.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Oct 2022 09:31:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1e39bc65ccfb8e149330d7e873c274251ceed84a\",\n",
      "\t\t\"parent\": \"d98c808d3f087645d8dcfd516e77b0058bdfd389\",\n",
      "\t\t\"subject\": \"Another simpler attempt to fix travis build (#13257)\",\n",
      "\t\t\"sanitized_subject_line\": \"Another-simpler-attempt-to-fix-travis-build-13257\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove usage of method deleted in latest jackson-databind  * Revert \\\"Remove usage of method deleted in latest jackson-databind\\\"  This reverts commit 81cb5d41d9afd5beb9b629e3e6248bdaa002a456.  * Use get-pip to install pip  * Use default pyyaml version  * Upgrade pyyaml\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Oct 2022 11:41:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d98c808d3f087645d8dcfd516e77b0058bdfd389\",\n",
      "\t\t\"parent\": \"86e6e61e884230e7a82e726f5f5c33602b242caf\",\n",
      "\t\t\"subject\": \"Remove basePersistDirectory from tuning configs. (#13040)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-basePersistDirectory-from-tuning-configs.-13040\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove basePersistDirectory from tuning configs.  Since the removal of CliRealtime, it serves no purpose, since it is always overridden in production using withBasePersistDirectory given some subdirectory of the task work directory.  Removing this from the tuning config has a benefit beyond removing no-longer-needed logic: it also avoids the side effect of empty \\\"druid-realtime-persist\\\" directories getting created in the systemwide temp directory.  * Test adjustments to appropriately set basePersistDirectory.  * Remove unused import.  * Fix RATC constructor.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 21 Oct 2022 17:25:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"86e6e61e884230e7a82e726f5f5c33602b242caf\",\n",
      "\t\t\"parent\": \"fc262dfbaf434614a2ef550775b0c6b736856e28\",\n",
      "\t\t\"subject\": \"Modular Calcite Test Framework (#12965)\",\n",
      "\t\t\"sanitized_subject_line\": \"Modular-Calcite-Test-Framework-12965\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor Calcite test \\\"framework\\\" for planner tests  Refactors the current Calcite tests to make it a bit easier to adjust the set of runtime objects used within a test.  * Move data creation out of CalciteTests into TestDataBuilder * Move \\\"framework\\\" creation out of CalciteTests into   a QueryFramework * Move injector-dependent functions from CalciteTests   into QueryFrameworkUtils * Wrapper around the planner factory, etc. to allow   customization. * Bulk of the \\\"framework\\\" created once per class rather   than once per test. * Refactor tests to use a test builder * Change all testQuery() methods to use the test builder. Move test execution & verification into a test runner. \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Oct 2022 15:45:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fc262dfbaf434614a2ef550775b0c6b736856e28\",\n",
      "\t\t\"parent\": \"9763bf8050a636ab4781c1b71539b6c0e089120b\",\n",
      "\t\t\"subject\": \"MSQ: Report the warning directly as an error if none of it is allowed by the user (#13198)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-Report-the-warning-directly-as-an-error-if-none-of-it-is-allowed-by-the-user-13198\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In MSQ, there can be an upper limit to the number of worker warnings. For example, for parseExceptions encountered while parsing the external data, the user can specify an upper limit to the number of parse exceptions that can be allowed before it throws an error of type TooManyWarnings.  This PR makes it so that if the user disallows warnings of a certain type i.e. the limit is 0 (or is executing in strict mode), instead of throwing an error of type TooManyWarnings, we can directly surface the warning as the error, saving the user from the hassle of going throw the warning reports.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Oct 2022 13:43:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9763bf8050a636ab4781c1b71539b6c0e089120b\",\n",
      "\t\t\"parent\": \"c83115e4e19a5825413c09566d165aa142a712a7\",\n",
      "\t\t\"subject\": \"Fix race condition in HttpPostEmitter (#13237)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-race-condition-in-HttpPostEmitter-13237\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Oct 2022 13:40:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c83115e4e19a5825413c09566d165aa142a712a7\",\n",
      "\t\t\"parent\": \"b34b4353f4a27065b37feac97995d4984334f8ed\",\n",
      "\t\t\"subject\": \"api: change API page formatting (#13213)\",\n",
      "\t\t\"sanitized_subject_line\": \"api-change-API-page-formatting-13213\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Tracking additional improvements requested by @paul-rogers: #13239  * api: refactor page so that indented bullet is child and unindented portion is parent  * get rid of post etc headings and combine them with the endpoint  * Update docs/operations/api-reference.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * fix broken links  * fix typo  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Oct 2022 13:22:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b34b4353f4a27065b37feac97995d4984334f8ed\",\n",
      "\t\t\"parent\": \"cc10350870dbe22f74aef0bb500c6e7894b916dd\",\n",
      "\t\t\"subject\": \"Async reads for JDBC (#13196)\",\n",
      "\t\t\"sanitized_subject_line\": \"Async-reads-for-JDBC-13196\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Async reads for JDBC: Prevents JDBC timeouts on long queries by returning empty batches when a batch fetch takes too long. Uses an async model to run the result fetch concurrently with JDBC requests.  Fixed race condition in Druid's Avatica server-side handler Fixed issue with no-user connections\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Oct 2022 11:40:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc10350870dbe22f74aef0bb500c6e7894b916dd\",\n",
      "\t\t\"parent\": \"6aca61763ef16f232c0059c4eaade0e59acf774a\",\n",
      "\t\t\"subject\": \"Collocated processes instructions (#13224)\",\n",
      "\t\t\"sanitized_subject_line\": \"Collocated-processes-instructions-13224\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"cristian-popa\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Oct 2022 11:56:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6aca61763ef16f232c0059c4eaade0e59acf774a\",\n",
      "\t\t\"parent\": \"b88e1c21eaec38d7c2d61ddbe59051a746ab78a9\",\n",
      "\t\t\"subject\": \"SQL: Use timestamp_floor when granularity is not safe. (#13206)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Use-timestamp_floor-when-granularity-is-not-safe.-13206\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Use timestamp_floor when granularity is not safe.  PR #12944 added a check at the execution layer to avoid materializing excessive amounts of time-granular buckets. This patch modifies the SQL planner to avoid generating queries that would throw such errors, by switching certain plans to use the timestamp_floor function instead of granularities. This applies both to the Timeseries query type, and the GroupBy timestampResultFieldGranularity feature.  The patch also goes one step further: we switch to timestamp_floor not just in the ETERNITY + non-ALL case, but also if the estimated number of time-granular buckets exceeds 100,000.  Finally, the patch modifies the timestampResultFieldGranularity field to consistently be a String rather than a Granularity. This ensures that it can be round-trip serialized and deserialized, which is useful when trying to execute the results of \\\"EXPLAIN PLAN FOR\\\" with GroupBy queries that use the timestampResultFieldGranularity feature.  * Fix test, address PR comments.  * Fix ControllerImpl.  * Fix test.  * Fix unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Oct 2022 08:22:45 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b88e1c21eaec38d7c2d61ddbe59051a746ab78a9\",\n",
      "\t\t\"parent\": \"3bbb76f17bab32b3d3e12a472e8403affeb09108\",\n",
      "\t\t\"subject\": \"Fix Overlord leader election when task lock re-acquisition fails (#13172)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Overlord-leader-election-when-task-lock-re-acquisition-fails-13172\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Overlord leader election can sometimes fail due to task lock re-acquisition issues. This commit solves the issue by failing such tasks and clearing all their locks. \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Oct 2022 15:23:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3bbb76f17bab32b3d3e12a472e8403affeb09108\",\n",
      "\t\t\"parent\": \"f4dcc52dac60fff3037321f0cf19b63d014ad816\",\n",
      "\t\t\"subject\": \"Docs: Add query/cpu/time to real-time metrics. (#13229)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Add-query-cpu-time-to-real-time-metrics.-13229\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Oct 2022 18:26:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f4dcc52dac60fff3037321f0cf19b63d014ad816\",\n",
      "\t\t\"parent\": \"6332c571bd72d83cbe28f479da549272e37e183f\",\n",
      "\t\t\"subject\": \"Redesign QueryContext class (#13071)\",\n",
      "\t\t\"sanitized_subject_line\": \"Redesign-QueryContext-class-13071\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We introduce two new configuration keys that refine the query context security model controlled by druid.auth.authorizeQueryContextParams. When that value is set to true then two other configuration options become available:  druid.auth.unsecuredContextKeys: The set of query context keys that do not require a security check. Use this for the \\\"white-list\\\" of key to allow. All other keys go through the existing context key security checks. druid.auth.securedContextKeys: The set of query context keys that do require a security check. Use this when you want to allow all but a specific set of keys: only these keys go through the existing context key security checks. Both are set using JSON list format:  druid.auth.securedContextKeys=[\\\"secretKey1\\\", \\\"secretKey2\\\"] You generally set one or the other values. If both are set, unsecuredContextKeys acts as exceptions to securedContextKeys.  In addition, Druid defines two query context keys which always bypass checks because Druid uses them internally:  sqlQueryId sqlStringifyArrays \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Oct 2022 11:02:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6332c571bd72d83cbe28f479da549272e37e183f\",\n",
      "\t\t\"parent\": \"42384d85e7153a2aff780d3781ed2c46a66fe0c0\",\n",
      "\t\t\"subject\": \"Support to read task logs from some S3 compatible cloud storage (#13195)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-to-read-task-logs-from-some-S3-compatible-cloud-storage-13195\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* follow RFC7232  * Only unquoted strings are processed according to RFC7232.  * Add help method and test cases.\",\n",
      "\t\t\"author_name\": \"hnakamor\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Oct 2022 10:44:23 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"42384d85e7153a2aff780d3781ed2c46a66fe0c0\",\n",
      "\t\t\"parent\": \"02ad62a08cd245da62f2625dced17ae2a55224cc\",\n",
      "\t\t\"subject\": \"Update nested-columns.md (#13227)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-nested-columns.md-13227\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"typo error corrected.\",\n",
      "\t\t\"author_name\": \"arvindanugula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Oct 2022 16:15:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"02ad62a08cd245da62f2625dced17ae2a55224cc\",\n",
      "\t\t\"parent\": \"9d51e466b1cf0abd4eaae80bbc40cf59c05651f4\",\n",
      "\t\t\"subject\": \"Docs: update description of query priority default value (#13191)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-update-description-of-query-priority-default-value-13191\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update description of default for query priority  * update order  * update terms  * standardize to query context parameters\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Oct 2022 14:28:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9d51e466b1cf0abd4eaae80bbc40cf59c05651f4\",\n",
      "\t\t\"parent\": \"2f2fe20089d54188374ee8072ed8d39564f6f9ab\",\n",
      "\t\t\"subject\": \"Minor doc update for BroadcastTablesTooLarge (#13218)\",\n",
      "\t\t\"sanitized_subject_line\": \"Minor-doc-update-for-BroadcastTablesTooLarge-13218\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Minor doc update for `BroadcastTablesTooLarge`. Now the user will know what to do in case this fault is encountered.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 14 Oct 2022 09:06:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f2fe20089d54188374ee8072ed8d39564f6f9ab\",\n",
      "\t\t\"parent\": \"45dfd679e92e668172c470c37615e7447b601af1\",\n",
      "\t\t\"subject\": \"Improve global-cached-lookups metric reporting (#13219)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-global-cached-lookups-metric-reporting-13219\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"It was found that the namespace/cache/heapSizeInBytes metric that tracks the total heap size in bytes of all lookup caches loaded on a service instance was being under reported. We were not accounting for the memory overhead of the String object, which I've found in testing to be ~40 bytes. While this overhead may be java version dependent, it should not vary much, and accounting for this provides a better estimate. Also fixed some logging, and reading bytes from the JDBI result set a little more efficient by saving hash table lookups. Also added some of the lookup metrics to the default statsD emitter metric whitelist.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Oct 2022 18:51:54 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45dfd679e92e668172c470c37615e7447b601af1\",\n",
      "\t\t\"parent\": \"346fbf133fa338fe0ccf76b5537eb1627f28a487\",\n",
      "\t\t\"subject\": \"Composite approach for checking in-filter values set in column dictionary (#13133)\",\n",
      "\t\t\"sanitized_subject_line\": \"Composite-approach-for-checking-in-filter-values-set-in-column-dictionary-13133\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Oct 2022 12:32:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"346fbf133fa338fe0ccf76b5537eb1627f28a487\",\n",
      "\t\t\"parent\": \"548d0d0bb2a54d151e8bb7283bb03f43e37e582e\",\n",
      "\t\t\"subject\": \"Make DimensionDictionary abstract (#13215)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-DimensionDictionary-abstract-13215\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This is in preparation for eventually retiring the flag `useMaxMemoryEstimates`,  after which the footprint of a value in the dimension dictionary will always be  estimated using the `estimateSizeOfValue()` method.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Oct 2022 07:18:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"548d0d0bb2a54d151e8bb7283bb03f43e37e582e\",\n",
      "\t\t\"parent\": \"6eff6c9ae42c7a4689bd77e2337735c9edf38c54\",\n",
      "\t\t\"subject\": \"Add more information to exceptions occurred while writing temporary data (#13217)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-more-information-to-exceptions-occurred-while-writing-temporary-data-13217\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add more information to exceptions when writing tmp data to disk  * Better error message\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Oct 2022 08:23:51 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6eff6c9ae42c7a4689bd77e2337735c9edf38c54\",\n",
      "\t\t\"parent\": \"3e13584e0ec18f2860e6817baf90bf44343769d9\",\n",
      "\t\t\"subject\": \"fix json_value sql planning with decimal type, fix vectorized expression math null value handling in default mode (#13214)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-json_value-sql-planning-with-decimal-type-fix-vectorized-expression-math-null-value-handling-in-default-mode-13214\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix json_value sql planning with decimal type, fix vectorized expression math null value handling in default mode changes: * json_value 'returning' decimal will now plan to native double typed query instead of ending up with default string typing, allowing decimal vector math expressions to work with this type * vector math expressions now zero out 'null' values even in 'default' mode (druid.generic.useDefaultValueForNull=false) to prevent downstream things that do not check the null vector from producing incorrect results  * more better  * test and why not vectorize  * more test, more fix\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Oct 2022 16:28:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3e13584e0ec18f2860e6817baf90bf44343769d9\",\n",
      "\t\t\"parent\": \"59e2afc566c51779d591df977a8f9abeee747be5\",\n",
      "\t\t\"subject\": \"Adds Idle feature to `SeekableStreamSupervisor` for inactive stream (#13144)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adds-Idle-feature-to-SeekableStreamSupervisor-for-inactive-stream-13144\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Idle Seekable stream supervisor changes.  * nit  * nit  * nit  * Adds unit tests  * Supervisor decides it's idle state instead of AutoScaler  * docs update  * nit  * nit  * docs update  * Adds Kafka unit test  * Adds Kafka Integration test.  * Updates travis config.  * Updates kafka-indexing-service dependencies.  * updates previous offsets snapshot & doc  * Doesn't act if supervisor is suspended.  * Fixes highest current offsets fetch bug, adds new Kafka UT tests, doc changes.  * Reverts Kinesis Supervisor idle behaviour changes.  * nit  * nit  * Corrects SeekableStreamSupervisorSpec check on idle behaviour config, adds tests.  * Fixes getHighestCurrentOffsets to fetch offsets of publishing tasks too  * Adds Kafka Supervisor UT  * Improves test coverage in druid-server  * Corrects IT override config  * Doc updates and Syntactic changes  * nit  * supervisorSpec.ioConfig.idleConfig changes\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Oct 2022 18:31:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"59e2afc566c51779d591df977a8f9abeee747be5\",\n",
      "\t\t\"parent\": \"80e10ffe2207e0fcaf1273ffb70e696ee002eb3d\",\n",
      "\t\t\"subject\": \"use object[] instead of string[] for vector expressions to be consistent with vector object selectors (#13209)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-object-instead-of-string-for-vector-expressions-to-be-consistent-with-vector-object-selectors-13209\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use object[] instead of string[] for vector expressions to be consistent with vector object selectors  * simplify\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Oct 2022 02:53:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"80e10ffe2207e0fcaf1273ffb70e696ee002eb3d\",\n",
      "\t\t\"parent\": \"9688674ea880194caff1f12e38ad31ca0220ce0d\",\n",
      "\t\t\"subject\": \"CompressedBigDecimal Min/Max (#13141)\",\n",
      "\t\t\"sanitized_subject_line\": \"CompressedBigDecimal-Min-Max-13141\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This adds min/max functions for CompressedBigDecimal. It exposes these functions via sql (BIG_MAX, BIG_MIN--see the SqlAggFunction implementations).  It also includes various bug fixes and cleanup to the original CompressedBigDecimal code include the AggregatorFactories. Various null handling was improved.  Additional test cases were added for both new and existing code including a base test case for AggregationFactories. Other tests common across sum,min,max may be refactored also to share the varoius cases in the future.\",\n",
      "\t\t\"author_name\": \"Sam Rash\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Oct 2022 16:35:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9688674ea880194caff1f12e38ad31ca0220ce0d\",\n",
      "\t\t\"parent\": \"c19ae13323e74de03fc9b4ede4cbe9a550711dc8\",\n",
      "\t\t\"subject\": \"fix issue with nested column null value index incorrectly matching non-null values (#13211)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-nested-column-null-value-index-incorrectly-matching-non-null-values-13211\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Oct 2022 15:54:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c19ae13323e74de03fc9b4ede4cbe9a550711dc8\",\n",
      "\t\t\"parent\": \"9b8e69c99a410ba10496e375fc8cbb9c84f6d59b\",\n",
      "\t\t\"subject\": \"Improve direct-memory check on startup. (#13207)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-direct-memory-check-on-startup.-13207\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"1) Better support for Java 9+ in RuntimeInfo. This means that in many cases,    an actual validation can be done.  2) Clearer log message in cases where an actual validation cannot be done.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Oct 2022 05:10:25 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9b8e69c99a410ba10496e375fc8cbb9c84f6d59b\",\n",
      "\t\t\"parent\": \"2a24c20454ea16487cca500ad89410c93f1b54e4\",\n",
      "\t\t\"subject\": \"Add inline descriptor Protobuf bytes decoder (#13192)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-inline-descriptor-Protobuf-bytes-decoder-13192\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add inline descriptor Protobuf bytes decoder  * PR comments  * Update tests, check for IllegalArgumentException  * Fix license, add equals test  * Update extensions-core/protobuf-extensions/src/main/java/org/apache/druid/data/input/protobuf/InlineDescriptorProtobufBytesDecoder.java  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Oct 2022 13:37:28 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2a24c20454ea16487cca500ad89410c93f1b54e4\",\n",
      "\t\t\"parent\": \"d30cf8c3089e72ef4a12e7aab4afb094a2bb6813\",\n",
      "\t\t\"subject\": \"process: update PR template to include release notes (#13188)\",\n",
      "\t\t\"sanitized_subject_line\": \"process-update-PR-template-to-include-release-notes-13188\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* process: update PR template to include release notes  * Update .github/pull_request_template.md [ci skip]  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update .github/pull_request_template.md  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  * incorporate feedback from paul  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Clint Wylie <cjwylie@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Oct 2022 10:29:18 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d30cf8c3089e72ef4a12e7aab4afb094a2bb6813\",\n",
      "\t\t\"parent\": \"5b519f3689b750f3119e115dd6c5a6a02ce237b1\",\n",
      "\t\t\"subject\": \"Dependency cleanup (#13194)\",\n",
      "\t\t\"sanitized_subject_line\": \"Dependency-cleanup-13194\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Clean up dependency in extensions  * Bump protobuf/aws.sdk  * Bump aws-sdk to 1.12.317  * Fix CI  * Fix CI  * Update license  * Update license\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Oct 2022 20:34:38 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5b519f3689b750f3119e115dd6c5a6a02ce237b1\",\n",
      "\t\t\"parent\": \"573e12c75fc0465d38ef37cae092125882f27eeb\",\n",
      "\t\t\"subject\": \"Fix null message handling in AllowedRegexErrorResponseTransformStrategy. (#13177)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-null-message-handling-in-AllowedRegexErrorResponseTransformStrategy.-13177\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Error messages can be null. If the incoming error message is null, then return null.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 9 Oct 2022 07:42:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"573e12c75fc0465d38ef37cae092125882f27eeb\",\n",
      "\t\t\"parent\": \"25c1d55dd6c1c8594902e7fd8faabb2d8f0f3ff4\",\n",
      "\t\t\"subject\": \"Web console: making the cell filter menu more functional, removing the old query view, and updating d3 (#13169)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-making-the-cell-filter-menu-more-functional-removing-the-old-query-view-and-updating-d3-13169\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove old query view  * update tests  * add filter  * fix test  * bump d3 things to latest versions  * rent too far into the future with d3  * make config dialogs load  * goodies  * update snapshots  * only compute duration when running or pending\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Oct 2022 12:44:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"25c1d55dd6c1c8594902e7fd8faabb2d8f0f3ff4\",\n",
      "\t\t\"parent\": \"f89496ccacedc01449fb8ed4e45cf2345cb3ed34\",\n",
      "\t\t\"subject\": \"Clarify behavior when decommissioningMaxPercentOfMaxSegmentsToMove = 0 (#13157)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clarify-behavior-when-decommissioningMaxPercentOfMaxSegmentsToMove-0-13157\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Oct 2022 09:01:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f89496ccacedc01449fb8ed4e45cf2345cb3ed34\",\n",
      "\t\t\"parent\": \"0edceead80e0770ed93230fe7e097fe72d731bba\",\n",
      "\t\t\"subject\": \"Revert Accidental Change to Druid.xml (#13190)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Accidental-Change-to-Druid.xml-13190\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"See commit 54a2eb for accidental commit\",\n",
      "\t\t\"author_name\": \"Sam Rash\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Oct 2022 14:42:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0edceead80e0770ed93230fe7e097fe72d731bba\",\n",
      "\t\t\"parent\": \"41e51b21c3396a78c7a6b736bcb87903876991b2\",\n",
      "\t\t\"subject\": \"msq: update known issue about GROUPING SETS and COUNT DISTINCT (#13185)\",\n",
      "\t\t\"sanitized_subject_line\": \"msq-update-known-issue-about-GROUPING-SETS-and-COUNT-DISTINCT-13185\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* msq: update known issue about GROUPING SETS and COUNT DISTINCT  * address feedback from Gian\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Oct 2022 19:47:03 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"41e51b21c3396a78c7a6b736bcb87903876991b2\",\n",
      "\t\t\"parent\": \"eff7edb6032fecf112feb289c8193baec8e4b41b\",\n",
      "\t\t\"subject\": \"Make http options the default configurations (#13092)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-http-options-the-default-configurations-13092\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Druid currently uses Zookeeper dependent options as the default. This commit updates the following to use HTTP as the default instead. - task runner. `druid.indexer.runner.type=remote -> httpRemote` - load queue peon. `druid.coordinator.loadqueuepeon.type=curator -> http` - server inventory view. `druid.serverview.type=curator -> http`\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Oct 2022 05:35:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eff7edb6032fecf112feb289c8193baec8e4b41b\",\n",
      "\t\t\"parent\": \"e3f9a0ed4491c0876783411be7b7973c777edfda\",\n",
      "\t\t\"subject\": \"update core Apache Kafka dependencies to 3.3.1 (#13176)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-core-Apache-Kafka-dependencies-to-3.3.1-13176\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Announcement: - https://blogs.apache.org/kafka/entry/what-rsquo-s-new-in  Release notes: - https://archive.apache.org/dist/kafka/3.3.0/RELEASE_NOTES.html - https://downloads.apache.org/kafka/3.3.1/RELEASE_NOTES.html\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Oct 2022 12:52:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e3f9a0ed4491c0876783411be7b7973c777edfda\",\n",
      "\t\t\"parent\": \"b07f01d645fe23dfa8d35b5588b3656b0c36cdce\",\n",
      "\t\t\"subject\": \"Lazy initialization of segment killers, movers and archivers (#13170)\",\n",
      "\t\t\"sanitized_subject_line\": \"Lazy-initialization-of-segment-killers-movers-and-archivers-13170\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Lazy initialization of segment killers, movers and archivers  * Add test for lazy killer  * Add more tests  * Intellij fixes\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Oct 2022 15:55:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b07f01d645fe23dfa8d35b5588b3656b0c36cdce\",\n",
      "\t\t\"parent\": \"7fa53ff4b321590eb97100c3fe21868badbc0051\",\n",
      "\t\t\"subject\": \"Set useMaxMemoryEstimates=false by default (#13178)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-useMaxMemoryEstimates-false-by-default-13178\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"A value of `false` denotes that the new flow with improved estimates will be used.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Oct 2022 15:04:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7fa53ff4b321590eb97100c3fe21868badbc0051\",\n",
      "\t\t\"parent\": \"4bfae1deee75be688ee5b428a13b32e9f24ead4f\",\n",
      "\t\t\"subject\": \"Exclude calcite from dependabot (#13160)\",\n",
      "\t\t\"sanitized_subject_line\": \"Exclude-calcite-from-dependabot-13160\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Exclude calcite from dependabot  * Update .github/dependabot.yml  Co-authored-by: Liam Newman <96086065+liam-verta@users.noreply.github.com>  * Update dependabot.yml  Co-authored-by: Liam Newman <96086065+liam-verta@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Oct 2022 10:21:11 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4bfae1deee75be688ee5b428a13b32e9f24ead4f\",\n",
      "\t\t\"parent\": \"92d2633ae6808116c52d5b813403fd1f5b84309c\",\n",
      "\t\t\"subject\": \"Docs: fix doc search (#13164)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-fix-doc-search-13164\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix doc search  * upgrade website node to 16  * change website travis script  * move spellcheck notification  * explicit path to npm bin  * cd to the correct place\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Oct 2022 16:48:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"92d2633ae6808116c52d5b813403fd1f5b84309c\",\n",
      "\t\t\"parent\": \"ebfe1c0c90d86e4d188617fe840dafb2c9b7e5b0\",\n",
      "\t\t\"subject\": \"Update ClusterByStatisticsCollectorImpl to use bytes instead of keys (#12998)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ClusterByStatisticsCollectorImpl-to-use-bytes-instead-of-keys-12998\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update clusterByStatistics to use bytes instead of keys  * Address review comments  * Resolve checkstyle  * Increase test coverage  * Update test  * Update thresholds  * Update retained keys function  * Update docs  * Fix spelling\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 3 Oct 2022 12:08:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ebfe1c0c90d86e4d188617fe840dafb2c9b7e5b0\",\n",
      "\t\t\"parent\": \"ce5f55e5ce00d876277424ea0724b70a330315b3\",\n",
      "\t\t\"subject\": \"Web console: fix DQT import (#13159)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-fix-DQT-import-13159\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix dqt import  * update licenses  * update tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 30 Sep 2022 09:31:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ce5f55e5ce00d876277424ea0724b70a330315b3\",\n",
      "\t\t\"parent\": \"61b34950e7dd80f35c8e3d1db71fcf24cfaf9238\",\n",
      "\t\t\"subject\": \"Fix over-replication caused by balancing when inventory is not updated yet (#13114)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-over-replication-caused-by-balancing-when-inventory-is-not-updated-yet-13114\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add coordinator test framework  * Remove outdated changes  * Add more tests  * Add option to auto-sync inventory  * Minor cleanup  * Fix inspections  * Add README for simulations, add SegmentLoadingNegativeTest  * Fix over-replication from balancing  * Fix README  * Cleanup unnecessary fields from DruidCoordinator  * Add a test  * Fix DruidCoordinatorTest  * Remove unused import  * Fix CuratorDruidCoordinatorTest  * Remove test log4j2.xml\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 29 Sep 2022 12:06:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"61b34950e7dd80f35c8e3d1db71fcf24cfaf9238\",\n",
      "\t\t\"parent\": \"acafd0d1e03a2f4827f1e300843dc178f95fdd14\",\n",
      "\t\t\"subject\": \"Fix assertion error in sql planning for latest aggregators (#13151)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-assertion-error-in-sql-planning-for-latest-aggregators-13151\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix sql planning bug for latest aggregators  * change test name  * Fix error messages  * fix error message again\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Sep 2022 21:01:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"acafd0d1e03a2f4827f1e300843dc178f95fdd14\",\n",
      "\t\t\"parent\": \"548d810baa0dc7915afa498fb8249ca66a30d9e2\",\n",
      "\t\t\"subject\": \"Upgrade kafka version to 3.2.3 to fix CVE (#13142)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-kafka-version-to-3.2.3-to-fix-CVE-13142\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Upgrade to 3.2.3 to fix CVE: https://nvd.nist.gov/vuln/detail/CVE-2022-34917 \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Sep 2022 10:47:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"548d810baa0dc7915afa498fb8249ca66a30d9e2\",\n",
      "\t\t\"parent\": \"0d7bf66578479afd920ba96db4c44a01e912833b\",\n",
      "\t\t\"subject\": \"Correct nested columns example (#13150)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correct-nested-columns-example-13150\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 28 Sep 2022 10:39:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0d7bf66578479afd920ba96db4c44a01e912833b\",\n",
      "\t\t\"parent\": \"c8f4d72fb1258cd34fb4482e29113a044dd741ab\",\n",
      "\t\t\"subject\": \"Add a note to the documentation about pre-built HLLSketches (#13088)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-note-to-the-documentation-about-pre-built-HLLSketches-13088\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add a note to the documentation about pre-built HLLSketches  Druid actually supports ingesting a pre-generated sketch column by using the HLLSketchMerge aggregator. However, this functionality was previously not made clear in the documentation.  * copyedit from the King's English to American English  * add suggested style changes  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"David Palmer\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Sep 2022 10:29:39 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c8f4d72fb1258cd34fb4482e29113a044dd741ab\",\n",
      "\t\t\"parent\": \"28b9edc2a8da0188a0195fe18cdd20819a850c30\",\n",
      "\t\t\"subject\": \"Fix documentation bug about injective lookups (#13147)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-documentation-bug-about-injective-lookups-13147\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"replace mapping to `unique keys` with mapping to `unique values`.\",\n",
      "\t\t\"author_name\": \"Apoorv Gupta\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 27 Sep 2022 10:16:48 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"28b9edc2a8da0188a0195fe18cdd20819a850c30\",\n",
      "\t\t\"parent\": \"1f1fced6d4c1866c2763df75438e46c5d4cef718\",\n",
      "\t\t\"subject\": \"Add BIG_SUM SQL function (#13102)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-BIG_SUM-SQL-function-13102\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This adds a sql function, \\\"BIG_SUM\\\", that uses CompressedBigDecimal to do a sum. Other misc changes:  1. handle NumberFormatExceptions when parsing a string (default to set    to 0, configurable in agg factory to be strict and throw on error) 2. format pom file (whitespace) + add dependency 3. scaleUp -> scale and always require scale as a parameter\",\n",
      "\t\t\"author_name\": \"Sam Rash\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Sep 2022 18:02:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f1fced6d4c1866c2763df75438e46c5d4cef718\",\n",
      "\t\t\"parent\": \"e839660b6ae0564aef7080c127e214314c8d216a\",\n",
      "\t\t\"subject\": \"Add JsonInputFormat option to assume newline delimited JSON, improve parse exception handling for multiline JSON (#13089)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-JsonInputFormat-option-to-assume-newline-delimited-JSON-improve-parse-exception-handling-for-multiline-JSON-13089\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add JsonInputFormat option to assume newline delimited JSON, improve handling for non-NDJSON  * Fix serde and docs  * Add PR comment check\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Sep 2022 19:51:04 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e839660b6ae0564aef7080c127e214314c8d216a\",\n",
      "\t\t\"parent\": \"0bfa81b7df4b0ae76ac45497b007b6857acb419f\",\n",
      "\t\t\"subject\": \"Grab the thread name in a poisoned pool (#13143)\",\n",
      "\t\t\"sanitized_subject_line\": \"Grab-the-thread-name-in-a-poisoned-pool-13143\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 26 Sep 2022 17:09:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0bfa81b7df4b0ae76ac45497b007b6857acb419f\",\n",
      "\t\t\"parent\": \"306f612f866790eb69a6e6fa365b70c542135fe4\",\n",
      "\t\t\"subject\": \"Fix the Injector creation in HadoopTask (#13138)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-Injector-creation-in-HadoopTask-13138\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Injector fix in HadoopTask  * Log the ExtensionsConfig while instantiating the HadoopTask  * Log the config in the run() method instead of the ctor\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 24 Sep 2022 10:38:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"306f612f866790eb69a6e6fa365b70c542135fe4\",\n",
      "\t\t\"parent\": \"a910764e4102c6e02d8a078843041ee761fd01cf\",\n",
      "\t\t\"subject\": \"Suppress Calcite CVE (#13119)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-Calcite-CVE-13119\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Suppress Calcite CVE  * Update comment\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 23 Sep 2022 16:23:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a910764e4102c6e02d8a078843041ee761fd01cf\",\n",
      "\t\t\"parent\": \"6c1dc6589e815ccc1494e07bc97f4a30fde00e2b\",\n",
      "\t\t\"subject\": \"better spec conversion with issues (#13136)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-spec-conversion-with-issues-13136\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Sep 2022 10:46:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c1dc6589e815ccc1494e07bc97f4a30fde00e2b\",\n",
      "\t\t\"parent\": \"728745a1d338b618752c96486fe6f63dd9739ab2\",\n",
      "\t\t\"subject\": \"initialize all counters for stages with input (#13137)\",\n",
      "\t\t\"sanitized_subject_line\": \"initialize-all-counters-for-stages-with-input-13137\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Sep 2022 08:10:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"728745a1d338b618752c96486fe6f63dd9739ab2\",\n",
      "\t\t\"parent\": \"044cab50945ea654c0d962f756122055ba168f58\",\n",
      "\t\t\"subject\": \"Add IT for MSQ task engine using the new IT framework (#12992)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-IT-for-MSQ-task-engine-using-the-new-IT-framework-12992\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* first test, serde causing problems  * serde working  * insert and select check  * Add cluster annotations for MSQ test cases  * Add cluster config for MSQ  * Add MSQ config to the pom.xml  * cleanup unnecessary changes  * Remove model classes  * Comments, checkstyle, check queries from file  * fixup test case name  * build failure fix  * review changes  * build failure fix  * Trigger Build  * Log the mismatch in QueryResultsVerifier  * Trigger Build  * Change the signature of the results verifier  * review changes  * LGTM fix  * build, change pom  * Trigger Build  * Trigger Build  * trigger build with minimal pom changes  * guice fix in tests  * travis.yml\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Sep 2022 16:09:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"044cab50945ea654c0d962f756122055ba168f58\",\n",
      "\t\t\"parent\": \"f1d3728371731dae22ed88af6ee904acf0f0d6f0\",\n",
      "\t\t\"subject\": \"Optimize CompressedBigDecimal compareTo() (#13086)\",\n",
      "\t\t\"sanitized_subject_line\": \"Optimize-CompressedBigDecimal-compareTo-13086\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Optimizes the compareTo() function in CompressedBigDecimal. It directly compares the int[] rather than creating BigDecimal objects and using its compareTo.  It handles unequal sized CBDs, but does require the scales to match.\",\n",
      "\t\t\"author_name\": \"Sam Rash\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 20:31:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f1d3728371731dae22ed88af6ee904acf0f0d6f0\",\n",
      "\t\t\"parent\": \"eb760c3d1d314414ab8616c4a42796b20e798ed5\",\n",
      "\t\t\"subject\": \"append to exisitng callout (#13130)\",\n",
      "\t\t\"sanitized_subject_line\": \"append-to-exisitng-callout-13130\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 19:39:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb760c3d1d314414ab8616c4a42796b20e798ed5\",\n",
      "\t\t\"parent\": \"12f12a13a943e87abb173530069cc9242dabec5b\",\n",
      "\t\t\"subject\": \"update log4j example (#13095)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-log4j-example-13095\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update log4j example  * fix some style issues  * Update docs/configuration/logging.md  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Sep 2022 09:46:49 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"12f12a13a943e87abb173530069cc9242dabec5b\",\n",
      "\t\t\"parent\": \"7fa35839c0494dae1bbfc7433687ec2c974402fc\",\n",
      "\t\t\"subject\": \"fix: fix broken postgres link (#13135)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-fix-broken-postgres-link-13135\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 22 Sep 2022 09:46:20 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7fa35839c0494dae1bbfc7433687ec2c974402fc\",\n",
      "\t\t\"parent\": \"2f731f356ed6fe8e39d23aae398fe16b20d55fae\",\n",
      "\t\t\"subject\": \"fix: follow naming convention for msq task engine (#13127)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-follow-naming-convention-for-msq-task-engine-13127\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix: follow naming convention for msq task engine  * more fixes  * add back in experimental  * fix anchor\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 18:46:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f731f356ed6fe8e39d23aae398fe16b20d55fae\",\n",
      "\t\t\"parent\": \"331e6d707b003391d44ee583dbc328b2b6359425\",\n",
      "\t\t\"subject\": \"Update pull-deps docs with correct repo list. (#13134)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-pull-deps-docs-with-correct-repo-list.-13134\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"There is only one default remote repo at this time.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 12:16:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"331e6d707b003391d44ee583dbc328b2b6359425\",\n",
      "\t\t\"parent\": \"90d14f629a232ea97c66c3df01a69f902a999140\",\n",
      "\t\t\"subject\": \"Add KafkaConfigOverrides extension point (#13122)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-KafkaConfigOverrides-extension-point-13122\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add KafkaConfigOverrides extension point  * X\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 11:47:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90d14f629a232ea97c66c3df01a69f902a999140\",\n",
      "\t\t\"parent\": \"0039409817530bb0eaed0a78549b278e56d51778\",\n",
      "\t\t\"subject\": \"spatial-filters (#13124)\",\n",
      "\t\t\"sanitized_subject_line\": \"spatial-filters-13124\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Sep 2022 22:48:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0039409817530bb0eaed0a78549b278e56d51778\",\n",
      "\t\t\"parent\": \"5ed5c83aab6bac365cc584e04fdf6122c7ac5ed1\",\n",
      "\t\t\"subject\": \"Add test framework to simulate segment loading and balancing (#13074)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-test-framework-to-simulate-segment-loading-and-balancing-13074\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes #12822   The framework added here make it easy to write tests that verify the behaviour and interactions of the following entities under various conditions: - `DruidCoordinator` - `HttpLoadQueuePeon`, `LoadQueueTaskMaster` - coordinator duties: `BalanceSegments`, `RunRules`, `UnloadUnusedSegments`, etc. - datasource retention rules: `LoadRule`, `DropRule`  Changes: Add the following main classes: - `CoordinatorSimulation` and related interfaces to dictate behaviour of simulation - `CoordinatorSimulationBuilder` to build a simulation. - `BlockingExecutorService` to keep submitted tasks in queue and execute them   only when explicitly invoked.  Add tests: - `CoordinatorSimulationBaseTest`, `SegmentLoadingTest`, `SegmentBalancingTest` - `SegmentLoadingNegativeTest` to contain tests which assert the existing erroneous behaviour of segment loading. Once the behaviour is fixed, these tests will be moved to the regular `SegmentLoadingTest`.  Please refer to the README.md in `org.apache.druid.server.coordinator.simulate` for more details\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 21 Sep 2022 09:51:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ed5c83aab6bac365cc584e04fdf6122c7ac5ed1\",\n",
      "\t\t\"parent\": \"edc444a4bcec710ae8882d3af29106d41fd6a803\",\n",
      "\t\t\"subject\": \"Clarified the behaviour of SQL COUNT(DISTINCT dim) on multi-value dimensions (#13128)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clarified-the-behaviour-of-SQL-COUNT-DISTINCT-dim-on-multi-value-dimensions-13128\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Clarified the behaviour of COUNT(DISTINCT column) on multi-value columns  * Update docs/querying/sql-aggregations.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Vadim Ogievetsky <vadimon@gmail.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"hosswald\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Sep 2022 18:03:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"edc444a4bcec710ae8882d3af29106d41fd6a803\",\n",
      "\t\t\"parent\": \"455b074b36ccb7986c7c4eb69b90dd1558a1fc56\",\n",
      "\t\t\"subject\": \"fix quickstart (#13126)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-quickstart-13126\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Sep 2022 17:44:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"455b074b36ccb7986c7c4eb69b90dd1558a1fc56\",\n",
      "\t\t\"parent\": \"b9edfe34a40ef033f3d9c362227fc83827c5b2f1\",\n",
      "\t\t\"subject\": \"Move JDK11 ITs to cron stage (#13075)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-JDK11-ITs-to-cron-stage-13075\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Move JDK11 ITs to cron stage  * Make cron run on release branches  * Review comments  * fix spelling\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 20 Sep 2022 09:18:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b9edfe34a40ef033f3d9c362227fc83827c5b2f1\",\n",
      "\t\t\"parent\": \"a3391693eb4af9b38f3c23aa275765749d0a5cb9\",\n",
      "\t\t\"subject\": \"be consistent about referring to the web console by its name (#13118)\",\n",
      "\t\t\"sanitized_subject_line\": \"be-consistent-about-referring-to-the-web-console-by-its-name-13118\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Sep 2022 15:02:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3391693eb4af9b38f3c23aa275765749d0a5cb9\",\n",
      "\t\t\"parent\": \"48638a5438db1d58ee0145e02723745db0dc940d\",\n",
      "\t\t\"subject\": \"Improve a MSQ planning error message (#13113)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-a-MSQ-planning-error-message-13113\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Sep 2022 23:11:54 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48638a5438db1d58ee0145e02723745db0dc940d\",\n",
      "\t\t\"parent\": \"a0e0fbe1b349debd3da4a136b9a25b5316291d55\",\n",
      "\t\t\"subject\": \"Getting extension list from pom (#13073)\",\n",
      "\t\t\"sanitized_subject_line\": \"Getting-extension-list-from-pom-13073\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Getting extension list from pom  * Trigger Build\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Sep 2022 15:14:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a0e0fbe1b349debd3da4a136b9a25b5316291d55\",\n",
      "\t\t\"parent\": \"8ce03eb094d6723b831ac03a067e2c4e3cf499fb\",\n",
      "\t\t\"subject\": \"nested column serializer performance improvement for sparse columns (#13101)\",\n",
      "\t\t\"sanitized_subject_line\": \"nested-column-serializer-performance-improvement-for-sparse-columns-13101\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Sep 2022 14:07:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ce03eb094d6723b831ac03a067e2c4e3cf499fb\",\n",
      "\t\t\"parent\": \"bb0b810b1dc54ef0ea971c8f3c6d4d9e7f64ff6b\",\n",
      "\t\t\"subject\": \"Convert the Druid planner to use statement handlers (#12905)\",\n",
      "\t\t\"sanitized_subject_line\": \"Convert-the-Druid-planner-to-use-statement-handlers-12905\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Converted Druid planner to use statement handlers  Converts the large collection of if-statements for statement types into a set of classes: one per supported statement type. Cleans up a few error messages.  * Revisions from review comments  * Build fix  * Build fix  * Resolve merge confict.  * More merges with QueryResponse PR  * More parameterized type cleanup  Forces a rebuild due to a flaky test\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 19 Sep 2022 11:58:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bb0b810b1dc54ef0ea971c8f3c6d4d9e7f64ff6b\",\n",
      "\t\t\"parent\": \"2e729170cc511d2d5f210e37de20cf8789bd400a\",\n",
      "\t\t\"subject\": \"fix html tags in docs (#13117)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-html-tags-in-docs-13117\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix html tags in docs  * revert not null\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 18 Sep 2022 19:40:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2e729170cc511d2d5f210e37de20cf8789bd400a\",\n",
      "\t\t\"parent\": \"de8f229bed6624b2b4fca493ff4a9e8ca04c0fb1\",\n",
      "\t\t\"subject\": \"Kill task: Don't include markAsUnused unless set. (#13104)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kill-task-Don-t-include-markAsUnused-unless-set.-13104\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Cleans up the serialized JSON.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Sep 2022 14:03:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de8f229bed6624b2b4fca493ff4a9e8ca04c0fb1\",\n",
      "\t\t\"parent\": \"d9b2968edba9300464d3579efce9b67da72605dc\",\n",
      "\t\t\"subject\": \"Web console: correctly escape path based flatten specs (#13105)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-correctly-escape-path-based-flatten-specs-13105\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix path generation  * do escape  * fix replace  * fix replace for good\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Sep 2022 14:02:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d9b2968edba9300464d3579efce9b67da72605dc\",\n",
      "\t\t\"parent\": \"b366a6c5a4aff9b535f35a200b30123737c790d3\",\n",
      "\t\t\"subject\": \"Docs: Clarify the situation with SELECT. (#13109)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Clarify-the-situation-with-SELECT.-13109\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Sep 2022 10:47:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b366a6c5a4aff9b535f35a200b30123737c790d3\",\n",
      "\t\t\"parent\": \"da30c8070a073b3d694e4aefd7bd076198d27c3c\",\n",
      "\t\t\"subject\": \"Add clarification around docker environment #8926 (#13084)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-clarification-around-docker-environment-8926-13084\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add clarification around docker environment #8926  * fix spelling  * Update docs/tutorials/docker.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/tutorials/docker.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * fix nano quickstart  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Sep 2022 20:44:24 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"da30c8070a073b3d694e4aefd7bd076198d27c3c\",\n",
      "\t\t\"parent\": \"d4967c38f87320cd2ac08047be973dedeeb330c0\",\n",
      "\t\t\"subject\": \"kafka consumer: custom serializer can't be configured after it's instantiation (#12960) (#13097)\",\n",
      "\t\t\"sanitized_subject_line\": \"kafka-consumer-custom-serializer-can-t-be-configured-after-it-s-instantiation-12960-13097\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* allow kakfa custom serializer to be configured    * add unit tests  Co-authored-by: ellen shen <ellenshen@apple.com>\",\n",
      "\t\t\"author_name\": \"Ellen Shen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 17 Sep 2022 20:42:21 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4967c38f87320cd2ac08047be973dedeeb330c0\",\n",
      "\t\t\"parent\": \"c62a8221211dbf6a6b6111ff11eed4cff9febaf7\",\n",
      "\t\t\"subject\": \"Various documentation updates. (#13107)\",\n",
      "\t\t\"sanitized_subject_line\": \"Various-documentation-updates.-13107\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Various documentation updates.  1) Split out \\\"data management\\\" from \\\"ingestion\\\". Break it into thematic pages.  2) Move \\\"SQL-based ingestion\\\" into the Ingestion category. Adjust content so    all conceptual content is in concepts.md and all syntax content is in reference.md.    Shorten the known issues page to the most interesting ones.  3) Add SQL-based ingestion to the ingestion method comparison page. Remove the    index task, since index_parallel is just as good when maxNumConcurrentSubTasks: 1.  4) Rename various mentions of \\\"Druid console\\\" to \\\"web console\\\".  5) Add additional information to ingestion/partitioning.md.  6) Remove a mention of Tranquility.  7) Remove a note about upgrading to Druid 0.10.1.  8) Remove no-longer-relevant task types from ingestion/tasks.md.  9) Move ingestion/native-batch-firehose.md to the hidden section. It was previously deprecated.  10) Move ingestion/native-batch-simple-task.md to the hidden section. It is still linked in some     places, but it isn't very useful compared to index_parallel, so it shouldn't take up space     in the sidebar.  11) Make all br tags self-closing.  12) Certain other cosmetic changes.  13) Update to node-sass 7.  * make travis use node12 for docs  Co-authored-by: Vadim Ogievetsky <vadim@ogievetsky.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 21:58:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c62a8221211dbf6a6b6111ff11eed4cff9febaf7\",\n",
      "\t\t\"parent\": \"9b53b0184f12e072074e35e58633f442f2acb6da\",\n",
      "\t\t\"subject\": \"support kafka lookups (#13098)\",\n",
      "\t\t\"sanitized_subject_line\": \"support-kafka-lookups-13098\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 15:25:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9b53b0184f12e072074e35e58633f442f2acb6da\",\n",
      "\t\t\"parent\": \"2493eb17bf0d7665bfceac5878ff35e410812b80\",\n",
      "\t\t\"subject\": \"Allocate numCorePartitions using only used segments (#13070)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allocate-numCorePartitions-using-only-used-segments-13070\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Allocate numCorePartitions using only used segments  * Add corePartition checks in existing test  * Separate committedMaxId and overallMaxId  * Fix bug: replace overall with committed\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 19:16:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2493eb17bf0d7665bfceac5878ff35e410812b80\",\n",
      "\t\t\"parent\": \"5ece87063430e142151af88c7941222991cc5763\",\n",
      "\t\t\"subject\": \"Doc fixes around msq (#13090)\",\n",
      "\t\t\"sanitized_subject_line\": \"Doc-fixes-around-msq-13090\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove things that do not apply  * fix more things  * pin node to a working version  * fix  * fixes  * known issues tidy up  * revert auto formatting changes  * remove management-uis page which is 100% lies  * don't mention the Coordinator console (that no longer exits)  * goodies  * fix typo\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 02:15:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ece87063430e142151af88c7941222991cc5763\",\n",
      "\t\t\"parent\": \"2218c8d23ce1a29a22dea30c8b209d856109d8ba\",\n",
      "\t\t\"subject\": \"split up NestedDataColumnSerializer into separate files (#13096)\",\n",
      "\t\t\"sanitized_subject_line\": \"split-up-NestedDataColumnSerializer-into-separate-files-13096\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* split up NestedDataColumnSerializer into separate files  * fix it\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 01:28:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2218c8d23ce1a29a22dea30c8b209d856109d8ba\",\n",
      "\t\t\"parent\": \"68262e43f88876ac7041d5df509760f6185fcf3f\",\n",
      "\t\t\"subject\": \"Documentation: Update spatial indexing example (#12555)\",\n",
      "\t\t\"sanitized_subject_line\": \"Documentation-Update-spatial-indexing-example-12555\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix spatial indexing example  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update text and example  * Format JSON example  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/development/geo.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Accept review suggestions  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 10:32:19 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"68262e43f88876ac7041d5df509760f6185fcf3f\",\n",
      "\t\t\"parent\": \"b8dd822f32d35ddd37547d9441bf61c4cba85332\",\n",
      "\t\t\"subject\": \"Docs \\u2013 README.md update around documentation contributions (#12850)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-README.md-update-around-documentation-contributions-12850\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update README.md  Expansion on the process and where everything is.  * Update README.md  Switcheroo and a typo fix.  * Update README.md  Header link update to take to the H2.  * Update README.md  Reverted docs link after feedback  * Update README.md  Amended language.  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update README.md  PR term update  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 10:31:06 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b8dd822f32d35ddd37547d9441bf61c4cba85332\",\n",
      "\t\t\"parent\": \"078b50ebe1951f113c96fe8e28290246028ab6b7\",\n",
      "\t\t\"subject\": \"Some improvements about Docker (#13059)\",\n",
      "\t\t\"sanitized_subject_line\": \"Some-improvements-about-Docker-13059\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 16 Sep 2022 09:25:52 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"078b50ebe1951f113c96fe8e28290246028ab6b7\",\n",
      "\t\t\"parent\": \"c32bf0df65faed5606a395f9be06b58f598536cf\",\n",
      "\t\t\"subject\": \"link to error docs (#13094)\",\n",
      "\t\t\"sanitized_subject_line\": \"link-to-error-docs-13094\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Sep 2022 15:06:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c32bf0df65faed5606a395f9be06b58f598536cf\",\n",
      "\t\t\"parent\": \"c153c2a712fda09b7ea78a74f533578e57bdcb9f\",\n",
      "\t\t\"subject\": \"Docs - README.md community channels removal + link (#12843)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-README.md-community-channels-removal-link-12843\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* README.md community channels  Removed explicit links to project channels in favour of a link direct to the Community page on druid.apache.org.  Updated nav to match remaining headings in the README.  * Update README.md  Reintroduced the old section and amended the nav bar to point to back to the community section.  * Incorporated suggested wording from @paul-rogers with some stylistic blahness * Updated Slack phraseology to be closer to the Google User Groups header wording and called out specific channels * Added new wording re: events and articles with link to the repo to contribute them\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Sep 2022 20:52:46 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c153c2a712fda09b7ea78a74f533578e57bdcb9f\",\n",
      "\t\t\"parent\": \"1311e85f6588016176c29c3eb37b09ddb9865f7d\",\n",
      "\t\t\"subject\": \"Initialize NullValueHandlingConfig for failed tests  (#13078)\",\n",
      "\t\t\"sanitized_subject_line\": \"Initialize-NullValueHandlingConfig-for-failed-tests-13078\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Initialize null handling  * Refactor nullhandlingconfig init\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Sep 2022 20:47:10 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1311e85f6588016176c29c3eb37b09ddb9865f7d\",\n",
      "\t\t\"parent\": \"aa9b0900d434f6e882adc6715adfbc787a68e302\",\n",
      "\t\t\"subject\": \"Faster fix for dangling tasks upon supervisor termination (#13072)\",\n",
      "\t\t\"sanitized_subject_line\": \"Faster-fix-for-dangling-tasks-upon-supervisor-termination-13072\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit fixes issues with delayed supervisor termination during certain transient states. Tasks can be created during supervisor termination and left behind since the cleanup may not consider these newly added tasks.  #12178 added a lock for the entire process of task creation to prevent such dangling tasks. But it also introduced a deadlock scenario as follows: - An invocation of `runInternal` is in progress. - A `stop` request comes, acquires `stateChangeLock` and submit a `ShutdownNotice` - `runInternal` keeps waiting to acquire the `stateChangeLock` - `ShutdownNotice` remains stuck in the notice queue because `runInternal` is still running - After some timeout, the supervisor goes through a forced termination  Fix:  * `SeekableStreamSupervisor.runInternal` - do not try to acquire lock if supervisor is already stopping  * `SupervisorStateManager.maybeSetState` - do not allow transitions from STOPPING state \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Sep 2022 15:31:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"aa9b0900d434f6e882adc6715adfbc787a68e302\",\n",
      "\t\t\"parent\": \"5733360dfd8446234f2284b6a84d3678e6dbd038\",\n",
      "\t\t\"subject\": \"Move web-console dependency declaration from druid-server to druid-distribution (#12501)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-web-console-dependency-declaration-from-druid-server-to-druid-distribution-12501\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Move web-console dependency from druid-server to distribution  * Add a test to check if the web-console is correctly integrated  * exclude web-console from 'other integration tests'  * Revert \\\"exclude web-console from 'other integration tests'\\\"  This reverts commit 8d72225544f83514c344b5ecd9c69c9b3114ee33.  * Revert \\\"Add a test to check if the web-console is correctly integrated\\\"  This reverts commit d6ac8f3087b22515b03e42fd57d24e7f3ddca254.\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 15 Sep 2022 10:39:30 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5733360dfd8446234f2284b6a84d3678e6dbd038\",\n",
      "\t\t\"parent\": \"f4ec50bf7a9e7e423dad4b1c2fb3c5af846ef075\",\n",
      "\t\t\"subject\": \"Update Snappy to 1.1.8.4. (#13081)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Snappy-to-1.1.8.4.-13081\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update Snappy to 1.1.8.4.  Prior to this, because snappy-java wasn't included in dependencyManagement, we actually shipped multiple different versions for different extensions, ranging from 1.1.7.1 to 1.1.8.4. Now, we standardize on 1.1.8.4.  Among other things, this enables the tests to pass on M1 Macs.  * Update snappy-java versions in licenses.yaml.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Sep 2022 15:13:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f4ec50bf7a9e7e423dad4b1c2fb3c5af846ef075\",\n",
      "\t\t\"parent\": \"a8fd3a90779a007676ba4cb9ca8d35633b781884\",\n",
      "\t\t\"subject\": \"fix JsonParserIteratorTest (#13083)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-JsonParserIteratorTest-13083\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Sep 2022 20:49:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8fd3a90779a007676ba4cb9ca8d35633b781884\",\n",
      "\t\t\"parent\": \"54a2eb7dccbd4b395587f71625669c0f4cb3500b\",\n",
      "\t\t\"subject\": \"Provide service specific log4j overrides in containerized deployments (#13020)\",\n",
      "\t\t\"sanitized_subject_line\": \"Provide-service-specific-log4j-overrides-in-containerized-deployments-13020\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Provide service specific log4j overrides  * Clarify comments  * Add docs\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 14 Sep 2022 11:47:11 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"54a2eb7dccbd4b395587f71625669c0f4cb3500b\",\n",
      "\t\t\"parent\": \"fd6c05eee8941c6fb3ade67217cb244748142dac\",\n",
      "\t\t\"subject\": \"Compressed Big Decimal Cleanup and Extension (#13048)\",\n",
      "\t\t\"sanitized_subject_line\": \"Compressed-Big-Decimal-Cleanup-and-Extension-13048\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"1. remove unnecessary generic type from CompressedBigDecimal 2. support Number input types 3. support aggregator reading supported input types directly (uningested    data) 4. fix scaling bug in buffer aggregator\",\n",
      "\t\t\"author_name\": \"sr\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Sep 2022 19:14:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd6c05eee8941c6fb3ade67217cb244748142dac\",\n",
      "\t\t\"parent\": \"08d6aca52865ab7bcbf75e16c4ca153bd3ca06f3\",\n",
      "\t\t\"subject\": \"Avoid ClassCastException when getting values from `QueryContext` (#13022)\",\n",
      "\t\t\"sanitized_subject_line\": \"Avoid-ClassCastException-when-getting-values-from-QueryContext-13022\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use safe conversion methods  * Rename method  * Add getContextAsBoolean  * Update test case  * Remove generic from getContextValue  * Update catch-handler  * Add test  * Resolve comments  * Replace 'getContextXXX' to 'getQueryContext().getAsXXXX'\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 13 Sep 2022 18:00:09 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"08d6aca52865ab7bcbf75e16c4ca153bd3ca06f3\",\n",
      "\t\t\"parent\": \"77925cdcdd9c2da98c4cbf175cdb687e47ed07ed\",\n",
      "\t\t\"subject\": \"Web console: better detection for arrays containing objects (#13077)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-better-detection-for-arrays-containing-objects-13077\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* better detection for arrays containing objects  * include boolean also\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 18:50:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"77925cdcdd9c2da98c4cbf175cdb687e47ed07ed\",\n",
      "\t\t\"parent\": \"c00ad28ecc06d009d868794354ffb8a0f1556f35\",\n",
      "\t\t\"subject\": \"Expressions: fixes for round-trips of floating point literals, Long.MIN_VALUE literals, Shuffle.visitAll. (#13037)\",\n",
      "\t\t\"sanitized_subject_line\": \"Expressions-fixes-for-round-trips-of-floating-point-literals-Long.MIN_VALUE-literals-Shuffle.visitAll.-13037\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Fix round-trips of floating point literals.  When writing RexLiterals into Druid expressions, we now write non-integer numeric literals in such a way that ensures they are parsed as doubles on the other end.  * Updates from code review, and some additional stuff inspired by the investigation.  - Remove unnecessary formatting code from DruidExpression.doubleLiteral:   it handles things just fine with its default behavior.  - Fix a problem where expression literals could not represent Long.MIN_VALUE.   Now, integer literals start life off as BigIntegerExpr instead of LongExpr,   and are converted to LongExpr during flattening. This is necessary because,   in order to avoid ambiguity between unary minus and negative literals, our   grammar does not actually have true negative literals. Negative numbers must   be represented as unary minus next to a positive literal.  - Fix a bug  introduced in #12230 where shuttle.visitAll(args) delegated   to shuttle.visit(arg) instead of arg.visit(shuttle). The latter does   a recursive visitation, which is the intended behavior.  * Style fixes.  * Move regexp to the right place.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 17:06:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c00ad28ecc06d009d868794354ffb8a0f1556f35\",\n",
      "\t\t\"parent\": \"80b97ac24dde0fe2ca1ff2d3a3156182b30de451\",\n",
      "\t\t\"subject\": \"Cleaner JSON for various input sources and formats. (#13064)\",\n",
      "\t\t\"sanitized_subject_line\": \"Cleaner-JSON-for-various-input-sources-and-formats.-13064\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Cleaner JSON for various input sources and formats.  Add JsonInclude to various properties, to avoid population of default values in serialized JSON.  Also fixes a bug in OrcInputFormat: it was not writing binaryAsString, so the property would be lost on serde.  * Additonal test cases.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 10:29:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"80b97ac24dde0fe2ca1ff2d3a3156182b30de451\",\n",
      "\t\t\"parent\": \"eff7c6422833236bbc96ac9cf57e1c50c124d3e3\",\n",
      "\t\t\"subject\": \"Create a copy of the shared JDBC context (#13049)\",\n",
      "\t\t\"sanitized_subject_line\": \"Create-a-copy-of-the-shared-JDBC-context-13049\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 10:27:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eff7c6422833236bbc96ac9cf57e1c50c124d3e3\",\n",
      "\t\t\"parent\": \"5ba0075c0c5054b7f11b02201e80e952dcf0e691\",\n",
      "\t\t\"subject\": \"export com.sun.management.internal (#13068)\",\n",
      "\t\t\"sanitized_subject_line\": \"export-com.sun.management.internal-13068\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 09:03:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5ba0075c0c5054b7f11b02201e80e952dcf0e691\",\n",
      "\t\t\"parent\": \"f60ec8e7ca4a7d5a5c32a8926b3547e95783106f\",\n",
      "\t\t\"subject\": \"Expose HTTP Response headers from SqlResource (#13052)\",\n",
      "\t\t\"sanitized_subject_line\": \"Expose-HTTP-Response-headers-from-SqlResource-13052\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Expose HTTP Response headers from SqlResource  This change makes the SqlResource expose HTTP response headers in the same way that the QueryResource exposes them.  Fundamentally, the change is to pipe the QueryResponse object all the way through to the Resource so that it can populate response headers.  There is also some code cleanup around DI, as there was a superfluous FactoryFactory class muddying things up.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 12 Sep 2022 01:40:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f60ec8e7ca4a7d5a5c32a8926b3547e95783106f\",\n",
      "\t\t\"parent\": \"4bde50e683e649c57a5d1a147bb15c6286e9eb97\",\n",
      "\t\t\"subject\": \"Enable msq for docker by default (#13069)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-msq-for-docker-by-default-13069\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 11 Sep 2022 21:00:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4bde50e683e649c57a5d1a147bb15c6286e9eb97\",\n",
      "\t\t\"parent\": \"4fc43670e5965e25c9e4056cff91022f0b927c93\",\n",
      "\t\t\"subject\": \"Bump the version of Druid docker image from 0.16.0-incubating to latest (#13058)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-the-version-of-Druid-docker-image-from-0.16.0-incubating-to-latest-13058\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 10 Sep 2022 14:06:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4fc43670e5965e25c9e4056cff91022f0b927c93\",\n",
      "\t\t\"parent\": \"d978afc5b79db7d62694008800c43cf3380c69fc\",\n",
      "\t\t\"subject\": \"adjust docs and images (#13067)\",\n",
      "\t\t\"sanitized_subject_line\": \"adjust-docs-and-images-13067\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 10 Sep 2022 14:05:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d978afc5b79db7d62694008800c43cf3380c69fc\",\n",
      "\t\t\"parent\": \"e29e7a843461562386d1febadb8c62739aa7605d\",\n",
      "\t\t\"subject\": \"fix number of expected functions (#13050)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-number-of-expected-functions-13050\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 13:42:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e29e7a843461562386d1febadb8c62739aa7605d\",\n",
      "\t\t\"parent\": \"5cc5f7b60c8d2591eb01d273cc37dc4dd18b99be\",\n",
      "\t\t\"subject\": \"Add ARRAY_QUANTILE function. (#13061)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-ARRAY_QUANTILE-function.-13061\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add ARRAY_QUANTILE function.  Expected usage is like: ARRAY_QUANTILE(ARRAY_AGG(x), 0.9).  * Fix test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 11:29:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5cc5f7b60c8d2591eb01d273cc37dc4dd18b99be\",\n",
      "\t\t\"parent\": \"dced61645f360aa140334d697c520061cd601b5c\",\n",
      "\t\t\"subject\": \"quote columns, datasources in auto complete if needed (#13060)\",\n",
      "\t\t\"sanitized_subject_line\": \"quote-columns-datasources-in-auto-complete-if-needed-13060\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 11:22:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dced61645f360aa140334d697c520061cd601b5c\",\n",
      "\t\t\"parent\": \"48c99054d038afcf1ef9d5c0699de213b80b6172\",\n",
      "\t\t\"subject\": \"prometheus-emitter supports sending metrics to pushgateway regularly \\u2026 (#13034)\",\n",
      "\t\t\"sanitized_subject_line\": \"prometheus-emitter-supports-sending-metrics-to-pushgateway-regularly-13034\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* prometheus-emitter supports sending metrics to pushgateway regularly and continuously  * spell check fix  * Optimization variable name and related documents  * Update docs/development/extensions-contrib/prometheus.md  OK, it looks more conspicuous  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update doc  * Update docs/development/extensions-contrib/prometheus.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * When PrometheusEmitter is closed, close the scheduler  * Ensure that registeredMetrics is thread safe.  * Local variable name optimization  * Remove unnecessary white space characters  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"DENNIS\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 20:46:14 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48c99054d038afcf1ef9d5c0699de213b80b6172\",\n",
      "\t\t\"parent\": \"6438f4198db28c4accfb3524a9a1555a335d9bcf\",\n",
      "\t\t\"subject\": \"Update tutorial-kafka.md (#13056)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-tutorial-kafka.md-13056\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update tutorial-kafka.md  Added missing command to the doc for zookeeper before starting kafka  * Update docs/tutorials/tutorial-kafka.md  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"sachidananda007\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 10:06:19 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6438f4198db28c4accfb3524a9a1555a335d9bcf\",\n",
      "\t\t\"parent\": \"d57557d51d94b41c75539d401db6d49d5f9ee2a8\",\n",
      "\t\t\"subject\": \"improve nested column serializer (#13051)\",\n",
      "\t\t\"sanitized_subject_line\": \"improve-nested-column-serializer-13051\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * long and double value columns are now written directly, at the same time as writing out the 'intermediary' dictionaryid column with unsorted ids * remove reverse value lookup from GlobalDictionaryIdLookup since it is no longer needed\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 8 Sep 2022 18:32:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d57557d51d94b41c75539d401db6d49d5f9ee2a8\",\n",
      "\t\t\"parent\": \"99fd22c79be85763d48b1caf3ec67767a0c5f9ad\",\n",
      "\t\t\"subject\": \"Improve doc and configuration of prometheus emitter (#13028)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-doc-and-configuration-of-prometheus-emitter-13028\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve doc and validation  * Add configuration for peon tasks  * Update doc  * Update test case  * Fix typo  * Update docs/development/extensions-contrib/prometheus.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  * Update docs/development/extensions-contrib/prometheus.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 9 Sep 2022 02:20:34 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"99fd22c79be85763d48b1caf3ec67767a0c5f9ad\",\n",
      "\t\t\"parent\": \"7e20d7024244544981781ac58c1a67f43053d142\",\n",
      "\t\t\"subject\": \"fix bug in /status/properties filtering (#13045)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-in-status-properties-filtering-13045\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix bug in /status/properties filtering  * Refactor tests to use jackson for parsing druid.server.hiddenProperties instead of hacky string modifications  * make javadoc more descriptive using example  * add in a sanity assertion that raw properties keyset size is greater than filtered properties keyset size\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 17:45:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7e20d7024244544981781ac58c1a67f43053d142\",\n",
      "\t\t\"parent\": \"92789cfc4a885843c15f38ba5b0da99b1c0f555c\",\n",
      "\t\t\"subject\": \"Fix web-console message in MSQ data loader (#12996)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-web-console-message-in-MSQ-data-loader-12996\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix typo in web-console message  * Prettify the changes\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 13:34:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"92789cfc4a885843c15f38ba5b0da99b1c0f555c\",\n",
      "\t\t\"parent\": \"f00f1f754d431bafe34b20d614c9346c6f6f5e53\",\n",
      "\t\t\"subject\": \"default to no compare (#13041)\",\n",
      "\t\t\"sanitized_subject_line\": \"default-to-no-compare-13041\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 08:28:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f00f1f754d431bafe34b20d614c9346c6f6f5e53\",\n",
      "\t\t\"parent\": \"2f156b3610d47983819f928e774ccbe3f067e1e4\",\n",
      "\t\t\"subject\": \"MSQ extension: Fix over-capacity write in ScanQueryFrameProcessor. (#13036)\",\n",
      "\t\t\"sanitized_subject_line\": \"MSQ-extension-Fix-over-capacity-write-in-ScanQueryFrameProcessor.-13036\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ extension: Fix over-capacity write in ScanQueryFrameProcessor.  Frame processors are meant to write only one output frame per cycle. The ScanQueryFrameProcessor would write two when reading from a channel if the input frame cursor cycled and then the output frame filled up while reading from the next frame.  This patch fixes the bug, and adds a test. It also makes some adjustments to the processor code in order to make it easier to test.  * Add license header.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 19:32:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f156b3610d47983819f928e774ccbe3f067e1e4\",\n",
      "\t\t\"parent\": \"7aa8d7f9875cbe950696b5c94e375ac616dd2d04\",\n",
      "\t\t\"subject\": \"Disallow timeseries queries with ETERNITY interval and non-ALL granularity (#12944)\",\n",
      "\t\t\"sanitized_subject_line\": \"Disallow-timeseries-queries-with-ETERNITY-interval-and-non-ALL-granularity-12944\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 16:45:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7aa8d7f9875cbe950696b5c94e375ac616dd2d04\",\n",
      "\t\t\"parent\": \"ee22663dd3b033fad4b349925e7f45e220077183\",\n",
      "\t\t\"subject\": \"Add query/time metric for SQL queries from router (#12867)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-query-time-metric-for-SQL-queries-from-router-12867\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add query/time metric for SQL queries from router  * Fix query cancel bug when user has overriden native query-id in a SQL query\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 13:54:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee22663dd3b033fad4b349925e7f45e220077183\",\n",
      "\t\t\"parent\": \"a3a377e570142e26c603390df73c4180741a0837\",\n",
      "\t\t\"subject\": \"Add interpolation to JsonConfigurator (#13023)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-interpolation-to-JsonConfigurator-13023\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add interpolation to JsonConfigurator  * Fix checkstyle  * Fix tests by removing common-text override  * Add back commons-text without version  * Remove unused hadoopDir configs  * Move some stuff to hopefully pass coverage\",\n",
      "\t\t\"author_name\": \"Adam Peck\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 7 Sep 2022 12:48:01 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3a377e570142e26c603390df73c4180741a0837\",\n",
      "\t\t\"parent\": \"ed26e2d6348772e91977ae67b747105ac0e5e5f3\",\n",
      "\t\t\"subject\": \"more consistent expression error messages (#12995)\",\n",
      "\t\t\"sanitized_subject_line\": \"more-consistent-expression-error-messages-12995\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* more consistent expression error messages  * review stuff  * add NamedFunction for Function, ApplyFunction, and ExprMacro to share common stuff  * fixes  * add expression transform name to transformer failure, better parse_json error messaging\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 23:21:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ed26e2d6348772e91977ae67b747105ac0e5e5f3\",\n",
      "\t\t\"parent\": \"1f691406237853409207d51ddde3c7546ca6fe47\",\n",
      "\t\t\"subject\": \"Improve String Last/First Storage Efficiency (#12879)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-String-Last-First-Storage-Efficiency-12879\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"-Add classes for writing cell values in LZ4 block compressed format. Payloads are indexed by element number for efficient random lookup -update SerializablePairLongStringComplexMetricSerde to use block compression -SerializablePairLongStringComplexMetricSerde also uses delta encoding of the Long by doing 2-pass encoding: buffers first to find min/max numbers and delta-encodes as integers if possible  Entry points for doing block-compressed storage of byte[] payloads are the CellWriter and CellReader class. See SerializablePairLongStringComplexMetricSerde for how these are used along with how to do full column-based storage (delta encoding here) which includes 2-pass encoding to compute a column header\",\n",
      "\t\t\"author_name\": \"sr\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 20:00:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f691406237853409207d51ddde3c7546ca6fe47\",\n",
      "\t\t\"parent\": \"897689c03b328567eb420bf998116fef03fa009c\",\n",
      "\t\t\"subject\": \"Nested columns documentation (#12946)\",\n",
      "\t\t\"sanitized_subject_line\": \"Nested-columns-documentation-12946\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Clint Wylie <cjwylie@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: brian.le <brian.le@imply.io>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 14:42:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"897689c03b328567eb420bf998116fef03fa009c\",\n",
      "\t\t\"parent\": \"2a039e7e6a4ebe5d02987a3fc74f29311b07ce08\",\n",
      "\t\t\"subject\": \"remove mentions of DruidQueryRel from docs (#13033)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-mentions-of-DruidQueryRel-from-docs-13033\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove mentions of DruidQueryRel  * Update docs/querying/sql-translation.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql-translation.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 13:37:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2a039e7e6a4ebe5d02987a3fc74f29311b07ce08\",\n",
      "\t\t\"parent\": \"2cf449386f876100bbd9e74badbd27c407fad601\",\n",
      "\t\t\"subject\": \"Add CTA and fix typo (#13009)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-CTA-and-fix-typo-13009\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add CTA and fix typo  * resolve hostname better\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 11:16:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2cf449386f876100bbd9e74badbd27c407fad601\",\n",
      "\t\t\"parent\": \"d4233ef2a1739f15a6a224d466ddc459844dc67f\",\n",
      "\t\t\"subject\": \"Web console: upgrade the console to use node 16 (#13017)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-upgrade-the-console-to-use-node-16-13017\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* upgrade the console to use node 16  * run npm audit fix\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 11:15:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4233ef2a1739f15a6a224d466ddc459844dc67f\",\n",
      "\t\t\"parent\": \"66545a0f3d1acd752da5f3ebb581b06c71ea186d\",\n",
      "\t\t\"subject\": \"msq: add multi-stage-query docs (#12983)\",\n",
      "\t\t\"sanitized_subject_line\": \"msq-add-multi-stage-query-docs-12983\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* msq: add multi-stage-query docs  * add screenshots  add back theta sketches tutoria  change filename  fix filename  fix link  fix headings  * fixes  * fixes  * fix spelling issues and update spell file  * address feedback from karan  * add missing guardrail to known issues  * update blurb  * fix typo  * remove durable storage info  * update titles  * Restore en.json  * Update query view  * address comments from vad  * Update docs/multi-stage-query/msq-known-issues.md  finish sentence  * add apache license to docs  * add apache license to docs  Co-authored-by: Katya Macedo <katya.macedo@imply.io> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 23:06:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"66545a0f3d1acd752da5f3ebb581b06c71ea186d\",\n",
      "\t\t\"parent\": \"3d9aef225d302c663df8fd1d832b80108ea54047\",\n",
      "\t\t\"subject\": \"Fix compiler error: The project was not built since its build path is incomplete. Cannot find the class file for org.slf4j.Logger. Fix the build path then try building this project (#13029)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-compiler-error-The-project-was-not-built-since-its-build-path-is-incomplete.-Cannot-find-the-class-file-for-org.slf4j.Logger.-Fix-the-build-path-then-try-building-this-project-13029\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Didip Kerabat <didip@apple.com>\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 20:49:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3d9aef225d302c663df8fd1d832b80108ea54047\",\n",
      "\t\t\"parent\": \"7d332c6f6a6359e6656b71d5efccdb86c9222a74\",\n",
      "\t\t\"subject\": \"compressed big decimal - module  (#10705)\",\n",
      "\t\t\"sanitized_subject_line\": \"compressed-big-decimal-module-10705\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Compressed Big Decimal is an extension which provides support for  Mutable big decimal value that can be used to accumulate values  without losing precision or reallocating memory. This type helps in  absolute precision arithmetic on large numbers in applications,  where greater level of accuracy is required, such as financial  applications, currency based transactions. This helps avoid rounding  issues where in potentially large amount of money can be lost.  Accumulation requires that the two numbers have the same scale,  but does not require that they are of the same size. If the value  being accumulated has a larger underlying array than this value  (the result), then the higher order bits are dropped, similar to what  happens when adding a long to an int and storing the result in an  int. A compressed big decimal that holds its data with an embedded  array.  Compressed big decimal is an absolute number based complex type  based on big decimal in Java. This supports all the functionalities  supported by Java Big Decimal. Java Big Decimal is not mutable in  order to avoid big garbage collection issues. Compressed big decimal  is needed to mutate the value in the accumulator.\",\n",
      "\t\t\"author_name\": \"senthilkv\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 00:06:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7d332c6f6a6359e6656b71d5efccdb86c9222a74\",\n",
      "\t\t\"parent\": \"6805a7f9c243445b95090e9aa777512f6411b506\",\n",
      "\t\t\"subject\": \"Suppress false CVEs (#13026)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-false-CVEs-13026\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Suppress CVEs  * Add more suppressions\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 6 Sep 2022 11:46:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6805a7f9c243445b95090e9aa777512f6411b506\",\n",
      "\t\t\"parent\": \"0ae515bd3c3a7215801c629fe475bb6ff47fd4aa\",\n",
      "\t\t\"subject\": \"Ease of hidding sensitive properties from /status/proper\\u2026 (#12950)\",\n",
      "\t\t\"sanitized_subject_line\": \"Ease-of-hidding-sensitive-properties-from-status-proper-12950\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* apache#12063 Ease of hidding sensitive properties from /status/properties endpoint  * apache#12063 Ease of hidding sensitive properties from /status/properties endpoint  * apache#12063 Ease of hidding sensitive properties from /status/properties endpoint  using one property for hiding properties, updated the index.md to document hiddenProperties  * apache#12063 Ease of hidding sensitive properties from /status/properties endpoint  Added java docs  * apache#12063 Ease of hidding sensitive properties from /status/properties endpoint  Add \\\"password\\\", \\\"key\\\", \\\"token\\\", \\\"pwd\\\" as default druid.server.hiddenProperties  fixed typo and removed redundant space  Co-authored-by: zemin <zemin.piao@adyen.com>\",\n",
      "\t\t\"author_name\": \"zemin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 2 Sep 2022 08:51:25 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0ae515bd3c3a7215801c629fe475bb6ff47fd4aa\",\n",
      "\t\t\"parent\": \"85d2a6d879358a7154e49aa41423a49224303988\",\n",
      "\t\t\"subject\": \"Web console: don't crash if cookies are totally disabled (#13013)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-don-t-crash-if-cookies-are-totally-disabled-13013\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix local storage detection  * fix numeric input dialog\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Sep 2022 16:10:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"85d2a6d879358a7154e49aa41423a49224303988\",\n",
      "\t\t\"parent\": \"d73a011f700ce2a1bc77658eb6aefece7eceeb76\",\n",
      "\t\t\"subject\": \"Improve range partitioning docs. (#13016)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-range-partitioning-docs.-13016\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Two improvements:  - Use a realistic targetRowsPerSegment, so if people copy and paste   the example from the docs, it will generate reasonable segments. - Spell \\\"countryName\\\" correctly.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 1 Sep 2022 15:21:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d73a011f700ce2a1bc77658eb6aefece7eceeb76\",\n",
      "\t\t\"parent\": \"5e850c6ea3e5504b47274fb311af3deccef2fc4c\",\n",
      "\t\t\"subject\": \"Bump the version of Maven in the Dockerfile (#11994)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-the-version-of-Maven-in-the-Dockerfile-11994\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 31 Aug 2022 22:54:24 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5e850c6ea3e5504b47274fb311af3deccef2fc4c\",\n",
      "\t\t\"parent\": \"054688528f5ade4b91f8b85447f947bf886581dc\",\n",
      "\t\t\"subject\": \"Make console e2e tests run in band so as to not hog task slots (#13004)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-console-e2e-tests-run-in-band-so-as-to-not-hog-task-slots-13004\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* increase e2e timeline  * get rid of pull deps  * increase post index task timeoout  * boost msq e2e timeout  * run in band\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Aug 2022 21:55:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"054688528f5ade4b91f8b85447f947bf886581dc\",\n",
      "\t\t\"parent\": \"48ceab2153d1cf667280b599f81bbf55d10fa95d\",\n",
      "\t\t\"subject\": \"don't show transform actions on * queries (#13005)\",\n",
      "\t\t\"sanitized_subject_line\": \"don-t-show-transform-actions-on-queries-13005\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Aug 2022 21:54:18 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48ceab2153d1cf667280b599f81bbf55d10fa95d\",\n",
      "\t\t\"parent\": \"2450b96ac80f6881a2b57cd3e0f116da860cb022\",\n",
      "\t\t\"subject\": \"Add Java 17 information to documentation. (#12990)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Java-17-information-to-documentation.-12990\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The docs say Java 17 support is experimental, and give tips on running successfully with Java 17.  This patch also removes java.base/jdk.internal.perf and jdk.management/com.sun.management.internal from the list of required exports and opens, because they were formerly needed for JvmMonitor, which was rewritten in #12481 to use MXBeans instead.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Aug 2022 12:32:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2450b96ac80f6881a2b57cd3e0f116da860cb022\",\n",
      "\t\t\"parent\": \"f3c47cf68c009ab59853c418eef98a3b75984238\",\n",
      "\t\t\"subject\": \"FrameFile: Java 17 compatibility. (#12987)\",\n",
      "\t\t\"sanitized_subject_line\": \"FrameFile-Java-17-compatibility.-12987\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* FrameFile: Java 17 compatibility.  DataSketches Memory.map is not Java 17 compatible, and from discussions with the team, is challenging to make compatible with 17 while also retaining compatibility with 8 and 11. So, in this patch, we switch away from Memory.map and instead use the builtin JDK mmap functionality. Since it only supports maps up to Integer.MAX_VALUE, we also implement windowing in FrameFile, such that we can still handle large files.  Other changes:  1) Add two new \\\"map\\\" functions to FileUtils, which we use in this patch. 2) Add a footer checksum to the FrameFile format. Individual frames    already have checksums, but the footer was missing one.  * Changes for static analysis.  * wip  * Fixes.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Aug 2022 11:13:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f3c47cf68c009ab59853c418eef98a3b75984238\",\n",
      "\t\t\"parent\": \"414176fb97b0bb852feffa11bb1914d4c82e6d64\",\n",
      "\t\t\"subject\": \"Building druid-it-tools and running for travis in it.sh (#12957)\",\n",
      "\t\t\"sanitized_subject_line\": \"Building-druid-it-tools-and-running-for-travis-in-it.sh-12957\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Building druid-it-tools and running for travis in it.sh  * Addressing comments  * Updating druid-it-image pom to point to correct it-tools  * Updating all it-tools references to druid-it-tools  * Adding dist back to it.sh travis  * Trigger Build  * Disabling batchIndex tests and commenting out user specific code  * Fixing checkstyle and intellij inspection errors  * Replacing tabs with spaces in it.sh  * Enabling old batch index tests with indexer\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Aug 2022 12:48:07 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"414176fb97b0bb852feffa11bb1914d4c82e6d64\",\n",
      "\t\t\"parent\": \"9eb20e5e7cffb4064b405085979f679ccb246048\",\n",
      "\t\t\"subject\": \"Fix accounting of bytesAdded in ReadableByteChunksFrameChannel. (#12988)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-accounting-of-bytesAdded-in-ReadableByteChunksFrameChannel.-12988\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix accounting of bytesAdded in ReadableByteChunksFrameChannel.  Could cause WorkerInputChannelFactory to get into an infinite loop when reading the footer of a frame file.  * Additional tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 18:25:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9eb20e5e7cffb4064b405085979f679ccb246048\",\n",
      "\t\t\"parent\": \"0460d8a502fa5a1c5e06ef542fc9edf3aeb65e77\",\n",
      "\t\t\"subject\": \"Remove dependency on jvm-attach. (#12989)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-dependency-on-jvm-attach.-12989\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This dependency was no longer needed after #12481, but remained because it was used for a (now useless) test. This patch removes the test and the dependency.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 14:18:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0460d8a502fa5a1c5e06ef542fc9edf3aeb65e77\",\n",
      "\t\t\"parent\": \"9fd8ab3c750c57dae3a6cf2608b9ee3e83e2614f\",\n",
      "\t\t\"subject\": \"Adjust SQL \\\"cannot plan\\\" error message. (#12903)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adjust-SQL-cannot-plan-error-message.-12903\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Two changes:  1) Restore the text of the SQL query. It was removed in #12897, but    then it was later pointed out that the text is helpful for end    users querying Druid through tools that do not show the SQL queries    that they are making.  2) Adjust wording slightly, from \\\"Cannot build plan for query\\\" to    \\\"Query not supported\\\". This will be clearer to most users. Generally    the reason we get these errors is due to unsupported SQL constructs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 18:33:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9fd8ab3c750c57dae3a6cf2608b9ee3e83e2614f\",\n",
      "\t\t\"parent\": \"618757352bae85058ad59da6c4350f4092dd2365\",\n",
      "\t\t\"subject\": \"[Issue 10331] Fresh Docker install results in \\\"Uh... I have no servers. Not assigning anything... (#12963)\",\n",
      "\t\t\"sanitized_subject_line\": \"Issue-10331-Fresh-Docker-install-results-in-Uh.-I-have-no-servers.-Not-assigning-anything.-12963\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add env var DRUID_SINGLE_NODE_CONF  * no message  * typo fix  Co-authored-by: Wil Quan <wiquan@appdynamics.com>\",\n",
      "\t\t\"author_name\": \"wiquan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 17:43:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"618757352bae85058ad59da6c4350f4092dd2365\",\n",
      "\t\t\"parent\": \"9843355ddd8bf71c070b71d9832b12e66486ed1f\",\n",
      "\t\t\"subject\": \"Bump up the version to 25.0.0 (#12975)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-up-the-version-to-25.0.0-12975\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump up the version to 25.0.0  * Fix the version in console\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 11:27:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9843355ddd8bf71c070b71d9832b12e66486ed1f\",\n",
      "\t\t\"parent\": \"16f5ac5bd5ea4d8ce1eef546793c90298f1a43e0\",\n",
      "\t\t\"subject\": \"Throw parse exception for multi-valued numeric dims (#12953)\",\n",
      "\t\t\"sanitized_subject_line\": \"Throw-parse-exception-for-multi-valued-numeric-dims-12953\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"During ingestion, if a row containing multiple values for a numeric dimension is encountered, the whole ingestion task fails. Ideally, this should just be registered as a parse exception.  Changes: - Remove `instanceof List` check from `LongDimensionIndexer`, `FloatDimensionIndexer` and `DoubleDimensionIndexer`.  Any invalid type, including list, throws a parse exception in `DimensionHandlerUtils.convertObjectToXXX` methods. `ParseException` is already handled in `OnHeapIncrementalIndex` and does not fail the entire task.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Aug 2022 10:33:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"16f5ac5bd5ea4d8ce1eef546793c90298f1a43e0\",\n",
      "\t\t\"parent\": \"7e2371bbdebd3c9a111d40543dbee12ee2e7c045\",\n",
      "\t\t\"subject\": \"json_value adjustments (#12968)\",\n",
      "\t\t\"sanitized_subject_line\": \"json_value-adjustments-12968\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* json_value adjustments changes: * native json_value expression now has optional 3rd argument to specify type, which will cast all values to the specified type * rework how JSON_VALUE is wired up in SQL. Now we are using a custom convertlet to translate JSON_VALUE(... RETURNING type) into dedicated JSON_VALUE_BIGINT, JSON_VALUE_DOUBLE, JSON_VALUE_VARCHAR, JSON_VALUE_ANY instead of using the calcite StandardConvertletTable that wraps JSON_VALUE_ANY in a CAST, so that we preserve the typing of JSON_VALUE to pass down to the native expression as the 3rd argument  * fix json_value_any to be usable by humans too, coverage  * fix bug  * checkstyle  * checkstyle  * review stuff  * validate that options to json_value are the supported options rather than ignore them  * remove more legacy undocumented functions\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 27 Aug 2022 07:15:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7e2371bbdebd3c9a111d40543dbee12ee2e7c045\",\n",
      "\t\t\"parent\": \"21b73bde20b58d9b9d6f9e905a8ef9ad04e9cca3\",\n",
      "\t\t\"subject\": \"KLL sketch (#12498)\",\n",
      "\t\t\"sanitized_subject_line\": \"KLL-sketch-12498\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* KLL sketch  * added documentation  * direct static refs  * direct static refs  * fixed test  * addressed review points  * added KLL sketch related terms  * return a copy from get  * Copy unions when returning them from \\\"get\\\".  * Remove redundant \\\"final\\\".  Co-authored-by: AlexanderSaydakov <AlexanderSaydakov@users.noreply.github.com> Co-authored-by: Gian Merlino <gianmerlino@gmail.com>\",\n",
      "\t\t\"author_name\": \"Alexander Saydakov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 26 Aug 2022 21:19:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"21b73bde20b58d9b9d6f9e905a8ef9ad04e9cca3\",\n",
      "\t\t\"parent\": \"4bdf9815c152aa8f0cfb8b5e7759e377444f2559\",\n",
      "\t\t\"subject\": \"Update Curator to 5.3.0 (#12939)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Curator-to-5.3.0-12939\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update Curator to 5.3.0  * Update licenses.yaml  * Fix inspections + add tests.  * Fix checkstyle  * Another intellij inspection fix  * Update curator exclusions  * Cleanup new exhibitor references  * Remove unused dep and checkstyle fix\",\n",
      "\t\t\"author_name\": \"Adam Peck\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 26 Aug 2022 18:23:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4bdf9815c152aa8f0cfb8b5e7759e377444f2559\",\n",
      "\t\t\"parent\": \"acb09ff18bc36bcc474da22f313d665d31ae1907\",\n",
      "\t\t\"subject\": \"fix issue with SQL planner and null array constants (#12971)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-SQL-planner-and-null-array-constants-12971\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 26 Aug 2022 04:44:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"acb09ff18bc36bcc474da22f313d665d31ae1907\",\n",
      "\t\t\"parent\": \"e476e754627183734cbbef7316c248cd6b72a87f\",\n",
      "\t\t\"subject\": \"grab warnings from correct key + test (#12977)\",\n",
      "\t\t\"sanitized_subject_line\": \"grab-warnings-from-correct-key-test-12977\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 18:47:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e476e754627183734cbbef7316c248cd6b72a87f\",\n",
      "\t\t\"parent\": \"275f834b2a9f23cec59dfeeb9ab44ac9081620fe\",\n",
      "\t\t\"subject\": \"fix #12945 - type conversion exception occurs during the variance query (#12967)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-12945-type-conversion-exception-occurs-during-the-variance-query-12967\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: gejun <gejun@tingyun.com>\",\n",
      "\t\t\"author_name\": \"Junge\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 18:10:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"275f834b2a9f23cec59dfeeb9ab44ac9081620fe\",\n",
      "\t\t\"parent\": \"72aba00e0991f301e12db77055cd43ffd2f85fe1\",\n",
      "\t\t\"subject\": \"Race in Task report/log streamer (#12931)\",\n",
      "\t\t\"sanitized_subject_line\": \"Race-in-Task-report-log-streamer-12931\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing RACE in HTTP remote task Runner  * Changes in the interface  * Updating documentation  * Adding test cases to SwitchingTaskLogStreamer  * Adding more tests\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 17:56:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"72aba00e0991f301e12db77055cd43ffd2f85fe1\",\n",
      "\t\t\"parent\": \"4c61378ad1da25960b8283e58f890c9b1a47ddfa\",\n",
      "\t\t\"subject\": \"add json function support for paths with negative array indexes (#12972)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-json-function-support-for-paths-with-negative-array-indexes-12972\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 17:11:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4c61378ad1da25960b8283e58f890c9b1a47ddfa\",\n",
      "\t\t\"parent\": \"ad62c0eb31644158343e590a92a4f4dbbaa1df2b\",\n",
      "\t\t\"subject\": \"fix broken link in web-console (#12976)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-broken-link-in-web-console-12976\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In 0.23.0, the info-button links to https://druid.apache.org/docs/0.23.0/ingestion/flatten-json.html which is a 404  If I got the spot right, this should now link to https://druid.apache.org/docs/[VERSION]/ingestion/data-formats.html#flattenspec\",\n",
      "\t\t\"author_name\": \"Lee Surprenant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 16:47:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ad62c0eb31644158343e590a92a4f4dbbaa1df2b\",\n",
      "\t\t\"parent\": \"7a1e1f88bb16876d231da8d57b6bb121738c8e16\",\n",
      "\t\t\"subject\": \"ignore licenses changes in check test script (#12964)\",\n",
      "\t\t\"sanitized_subject_line\": \"ignore-licenses-changes-in-check-test-script-12964\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 12:31:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7a1e1f88bb16876d231da8d57b6bb121738c8e16\",\n",
      "\t\t\"parent\": \"fd6cfcb8fb566bdff3bc9310fbec11bf628cf7c0\",\n",
      "\t\t\"subject\": \"Remove experimental note from stable features (#12973)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-experimental-note-from-stable-features-12973\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Removed experimental note for features that are no longer experimental  * Updated native batch doc\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 09:26:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fd6cfcb8fb566bdff3bc9310fbec11bf628cf7c0\",\n",
      "\t\t\"parent\": \"31dc9004bd31b4a7e32744dc11b1dba768f0d5be\",\n",
      "\t\t\"subject\": \"Web console: fix pagination, add error delimiters (#12969)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-fix-pagination-add-error-delimiters-12969\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix pagination, add error delimiters  * reword debug message\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 08:18:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31dc9004bd31b4a7e32744dc11b1dba768f0d5be\",\n",
      "\t\t\"parent\": \"9cc30ee1205e3b195d767e377d48c77888ffd7d7\",\n",
      "\t\t\"subject\": \"Auto-reload TLS certs for druid endpoints (#12933)\",\n",
      "\t\t\"sanitized_subject_line\": \"Auto-reload-TLS-certs-for-druid-endpoints-12933\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* #12064 Auto-reload tls certs for druid endpoints  * #12064 Add missing toString param  * #12064 Add tests and new jks Co-authored-by: zemin-piao <pzm6391@gmail.com>  * #12064 Refine tests  * #12064 Add documentation  * Apply suggestions from code review  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: santosh <santosh.pingale@adyen.com> Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Santosh Pingale\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 20:12:43 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9cc30ee1205e3b195d767e377d48c77888ffd7d7\",\n",
      "\t\t\"parent\": \"8ee8786d3ce32f39d8517b5a0dddd6211101b2a4\",\n",
      "\t\t\"subject\": \"Suppressing CVE-2022-25168 - hadoop-common-2.8.5.jar (#12970)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppressing-CVE-2022-25168-hadoop-common-2.8.5.jar-12970\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"abhagraw\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 16:02:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ee8786d3ce32f39d8517b5a0dddd6211101b2a4\",\n",
      "\t\t\"parent\": \"82ad92708778de02eb3857cc6aca337663bed871\",\n",
      "\t\t\"subject\": \"add maxBytesInMemory and maxClientResponseBytes to SamplerConfig (#12947)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-maxBytesInMemory-and-maxClientResponseBytes-to-SamplerConfig-12947\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add maxBytesInMemory and maxClientResponseBytes to SamplerConfig\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 00:50:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"82ad92708778de02eb3857cc6aca337663bed871\",\n",
      "\t\t\"parent\": \"599bdde02a0a1ee40c8bca5a09ff4911885158b8\",\n",
      "\t\t\"subject\": \"tighten up array handling, fix bug with array_slice output type inference (#12914)\",\n",
      "\t\t\"sanitized_subject_line\": \"tighten-up-array-handling-fix-bug-with-array_slice-output-type-inference-12914\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 00:48:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"599bdde02a0a1ee40c8bca5a09ff4911885158b8\",\n",
      "\t\t\"parent\": \"31db3beed8fd94e9478406b1424c7d88e7a84cb5\",\n",
      "\t\t\"subject\": \"Update asf-release-process-guide.md (#12966)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-asf-release-process-guide.md-12966\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update asf-release-process-guide.md  * Update asf-release-process-guide.md\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 13:15:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31db3beed8fd94e9478406b1424c7d88e7a84cb5\",\n",
      "\t\t\"parent\": \"04ee7abeff7db86aca350a5daae8bf8cfa0da81f\",\n",
      "\t\t\"subject\": \"Fixing json creator for s3 storage connector provider (#12948)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-json-creator-for-s3-storage-connector-provider-12948\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing json creator for s3 storage connector provider  * Adding guice tests\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Aug 2022 11:08:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"04ee7abeff7db86aca350a5daae8bf8cfa0da81f\",\n",
      "\t\t\"parent\": \"02914c17b9cfd4a81a9db5f650d1a1d378b14414\",\n",
      "\t\t\"subject\": \"Web console: Multi-stage query support (#12919)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Multi-stage-query-support-12919\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* MSQ web console  * fix typo in comments  * remove useless conditional  * wrap SQL_DATA_TYPES  * fixes sus regex  * rewrite regex  * remove problematic regex  * fix UTs  * convert PARTITIONED / CLUSTERED BY to ORDER BY for preview  * fix log  * updated to use shuffle  * Web console: Use Ace.Completion directly (#1405)  * Use Ace.Completion directly  * Another Ace.Completion  * better comment  * fix column ordering in e2e test  * add nested data example also  Co-authored-by: John Gozde <john.gozde@imply.io>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 16:17:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"02914c17b9cfd4a81a9db5f650d1a1d378b14414\",\n",
      "\t\t\"parent\": \"35aaaa9573161e3916a8fef3167d842f733573e4\",\n",
      "\t\t\"subject\": \"Tutorial on ingesting and querying Theta sketches (#12723)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tutorial-on-ingesting-and-querying-Theta-sketches-12723\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 09:23:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"35aaaa9573161e3916a8fef3167d842f733573e4\",\n",
      "\t\t\"parent\": \"c1a75fca3cb2bd76d4db5510daa02e4df318fd6c\",\n",
      "\t\t\"subject\": \"Fix serialization in TaskReportFileWriters. (#12938)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-serialization-in-TaskReportFileWriters.-12938\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix serialization in TaskReportFileWriters.  For some reason, serializing a Map<String, TaskReport> would omit the \\\"type\\\" field. Explicitly sending each value through the ObjectMapper fixes this, because the type information does not get lost.  * Fixes for static analysis.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 08:11:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1a75fca3cb2bd76d4db5510daa02e4df318fd6c\",\n",
      "\t\t\"parent\": \"f7c63169924611969139783a711275f33f694676\",\n",
      "\t\t\"subject\": \"Docs: fix doc footer (#12943)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-fix-doc-footer-12943\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix doc footer  * move the logic to the fix-path script\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 06:47:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7c63169924611969139783a711275f33f694676\",\n",
      "\t\t\"parent\": \"cfed036091038dc05cdb246e2849fdbed39aec0d\",\n",
      "\t\t\"subject\": \"Setting useNativeQueryExplain to true (#12936)\",\n",
      "\t\t\"sanitized_subject_line\": \"Setting-useNativeQueryExplain-to-true-12936\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Setting useNativeQueryExplain to true  * Update docs/querying/sql-query-context.md  Co-authored-by: Santosh Pingale <pingalesantosh@gmail.com>  * Fixing tests  * Fixing broken tests  Co-authored-by: Santosh Pingale <pingalesantosh@gmail.com>\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 17:39:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cfed036091038dc05cdb246e2849fdbed39aec0d\",\n",
      "\t\t\"parent\": \"0bc9f9f30395309995a851fb4ed60a0521381b82\",\n",
      "\t\t\"subject\": \"Add the new integration test framework (#12368)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-the-new-integration-test-framework-12368\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit is a first draft of the revised integration test framework which provides: - A new directory, integration-tests-ex that holds the new integration test structure. (For now, the existing integration-tests is left unchanged.) - Maven module druid-it-tools to hold code placed into the Docker image. - Maven module druid-it-image to build the Druid-only test image from the tarball produced in distribution. (Dependencies live in their \\\"official\\\" image.) - Maven module druid-it-cases that holds the revised tests and the framework itself. The framework includes file-based test configuration, test-specific clients, test initialization and updated versions of some of the common test support classes.  The integration test setup is primarily a huge mass of details. This approach refactors many of those details: from how the image is built and configured to how the Docker Compose scripts are structured to test configuration. An extensive set of \\\"readme\\\" files explains those details. Rather than repeat that material here, please consult those files for explanations.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 17:03:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0bc9f9f30395309995a851fb4ed60a0521381b82\",\n",
      "\t\t\"parent\": \"3b58a01c7c92a1dee299d9b08031932ff869be79\",\n",
      "\t\t\"subject\": \"#12912 Fix KafkaEmitter not emitting queryType for a native query (#12915)\",\n",
      "\t\t\"sanitized_subject_line\": \"12912-Fix-KafkaEmitter-not-emitting-queryType-for-a-native-query-12915\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes KafkaEmitter not emitting queryType for a native query. The Event to JSON serialization was extracted to the external class: EventToJsonSerializer. This was done to simplify the testing logic for the serialization as well as extract the responsibility of serialization to the separate class.  The logic builds ObjectNode incrementally based on the event .toMap method. Parsing each entry individually ensures that the Jackson polymorphic annotations are respected. Not respecting these annotation caused the missing of the queryType from output event.\",\n",
      "\t\t\"author_name\": \"Bartosz Mikulski\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 14:07:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3b58a01c7c92a1dee299d9b08031932ff869be79\",\n",
      "\t\t\"parent\": \"31eda58e9aee33b393fa4e45d458b27b7d190c02\",\n",
      "\t\t\"subject\": \"Correct spelling in messages and variable names. (#12932)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correct-spelling-in-messages-and-variable-names.-12932\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 11:06:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31eda58e9aee33b393fa4e45d458b27b7d190c02\",\n",
      "\t\t\"parent\": \"d7d15ba51f15f15ac438a05172c6e83e4702f166\",\n",
      "\t\t\"subject\": \"Fix misspelling in license.md (#12941)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-misspelling-in-license.md-12941\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Adam Peck\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Aug 2022 10:53:47 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7d15ba51f15f15ac438a05172c6e83e4702f166\",\n",
      "\t\t\"parent\": \"f0fc45028e48bd4efe65e2ecee3c787f84e83e0a\",\n",
      "\t\t\"subject\": \"Add druid-multi-stage-query extension. (#12918)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-druid-multi-stage-query-extension.-12918\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add druid-multi-stage-query extension.  * Adjustments from CI.  * Task ID validation.  * Various changes from code review.  * Remove unnecessary code.  * LGTM-related.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Aug 2022 18:44:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f0fc45028e48bd4efe65e2ecee3c787f84e83e0a\",\n",
      "\t\t\"parent\": \"a1c4eab5222f0645723d12b34983a98b6a7f804b\",\n",
      "\t\t\"subject\": \"Update year in the notice file and the release process instructions (#12622)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-year-in-the-notice-file-and-the-release-process-instructions-12622\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update notice file  * Update release process instructions  * Better release instructions  * Update copyright year  * Web console: updated the doc link (#12619)  * updated the doc link  * update snapshots  Co-authored-by: Vadim Ogievetsky <vadim@ogievetsky.com>\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Aug 2022 18:17:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a1c4eab5222f0645723d12b34983a98b6a7f804b\",\n",
      "\t\t\"parent\": \"0c56b22a39339db1adb4aacf33baa2b60e66ed9e\",\n",
      "\t\t\"subject\": \"Update ORC to 1.7.6 (#12928)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ORC-to-1.7.6-12928\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"William Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Aug 2022 01:09:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0c56b22a39339db1adb4aacf33baa2b60e66ed9e\",\n",
      "\t\t\"parent\": \"289e43281eeec2742a2d5a60ad166a29ad4f6803\",\n",
      "\t\t\"subject\": \"Update .spelling (#12940)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-.spelling-12940\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 18:47:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"289e43281eeec2742a2d5a60ad166a29ad4f6803\",\n",
      "\t\t\"parent\": \"6fec1d4c95a93b14e334b5fe8713408f4ebc1f0e\",\n",
      "\t\t\"subject\": \"stricter behavior for parse_json, add try_parse_json, remove to_json (#12920)\",\n",
      "\t\t\"sanitized_subject_line\": \"stricter-behavior-for-parse_json-add-try_parse_json-remove-to_json-12920\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 18:41:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6fec1d4c95a93b14e334b5fe8713408f4ebc1f0e\",\n",
      "\t\t\"parent\": \"379df5f103ca6d2d0049a53b674078e69713aacf\",\n",
      "\t\t\"subject\": \"Add useNativeQueryExplain in sql query context documentation (#12924) (#12934)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-useNativeQueryExplain-in-sql-query-context-documentation-12924-12934\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Petar Petrov <petar.petrov@system73.com>\",\n",
      "\t\t\"author_name\": \"Petar Petrov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 16:31:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"379df5f103ca6d2d0049a53b674078e69713aacf\",\n",
      "\t\t\"parent\": \"a879d91a2059afb63a29c34577b2009f1c83121f\",\n",
      "\t\t\"subject\": \"Kinesis docs and logs improvements (#12886)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kinesis-docs-and-logs-improvements-12886\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Going ahead with the merge. CI is failing because of a code coverage change in the log line. \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 14:49:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a879d91a2059afb63a29c34577b2009f1c83121f\",\n",
      "\t\t\"parent\": \"3c129f672827ce6ca0e3404a51c000e25d158e80\",\n",
      "\t\t\"subject\": \"Remove misleading logging on router for JDBC queries (#12925)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-misleading-logging-on-router-for-JDBC-queries-12925\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 11:58:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c129f672827ce6ca0e3404a51c000e25d158e80\",\n",
      "\t\t\"parent\": \"f8097ccfaadbe2d2fc1d1dbef75019e55df94aa1\",\n",
      "\t\t\"subject\": \"Add sql planning time metric (#12923)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-sql-planning-time-metric-12923\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Aug 2022 11:09:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f8097ccfaadbe2d2fc1d1dbef75019e55df94aa1\",\n",
      "\t\t\"parent\": \"69fe1f04e5657139b2d0e22d085df089b27fa788\",\n",
      "\t\t\"subject\": \"basic docs for nested column query functions (#12922)\",\n",
      "\t\t\"sanitized_subject_line\": \"basic-docs-for-nested-column-query-functions-12922\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* basic docs for nested column query functions\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 Aug 2022 17:12:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"69fe1f04e5657139b2d0e22d085df089b27fa788\",\n",
      "\t\t\"parent\": \"eb902375a233266229c6955cbe16833992579605\",\n",
      "\t\t\"subject\": \"document virtualColumns in native query documentation, fix some redirects (#12917)\",\n",
      "\t\t\"sanitized_subject_line\": \"document-virtualColumns-in-native-query-documentation-fix-some-redirects-12917\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* document virtualColumns in native query documentation, fix some redirects  * after all that, forgot to run spellcheck locally  * review stuff\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Aug 2022 20:49:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb902375a233266229c6955cbe16833992579605\",\n",
      "\t\t\"parent\": \"7fb1153bba73bbb1ae245a8acc7bf605463ed725\",\n",
      "\t\t\"subject\": \"Light refactor of the heavily refactored statement classes (#12909)\",\n",
      "\t\t\"sanitized_subject_line\": \"Light-refactor-of-the-heavily-refactored-statement-classes-12909\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Reflects lessons learned from working with consumers of the new code.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 Aug 2022 02:31:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7fb1153bba73bbb1ae245a8acc7bf605463ed725\",\n",
      "\t\t\"parent\": \"770358dc349be088bccc558d01f81d27e2588602\",\n",
      "\t\t\"subject\": \"add virtual columns to search query cache key (#12907)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-virtual-columns-to-search-query-cache-key-12907\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add virtual columns to search query cache key\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 Aug 2022 20:26:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"770358dc349be088bccc558d01f81d27e2588602\",\n",
      "\t\t\"parent\": \"536415b9487640cee2dee6e1b31a0bd5b062057b\",\n",
      "\t\t\"subject\": \"Update tls-support.md (#12916)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-tls-support.md-12916\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixing \\\" lists all possible values for the configs belong\\\" in TLS section\",\n",
      "\t\t\"author_name\": \"Ian Roberts\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Aug 2022 09:46:30 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"536415b9487640cee2dee6e1b31a0bd5b062057b\",\n",
      "\t\t\"parent\": \"752e42a312e98f83c3a89af3648065b4b909fe59\",\n",
      "\t\t\"subject\": \"Stop leaking Avro objects from parser (#12828)\",\n",
      "\t\t\"sanitized_subject_line\": \"Stop-leaking-Avro-objects-from-parser-12828\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The Avro parsing code leaks some \\\"object\\\" representations. We need to convert them into Maps/Lists so that other code can understand and expect good things.  Previously, these objects were handled with .toString(), but that's not a good contract in terms of how to work with objects.\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Aug 2022 03:16:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"752e42a312e98f83c3a89af3648065b4b909fe59\",\n",
      "\t\t\"parent\": \"a3a9c5f409f7a0985973e062ecd5756f653bb486\",\n",
      "\t\t\"subject\": \"fix running integration tests on macos aarch64 (#12913)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-running-integration-tests-on-macos-aarch64-12913\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add osx-aarch_64 netty-transport-native-kqueue native dependency * align docker-java dependency versions using bom and update to 3.2.13\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 Aug 2022 18:03:24 +0200\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3a9c5f409f7a0985973e062ecd5756f653bb486\",\n",
      "\t\t\"parent\": \"f70f7b4b89a4b2d49a4a994541a16ea31d19fbac\",\n",
      "\t\t\"subject\": \"Fixing overlord issued too many redirects (#12908)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-overlord-issued-too-many-redirects-12908\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixing race in overlord redirects where the node was redirecting to itself  * Fixing test cases\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 Aug 2022 18:27:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f70f7b4b89a4b2d49a4a994541a16ea31d19fbac\",\n",
      "\t\t\"parent\": \"d3015d0f8e3e22ae338c9396a12aec17979d9f29\",\n",
      "\t\t\"subject\": \"Bump postgresql from 42.3.3 to 42.4.1 (#12871)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-postgresql-from-42.3.3-to-42.4.1-12871\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump postgresql from 42.3.3 to 42.4.1  Bumps [postgresql](https://github.com/pgjdbc/pgjdbc) from 42.3.3 to 42.4.1. - [Release notes](https://github.com/pgjdbc/pgjdbc/releases) - [Changelog](https://github.com/pgjdbc/pgjdbc/blob/master/CHANGELOG.md) - [Commits](https://github.com/pgjdbc/pgjdbc/compare/REL42.3.3...REL42.4.1)  --- updated-dependencies: - dependency-name: org.postgresql:postgresql   dependency-type: direct:production ...  Signed-off-by: dependabot[bot] <support@github.com>  * update licenses.yaml  Signed-off-by: dependabot[bot] <support@github.com> Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com> Co-authored-by: Xavier L\\u00e9aut\\u00e9 <xvrl@apache.org>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 23:25:39 +0200\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d3015d0f8e3e22ae338c9396a12aec17979d9f29\",\n",
      "\t\t\"parent\": \"f665a0c0770afc2ece782c9da02bdf21dc98a174\",\n",
      "\t\t\"subject\": \"DruidQuery: Return a copy from withScanSignatureIfNeeded, as promised. (#12906)\",\n",
      "\t\t\"sanitized_subject_line\": \"DruidQuery-Return-a-copy-from-withScanSignatureIfNeeded-as-promised.-12906\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The method wasn't following its contract, leading to pollution of the overall planner context, when really we just want to create a new context for a specific query.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 13:23:14 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f665a0c0770afc2ece782c9da02bdf21dc98a174\",\n",
      "\t\t\"parent\": \"adbebc174ab56bf9605658e80045dda3fe4ec527\",\n",
      "\t\t\"subject\": \"Docs - Add links to Basic Tuning guide in process pages (#12741)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Add-links-to-Basic-Tuning-guide-in-process-pages-12741\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Added link to the relevant section of the Basic Cluster Tuning page on each process page.  This is in order to improve access to this information, which is not easy to find through search or nav.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 18:42:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"adbebc174ab56bf9605658e80045dda3fe4ec527\",\n",
      "\t\t\"parent\": \"3755f30bc48ce96a57e8be73c3602ccc6b86e710\",\n",
      "\t\t\"subject\": \"Fix flaky tests in SeekableStreamSupervisorStateTest (#12875)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-tests-in-SeekableStreamSupervisorStateTest-12875\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix flaky test in SeekableStreamSupervisorStateTest  * Fix for flaky security IT Test  * fix tests  * retry queries if there is some flakiness\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 18:38:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3755f30bc48ce96a57e8be73c3602ccc6b86e710\",\n",
      "\t\t\"parent\": \"ec8bdeb9f6f2aac28e78eb41df210da7e74370bb\",\n",
      "\t\t\"subject\": \"Add export parameters for Java 11 (#12859)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-export-parameters-for-Java-11-12859\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add exports for Java 11 parameters  * Add parameters for data sketches\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 13:05:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ec8bdeb9f6f2aac28e78eb41df210da7e74370bb\",\n",
      "\t\t\"parent\": \"e42e02529629de908c1a32a2ff7639a054a4a371\",\n",
      "\t\t\"subject\": \"Document missing property - druid.announcer.skipSegmentAnnouncementOnZk (#12891)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-missing-property-druid.announcer.skipSegmentAnnouncementOnZk-12891\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* document missing config related to segment announcement  * improve wording  * improve wording  * update docs\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Aug 2022 12:32:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e42e02529629de908c1a32a2ff7639a054a4a371\",\n",
      "\t\t\"parent\": \"28836dfa71d0bf9baac5512fb86bd40c5ea51c46\",\n",
      "\t\t\"subject\": \"inject @Json ObjectMapper for to_json_string and parse_json expressions (#12900)\",\n",
      "\t\t\"sanitized_subject_line\": \"inject-Json-ObjectMapper-for-to_json_string-and-parse_json-expressions-12900\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* inject @Json ObjectMapper for to_json_string and parse_json expressions  * fix npe  * better\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 Aug 2022 08:44:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"28836dfa71d0bf9baac5512fb86bd40c5ea51c46\",\n",
      "\t\t\"parent\": \"6c5a43106a1f7d0b0258b943c51b93c52563e9ed\",\n",
      "\t\t\"subject\": \"Fix race in TaskQueue.notifyStatus. (#12901)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-race-in-TaskQueue.notifyStatus.-12901\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix race in TaskQueue.notifyStatus.  It was possible for manageInternal to relaunch a task while it was being cleaned up, due to a race that happens when notifyStatus is called to clean up a successful task:  1) In a critical section, notifyStatus removes the task from \\\"tasks\\\". 2) Outside a critical section, notifyStatus calls taskRunner.shutdown    to let the task runner know it can clear out its data structures. 3) In a critical section, syncFromStorage adds the task back to \\\"tasks\\\",    because it is still present in metadata storage. 4) In a critical section, manageInternalCritical notices that the task    is in \\\"tasks\\\" and is not running in the taskRunner, so it launches    it again. 5) In a (different) critical section, notifyStatus updates the metadata    store to set the task status to SUCCESS. 6) The task continues running even though it should not be.  The possibility for this race was introduced in #12099, which shrunk the critical section in notifyStatus. Prior to that patch, a single critical section encompassed (1), (2), and (5), so the ordering above was not possible.  This patch does the following:  1) Fixes the race by adding a recentlyCompletedTasks set that prevents    the main management loop from doing anything with tasks that are    currently being cleaned up. 2) Switches the order of the critical sections in notifyStatus, so    metadata store updates happen first. This is useful in case of    server failures: it ensures that if the Overlord fails in the midst    of notifyStatus, then completed-task statuses are still available in    ZK or on MMs for the next Overlord. (Those are cleaned up by    taskRunner.shutdown, which formerly ran first.) This isn't related    to the race described above, but is fixed opportunistically as part    of the same patch. 3) Changes the \\\"tasks\\\" list to a map. Many operations require retrieval    or removal of individual tasks; those are now O(1) instead of O(N)    in the number of running tasks. 4) Changes various log messages to use task ID instead of full task    payload, to make the logs more readable.  * Fix format string.  * Update comment.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 Aug 2022 23:34:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c5a43106a1f7d0b0258b943c51b93c52563e9ed\",\n",
      "\t\t\"parent\": \"846345669d5fa625666eb3682260b7a80d9769c1\",\n",
      "\t\t\"subject\": \"SQL: Morph QueryMakerFactory into SqlEngine. (#12897)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Morph-QueryMakerFactory-into-SqlEngine.-12897\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Morph QueryMakerFactory into SqlEngine.  Groundwork for introducing an indexing-service-task-based SQL engine under the umbrella of #12262. Also includes some other changes related to improving error behavior.  Main changes:  1) Elevate the QueryMakerFactory interface (an extension point that allows    customization of how queries are made) into SqlEngine. SQL engines    can influence planner behavior through EngineFeatures, and can fully    control the mechanics of query execution using QueryMakers.  2) Remove the server-wide QueryMakerFactory choice, in favor of the choice    being made by the SQL entrypoint. The indexing-service-task-based    SQL engine would be associated with its own entrypoint, like    /druid/v2/sql/task.  Other changes:  1) Adjust DruidPlanner to try either DRUID or BINDABLE convention based    on analysis of the planned rels; never try both. In particular, we    no longer try BINDABLE when DRUID fails. This simplifies the logic    and improves error messages.  2) Adjust error message \\\"Cannot build plan for query\\\" to omit the SQL    query text. Useful because the text can be quite long, which makes it    easy to miss the text about the problem.  3) Add a feature to block context parameters used internally by the SQL    planner from being supplied by end users.  4) Add a feature to enable adding row signature to the context for    Scan queries. This is useful in building the task-based engine.  5) Add saffron.properties file that turns off sets and graphviz dumps    in \\\"cannot plan\\\" errors. Significantly reduces log spam on the Broker.  * Fixes from CI.  * Changes from review.  * Can vectorize, now that join-to-filter is on by default.  * Checkstyle! And variable renames!  * Remove throws from test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 Aug 2022 23:31:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"846345669d5fa625666eb3682260b7a80d9769c1\",\n",
      "\t\t\"parent\": \"b26ab678b9e3b9724a667914234fe30e9a71038e\",\n",
      "\t\t\"subject\": \"Error handling improvements for frame channels. (#12895)\",\n",
      "\t\t\"sanitized_subject_line\": \"Error-handling-improvements-for-frame-channels.-12895\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Error handling improvements for frame channels.  Two changes:  1) Send errors down in-memory channels (BlockingQueueFrameChannel) on    failure. This ensures that in situations where a chain of processors    has been set up on a single machine, all processors see the root    cause error. In particular, this means the final processor in the    chain reports the root cause error, which ensures that someone with    a handle to the final processor will get the proper error.  2) Update FrameFileHttpResponseHandler to expect that the final fetch,    rather than being simply empty, is also empty with a special header.    This ensures that the handler is able to tell the difference between    an empty fetch due to being at EOF, and an empty fetch due to a    truncated HTTP response (after the 200 OK and headers are sent down,    but before any content appears).  * Fix tests, imports.  * Checkstyle!\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 Aug 2022 11:31:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b26ab678b9e3b9724a667914234fe30e9a71038e\",\n",
      "\t\t\"parent\": \"41712b7a3a938e6157c9f6663b5073093729a56e\",\n",
      "\t\t\"subject\": \"Do no create filters on right side table columns while join to filter conversion (#12899)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-no-create-filters-on-right-side-table-columns-while-join-to-filter-conversion-12899\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 Aug 2022 08:35:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"41712b7a3a938e6157c9f6663b5073093729a56e\",\n",
      "\t\t\"parent\": \"4d65c085766786b6ae436f04943572c5beae58fa\",\n",
      "\t\t\"subject\": \"Refactor SqlLifecycle into statement classes (#12845)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-SqlLifecycle-into-statement-classes-12845\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor SqlLifecycle into statement classes  Create direct & prepared statements Remove redundant exceptions from tests Tidy up Calcite query tests Make PlannerConfig more testable  * Build fixes  * Added builder to SqlQueryPlus  * Moved Calcites system properties to saffron.properties  * Build fix  * Resolve merge conflict  * Fix IntelliJ inspection issue  * Revisions from reviews  Backed out a revision to Calcite tests that didn't work out as planned  * Build fix  * Fixed spelling errors  * Fixed failed test  Prepare now enforces security; before it did not.  * Rebase and fix IntelliJ inspections issue  * Clean up exception handling  * Fix handling of JDBC auth errors  * Build fix  * More tweaks to security messages\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 Aug 2022 00:44:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4d65c085766786b6ae436f04943572c5beae58fa\",\n",
      "\t\t\"parent\": \"f4e0909e924dc24539857ada817cbd0cfdacd729\",\n",
      "\t\t\"subject\": \"changes to run examples when CDPATH environment variable is set where cd command returns current dir\\u2026 (#12877)\",\n",
      "\t\t\"sanitized_subject_line\": \"changes-to-run-examples-when-CDPATH-environment-variable-is-set-where-cd-command-returns-current-dir-12877\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* changes to run examples on macos where cd command returns current directory  * Update examples/bin/run-druid  Co-authored-by: Frank Chen <frankchen@apache.org>  * merging  * sending output of cd command to /dev/null  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"vimil-saju\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 14 Aug 2022 13:15:24 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f4e0909e924dc24539857ada817cbd0cfdacd729\",\n",
      "\t\t\"parent\": \"53948380305d8495285aa6db2f49e6348d57049f\",\n",
      "\t\t\"subject\": \"fix bug with json_object expression not fully unwrapping inputs (#12893)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-with-json_object-expression-not-fully-unwrapping-inputs-12893\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Aug 2022 21:15:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"53948380305d8495285aa6db2f49e6348d57049f\",\n",
      "\t\t\"parent\": \"af700bba0c8408d63de7374d77f681bf8fdeb2f7\",\n",
      "\t\t\"subject\": \"Enable conversion of join to filter by default (#12868)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-conversion-of-join-to-filter-by-default-12868\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Aug 2022 20:37:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"af700bba0c8408d63de7374d77f681bf8fdeb2f7\",\n",
      "\t\t\"parent\": \"836430019ab24c264bb52b8f2d6e35091869c5fd\",\n",
      "\t\t\"subject\": \"Fix hasBuiltInFilters for joins (#12894)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-hasBuiltInFilters-for-joins-12894\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Aug 2022 16:26:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"836430019ab24c264bb52b8f2d6e35091869c5fd\",\n",
      "\t\t\"parent\": \"3a3271eddc946599e1c9b81154d2f37663b186c5\",\n",
      "\t\t\"subject\": \"Add EXTERNAL resource type. (#12896)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-EXTERNAL-resource-type.-12896\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This is used to control access to the EXTERN function, which allows reading external data in SQL. The EXTERN function is not usable in production as of today, but it is used by the task-based SQL engine contemplated in #12262.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 Aug 2022 10:57:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3a3271eddc946599e1c9b81154d2f37663b186c5\",\n",
      "\t\t\"parent\": \"2f2d8ded5a4d090ee96cfeee195f1833d1030669\",\n",
      "\t\t\"subject\": \"Introduce defaultOnDiskStorage config for Group By (#12833)\",\n",
      "\t\t\"sanitized_subject_line\": \"Introduce-defaultOnDiskStorage-config-for-Group-By-12833\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Introduce defaultOnDiskStorage config for groupBy  * add debug log to groupby query config  * Apply config change suggestion from review  * Remove accidental new lines  * update default value of new default disk storage config  * update debug log to have more descriptive text  * Make maxOnDiskStorage and defaultOnDiskStorage HumanRedadableBytes  * improve test coverage  * Provide default implementation to new default method on advice of reviewer\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 Aug 2022 09:40:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f2d8ded5a4d090ee96cfeee195f1833d1030669\",\n",
      "\t\t\"parent\": \"38af5f7b57769e026f028a56bb9be8003e01ddc5\",\n",
      "\t\t\"subject\": \"Introducing Storage connector Interface (#12874)\",\n",
      "\t\t\"sanitized_subject_line\": \"Introducing-Storage-connector-Interface-12874\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In the current druid code base, we have the interface DataSegmentPusher which allows us to push segments to the appropriate deep storage without the extension being worried about the semantics of how to push too deep storage.  While working on #12262, whose some part of the code will go as an extension, I realized that we do not have an interface that allows us to do basic \\\"write, get, delete, deleteAll\\\" operations on the appropriate deep storage without let's say pulling the s3-storage-extension dependency in the custom extension.  Hence, the idea of StorageConnector was born where the storage connector sits inside the druid core so all extensions have access to it.  Each deep storage implementation, for eg s3, GCS, will implement this interface. Now with some Jackson magic, we bind the implementation of the correct deep storage implementation on runtime using a type variable.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 Aug 2022 16:11:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"38af5f7b57769e026f028a56bb9be8003e01ddc5\",\n",
      "\t\t\"parent\": \"b4985ccd5e9b10fec847b3316259fc97996eebca\",\n",
      "\t\t\"subject\": \"NettyHttpClient: Cleaner state transitions for handlers. (#12889)\",\n",
      "\t\t\"sanitized_subject_line\": \"NettyHttpClient-Cleaner-state-transitions-for-handlers.-12889\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The Netty pipeline set up by the client can deliver multiple exceptions, and can deliver chunks even after delivering exceptions. This makes it difficult to implement HttpResponseHandlers. Looking at existing handler implementations, I do not see attempts to handle this case, so it's also a potential source of bugs.  This patch updates the client to track whether an exception was encountered, and if so, to not call any additional methods on the handler after exceptionCaught. It also harmonizes exception handling between exceptionCaught and channelDisconnected.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 Aug 2022 09:31:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b4985ccd5e9b10fec847b3316259fc97996eebca\",\n",
      "\t\t\"parent\": \"4706a4c5725211cd1967403c65454c42bfb12343\",\n",
      "\t\t\"subject\": \"Suppress CVEs - Avatica, Postgres (#12884)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVEs-Avatica-Postgres-12884\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Aug 2022 14:18:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4706a4c5725211cd1967403c65454c42bfb12343\",\n",
      "\t\t\"parent\": \"8ad8582dc85721e920aa57dcada2803c65fd6294\",\n",
      "\t\t\"subject\": \"Docker build for the revised ITs (#12707)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docker-build-for-the-revised-ITs-12707\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Docker build for the revised ITs  * Fix POM versions  * Update comments from review suggestions\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Aug 2022 14:17:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ad8582dc85721e920aa57dcada2803c65fd6294\",\n",
      "\t\t\"parent\": \"ee41cc770f3a2b666e380d25ffbc5469a42a1d36\",\n",
      "\t\t\"subject\": \"Refactor DruidSchema & DruidTable (#12835)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-DruidSchema-DruidTable-12835\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Refactors the DruidSchema and DruidTable abstractions to prepare for the Druid Catalog.  As we add the catalog, we\\u2019ll want to combine physical segment metadata information with \\u201chints\\u201d provided by the catalog. This is best done if we tidy up the existing code to more clearly separate responsibilities.  This PR is purely a refactoring move: no functionality changed. There is no difference to user functionality or external APIs. Functionality changes will come later as we add the catalog itself.  DruidSchema In the present code, DruidSchema does three tasks:  Holds the segment metadata cache Interfaces with an external schema manager Acts as a schema to Calcite This PR splits those responsibilities.  DruidSchema holds the Calcite schema for the druid namespace, combining information fro the segment metadata cache, from the external schema manager and (later) from the catalog. SegmentMetadataCache holds the segment metadata cache formerly in DruidSchema. DruidTable The present DruidTable class is a bit of a kitchen sink: it holds all the various kinds of tables which Druid supports, and uses if-statements to handle behavior that differs between types. Yet, any given DruidTable will handle only one such table type. To more clearly model the actual table types, we split DruidTable into several classes:  DruidTable becomes an abstract base class to hold Druid-specific methods. DatasourceTable represents a datasource. ExternalTable represents an external table, such as from EXTERN or (later) from the catalog. InlineTable represents the internal case in which we attach data directly to a table. LookupTable represents Druid\\u2019s lookup table mechanism. The new subclasses are more focused: they can be selective about the data they hold and the various predicates since they represent just one table type. This will be important as the catalog information will differ depending on table type and the new structure makes adding that logic cleaner.  DatasourceMetadata Previously, the DruidSchema segment cache would work with DruidTable objects. With the catalog, we need a layer between the segment metadata and the table as presented to Calcite. To fix this, the new SegmentMetadataCache class uses a new DatasourceMetadata class as its cache entry to hold only the \\u201cphysical\\u201d segment metadata information: it is up to the DruidTable to combine this with the catalog information in a later PR.  More Efficient Table Resolution Calcite provides a convenient base class for schema objects: AbstractSchema. However, this class is a bit too convenient: all we have to do is provide a map of tables and Calcite does the rest. This means that, to resolve any single datasource, say, foo, we need to cache segment metadata, external schema information, and catalog information for all tables. Just so Calcite can do a map lookup.  There is nothing special about AbstractSchema. We can handle table lookups ourselves. The new AbstractTableSchema does this. In fact, all the rest of Calcite wants is to resolve individual tables by name, and, for commands we don\\u2019t use, to provide a list of table names.  DruidSchema now extends AbstractTableSchema. SegmentMetadataCache resolves individual tables (and provides table names.)  DruidSchemaManager DruidSchemaManager provides a way to specify table schemas externally. In this sense, it is similar to the catalog, but only for datasources. It originally followed the AbstractSchema pattern: it implements provide a map of tables. This PR provides new optional methods for the table lookup and table names operations. The default implementations work the same way that AbstractSchema works: we get the entire map and pick out the information we need. Extensions that use this API should be revised to support the individual operations instead. Druid code no longer calls the original getTables() method.  The PR has one breaking change: since the DruidSchemaManager map is read-only to the rest of Druid, we should return a Map, not a ConcurrentMap.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Aug 2022 10:24:04 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee41cc770f3a2b666e380d25ffbc5469a42a1d36\",\n",
      "\t\t\"parent\": \"2855fb6ff8181d83fa679db26c8bbddf839391fd\",\n",
      "\t\t\"subject\": \"fix issue with SQL sum aggregator due to bug with DruidTypeSystem and AggregateRemoveRule (#12880)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-SQL-sum-aggregator-due-to-bug-with-DruidTypeSystem-and-AggregateRemoveRule-12880\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issue with SQL sum aggregator due to bug with DruidTypeSystem and AggregateRemoveRule  * fix style  * add comment about using custom sum function\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Aug 2022 15:17:45 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2855fb6ff8181d83fa679db26c8bbddf839391fd\",\n",
      "\t\t\"parent\": \"ebe783dbdcc9d5bc95e2a7284dd543cd643cba87\",\n",
      "\t\t\"subject\": \"Change Kafka Lookup Extractor to not register consumer group (#12842)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-Kafka-Lookup-Extractor-to-not-register-consumer-group-12842\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* change kafka lookups module to not commit offsets  The current behaviour of the Kafka lookup extractor is to not commit offsets by assigning a unique ID to the consumer group and setting auto.offset.reset to earliest. This does the job but also pollutes the Kafka broker with a bunch of \\\"ghost\\\" consumer groups that will never again be used.  To fix this, we now set enable.auto.commit to false, which prevents the ghost consumer groups being created in the first place.  * update docs to include new enable.auto.commit setting behaviour  * update kafka-lookup-extractor documentation  Provide some additional detail on functionality and configuration. Hopefully this will make it clearer how the extractor works for developers who aren't so familiar with Kafka.  * add comments better explaining the logic of the code  * add spelling exceptions for kafka lookup docs\",\n",
      "\t\t\"author_name\": \"David Palmer\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Aug 2022 16:14:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ebe783dbdcc9d5bc95e2a7284dd543cd643cba87\",\n",
      "\t\t\"parent\": \"abd7a9748d84b536bcabe44af655c5d37826ae15\",\n",
      "\t\t\"subject\": \"Correct minor format issue (#12882)\",\n",
      "\t\t\"sanitized_subject_line\": \"Correct-minor-format-issue-12882\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"\\u7d75\\u7a7a\\u4e8b\\u30b9\\u30d4\\u30ea\\u30c3\\u30c8\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Aug 2022 18:15:41 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"abd7a9748d84b536bcabe44af655c5d37826ae15\",\n",
      "\t\t\"parent\": \"a7e89de6107ee77cd8a3c2760deb37642db79225\",\n",
      "\t\t\"subject\": \"Remove kafka lookup records when a record is tombstoned (#12819)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-kafka-lookup-records-when-a-record-is-tombstoned-12819\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove kafka lookup records from factory when record tombstoned  * update kafka lookup docs to include tombstone behaviour  * change test wait time down to 10ms  Co-authored-by: David Palmer <david.palmer@adscale.co.nz>\",\n",
      "\t\t\"author_name\": \"Hamish Ball\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Aug 2022 10:42:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7e89de6107ee77cd8a3c2760deb37642db79225\",\n",
      "\t\t\"parent\": \"533c39f35a9e8459e3038fb458ab272648bc39c9\",\n",
      "\t\t\"subject\": \"fix JsonNode leaking from JSON flattener (#12873)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-JsonNode-leaking-from-JSON-flattener-12873\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix JsonNode leaking from JSON flattener  * adjustments\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Aug 2022 19:51:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"533c39f35a9e8459e3038fb458ab272648bc39c9\",\n",
      "\t\t\"parent\": \"267b32c2e2c283ea0602a3b080df3ae553c73683\",\n",
      "\t\t\"subject\": \"Fix rollup docs bullet formatting (#12876)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-rollup-docs-bullet-formatting-12876\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"David Hergenroeder\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Aug 2022 10:10:07 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"267b32c2e2c283ea0602a3b080df3ae553c73683\",\n",
      "\t\t\"parent\": \"01d555e47bdd87419242a9327b16cfbe017bcfa4\",\n",
      "\t\t\"subject\": \"Set druid.processing.fifo to true by default (#12571)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-druid.processing.fifo-to-true-by-default-12571\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Aug 2022 10:18:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"01d555e47bdd87419242a9327b16cfbe017bcfa4\",\n",
      "\t\t\"parent\": \"607b0b9310db0b3a063c24e1ee752c0f1e7c51b1\",\n",
      "\t\t\"subject\": \"Adjust \\\"in\\\" filter null behavior to match \\\"selector\\\". (#12863)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adjust-in-filter-null-behavior-to-match-selector-.-12863\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adjust \\\"in\\\" filter null behavior to match \\\"selector\\\".  Now, both of them match numeric nulls if constructed with a \\\"null\\\" value.  This is consistent as far as native execution goes, but doesn't match the behavior of SQL = and IN. So, to address that, this patch also updates the docs to clarify that the native filters do match nulls.  This patch also updates the SQL docs to describe how Boolean logic is handled in addition to how NULL values are handled.  Fixes #12856.  * Fix test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Aug 2022 09:08:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"607b0b9310db0b3a063c24e1ee752c0f1e7c51b1\",\n",
      "\t\t\"parent\": \"2045a1345c9c7cde98b4b1454b1f6fd82b71b96a\",\n",
      "\t\t\"subject\": \"Adding withName implementation to AggregatorFactory  (#12862)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-withName-implementation-to-AggregatorFactory-12862\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding agg factory with name impl  * Adding test cases  * Fixing test case  * Fixing test case  * Updated java docs.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Aug 2022 18:31:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2045a1345c9c7cde98b4b1454b1f6fd82b71b96a\",\n",
      "\t\t\"parent\": \"9f8982a9a6b6d1b49ce00d9930b730f40c14260c\",\n",
      "\t\t\"subject\": \"Fix NPE when applying a transform that outputs to __time (#12870)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-NPE-when-applying-a-transform-that-outputs-to-__time-12870\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 7 Aug 2022 19:21:47 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9f8982a9a6b6d1b49ce00d9930b730f40c14260c\",\n",
      "\t\t\"parent\": \"d294404924579526ca1396d004b499e59fd43bcb\",\n",
      "\t\t\"subject\": \"fix(druid-indexing): failed to get shardSpec for interval issue (#12573)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-druid-indexing-failed-to-get-shardSpec-for-interval-issue-12573\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Herb Brewer\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 Aug 2022 17:57:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d294404924579526ca1396d004b499e59fd43bcb\",\n",
      "\t\t\"parent\": \"24f8f9e1ab4199fd46e906e2506e35c0a467a65d\",\n",
      "\t\t\"subject\": \"Kinesis ingestion with empty shards (#12792)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kinesis-ingestion-with-empty-shards-12792\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Kinesis ingestion requires all shards to have at least 1 record at the required position in druid. Even if this is satisified initially, resharding the stream can lead to empty intermediate shards. A significant delay in writing to newly created shards was also problematic.  Kinesis shard sequence numbers are big integers. Introduce two more custom sequence tokens UNREAD_TRIM_HORIZON and UNREAD_LATEST to indicate that a shard has not been read from and that it needs to be read from the start or the end respectively. These values can be used to avoid the need to read at least one record to obtain a sequence number for ingesting a newly discovered shard.  If a record cannot be obtained immediately, use a marker to obtain the relevant shardIterator and use this shardIterator to obtain a valid sequence number. As long as a valid sequence number is not obtained, continue storing the token as the offset.  These tokens (UNREAD_TRIM_HORIZON and UNREAD_LATEST) are logically ordered to be earlier than any valid sequence number.  However, the ordering requires a few subtle changes to the existing mechanism for record sequence validation:  The sequence availability check ensures that the current offset is before the earliest available sequence in the shard. However, current token being an UNREAD token indicates that any sequence number in the shard is valid (despite the ordering)  Kinesis sequence numbers are inclusive i.e if current sequence == end sequence, there are more records left to read. However, the equality check is exclusive when dealing with UNREAD tokens.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 Aug 2022 22:38:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"24f8f9e1ab4199fd46e906e2506e35c0a467a65d\",\n",
      "\t\t\"parent\": \"ca4e64aea3951f8577f80a7aa0de6a50e83e86db\",\n",
      "\t\t\"subject\": \"Add check for eternity time segment to SqlSegmentsMetadataQuery (#12844)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-check-for-eternity-time-segment-to-SqlSegmentsMetadataQuery-12844\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add check for eternity time segment to SqlSegmentsMetadataQuery  * Add check for half eternities  * Add multiple segments test  * Add failing test to document known issue\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 Aug 2022 22:33:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca4e64aea3951f8577f80a7aa0de6a50e83e86db\",\n",
      "\t\t\"parent\": \"c6dd9dd4afa67ba3930fdcbfb1827900a0bd09ba\",\n",
      "\t\t\"subject\": \"Frame processing and channels. (#12848)\",\n",
      "\t\t\"sanitized_subject_line\": \"Frame-processing-and-channels.-12848\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Frame processing and channels.  Follow-up to #12745. This patch adds three new concepts:  1) Frame channels are interfaces for doing nonblocking reads and writes    of frames.  2) Frame processors are interfaces for doing nonblocking processing of    frames received from input channels and sent to output channels.  3) Cluster-by keys, which can be used for sorting or partitioning.  The patch also adds SuperSorter, a user of these concepts, both to illustrate how they are used, and also because it is going to be useful in future work.  Central classes:  - ReadableFrameChannel. Implementations include   BlockingQueueFrameChannel (in-memory channel that implements both interfaces),   ReadableFileFrameChannel (file-based channel),   ReadableByteChunksFrameChannel (byte-stream-based channel), and others.  - WritableFrameChannel. Implementations include BlockingQueueFrameChannel   and WritableStreamFrameChannel (byte-stream-based channel).  - ClusterBy, a sorting or partitioning key.  - FrameProcessor, nonblocking processor of frames. Implementations include   FrameChannelBatcher, FrameChannelMerger, and FrameChannelMuxer.  - FrameProcessorExecutor, an executor service that runs FrameProcessors.  - SuperSorter, a class that uses frame channels and processors to   do parallel external merge sort of any amount of data (as long as there   is enough disk space).  * Additional tests, fixes.  * Changes from review.  * Better implementation for ReadableInputStreamFrameChannel.  * Rename getFrameFileReference -> newFrameFileReference.  * Add InterruptedException to runIncrementally; add more tests.  * Cancellation adjustments.  * Review adjustments.  * Refactor BlockingQueueFrameChannel, rename doneReading and doneWriting to close.  * Additional changes from review.  * Additional changes.  * Fix test.  * Adjustments.  * Adjustments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 Aug 2022 21:29:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c6dd9dd4afa67ba3930fdcbfb1827900a0bd09ba\",\n",
      "\t\t\"parent\": \"73cfc4e5d0f04c4259898a32565fd80745da08b7\",\n",
      "\t\t\"subject\": \"Fix typo in compaction.md (#12774)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-typo-in-compaction.md-12774\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 Aug 2022 14:47:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"73cfc4e5d0f04c4259898a32565fd80745da08b7\",\n",
      "\t\t\"parent\": \"a618458bf00647dc8e5862472f3bc5410a9b5e0a\",\n",
      "\t\t\"subject\": \"fix expression plan type inference to correctly handle complex types (#12857)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-expression-plan-type-inference-to-correctly-handle-complex-types-12857\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 Aug 2022 02:56:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a618458bf00647dc8e5862472f3bc5410a9b5e0a\",\n",
      "\t\t\"parent\": \"ef6811ef882bb900f6ea249389758f500cfcaf00\",\n",
      "\t\t\"subject\": \"Tidy up construction of the Guice Injectors (#12816)\",\n",
      "\t\t\"sanitized_subject_line\": \"Tidy-up-construction-of-the-Guice-Injectors-12816\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor Guice initialization  Builders for various module collections Revise the extensions loader Injector builders for server startup Move Hadoop init to indexer Clean up server node role filtering Calcite test injector builder  * Revisions from review comments  * Build fixes  * Revisions from review comments\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 4 Aug 2022 00:05:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ef6811ef882bb900f6ea249389758f500cfcaf00\",\n",
      "\t\t\"parent\": \"623b075d127350f58d5981fe292e5d1f9ed72fcb\",\n",
      "\t\t\"subject\": \"Improved Java 17 support and Java runtime docs. (#12839)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improved-Java-17-support-and-Java-runtime-docs.-12839\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improved Java 17 support and Java runtime docs.  1) Add a \\\"Java runtime\\\" doc page with information about supported    Java versions, garbage collection, and strong encapsulation..  2) Update asm and equalsverifier to versions that support Java 17.  3) Add additional \\\"--add-opens\\\" lines to surefire configuration, so    tests can pass successfully under Java 17.  4) Switch openjdk15 tests to openjdk17.  5) Update FrameFile to specifically mention Java runtime incompatibility    as the cause of not being able to use Memory.map.  6) Update SegmentLoadDropHandler to log an error for Errors too, not    just Exceptions. This is important because an IllegalAccessError is    encountered when the correct \\\"--add-opens\\\" line is not provided,    which would otherwise be silently ignored.  7) Update example configs to use druid.indexer.runner.javaOptsArray    instead of druid.indexer.runner.javaOpts. (The latter is deprecated.)  * Adjustments.  * Use run-java in more places.  * Add run-java.  * Update .gitignore.  * Exclude hadoop-client-api.  Brought in when building on Java 17.  * Swap one more usage of java.  * Fix the run-java script.  * Fix flag.  * Include link to Temurin.  * Spelling.  * Update examples/bin/run-java  Co-authored-by: Xavier L\\u00e9aut\\u00e9 <xl+github@xvrl.net>  Co-authored-by: Xavier L\\u00e9aut\\u00e9 <xl+github@xvrl.net>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Aug 2022 23:16:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"623b075d127350f58d5981fe292e5d1f9ed72fcb\",\n",
      "\t\t\"parent\": \"6f5c1434b8cb1ce9e48efca465a81bed2741cada\",\n",
      "\t\t\"subject\": \"fix nested column sql operator return type inference (#12851)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-nested-column-sql-operator-return-type-inference-12851\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix nested column sql operator return type inference  * oops, final\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Aug 2022 15:39:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f5c1434b8cb1ce9e48efca465a81bed2741cada\",\n",
      "\t\t\"parent\": \"fbd1a07e7e912a35e02ce166e0d5ad76fa64013d\",\n",
      "\t\t\"subject\": \"fix get task may be null (#12100)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-get-task-may-be-null-12100\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"\\u5218\\u5c0f\\u8f89\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Aug 2022 09:23:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fbd1a07e7e912a35e02ce166e0d5ad76fa64013d\",\n",
      "\t\t\"parent\": \"0a4ed3ba61ab2a7b68f9ffc2e19da055fcd03692\",\n",
      "\t\t\"subject\": \"Fix kinesis IT flakiness (#12821)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-kinesis-IT-flakiness-12821\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Aug 2022 17:16:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0a4ed3ba61ab2a7b68f9ffc2e19da055fcd03692\",\n",
      "\t\t\"parent\": \"3290b4975456f8feb9afd006232741a0c7d98e63\",\n",
      "\t\t\"subject\": \"Readme - link fix to build guide (#12849)\",\n",
      "\t\t\"sanitized_subject_line\": \"Readme-link-fix-to-build-guide-12849\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Aug 2022 19:32:37 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3290b4975456f8feb9afd006232741a0c7d98e63\",\n",
      "\t\t\"parent\": \"2912a36a202672b2b025ef447c5bcbded7b20990\",\n",
      "\t\t\"subject\": \"Log4j bump to 2.18 due to [LOG4J2-3419] (#12847)\",\n",
      "\t\t\"sanitized_subject_line\": \"Log4j-bump-to-2.18-due-to-LOG4J2-3419-12847\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Log4j bump to 2.18 due to [LOG4J2-3419]  * Fixing license issues\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 23:25:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2912a36a202672b2b025ef447c5bcbded7b20990\",\n",
      "\t\t\"parent\": \"0ca37c20a6ab8e774931e6d504a3a4aa27a149bb\",\n",
      "\t\t\"subject\": \"Use nonzero default value of maxQueuedBytes. (#12840)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-nonzero-default-value-of-maxQueuedBytes.-12840\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use nonzero default value of maxQueuedBytes.  The purpose of this parameter is to prevent the Broker from running out of memory. The prior default is unlimited; this patch changes it to a relatively conservative 25MB.  This may be too low for larger clusters. The risk is that throughput can decrease for queries with large resultsets or large amounts of intermediate data. However, I think this is better than the risk of the prior default, which is that these queries can cause the Broker to go OOM.  * Alter calculation.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 17:57:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0ca37c20a6ab8e774931e6d504a3a4aa27a149bb\",\n",
      "\t\t\"parent\": \"6981b1cc12a6145109e9c19692ae3661aa383104\",\n",
      "\t\t\"subject\": \"Python 3 support for post-index-task. (#12841)\",\n",
      "\t\t\"sanitized_subject_line\": \"Python-3-support-for-post-index-task.-12841\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Python 3 support for post-index-task.  Useful when running on macOS or any other system that doesn't have Python 2.  * Encode JSON returned by read_task_file.  * Adjust.  * Skip needless loads.  * Add a decode.  * Additional decodes needed.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 17:53:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6981b1cc12a6145109e9c19692ae3661aa383104\",\n",
      "\t\t\"parent\": \"eabce8a1590d564702321fea98157289776e63c5\",\n",
      "\t\t\"subject\": \"fix bugs with nested column jsonpath parser (#12831)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bugs-with-nested-column-jsonpath-parser-12831\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 11:38:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eabce8a1590d564702321fea98157289776e63c5\",\n",
      "\t\t\"parent\": \"cceb2e849ee837beb1228adf018b9a1aec79e226\",\n",
      "\t\t\"subject\": \"Fix flakiness in query-retry ITs (#12818)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flakiness-in-query-retry-ITs-12818\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 17:20:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cceb2e849ee837beb1228adf018b9a1aec79e226\",\n",
      "\t\t\"parent\": \"6046a392b61b94bbfa6f7a083e2958e8e942ab6e\",\n",
      "\t\t\"subject\": \"Perform lazy initialization of parquet extensions module (#12827)\",\n",
      "\t\t\"sanitized_subject_line\": \"Perform-lazy-initialization-of-parquet-extensions-module-12827\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Historicals and middle managers crash with an `UnknownHostException` on trying to load `druid-parquet-extensions` with an ephemeral Hadoop cluster. This happens because the `fs.defaultFS` URI value cannot be resolved at start up time as the hadoop cluster may not exist at startup time.  This commit fixes the error by performing initialization of the filesystem in `ParquetInputFormat.createReader()` whenever a new reader is requested.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Aug 2022 13:41:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6046a392b61b94bbfa6f7a083e2958e8e942ab6e\",\n",
      "\t\t\"parent\": \"7ae6cc6e60b6bb7fd83c6a649861a5ddd982ea72\",\n",
      "\t\t\"subject\": \"add DictionaryEncodedStringValueIndex implementation to NestedFieldLiteralColumnIndexSupplier (#12837)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-DictionaryEncodedStringValueIndex-implementation-to-NestedFieldLiteralColumnIndexSupplier-12837\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 Aug 2022 21:40:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7ae6cc6e60b6bb7fd83c6a649861a5ddd982ea72\",\n",
      "\t\t\"parent\": \"553ff4761636c41ea3d718a31a660f2d92fb2f35\",\n",
      "\t\t\"subject\": \"Fix string first/last aggregator comparator (#12773)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-string-first-last-aggregator-comparator-12773\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 Aug 2022 20:54:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"553ff4761636c41ea3d718a31a660f2d92fb2f35\",\n",
      "\t\t\"parent\": \"d96a9c1e6f657e957d5971a252627cc7441b1a42\",\n",
      "\t\t\"subject\": \"fix: fix broken link to Class TTest (#12836)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-fix-broken-link-to-Class-TTest-12836\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 31 Jul 2022 10:18:14 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d96a9c1e6f657e957d5971a252627cc7441b1a42\",\n",
      "\t\t\"parent\": \"189e8b9d18b1f9266215ff4a6811b9b571e78aa0\",\n",
      "\t\t\"subject\": \"add missing selectors for explicit null columns (#12834)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-missing-selectors-for-explicit-null-columns-12834\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 29 Jul 2022 19:08:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"189e8b9d18b1f9266215ff4a6811b9b571e78aa0\",\n",
      "\t\t\"parent\": \"d52abe7b38508908ef45e016446bd1f7c0c1c7a7\",\n",
      "\t\t\"subject\": \"add NumericRangeIndex interface and BoundFilter support (#12830)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-NumericRangeIndex-interface-and-BoundFilter-support-12830\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"add NumericRangeIndex interface and BoundFilter support changes: * NumericRangeIndex interface, like LexicographicalRangeIndex but for numbers * BoundFilter now uses NumericRangeIndex if comparator is numeric and there is no extractionFn * NestedFieldLiteralColumnIndexSupplier.java now supports supplying NumericRangeIndex for single typed numeric nested literal columns  * better faster stronger and (ever so slightly) more understandable  * more tests, fix bug  * fix style\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 29 Jul 2022 18:58:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d52abe7b38508908ef45e016446bd1f7c0c1c7a7\",\n",
      "\t\t\"parent\": \"efbb58e90e5b1400f74c0eaa7ecb69e002176f17\",\n",
      "\t\t\"subject\": \"Today is that day - Single pass through Calcite planner (#12636)\",\n",
      "\t\t\"sanitized_subject_line\": \"Today-is-that-day-Single-pass-through-Calcite-planner-12636\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Druid planner now makes only one pass through Calcite planner  Resolves the issue that required two parse/plan cycles: one for validate, another for plan. Creates a clone of the Calcite planner and validator to resolve the conflict that prevented the merger. \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 29 Jul 2022 18:53:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"efbb58e90e5b1400f74c0eaa7ecb69e002176f17\",\n",
      "\t\t\"parent\": \"24c345cdf02648414c9d7d15e09017bc02748ec4\",\n",
      "\t\t\"subject\": \"docs: remove maxRowsPerSegment where appropriate (#12071)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-remove-maxRowsPerSegment-where-appropriate-12071\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove maxRowsPerSegment where appropriate  * fix tutorial, accept suggestions  * Update docs/design/coordinator.md  * additional tutorial file  * fix initial index spec  * accept comments  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * add back comment on maxrows per segment  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * rm duplicate entry  * Update native-batch-simple-task.md  remove ref to `maxrowspersegment`  * Update native-batch.md  remove ref to `maxrowspersegment`  * final tenticles  * Apply suggestions from code review  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 28 Jul 2022 16:52:13 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"24c345cdf02648414c9d7d15e09017bc02748ec4\",\n",
      "\t\t\"parent\": \"a8b155e9c6e4699d30ba2386c6ec88a3004eb819\",\n",
      "\t\t\"subject\": \"Allow dictionary encoded column to use a more generic index interface (#12826)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-dictionary-encoded-column-to-use-a-more-generic-index-interface-12826\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Jul 2022 15:23:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8b155e9c6e4699d30ba2386c6ec88a3004eb819\",\n",
      "\t\t\"parent\": \"93a9a4b1c5342d18abf269202d1c777852b6532a\",\n",
      "\t\t\"subject\": \"Fixes for the Avatica JDBC driver (#12709)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixes-for-the-Avatica-JDBC-driver-12709\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fixes for the Avatica JDBC driver  Correctly implement regular and prepared statements Correctly implement result sets Fix race condition with contexts Clarify when parameters are used Prepare for single-pass through the planner  * Addressed review comments  * Addressed review comment\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Jul 2022 15:22:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"93a9a4b1c5342d18abf269202d1c777852b6532a\",\n",
      "\t\t\"parent\": \"bf0886a8ab98ec5cf7b013b2e1811b1f6478da58\",\n",
      "\t\t\"subject\": \"Add retention for file request logs (#12559)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-retention-for-file-request-logs-12559\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add retention for file request logs  * Spelling\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Jul 2022 08:17:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bf0886a8ab98ec5cf7b013b2e1811b1f6478da58\",\n",
      "\t\t\"parent\": \"6b0b1d7af317d1a6b219cf1213139abf1607eaa0\",\n",
      "\t\t\"subject\": \"Fix hash calcuation in RendezvousHasher (#12817)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-hash-calcuation-in-RendezvousHasher-12817\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Jul 2022 12:16:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6b0b1d7af317d1a6b219cf1213139abf1607eaa0\",\n",
      "\t\t\"parent\": \"2e616e633a1b656d346f3e1236bd08dd6e625f19\",\n",
      "\t\t\"subject\": \"replaces hard-coded probe delays with helm values (#12805)\",\n",
      "\t\t\"sanitized_subject_line\": \"replaces-hard-coded-probe-delays-with-helm-values-12805\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jacques Arnoux\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Jul 2022 14:04:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2e616e633a1b656d346f3e1236bd08dd6e625f19\",\n",
      "\t\t\"parent\": \"d7d4314367a5561aebe53e90bf2630fd0604d1f5\",\n",
      "\t\t\"subject\": \"Determine type of `__time` column by RowSignature in case of External Datasource (#12770)\",\n",
      "\t\t\"sanitized_subject_line\": \"Determine-type-of-__time-column-by-RowSignature-in-case-of-External-Datasource-12770\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Some queries like `REPLACE INTO ... SELECT TIME_PARSE(\\\"__time\\\") AS __time FROM ...` fail at the Calcite layer because any column with name `__time` is considered to be of type `SqlTypeName.TIMESTAMP`.  Changes: - Modify `RowSignatures.toRelDataType()` so that the type of `__time` column   is determined by the RowSignature's type.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Jul 2022 12:09:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7d4314367a5561aebe53e90bf2630fd0604d1f5\",\n",
      "\t\t\"parent\": \"188b5b00278aadc20fd06a633366018e9af4336a\",\n",
      "\t\t\"subject\": \"remove ref to plywood repo (#12809)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-ref-to-plywood-repo-12809\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Jul 2022 10:12:13 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"188b5b00278aadc20fd06a633366018e9af4336a\",\n",
      "\t\t\"parent\": \"5772dfd1552ab18276a7f8de9335e3a1ef489733\",\n",
      "\t\t\"subject\": \"Upgrade to jetty 9.4.48.v20220622 due to CVEs (#12801)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-to-jetty-9.4.48.v20220622-due-to-CVEs-12801\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Upgrade to jetty 9.4.48.v20220622 due to CVEs  * Update licenses.yaml\",\n",
      "\t\t\"author_name\": \"PJ Fanning\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Jul 2022 10:11:48 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5772dfd1552ab18276a7f8de9335e3a1ef489733\",\n",
      "\t\t\"parent\": \"6394ecfd210d34c0e80bc59e7e09c0023edd0eca\",\n",
      "\t\t\"subject\": \"Peons should not report SysMonitor stats since MiddleManager reports them. (#12802)\",\n",
      "\t\t\"sanitized_subject_line\": \"Peons-should-not-report-SysMonitor-stats-since-MiddleManager-reports-them.-12802\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Sysmonitor stats (mem, fs, disk, net, cpu, swap, sys, tcp) are reported by all Druid processes, including Peons that are ephemeral in nature. Since Peons always run on the same host as the MiddleManager that spawned them and is unlikely to change, the SyMonitor metrics emitted by Peon are merely duplicates. This is often not a problem except when machines are super-beefy. Imagine a 64-core machine and 32 workers running on this machine. now you will have each Peon reporting metrics for each core. that's an increase of (32 * 64)x in the number of metrics. This leads to a metric explosion.  This PR updates MetricsModule to check node role running while registering SysMonitor and not to load any existing SysMonitor$Stats.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Jul 2022 13:32:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6394ecfd210d34c0e80bc59e7e09c0023edd0eca\",\n",
      "\t\t\"parent\": \"5417aa2055b3abb4b4515f9de81397a19e5ebc73\",\n",
      "\t\t\"subject\": \"update figure and reference (#12813)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-figure-and-reference-12813\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Jul 2022 15:54:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5417aa2055b3abb4b4515f9de81397a19e5ebc73\",\n",
      "\t\t\"parent\": \"6c96d096800961dd7399f19c01027b8ea4644e19\",\n",
      "\t\t\"subject\": \"Fix: ParseException swallow cause Exception (#12810)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-ParseException-swallow-cause-Exception-12810\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add impl  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Jul 2022 13:46:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c96d096800961dd7399f19c01027b8ea4644e19\",\n",
      "\t\t\"parent\": \"9e5f0109fd00ffbed2ee80ebb0dfae253660ed5f\",\n",
      "\t\t\"subject\": \"Suppress some false alarm CVEs (#12812)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-some-false-alarm-CVEs-12812\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit suppresses the following CVEs: - CVE-2021-43138: false alarm for async-http-client - CVE-2021-34538: applicable to Hive server - CVE-2020-25638: requires hibernate update, which causes Hadoop ingestion failure - CVE-2021-27568: false alarm for accessors-smart which is a dependency of json-smart (already suppressed)\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Jul 2022 22:27:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e5f0109fd00ffbed2ee80ebb0dfae253660ed5f\",\n",
      "\t\t\"parent\": \"a2be6858248224ab103dc31e7576a63e6b143e40\",\n",
      "\t\t\"subject\": \"Fix CVE-2022-2048 (jetty) and CVE-2022-31159 (aws-java-sdk-s3) (#12807)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-CVE-2022-2048-jetty-and-CVE-2022-31159-aws-java-sdk-s3-12807\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Upgrade aws sdk version from `1.12.37` to `1.12.264` - Upgrade jetty version from `9.4.41.v20210516` to `9.4.47.v20220610`\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Jul 2022 13:08:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a2be6858248224ab103dc31e7576a63e6b143e40\",\n",
      "\t\t\"parent\": \"3bf1e699ff09ef13807cc05f00eec032912a1206\",\n",
      "\t\t\"subject\": \"Remove the time bit, fix headings (#12808)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-the-time-bit-fix-headings-12808\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove the time bit, fix headings  * Adopt review suggestions  * Edits  * Update smoosh file description  * Adopt review suggestions  * Update spelling\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 20 Jul 2022 15:37:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3bf1e699ff09ef13807cc05f00eec032912a1206\",\n",
      "\t\t\"parent\": \"809bf161ce6913c930362239ca079c800e0c317e\",\n",
      "\t\t\"subject\": \"GREATEST/LEAST function is incorrectly specifying that it cannot return null (#12804)\",\n",
      "\t\t\"sanitized_subject_line\": \"GREATEST-LEAST-function-is-incorrectly-specifying-that-it-cannot-return-null-12804\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 20 Jul 2022 14:41:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"809bf161ce6913c930362239ca079c800e0c317e\",\n",
      "\t\t\"parent\": \"f3272a25f9d6b9c2b67d748b6b7a0077c0865400\",\n",
      "\t\t\"subject\": \"Add a note about setting the value of maxNumConcurrentSubTasks  (#12772)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-note-about-setting-the-value-of-maxNumConcurrentSubTasks-12772\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add clarification for combining input source  * Update inputFormat note  * Update maxNumConcurrentSubTasks note  * Fix broken link  * Update docs/ingestion/native-batch-input-source.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Jul 2022 15:34:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f3272a25f9d6b9c2b67d748b6b7a0077c0865400\",\n",
      "\t\t\"parent\": \"cc1ff56ca55e89ebf50932a34f78202b81de031c\",\n",
      "\t\t\"subject\": \"Add check for sqlOuterLimit to ingest queries (#12799)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-check-for-sqlOuterLimit-to-ingest-queries-12799\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add check for sqlOuterLimit to ingest queries  * Fix checkstyle  * Add comment\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Jul 2022 09:02:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc1ff56ca55e89ebf50932a34f78202b81de031c\",\n",
      "\t\t\"parent\": \"75045970cde40562d9445ba4a9d27705742b29ab\",\n",
      "\t\t\"subject\": \"Unregisters `RealtimeMetricsMonitor`, `TaskRealtimeMetricsMonitor` on Indexers after task completion (#12743)\",\n",
      "\t\t\"sanitized_subject_line\": \"Unregisters-RealtimeMetricsMonitor-TaskRealtimeMetricsMonitor-on-Indexers-after-task-completion-12743\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Few indexing tasks register RealtimeMetricsMonitor or TaskRealtimeMetricsMonitor with the process\\u2019s MonitorScheduler when they start. These monitors never unregister themselves (they always return true, they'd need to return false to unregister). Each of these monitors emits a set of metrics once every druid.monitoring.emissionPeriod. As a result, after executing several tasks for a while, Indexer emits metrics of these tasks even after they're long gone.  Proposed Solution Since one should be able to obtain the last round of ingestion metrics after the task unregisters the monitor, introducing lastRoundMetricsToBePushed variable to keep track of the same and overriding the AbstractMonitor.monitor method in RealtimeMetricsMonitor, TaskRealtimeMetricsMonitor to implement the new logic.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Jul 2022 14:34:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"75045970cde40562d9445ba4a9d27705742b29ab\",\n",
      "\t\t\"parent\": \"d4403c15aa8a43c957d6a18ad27812c8fe7dca90\",\n",
      "\t\t\"subject\": \"S3 Ingestion from non-default endpoints (#11798)\",\n",
      "\t\t\"sanitized_subject_line\": \"S3-Ingestion-from-non-default-endpoints-11798\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add endpoint support for s3inputsource  * Changes to tests  * Fix docs  * Fix config  * Fix inspections  * Fix spelling  * Remove password from toString\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Jul 2022 11:03:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4403c15aa8a43c957d6a18ad27812c8fe7dca90\",\n",
      "\t\t\"parent\": \"f2a7970a6c219a9b536af999169d098d98547d8d\",\n",
      "\t\t\"subject\": \"Upgrade prometheus version, add more labels to PrometheusEmitter (#12769)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-prometheus-version-add-more-labels-to-PrometheusEmitter-12769\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Upgrade prometheus to version 0.16.0 - Add optional labels `druid_service` and `host_name` to `PrometheusEmitter`\",\n",
      "\t\t\"author_name\": \"Jianhuan Liu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Jul 2022 14:43:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f2a7970a6c219a9b536af999169d098d98547d8d\",\n",
      "\t\t\"parent\": \"1e0542626bb7b4726ea4d63f7cab66c2198a44e5\",\n",
      "\t\t\"subject\": \"reindex flow should take order from Druid (#12790)\",\n",
      "\t\t\"sanitized_subject_line\": \"reindex-flow-should-take-order-from-Druid-12790\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 20:03:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1e0542626bb7b4726ea4d63f7cab66c2198a44e5\",\n",
      "\t\t\"parent\": \"ee15c238cce60a92392fcf5d13c8faf50a96089b\",\n",
      "\t\t\"subject\": \"add nested column query benchmarks (#12786)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-nested-column-query-benchmarks-12786\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 18:16:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee15c238cce60a92392fcf5d13c8faf50a96089b\",\n",
      "\t\t\"parent\": \"50f1f5840d2f090179ebafbe53a27cea54e7734d\",\n",
      "\t\t\"subject\": \"Clone Calcite planner to access validator (#12708)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clone-Calcite-planner-to-access-validator-12708\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Done in preparation for the \\\"single-pass\\\" planner.  \",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 18:10:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"50f1f5840d2f090179ebafbe53a27cea54e7734d\",\n",
      "\t\t\"parent\": \"82315779ff70de1771b9a69f653c86c9ce05213a\",\n",
      "\t\t\"subject\": \"show json and add search box (#12784)\",\n",
      "\t\t\"sanitized_subject_line\": \"show-json-and-add-search-box-12784\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Yuanli Han\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 17:01:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"82315779ff70de1771b9a69f653c86c9ce05213a\",\n",
      "\t\t\"parent\": \"14e5b8325c66f5c60d324cc1b8f94a78e7fb793b\",\n",
      "\t\t\"subject\": \"fix segment timeline bar chart (#12782)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-segment-timeline-bar-chart-12782\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Yuanli Han\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 16:58:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"14e5b8325c66f5c60d324cc1b8f94a78e7fb793b\",\n",
      "\t\t\"parent\": \"e25ba00470c17e6ff50c4d70d96b1c7ba0a1f200\",\n",
      "\t\t\"subject\": \"make tick formatting more robust (#12788)\",\n",
      "\t\t\"sanitized_subject_line\": \"make-tick-formatting-more-robust-12788\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 16:56:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e25ba00470c17e6ff50c4d70d96b1c7ba0a1f200\",\n",
      "\t\t\"parent\": \"05b2e967ed8f99bc4c81197dddad7b4fe1b71a85\",\n",
      "\t\t\"subject\": \"fix bug in ObjectFlatteners.toMap which caused null values in avro-stream/avro-ocf/parquet/orc to be converted to {} instead of null in web-console sampler UI (#12785)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-in-ObjectFlatteners.toMap-which-caused-null-values-in-avro-stream-avro-ocf-parquet-orc-to-be-converted-to-instead-of-null-in-web-console-sampler-UI-12785\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix bug in ObjectFlatteners.toMap which caused null values in avro-stream/avro-ocf/parquet/orc to be converted to {} instead of null * fix parquet test that expected wrong behavior, my bad heh\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 16:52:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"05b2e967ed8f99bc4c81197dddad7b4fe1b71a85\",\n",
      "\t\t\"parent\": \"a544aff7618460b2e7d74a9576f421a7197fde14\",\n",
      "\t\t\"subject\": \"druid nested data column type (#12753)\",\n",
      "\t\t\"sanitized_subject_line\": \"druid-nested-data-column-type-12753\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add new druid nested data column type  * fixes and such  * fixes  * adjustments, more tests  * self review  * oops  * fix and test  * more better  * style\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 12:07:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a544aff7618460b2e7d74a9576f421a7197fde14\",\n",
      "\t\t\"parent\": \"c0380e7b0ad84b65f6af22e08b9c20b3222221f7\",\n",
      "\t\t\"subject\": \"Document missed simple granularities (#12768)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-missed-simple-granularities-12768\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Document missed simple granularities  * Update docs/querying/granularities.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/granularities.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 14:02:28 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c0380e7b0ad84b65f6af22e08b9c20b3222221f7\",\n",
      "\t\t\"parent\": \"d8f8c56f94434b078d4c399b1653c9559f8b1a15\",\n",
      "\t\t\"subject\": \"* fix duplicate dimension (#12778)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-duplicate-dimension-12778\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 10:39:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d8f8c56f94434b078d4c399b1653c9559f8b1a15\",\n",
      "\t\t\"parent\": \"8c33508eafa6aa2e02bc8da309ed1abf00fbc3dd\",\n",
      "\t\t\"subject\": \"Docs: Index page with all SQL functions (#12771)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Index-page-with-all-SQL-functions-12771\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* list of all functions  * add function names to spelling file\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Jul 2022 09:59:55 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8c33508eafa6aa2e02bc8da309ed1abf00fbc3dd\",\n",
      "\t\t\"parent\": \"c1c2104bd6f258b1b1386e3c6006d4ca56c5846d\",\n",
      "\t\t\"subject\": \"run web-console e2e tests for java changes too (#12776)\",\n",
      "\t\t\"sanitized_subject_line\": \"run-web-console-e2e-tests-for-java-changes-too-12776\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* run web-console e2e tests for java changes too, fix travis stages for web e2e and docs jobs  * run the script test on script changes\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Jul 2022 16:12:57 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1c2104bd6f258b1b1386e3c6006d4ca56c5846d\",\n",
      "\t\t\"parent\": \"2ab20c9fc949d9099858ddcaedd67b372df4e76c\",\n",
      "\t\t\"subject\": \"fix ordering in e2e test (#12775)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-ordering-in-e2e-test-12775\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Jul 2022 15:08:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2ab20c9fc949d9099858ddcaedd67b372df4e76c\",\n",
      "\t\t\"parent\": \"8c02880d5f3e48d3e8189a240eae391eb6107862\",\n",
      "\t\t\"subject\": \"Surface more information about task status in tests (#12759)\",\n",
      "\t\t\"sanitized_subject_line\": \"Surface-more-information-about-task-status-in-tests-12759\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"I see some test runs failing because task status is not as expected. It will be helpful to know what error the task has.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Jul 2022 14:53:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8c02880d5f3e48d3e8189a240eae391eb6107862\",\n",
      "\t\t\"parent\": \"bb953be09bff79361331f74efa99317d2f3e6187\",\n",
      "\t\t\"subject\": \"Emit metrics for distribution of number of rows per segment (#12730)\",\n",
      "\t\t\"sanitized_subject_line\": \"Emit-metrics-for-distribution-of-number-of-rows-per-segment-12730\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* initial commit of bucket dimensions for metrics  return counts of segments that have rowcount in a bucket size for a datasource return average value of rowcount per segment in a datasource added unit test naming could use a lot of work buckets right now are not finalized added javadocs altered metrics.md  * fix checkstyle issues  * addressed review comments  add monitor test move added functionality to new monitor update docs  * address comments  renamed monitor handle tombstones better update docs added javadocs  * Add support for tombstones in the segment distribution  * undo changes to tombstone segmentizer factory  * fix accidental whitespacing changes  * address comments regarding metrics documentation  and rename variable to be more accurate  * fix tests  * fix checkstyle issues  * fix broken test  * undo removal of timeout\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 12 Jul 2022 07:04:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bb953be09bff79361331f74efa99317d2f3e6187\",\n",
      "\t\t\"parent\": \"cebf2ba9c79df12c214364380ccb53207776e34e\",\n",
      "\t\t\"subject\": \"Refactor usage of JoinableFactoryWrapper + more test coverage (#12767)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-usage-of-JoinableFactoryWrapper-more-test-coverage-12767\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Refactor usage of JoinableFactoryWrapper to add e2e test for createSegmentMapFn with joinToFilter feature enabled\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 12 Jul 2022 06:25:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cebf2ba9c79df12c214364380ccb53207776e34e\",\n",
      "\t\t\"parent\": \"97207cdcc7c8445bd3875bae0c41e5d2c0c9b082\",\n",
      "\t\t\"subject\": \"[Flaky unit test] Adding file based uri. (#12671)\",\n",
      "\t\t\"sanitized_subject_line\": \"Flaky-unit-test-Adding-file-based-uri.-12671\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding file based uri.  * Adding the HTTP entity test back\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Jul 2022 20:57:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"97207cdcc7c8445bd3875bae0c41e5d2c0c9b082\",\n",
      "\t\t\"parent\": \"d2576584a082be33cc540be57a9b33798aeed50e\",\n",
      "\t\t\"subject\": \"Automatic sizing for GroupBy dictionaries. (#12763)\",\n",
      "\t\t\"sanitized_subject_line\": \"Automatic-sizing-for-GroupBy-dictionaries.-12763\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Automatic sizing for GroupBy dictionary sizes.  Merging and selector dictionary sizes currently both default to 100MB. This is not optimal, because it can lead to OOM on small servers and insufficient resource utilization on larger servers. It also invites end users to try to tune it when queries run out of dictionary space, which can make things worse if the end user sets it to too high.  So, this patch:  - Adds automatic tuning for selector and merge dictionaries. Selectors   use up to 15% of the heap and merge buffers use up to 30% of the heap   (aggregate across all queries).  - Updates out-of-memory error messages to emphasize enabling disk   spilling vs. increasing memory parameters. With the memory parameters   automatically sized, it is more likely that an end user will get   benefit from enabling disk spilling.  - Removes the query context parameters that allow lowering of configured   dictionary sizes. These complicate the calculation, and I don't see a   reasonable use case for them.  * Adjust tests.  * Review adjustments.  * Additional comment.  * Remove unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Jul 2022 08:20:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d2576584a082be33cc540be57a9b33798aeed50e\",\n",
      "\t\t\"parent\": \"32946216d08c61ddb07b651b7f9976efabdd95b6\",\n",
      "\t\t\"subject\": \"Consolidate the two TaskStatus classes. (#12765)\",\n",
      "\t\t\"sanitized_subject_line\": \"Consolidate-the-two-TaskStatus-classes.-12765\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Consolidate the two TaskStatus classes.  There are two, but we don't need more than one.  * Fix import order.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Jul 2022 07:25:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"32946216d08c61ddb07b651b7f9976efabdd95b6\",\n",
      "\t\t\"parent\": \"864b77e91acc7064ce6ee6b06e1b497c990c79de\",\n",
      "\t\t\"subject\": \"Debugs Flaky License dependency Reports generation (#12744)\",\n",
      "\t\t\"sanitized_subject_line\": \"Debugs-Flaky-License-dependency-Reports-generation-12744\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Surfaces mvn command output in case of failure.  * formats output  * nit\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Jul 2022 14:35:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"864b77e91acc7064ce6ee6b06e1b497c990c79de\",\n",
      "\t\t\"parent\": \"8dc4a155c7d7d9a0b67c98eb2608852bd639528e\",\n",
      "\t\t\"subject\": \"SpillingGrouper: Make DISK_FULL sticky. (#12764)\",\n",
      "\t\t\"sanitized_subject_line\": \"SpillingGrouper-Make-DISK_FULL-sticky.-12764\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"When we return DISK_FULL to a processing thread, it skips the rest of the segment and the query is canceled. However, it's possible that the next segment starts processing before cancellation can kick in. We want that one, if it occurs, to see DISK_FULL too.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Jul 2022 06:45:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8dc4a155c7d7d9a0b67c98eb2608852bd639528e\",\n",
      "\t\t\"parent\": \"1558ef471cd727b82c03d63f12c2f37e8a60b9c8\",\n",
      "\t\t\"subject\": \"Fix flaky IT: ITPerfectRollupParallelBatchIndexTest (#12737)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-IT-ITPerfectRollupParallelBatchIndexTest-12737\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Increase worker.intermediaryPartitionTimeout in ITs to 30 mins  * Update timeout to 60 mins  * Remove timeout change from indexer\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Jul 2022 17:15:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1558ef471cd727b82c03d63f12c2f37e8a60b9c8\",\n",
      "\t\t\"parent\": \"48fd2e64007988e0764e8179fcd47230ab1e7dcc\",\n",
      "\t\t\"subject\": \"Add some debug tips for debugging peons (#12697)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-some-debug-tips-for-debugging-peons-12697\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add some debug tips  * address comments  * fix typo\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Jul 2022 01:47:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48fd2e64007988e0764e8179fcd47230ab1e7dcc\",\n",
      "\t\t\"parent\": \"edfbcc8455bcc71fd5584e4beceece5cd50b8828\",\n",
      "\t\t\"subject\": \"Add missing metrics into statsd-reporter. (#12762)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-missing-metrics-into-statsd-reporter.-12762\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 23:13:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"edfbcc8455bcc71fd5584e4beceece5cd50b8828\",\n",
      "\t\t\"parent\": \"9c925b4f09a4a2b8cd1734c802f196b55c1cef0e\",\n",
      "\t\t\"subject\": \"Preserve column order in DruidSchema, SegmentMetadataQuery. (#12754)\",\n",
      "\t\t\"sanitized_subject_line\": \"Preserve-column-order-in-DruidSchema-SegmentMetadataQuery.-12754\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Preserve column order in DruidSchema, SegmentMetadataQuery.  Instead of putting columns in alphabetical order. This is helpful because it makes query order better match ingestion order. It also allows tools, like the reindexing flow in the web console, to more easily do follow-on ingestions using a column order that matches the pre-existing column order.  We prefer the order from the latest segments. The logic takes all columns from the latest segments in the order they appear, then adds on columns from older segments after those.  * Additional test adjustments.  * Adjust imports.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 22:04:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9c925b4f09a4a2b8cd1734c802f196b55c1cef0e\",\n",
      "\t\t\"parent\": \"bcff35f798ffbce235adf34d68f1901bcbc6b909\",\n",
      "\t\t\"subject\": \"Frame format for data transfer and short-term storage. (#12745)\",\n",
      "\t\t\"sanitized_subject_line\": \"Frame-format-for-data-transfer-and-short-term-storage.-12745\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Frame format for data transfer and short-term storage.  As we move towards query execution plans that involve more transfer of data between servers, it's important to have a data format that provides for doing this more efficiently than the options available to us today.  This patch adds:  - Columnar frames, which support fast querying. - Row-based frames, which support fast sorting via memory comparison   and fast whole-row copies via memory copying. - Frame files, a container format that can be stored on disk or   transferred between servers.  The idea is we should use row-based frames when data is expected to be sorted, and columnar frames when data is expected to be queried.  The code in this patch is not used in production yet. Therefore, the patch involves minimal changes outside of the org.apache.druid.frame package.  The main ones are adjustments to SqlBenchmark to add benchmarks for queries on frames, and the addition of a \\\"forEach\\\" method to Sequence.  * Fixes based on tests, static analysis.  * Additional fixes.  * Skip DS mapping tests on JDK 14+  * Better JDK checking in tests.  * Fix imports.  * Additional comment.  * Adjustments from code review.  * Update test case.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 20:42:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bcff35f798ffbce235adf34d68f1901bcbc6b909\",\n",
      "\t\t\"parent\": \"378fea951756483831e47502fd18fb5ed58747af\",\n",
      "\t\t\"subject\": \"Pushdown join filter with right side referencing columns (#12749)\",\n",
      "\t\t\"sanitized_subject_line\": \"Pushdown-join-filter-with-right-side-referencing-columns-12749\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 19:59:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"378fea951756483831e47502fd18fb5ed58747af\",\n",
      "\t\t\"parent\": \"4574dea5e92beb72d93e1d6900ce1a63627330d0\",\n",
      "\t\t\"subject\": \"Retain CSP configuration in ServerConfig constructor. (#12755)\",\n",
      "\t\t\"sanitized_subject_line\": \"Retain-CSP-configuration-in-ServerConfig-constructor.-12755\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Without this change, CliIndexer would not apply custom CSP headers and would revert to the default.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 19:19:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4574dea5e92beb72d93e1d6900ce1a63627330d0\",\n",
      "\t\t\"parent\": \"e82890fde4ce9b6e45e0f4fe7e5147e161897a85\",\n",
      "\t\t\"subject\": \"Use MXBeans to get GC metrics #12476 (#12481)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-MXBeans-to-get-GC-metrics-12476-12481\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* jvm gc to mxbeans  * add zgc and shenandoah #12476  * remove tryCreateGcCounter  * separate the space collector  * blend GcGenerationCollector into GcCollector  * add jdk surefire argLine\",\n",
      "\t\t\"author_name\": \"Jianhuan Liu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Jul 2022 14:32:06 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e82890fde4ce9b6e45e0f4fe7e5147e161897a85\",\n",
      "\t\t\"parent\": \"059aba781a59652c09ddea29b7bd6c7d592fb3ce\",\n",
      "\t\t\"subject\": \"Mark specific nimbus.lang.tag.version. (#12751)\",\n",
      "\t\t\"sanitized_subject_line\": \"Mark-specific-nimbus.lang.tag.version.-12751\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Mark specific nimbus.lang.tag.version.  * Add ignoredUnusedDeclaredDependencies.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Jul 2022 09:58:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"059aba781a59652c09ddea29b7bd6c7d592fb3ce\",\n",
      "\t\t\"parent\": \"d732de99486988a4311e1bf5621d4a6d5511b950\",\n",
      "\t\t\"subject\": \"issue-12628: upgrade jetty to 9.4.41.v20210516 due to CVE (#12629)\",\n",
      "\t\t\"sanitized_subject_line\": \"issue-12628-upgrade-jetty-to-9.4.41.v20210516-due-to-CVE-12629\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* upgrade jetty to 9.4.41.v20210516 due to cve  * Update licenses.yaml\",\n",
      "\t\t\"author_name\": \"PJ Fanning\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Jul 2022 00:20:01 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d732de99486988a4311e1bf5621d4a6d5511b950\",\n",
      "\t\t\"parent\": \"49feffff1bd72781e2ca4c27312aedaf50b0510b\",\n",
      "\t\t\"subject\": \"Allow adding calcite rules from extensions (#12715)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-adding-calcite-rules-from-extensions-12715\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Allow adding calcite rules from extensions  * fixup! Allow adding calcite rules from extensions  * Move Rules to CalciteRulesManager  * fixup! Move Rules to CalciteRulesManager\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Jul 2022 19:32:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"49feffff1bd72781e2ca4c27312aedaf50b0510b\",\n",
      "\t\t\"parent\": \"682ea7f32d6669fbfd55deddd57f736a473a7b7b\",\n",
      "\t\t\"subject\": \"Add comment about double-close in ColumnSelectorColumnIndexSelector. (#12735)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-comment-about-double-close-in-ColumnSelectorColumnIndexSelector.-12735\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Jul 2022 00:50:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"682ea7f32d6669fbfd55deddd57f736a473a7b7b\",\n",
      "\t\t\"parent\": \"06251c5d2afff5534d136fe7ce1bababaa1fe8c5\",\n",
      "\t\t\"subject\": \"IMPLY-12348: Update description of UNION ALL in SQL syntax doc (#12710)\",\n",
      "\t\t\"sanitized_subject_line\": \"IMPLY-12348-Update-description-of-UNION-ALL-in-SQL-syntax-doc-12710\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* IMPLY-12348: Updated description of UNION ALL  * Update docs/querying/sql.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/sql.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update sql.md  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Jul 2022 13:08:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"06251c5d2afff5534d136fe7ce1bababaa1fe8c5\",\n",
      "\t\t\"parent\": \"2b330186e2a35ead88f3e1a5bfcd4de8853d081a\",\n",
      "\t\t\"subject\": \"Add EIGHT_HOUR into possible list of Granularities. (#12717)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-EIGHT_HOUR-into-possible-list-of-Granularities.-12717\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add EIGHT_HOUR into possible list of Granularities.  * Add the missing definition.  * fix test.  * Fix another test.  * Stylecheck finally passed.  Co-authored-by: Didip Kerabat <didip@apple.com>\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Jul 2022 11:05:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b330186e2a35ead88f3e1a5bfcd4de8853d081a\",\n",
      "\t\t\"parent\": \"36e38b319b9dfe5314932e6b938c01ecddfc7456\",\n",
      "\t\t\"subject\": \"Mid-level service client and updated high-level clients. (#12696)\",\n",
      "\t\t\"sanitized_subject_line\": \"Mid-level-service-client-and-updated-high-level-clients.-12696\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Mid-level service client and updated high-level clients.  Our servers talk to each other over HTTP. We have a low-level HTTP client (HttpClient) that is super-asynchronous and super-customizable through its handlers. It's also proven to be quite robust: we use it for Broker -> Historical communication over the wide variety of query types and workloads we support.  But the low-level client has no facilities for service location or retries, which means we have a variety of high-level clients that implement these in their own ways. Some high-level clients do a better job than others. This patch adds a mid-level ServiceClient that makes it easier for high-level clients to be built correctly and harmoniously, and migrates some of the high-level logic to use ServiceClients.  Main changes:  1) Add ServiceClient org.apache.druid.rpc package. That package also    contains supporting stuff like ServiceLocator and RetryPolicy    interfaces, and a DiscoveryServiceLocator based on    DruidNodeDiscoveryProvider.  2) Add high-level OverlordClient in org.apache.druid.rpc.indexing.  3) Indexing task client creator in TaskServiceClients. It uses    SpecificTaskServiceLocator to find the tasks. This improves on    ClientInfoTaskProvider by caching task locations for up to 30 seconds    across calls, reducing load on the Overlord.  4) Rework ParallelIndexSupervisorTaskClient to use a ServiceClient    instead of extending IndexTaskClient.  5) Rework RemoteTaskActionClient to use a ServiceClient instead of    DruidLeaderClient.  6) Rework LocalIntermediaryDataManager, TaskMonitor, and    ParallelIndexSupervisorTask. As a result, MiddleManager, Peon, and    Overlord no longer need IndexingServiceClient (which internally used    DruidLeaderClient).  There are some concrete benefits over the prior logic, namely:  - DruidLeaderClient does retries in its \\\"go\\\" method, but only retries   exactly 5 times, does not sleep between retries, and does not retry   retryable HTTP codes like 502, 503, 504. (It only retries IOExceptions.)   ServiceClient handles retries in a more reasonable way.  - DruidLeaderClient's methods are all synchronous, whereas ServiceClient   methods are asynchronous. This is used in one place so far: the   SpecificTaskServiceLocator, so we don't need to block a thread trying   to locate a task. It can be used in other places in the future.  - HttpIndexingServiceClient does not properly handle all server errors.   In some cases, it tries to parse a server error as a successful   response (for example: in getTaskStatus).  - IndexTaskClient currently makes an Overlord call on every task-to-task   HTTP request, as a way to find where the target task is. ServiceClient,   through SpecificTaskServiceLocator, caches these target locations   for a period of time.  * Style adjustments.  * For the coverage.  * Adjustments.  * Better behaviors.  * Fixes.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Jul 2022 09:43:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36e38b319b9dfe5314932e6b938c01ecddfc7456\",\n",
      "\t\t\"parent\": \"97a926fb29e7750db0836432615fd86b843edd1e\",\n",
      "\t\t\"subject\": \"add virtual column support to search query (#12720)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-virtual-column-support-to-search-query-12720\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Jul 2022 21:58:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"97a926fb29e7750db0836432615fd86b843edd1e\",\n",
      "\t\t\"parent\": \"d559773a0e3679a6894390b17380332b84843f57\",\n",
      "\t\t\"subject\": \"Suppress CVE-2022-33915 (#12740)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVE-2022-33915-12740\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Jul 2022 22:48:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d559773a0e3679a6894390b17380332b84843f57\",\n",
      "\t\t\"parent\": \"e3128e3fa322963b902ebecbdec60c740f55dd62\",\n",
      "\t\t\"subject\": \"sets Hadoop conf ClassLoader (#12738)\",\n",
      "\t\t\"sanitized_subject_line\": \"sets-Hadoop-conf-ClassLoader-12738\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Jul 2022 17:07:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e3128e3fa322963b902ebecbdec60c740f55dd62\",\n",
      "\t\t\"parent\": \"bbbb6e1c3f9ea52766fe0c330fe8e6d0249560a4\",\n",
      "\t\t\"subject\": \"Poison stupid pool (#12646)\",\n",
      "\t\t\"sanitized_subject_line\": \"Poison-stupid-pool-12646\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Poison StupidPool and fix resource leaks  There are various resource leaks from test setup as well as some corners in query processing.  We poison the StupidPool to start failing tests when the leaks come and fix any issues uncovered from that so that we can start from a clean baseline.  Unfortunately, because of how poisoning works, we can only fail future checkouts from the same pool, which means that there is a natural race between a leak happening -> GC occurs -> leak detected -> pool poisoned.  This race means that, depending on interleaving of tests, if the very last time that an object is checked out from the pool leaks, then it won't get caught. At some point in the future, something will catch it,  however and from that point on it will be deterministic.  * Remove various things left over from iterations  * Clean up FilterAnalysis and add javadoc on StupidPool  * Revert changes to .idea/misc.xml that accidentally got pushed  * Style and test branches  * Stylistic woes\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 3 Jul 2022 14:36:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bbbb6e1c3f9ea52766fe0c330fe8e6d0249560a4\",\n",
      "\t\t\"parent\": \"f5b5cb93ead1cb3bbd7a525445be2461c977c52c\",\n",
      "\t\t\"subject\": \"fix DruidSchema issue where datasources with no segments can become stuck in tables list indefinitely (#12727)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-DruidSchema-issue-where-datasources-with-no-segments-can-become-stuck-in-tables-list-indefinitely-12727\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 1 Jul 2022 18:54:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f5b5cb93ead1cb3bbd7a525445be2461c977c52c\",\n",
      "\t\t\"parent\": \"48731710fb54270758e29609968b6a1747616de6\",\n",
      "\t\t\"subject\": \"Fix expiry timeout bug in LocalIntermediateDataManager (#12722)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-expiry-timeout-bug-in-LocalIntermediateDataManager-12722\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The expiry timeout is compared against the current time but the condition is reversed. This means that as soon as a supervisor task finishes, its partitions are cleaned up, irrespective of the specified `intermediaryPartitionTimeout` period.  After these changes, the `intermediaryPartitionTimeout` will start getting honored.  Changes * Fix the condition * Add tests to verify the new correct behaviour * Reduce the default expiry timeout from P1D to PT5M    to retain current behaviour in case of default configs.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 1 Jul 2022 16:29:22 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48731710fb54270758e29609968b6a1747616de6\",\n",
      "\t\t\"parent\": \"d30efb1c1e2b36099727c48f7252cc0bd88a67e7\",\n",
      "\t\t\"subject\": \"precursor changes for nested columns to minimize files changed (#12714)\",\n",
      "\t\t\"sanitized_subject_line\": \"precursor-changes-for-nested-columns-to-minimize-files-changed-12714\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* precursor changes for nested columns to minimize files changed  * inspection fix  * visibility  * adjustment  * unecessary change\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 1 Jul 2022 02:27:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d30efb1c1e2b36099727c48f7252cc0bd88a67e7\",\n",
      "\t\t\"parent\": \"c09b5a2294f7d4357ed0484f7e1d6c5088b9b450\",\n",
      "\t\t\"subject\": \"fix bug when rewriting sql virtual column registry (#12718)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-bug-when-rewriting-sql-virtual-column-registry-12718\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 1 Jul 2022 02:24:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c09b5a2294f7d4357ed0484f7e1d6c5088b9b450\",\n",
      "\t\t\"parent\": \"068bea63346d1bbf12b8483e8811546c9405a380\",\n",
      "\t\t\"subject\": \"Fix skipTests build flag (#12716)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-skipTests-build-flag-12716\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix skipTests  * Skip console UTs with skipTests  * Use skipTests in skip-tests profile\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Jun 2022 21:59:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"068bea63346d1bbf12b8483e8811546c9405a380\",\n",
      "\t\t\"parent\": \"dbd45daf33f5d94ee0172edb9fa2744914b6dcc6\",\n",
      "\t\t\"subject\": \"deps: upgrade mysql-connector-java to v5.1.49 (#12704)\",\n",
      "\t\t\"sanitized_subject_line\": \"deps-upgrade-mysql-connector-java-to-v5.1.49-12704\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rui Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 29 Jun 2022 23:15:46 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dbd45daf33f5d94ee0172edb9fa2744914b6dcc6\",\n",
      "\t\t\"parent\": \"f83fab699ee3756d3a749961efa2dca41fad7841\",\n",
      "\t\t\"subject\": \"Flakiness and exceptions during tests (#12705)\",\n",
      "\t\t\"sanitized_subject_line\": \"Flakiness-and-exceptions-during-tests-12705\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 28 Jun 2022 10:36:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f83fab699ee3756d3a749961efa2dca41fad7841\",\n",
      "\t\t\"parent\": \"f7caee3b2595e339e7044735538cb6b98b979765\",\n",
      "\t\t\"subject\": \"Add IT-related changes pulled out of PR #12368 (#12673)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-IT-related-changes-pulled-out-of-PR-12368-12673\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit contains changes made to the existing ITs to support the new ITs.  Changes: - Make the \\\"custom node role\\\" code usable by the new ITs.  - Use flag `-DskipITs` to skips the integration tests but runs unit tests. - Use flag `-DskipUTs` skips unit tests but runs the \\\"new\\\" integration tests. - Expand the existing Druid profile, `-P skip-tests` to skip both ITs and UTs.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 26 Jun 2022 02:13:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7caee3b2595e339e7044735538cb6b98b979765\",\n",
      "\t\t\"parent\": \"679ccffe0fe11cd4ecc5998138c7436bb0b5955a\",\n",
      "\t\t\"subject\": \"Revert changes from #12672 (#12703)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-changes-from-12672-12703\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Revert changes from #12672  * Reverted more conflicting changes  Changes are not needed given previous reversions.\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 25 Jun 2022 09:10:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"679ccffe0fe11cd4ecc5998138c7436bb0b5955a\",\n",
      "\t\t\"parent\": \"2aadd69f54a130e4e0b5b0827ac5b8f22fa46c1b\",\n",
      "\t\t\"subject\": \"Revert \\\"SqlSegmentsMetadataQuery: Fix OVERLAPS for wide target segments. (#12600)\\\" (#12679)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-SqlSegmentsMetadataQuery-Fix-OVERLAPS-for-wide-target-segments.-12600-12679\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit 8fbf92e047f792ff1c69bf67d14784ac55eee88f.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 25 Jun 2022 09:08:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2aadd69f54a130e4e0b5b0827ac5b8f22fa46c1b\",\n",
      "\t\t\"parent\": \"d5abd06b9679d0223b8362855de5cb064ad76ef0\",\n",
      "\t\t\"subject\": \"Update ORC to 1.7.5 (#12667)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ORC-to-1.7.5-12667\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"William Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Jun 2022 16:08:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d5abd06b9679d0223b8362855de5cb064ad76ef0\",\n",
      "\t\t\"parent\": \"6ddb828c7a6422f6d2b2a9c59810b5aea7d518ef\",\n",
      "\t\t\"subject\": \"Fix flaky KafkaIndexTaskTest. (#12657)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-flaky-KafkaIndexTaskTest.-12657\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix flaky KafkaIndexTaskTest.  The testRunTransactionModeRollback case had many race conditions. Most notably, it would commit a transaction and then immediately check to see that the results were *not* indexed. This is racey because it relied on the indexing thread being slower than the test thread.  Now, the case waits for the transaction to be processed by the indexing thread before checking the results.  * Changes from review.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Jun 2022 13:53:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ddb828c7a6422f6d2b2a9c59810b5aea7d518ef\",\n",
      "\t\t\"parent\": \"1fc2f6e4b08d92f0c68d31afd7890ea9c211d4c2\",\n",
      "\t\t\"subject\": \"Able to filter Cloud objects with glob notation. (#12659)\",\n",
      "\t\t\"sanitized_subject_line\": \"Able-to-filter-Cloud-objects-with-glob-notation.-12659\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In a heterogeneous environment, sometimes you don't have control over the input folder. Upstream can put any folder they want. In this situation the S3InputSource.java is unusable.  Most people like me solved it by using Airflow to fetch the full list of parquet files and pass it over to Druid. But doing this explodes the JSON spec. We had a situation where 1 of the JSON spec is 16MB and that's simply too much for Overlord.  This patch allows users to pass {\\\"filter\\\": \\\"*.parquet\\\"} and let Druid performs the filtering of the input files.  I am using the glob notation to be consistent with the LocalFirehose syntax.\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Jun 2022 11:40:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1fc2f6e4b08d92f0c68d31afd7890ea9c211d4c2\",\n",
      "\t\t\"parent\": \"d29343cbe36357356ec65a2f56087d5b39e92148\",\n",
      "\t\t\"subject\": \"Throw BadQueryContextException if context params cannot be parsed (#12680)\",\n",
      "\t\t\"sanitized_subject_line\": \"Throw-BadQueryContextException-if-context-params-cannot-be-parsed-12680\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 24 Jun 2022 09:21:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d29343cbe36357356ec65a2f56087d5b39e92148\",\n",
      "\t\t\"parent\": \"ffcb996468c343450258f90bd88a6b55aae4ef59\",\n",
      "\t\t\"subject\": \"Disable autokill of segments by default. (#12693)\",\n",
      "\t\t\"sanitized_subject_line\": \"Disable-autokill-of-segments-by-default.-12693\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Also add clarifying commentary to the documentation about how durationToRetain works.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Jun 2022 17:17:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffcb996468c343450258f90bd88a6b55aae4ef59\",\n",
      "\t\t\"parent\": \"3d9e3dbad9d38b6be42ea29b4cf7bd9d49ce5d77\",\n",
      "\t\t\"subject\": \"Cleanup changes pulled out of PR #12368 (#12672)\",\n",
      "\t\t\"sanitized_subject_line\": \"Cleanup-changes-pulled-out-of-PR-12368-12672\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit contains the cleanup needed for the new integration test framework.  Changes: - Fix log lines, misspellings, docs, etc. - Allow the use of some of Druid's \\\"JSON config\\\" objects in tests - Fix minor bug in `BaseNodeRoleWatcher`\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Jun 2022 23:19:50 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3d9e3dbad9d38b6be42ea29b4cf7bd9d49ce5d77\",\n",
      "\t\t\"parent\": \"4d892483ca0b45c105cb645768f03ef93cb517da\",\n",
      "\t\t\"subject\": \"Fix hadoop library location for integration tests (#12497)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-hadoop-library-location-for-integration-tests-12497\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 23 Jun 2022 10:39:54 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4d892483ca0b45c105cb645768f03ef93cb517da\",\n",
      "\t\t\"parent\": \"b6f8d7a1b39793f7941e450925952c50e53fba9f\",\n",
      "\t\t\"subject\": \"Fix thread-unsafe emitter usage in SeekableStreamSupervisorStateTest. (#12658)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-thread-unsafe-emitter-usage-in-SeekableStreamSupervisorStateTest.-12658\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The TestEmitter is used from different threads without concurrency control. This patch makes the emitter thread-safe.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Jun 2022 22:29:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b6f8d7a1b39793f7941e450925952c50e53fba9f\",\n",
      "\t\t\"parent\": \"6bcb778eeb619c7d41c14e635e3dd6655dfd0599\",\n",
      "\t\t\"subject\": \"Add query context param `forceExpressionVirtualColumns` to always use \\\"expression\\\"-type virtual columns in query plan (#12583)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-query-context-param-forceExpressionVirtualColumns-to-always-use-expression-type-virtual-columns-in-query-plan-12583\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"SQL expressions such as those containing `MV_FILTER_ONLY` and `MV_FILTER_NONE` are planned as specialized virtual columns instead of the default `expression`-type virtual columns. This commit adds a new context parameter to force the `expression`-type virtual columns.  Changes - Add query context param `forceExpressionVirtualColumns` - Use context param to determine if specialized virtual columns should be used or not - Moved some tests into `CalciteExplainQueryTest` \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Jun 2022 15:33:50 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6bcb778eeb619c7d41c14e635e3dd6655dfd0599\",\n",
      "\t\t\"parent\": \"99e1b4efee3fd267e65337a31a5cfb32b548c711\",\n",
      "\t\t\"subject\": \"Add CVEs for Hadoop3 (#12336)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-CVEs-for-Hadoop3-12336\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add CVEs  * Move CVEs under hadoop3 section\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Jun 2022 14:12:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"99e1b4efee3fd267e65337a31a5cfb32b548c711\",\n",
      "\t\t\"parent\": \"0099940808946812523afa5b5caa68bf52569b75\",\n",
      "\t\t\"subject\": \"Update default value of `inputSegmentSizeBytes` in configuration docs (#12678)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-default-value-of-inputSegmentSizeBytes-in-configuration-docs-12678\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Jun 2022 09:05:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0099940808946812523afa5b5caa68bf52569b75\",\n",
      "\t\t\"parent\": \"eccdec9139c6946e26dbebe9be35f7c9f9cb521c\",\n",
      "\t\t\"subject\": \"Add TIME_IN_INTERVAL SQL operator. (#12662)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-TIME_IN_INTERVAL-SQL-operator.-12662\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add TIME_IN_INTERVAL SQL operator.  The operator is implemented as a convertlet rather than an OperatorConversion, because this allows it to be equivalent to using the >= and < operators directly.  * SqlParserPos cannot be null here.  * Remove unused import.  * Doc updates.  * Add words to dictionary.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Jun 2022 13:05:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eccdec9139c6946e26dbebe9be35f7c9f9cb521c\",\n",
      "\t\t\"parent\": \"a85b1d898557490ecc4ef1c4d2b8ea813e811389\",\n",
      "\t\t\"subject\": \"Reduce interval creation cost for segment cost computation (#12670)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-interval-creation-cost-for-segment-cost-computation-12670\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Reuse created interval in `SegmentId.getInterval()` - Intern intervals to save on memory footprint\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Jun 2022 17:39:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a85b1d898557490ecc4ef1c4d2b8ea813e811389\",\n",
      "\t\t\"parent\": \"818974f6e4d67651f8fe0f307a10ff72bebf385c\",\n",
      "\t\t\"subject\": \"Lazy Initialisation of Orc extensions module (#12663)\",\n",
      "\t\t\"sanitized_subject_line\": \"Lazy-Initialisation-of-Orc-extensions-module-12663\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Lazy initialization of Orc extension  * nit  * moving intialize method to OrcInputFormat\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Jun 2022 11:13:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"818974f6e4d67651f8fe0f307a10ff72bebf385c\",\n",
      "\t\t\"parent\": \"e76a5077efe64ea3108ff1133339c1ba5d19163f\",\n",
      "\t\t\"subject\": \"ScanQuery: Fix JsonIgnore for isLegacy. (#12674)\",\n",
      "\t\t\"sanitized_subject_line\": \"ScanQuery-Fix-JsonIgnore-for-isLegacy.-12674\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"True, false, and null have different meanings: true/false mean \\\"legacy\\\" and \\\"not legacy\\\"; null means use the default set by ScanQueryConfig. So, we need to respect this in the JsonIgnore setup.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 18 Jun 2022 15:55:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e76a5077efe64ea3108ff1133339c1ba5d19163f\",\n",
      "\t\t\"parent\": \"18937ffee210fb230737aac20e48ede9601b8096\",\n",
      "\t\t\"subject\": \"Fix self-referential shape inspection in BaseExpressionColumnValueSelector. (#12669)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-self-referential-shape-inspection-in-BaseExpressionColumnValueSelector.-12669\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix self-referential shape inspection in BaseExpressionColumnValueSelector.  The new test would throw StackOverflowError on the old code.  * Restore prior test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Jun 2022 16:15:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"18937ffee210fb230737aac20e48ede9601b8096\",\n",
      "\t\t\"parent\": \"893759de91133efee56a2ac919532afa4cb61bd3\",\n",
      "\t\t\"subject\": \"split out null value index (#12627)\",\n",
      "\t\t\"sanitized_subject_line\": \"split-out-null-value-index-12627\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* split out null value index  * gg spotbugs  * fix stuff\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Jun 2022 15:29:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"893759de91133efee56a2ac919532afa4cb61bd3\",\n",
      "\t\t\"parent\": \"f050069767b60c40be3ab2d01c8d6d957a1463dc\",\n",
      "\t\t\"subject\": \"Remove null and empty fields from native queries (#12634)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-null-and-empty-fields-from-native-queries-12634\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove null and empty fields from native queries  * Test fixes  * Attempted IT fix.  * Revisions from review comments  * Build fixes resulting from changes suggested by reviews  * IT fix for changed segment size\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Jun 2022 14:07:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f050069767b60c40be3ab2d01c8d6d957a1463dc\",\n",
      "\t\t\"parent\": \"f970757efc3413ce97b50fd06c57ac6f5ec39c46\",\n",
      "\t\t\"subject\": \"Segments doc update (#12344)\",\n",
      "\t\t\"sanitized_subject_line\": \"Segments-doc-update-12344\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Corrected heading levels in segments doc  * IMPLY-18394: Updated Segments doc  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/segments.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update segments.md  * Updated links to changed headings in Segments doc  * Corrected spelling error  * Update segments.md  Incorporated suggestions from Paul Rogers.  * Update index.md  * Update segments.md  * Update segments.md  * Update segments.md  * Update compaction.md  * Update docs/design/segments.md  fix typo  * Update docs/ingestion/compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/design/segments.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Jun 2022 13:25:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f970757efc3413ce97b50fd06c57ac6f5ec39c46\",\n",
      "\t\t\"parent\": \"602d95d86591869aa221701c72dfe3f7326da6e3\",\n",
      "\t\t\"subject\": \"Optimize overlord GET /tasks memory usage (#12404)\",\n",
      "\t\t\"sanitized_subject_line\": \"Optimize-overlord-GET-tasks-memory-usage-12404\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The web-console (indirectly) calls the Overlord\\u2019s GET tasks API to fetch the tasks' summary which in turn queries the metadata tasks table. This query tries to fetch several columns, including payload, of all the rows at once. This introduces a significant memory overhead and can cause unresponsiveness or overlord failure when the ingestion tab is opened multiple times (due to several parallel calls to this API)  Another thing to note is that the task table (the payload column in particular) can be very large. Extracting large payloads from such tables can be very slow, leading to slow UI. While we are fixing the memory pressure in the overlord, we can also fix the slowness in UI caused by fetching large payloads from the table. Fetching large payloads also puts pressure on the metadata store as reported in the community (Metadata store query performance degrades as the tasks in druid_tasks table grows \\u00b7 Issue #12318 \\u00b7 apache/druid )  The task summaries returned as a response for the API are several times smaller and can fit comfortably in memory. So, there is an opportunity here to fix the memory usage, slow ingestion, and under-pressure metadata store by removing the need to handle large payloads in every layer we can. Of course, the solution becomes complex as we try to fix more layers. With that in mind, this page captures two approaches. They vary in complexity and also in the degree to which they fix the aforementioned problems.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Jun 2022 22:30:37 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"602d95d86591869aa221701c72dfe3f7326da6e3\",\n",
      "\t\t\"parent\": \"94564b6ce681b858185fd4a1e7fa7f7b99c157c9\",\n",
      "\t\t\"subject\": \"Add a builder class for TestDruidCoordinatorConfig (#12624)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-builder-class-for-TestDruidCoordinatorConfig-12624\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add a builder class for TestDruidCoordinatorConfig  * updates after review  * Fix formatting\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Jun 2022 09:11:31 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"94564b6ce681b858185fd4a1e7fa7f7b99c157c9\",\n",
      "\t\t\"parent\": \"70f3b1362171da81013489bf2d7879b68d46c2f3\",\n",
      "\t\t\"subject\": \"Update screenshots for Druid console doc (#12593)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-screenshots-for-Druid-console-doc-12593\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* druid console doc updates  * remove extra image  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Apply suggestions from code review  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * updated screenshot labels  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Jun 2022 16:42:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"70f3b1362171da81013489bf2d7879b68d46c2f3\",\n",
      "\t\t\"parent\": \"45e31115495838b3327e0fff1d21bee0adf31132\",\n",
      "\t\t\"subject\": \"ForkingTaskRunner: Set ActiveProcessorCount for tasks. (#12592)\",\n",
      "\t\t\"sanitized_subject_line\": \"ForkingTaskRunner-Set-ActiveProcessorCount-for-tasks.-12592\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* ForkingTaskRunner: Set ActiveProcessorCount for tasks.  This prevents various automatically-sized thread pools from being unreasonably large (we don't want each task to size its pools as if it is the only thing on the entire machine).  * Fix tests.  * Add missing LifecycleStart annotation.  * ForkingTaskRunner needs ManageLifecycle.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Jun 2022 15:56:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45e31115495838b3327e0fff1d21bee0adf31132\",\n",
      "\t\t\"parent\": \"28f2c8e1120365bb45ed7531c26150432a935ee2\",\n",
      "\t\t\"subject\": \"Clean up query contexts (#12633)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clean-up-query-contexts-12633\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Clean up query contexts  Uses constants in place of literal strings for context keys. Moves some QueryContext methods to QueryContexts for reuse.  * Revisions from review comments\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Jun 2022 11:31:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"28f2c8e1120365bb45ed7531c26150432a935ee2\",\n",
      "\t\t\"parent\": \"283249c51b3e748fcd7eef942a2c509904708670\",\n",
      "\t\t\"subject\": \"Support LoadScope for Peons + Access Modifier Updates (#12640)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-LoadScope-for-Peons-Access-Modifier-Updates-12640\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support LoadScope for Peons  * Update access modifiers for GroupByEngineV2\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 21:52:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"283249c51b3e748fcd7eef942a2c509904708670\",\n",
      "\t\t\"parent\": \"1f6e888472d3102f574a088286f92cb8feff4c86\",\n",
      "\t\t\"subject\": \"NettyHttpClient: Fix double-return on certain exceptions. (#12626)\",\n",
      "\t\t\"sanitized_subject_line\": \"NettyHttpClient-Fix-double-return-on-certain-exceptions.-12626\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The \\\"exceptionCaught\\\" handler may get called multiple times. We should only return the channel to the pool the first time. Returning it more than once leads to a warning like \\\"Resource at key[%s] was returned multiple times?\\\"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 21:40:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f6e888472d3102f574a088286f92cb8feff4c86\",\n",
      "\t\t\"parent\": \"ceb4ace118944b04a4997d8e85e3cf19d0aa1fd9\",\n",
      "\t\t\"subject\": \"Add QoSFilters first in the chain. (#12625)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-QoSFilters-first-in-the-chain.-12625\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add QoSFilters first in the chain.  When a request is suspended and later resumed due to QoS constraints, its filter chain is restarted. Placing QoSFilters first in the chain avoids double-execution of other filters.  Fixes an issue where requests deferred by QoS would report 403 Forbidden due to double-execution of SecuritySanityCheckFilter.  * Smaller changes.  * Add QoS filters in BaseJettyTest.  * Remove unused parameter.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 13:37:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ceb4ace118944b04a4997d8e85e3cf19d0aa1fd9\",\n",
      "\t\t\"parent\": \"6f7fa334fd45f121e1663f98299549c6002f9593\",\n",
      "\t\t\"subject\": \"NettyHttpClient: Replace ReadTimeoutException with our own exception. (#12635)\",\n",
      "\t\t\"sanitized_subject_line\": \"NettyHttpClient-Replace-ReadTimeoutException-with-our-own-exception.-12635\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* NettyHttpClient: Replace ReadTimeoutException with our own exception.  * Replace exception with same type.  * Remove unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 13:34:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f7fa334fd45f121e1663f98299549c6002f9593\",\n",
      "\t\t\"parent\": \"68bae6eafb7b647aa34a23bcad54f53234dc159c\",\n",
      "\t\t\"subject\": \"Web console: totalNumMergeTasks can be set on range also (#12648)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-totalNumMergeTasks-can-be-set-on-range-also-12648\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* totalNumMergeTasks can be set on range also  * fix formatting\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 11:18:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"68bae6eafb7b647aa34a23bcad54f53234dc159c\",\n",
      "\t\t\"parent\": \"afaea251f2192fbba136ce86dd0b1fdf83a2047f\",\n",
      "\t\t\"subject\": \"Fix version in master (#12644)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-version-in-master-12644\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Jun 2022 11:32:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"afaea251f2192fbba136ce86dd0b1fdf83a2047f\",\n",
      "\t\t\"parent\": \"27e8b43673af6e6f6cabbea66582569577d4f613\",\n",
      "\t\t\"subject\": \"Push join build table values as filter incase of duplicates (#12225)\",\n",
      "\t\t\"sanitized_subject_line\": \"Push-join-build-table-values-as-filter-incase-of-duplicates-12225\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Push join build table values as filter  * Add tests for JoinableFactoryWrapper  * fixup! Push join build table values as filter  * fixup! Add tests for JoinableFactoryWrapper  * fixup! Push join build table values as filter\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Jun 2022 17:18:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"27e8b43673af6e6f6cabbea66582569577d4f613\",\n",
      "\t\t\"parent\": \"1ace7336cd292babea75a6bd589e836f68f30007\",\n",
      "\t\t\"subject\": \"fix: update footer copyright year (#12594)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-update-footer-copyright-year-12594\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Jun 2022 16:29:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1ace7336cd292babea75a6bd589e836f68f30007\",\n",
      "\t\t\"parent\": \"353475bd3613db194a4767591ffd636265f25a62\",\n",
      "\t\t\"subject\": \"Update node to 14.19.3. (#12632)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-node-to-14.19.3.-12632\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Jun 2022 10:18:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"353475bd3613db194a4767591ffd636265f25a62\",\n",
      "\t\t\"parent\": \"a3603ad6b05d9e119115549e8451099d25469103\",\n",
      "\t\t\"subject\": \"Docs for automatic compaction (#12569)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-for-automatic-compaction-12569\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs for auto-compaction  * fix broken links  * another link  * Apply suggestions from code review  Co-authored-by: Suneet Saldanha <suneet@apache.org>  * Apply suggestions from code review  Co-authored-by: Suneet Saldanha <suneet@apache.org>  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Suneet Saldanha <suneet@apache.org>  * reorg content for skipOffset  * Update docs/ingestion/automatic-compaction.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Apply suggestions from code review  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  Co-authored-by: Suneet Saldanha <suneet@apache.org> Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Jun 2022 14:55:12 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3603ad6b05d9e119115549e8451099d25469103\",\n",
      "\t\t\"parent\": \"8fbf92e047f792ff1c69bf67d14784ac55eee88f\",\n",
      "\t\t\"subject\": \"Use DefaultQueryConfig in SqlLifecycle to correctly populate request logs (#12613)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-DefaultQueryConfig-in-SqlLifecycle-to-correctly-populate-request-logs-12613\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes an issue where sql query request logs do not include the default query context values set via `druid.query.default.context.xyz` runtime properties.  # Change summary * Inject `DefaultQueryConfig` into `SqlLifecycleFactory` * Add params from `DefaultQueryConfig` to the query context in `SqlLifecycle`  # Description - This change does not affect query execution. This is because the   `DefaultQueryConfig` was already being used in `QueryLifecycle`,    which is initialized when the SQL is translated to a native query.  - This also handles any potential use case where a context parameter should be    handled at the SQL stage itself.\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Jun 2022 12:52:50 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8fbf92e047f792ff1c69bf67d14784ac55eee88f\",\n",
      "\t\t\"parent\": \"59a0c10c47af27b0186e4134b9f5461e9516f399\",\n",
      "\t\t\"subject\": \"SqlSegmentsMetadataQuery: Fix OVERLAPS for wide target segments. (#12600)\",\n",
      "\t\t\"sanitized_subject_line\": \"SqlSegmentsMetadataQuery-Fix-OVERLAPS-for-wide-target-segments.-12600\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SqlSegmentsMetadataQuery: Fix OVERLAPS for wide target segments.  Segments with endpoints prior to year 0 or after year 9999 may overlap the search intervals but not match the generated SQL conditions. So, we need to add an additional OR condition to catch these.  I checked a real, live MySQL metadata store to confirm that the query still uses metadata store indexes. It does.  * Add comments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Jun 2022 11:33:46 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"59a0c10c47af27b0186e4134b9f5461e9516f399\",\n",
      "\t\t\"parent\": \"81c37c651586b774a226e147d463c743928cdb8a\",\n",
      "\t\t\"subject\": \"Add remedial information in error message when type is unknown (#12612)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-remedial-information-in-error-message-when-type-is-unknown-12612\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Often users are submitting queries, and ingestion specs that work only if the relevant extension is not loaded. However, the error is too technical for the users and doesn't suggest them to check for missing extensions. This PR modifies the error message so users can at least check their settings before assuming that the error is because of a bug.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Jun 2022 20:22:45 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"81c37c651586b774a226e147d463c743928cdb8a\",\n",
      "\t\t\"parent\": \"5a283964cab8ec6d19b5130e458d6653062252fc\",\n",
      "\t\t\"subject\": \"Add validation for invalid partitioned by granularities (#12589)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-validation-for-invalid-partitioned-by-granularities-12589\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add validation for invalid partitioned by granularities  * review comments  * improve error message, change location of the method  * remove imports  * use StringUtils.lowercase  Co-authored-by: Adarsh Sanjeev <adarshsanjeev@gmail.com>\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Jun 2022 22:00:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5a283964cab8ec6d19b5130e458d6653062252fc\",\n",
      "\t\t\"parent\": \"abf0e0a1596e8c87796e10a90dc1bc9f7b314013\",\n",
      "\t\t\"subject\": \"Improve SQL validation error messages (#12611)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-SQL-validation-error-messages-12611\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Update the SQL validation error message to specify whether the ingest is INSERT or REPLACE for better user experience.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Jun 2022 16:14:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"abf0e0a1596e8c87796e10a90dc1bc9f7b314013\",\n",
      "\t\t\"parent\": \"a503683a4a98754dbbe06bb4ba0a2d88a10e7b3e\",\n",
      "\t\t\"subject\": \"CompressionStrategyTest: Fix thread-unsafe Closer usage. (#12605)\",\n",
      "\t\t\"sanitized_subject_line\": \"CompressionStrategyTest-Fix-thread-unsafe-Closer-usage.-12605\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Closer is not thread-safe, so we need one per thread in the concurrency tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Jun 2022 10:57:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a503683a4a98754dbbe06bb4ba0a2d88a10e7b3e\",\n",
      "\t\t\"parent\": \"1506b26ce4024d4f1a4bb8785dcf73015a1e2013\",\n",
      "\t\t\"subject\": \"Add caching and CSP response headers. (#12609)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-caching-and-CSP-response-headers.-12609\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add caching and CSP response headers.  * Fix tests.  * Fix checkstyle issues  Co-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Jun 2022 21:46:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1506b26ce4024d4f1a4bb8785dcf73015a1e2013\",\n",
      "\t\t\"parent\": \"a27f4f57407d853d980a526636cef19003ab9d96\",\n",
      "\t\t\"subject\": \"fix typo (#12607)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-typo-12607\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Jun 2022 13:14:18 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a27f4f57407d853d980a526636cef19003ab9d96\",\n",
      "\t\t\"parent\": \"9c8e6bb0000cffb4c904e94f0baf03fb9bd23af9\",\n",
      "\t\t\"subject\": \"Service stdout log files, move logs to log/. (#12570)\",\n",
      "\t\t\"sanitized_subject_line\": \"Service-stdout-log-files-move-logs-to-log-.-12570\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Service stdout log files, move logs to log/.  Two changes that make log behavior cleaner:  1) Redirect messages from the Java runtime to their own log files.    Otherwise, they would get jumbled up in the output of the all-in-one    start command.  2) Use log/ instead of bin/log/ for the default log directory. Makes them    easier to find.  Additionally, add documentation about how to avoid the reflective access warnings in Java 11.  * Spelling.  * See if code formatting affects spelling.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Jun 2022 10:44:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9c8e6bb0000cffb4c904e94f0baf03fb9bd23af9\",\n",
      "\t\t\"parent\": \"4558b815e555bab4ce4ca74fd644f2a22d0df1ba\",\n",
      "\t\t\"subject\": \"Addition to Multitenancy considerations doc (#12567)\",\n",
      "\t\t\"sanitized_subject_line\": \"Addition-to-Multitenancy-considerations-doc-12567\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Small addition to Multitenancy considerations doc  * Update docs/querying/multitenancy.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update multitenancy.md  Edit suggested by @kfaraz  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Jill Osborne\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Jun 2022 10:32:14 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4558b815e555bab4ce4ca74fd644f2a22d0df1ba\",\n",
      "\t\t\"parent\": \"c49277bd2b3c7364df1e98834a2ad94e12c1f8aa\",\n",
      "\t\t\"subject\": \"Bump eventsource from 1.1.0 to 1.1.1 in /web-console (#12595)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-eventsource-from-1.1.0-to-1.1.1-in-web-console-12595\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [eventsource](https://github.com/EventSource/eventsource) from 1.1.0 to 1.1.1. - [Release notes](https://github.com/EventSource/eventsource/releases) - [Changelog](https://github.com/EventSource/eventsource/blob/master/HISTORY.md) - [Commits](https://github.com/EventSource/eventsource/compare/v1.1.0...v1.1.1)  --- updated-dependencies: - dependency-name: eventsource   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 22:04:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c49277bd2b3c7364df1e98834a2ad94e12c1f8aa\",\n",
      "\t\t\"parent\": \"98f6bca2cda31762a9f259334f7eea384aac0477\",\n",
      "\t\t\"subject\": \"Bump eventsource from 1.0.7 to 1.1.1 in /website (#12596)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-eventsource-from-1.0.7-to-1.1.1-in-website-12596\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [eventsource](https://github.com/EventSource/eventsource) from 1.0.7 to 1.1.1. - [Release notes](https://github.com/EventSource/eventsource/releases) - [Changelog](https://github.com/EventSource/eventsource/blob/master/HISTORY.md) - [Commits](https://github.com/EventSource/eventsource/compare/v1.0.7...v1.1.1)  --- updated-dependencies: - dependency-name: eventsource   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 22:04:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"98f6bca2cda31762a9f259334f7eea384aac0477\",\n",
      "\t\t\"parent\": \"23b9a6f9eb119bf11f68da137e6a10579eea4fb5\",\n",
      "\t\t\"subject\": \"fix regression with ipv4_match and prefixes (#12542)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-regression-with-ipv4_match-and-prefixes-12542\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix issue with ipv4_match and prefixes\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 14:03:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"23b9a6f9eb119bf11f68da137e6a10579eea4fb5\",\n",
      "\t\t\"parent\": \"86d01b3681c48d3b868b76bfc76e872f19e629dd\",\n",
      "\t\t\"subject\": \"Bump lodash from 4.17.15 to 4.17.21 in /website (#12409)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-lodash-from-4.17.15-to-4.17.21-in-website-12409\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.15 to 4.17.21. - [Release notes](https://github.com/lodash/lodash/releases) - [Commits](https://github.com/lodash/lodash/compare/4.17.15...4.17.21)  --- updated-dependencies: - dependency-name: lodash   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 13:56:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"86d01b3681c48d3b868b76bfc76e872f19e629dd\",\n",
      "\t\t\"parent\": \"31f988ec76c802ae1cd487781554f33b7100ced8\",\n",
      "\t\t\"subject\": \"Bump opentelemetry-instrumentation-bom-alpha (#12531)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-opentelemetry-instrumentation-bom-alpha-12531\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [opentelemetry-instrumentation-bom-alpha](https://github.com/open-telemetry/opentelemetry-java-instrumentation) from 1.7.0-alpha to 1.14.0-alpha. - [Release notes](https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases) - [Changelog](https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/CHANGELOG.md) - [Commits](https://github.com/open-telemetry/opentelemetry-java-instrumentation/commits)  --- updated-dependencies: - dependency-name: io.opentelemetry.instrumentation:opentelemetry-instrumentation-bom-alpha   dependency-type: direct:production   update-type: version-update:semver-minor ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 13:51:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"31f988ec76c802ae1cd487781554f33b7100ced8\",\n",
      "\t\t\"parent\": \"f7ce73eee75cfb7a4dda47b3390866d4cb8b2577\",\n",
      "\t\t\"subject\": \"fix backwards compatibility for explicit null columns (#12585)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-backwards-compatibility-for-explicit-null-columns-12585\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 12:39:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7ce73eee75cfb7a4dda47b3390866d4cb8b2577\",\n",
      "\t\t\"parent\": \"dc0fdfec679908a6be04ba7ac8f330c2c7b59dac\",\n",
      "\t\t\"subject\": \"Suppress CVEs (#12590)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVEs-12590\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Jun 2022 21:22:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dc0fdfec679908a6be04ba7ac8f330c2c7b59dac\",\n",
      "\t\t\"parent\": \"0640c9c9ac65dbdec9a00fb3e90816a4ca9cb18b\",\n",
      "\t\t\"subject\": \"fix test comment (#12584)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-test-comment-12584\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 May 2022 12:39:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0640c9c9ac65dbdec9a00fb3e90816a4ca9cb18b\",\n",
      "\t\t\"parent\": \"02ae3e74ffcf99437bc6a608baf770d764f2c52f\",\n",
      "\t\t\"subject\": \"fix compression-strategy-test (#12575)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-compression-strategy-test-12575\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"fixes an issue caused by a test modification in #12408 that was closing buffers allocated by the compression strategy instead of allowing the closer to do it\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 May 2022 11:48:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"02ae3e74ffcf99437bc6a608baf770d764f2c52f\",\n",
      "\t\t\"parent\": \"b639298f6e6c348756b856cecdcdc88ec44d8a73\",\n",
      "\t\t\"subject\": \"RowBasedColumnSelectorFactory: Add \\\"useStringValueOfNullInLists\\\" parameter. (#12578)\",\n",
      "\t\t\"sanitized_subject_line\": \"RowBasedColumnSelectorFactory-Add-useStringValueOfNullInLists-parameter.-12578\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"RowBasedColumnSelectorFactory inherited strange behavior from Rows.objectToStrings for nulls that appear in lists: instead of being left as a null, it is replaced with the string \\\"null\\\". Some callers may need compatibility with this strange behavior, but it should be opt-in.  Query-time call sites are changed to opt-out of this behavior, since it is not consistent with query-time expectations. The IncrementalIndex ingestion-time call site retains the old behavior, as this is traditionally when Rows.objectToStrings would be used.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 May 2022 11:38:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b639298f6e6c348756b856cecdcdc88ec44d8a73\",\n",
      "\t\t\"parent\": \"6d2ff796a37726964807b285c615d70b0976fb08\",\n",
      "\t\t\"subject\": \"CompressionUtils: Increase gzip buffer size. (#12579)\",\n",
      "\t\t\"sanitized_subject_line\": \"CompressionUtils-Increase-gzip-buffer-size.-12579\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 May 2022 11:38:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6d2ff796a37726964807b285c615d70b0976fb08\",\n",
      "\t\t\"parent\": \"b746bf91298e704c16375a60df73bd73fe4e2309\",\n",
      "\t\t\"subject\": \"Add RowIdSupplier to ColumnSelectorFactory. (#12577)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-RowIdSupplier-to-ColumnSelectorFactory.-12577\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add RowIdSupplier to ColumnSelectorFactory.  This enables virtual columns to cache their outputs in case they are called multiple times on the same underlying row. This is common for numeric selectors, where the common pattern is to call isNull() and then follow with getLong(), getFloat(), or getDouble(). Here, output caching reduces the number of expression evals by half.  * Fix tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 31 May 2022 11:38:03 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b746bf91298e704c16375a60df73bd73fe4e2309\",\n",
      "\t\t\"parent\": \"7291c92f4f013f0495dbe405d4d9a32017c9dfdd\",\n",
      "\t\t\"subject\": \"fix virtual column cycle bug, sql virtual column optimize bug (#12576)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-virtual-column-cycle-bug-sql-virtual-column-optimize-bug-12576\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix virtual column cycle bug, sql virtual column optimize bug  * more test\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 30 May 2022 23:51:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7291c92f4f013f0495dbe405d4d9a32017c9dfdd\",\n",
      "\t\t\"parent\": \"79f86a051103991a164af5757ecf5cab5a30fe46\",\n",
      "\t\t\"subject\": \"Adding zstandard compression library (#12408)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-zstandard-compression-library-12408\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding zstandard compression library  * 1. Took @clintropolis's advice to have ZStandard decompressor use the byte array when the buffers are not direct. 2. Cleaned up checkstyle issues.  * Fixing zstandard version to latest stable version in pom's and updating license files  * Removing zstd from benchmarks and adding to processing (poms)  * fix the intellij inspection issue  * Removing the prefix v for the version in the license check for ztsd  * Fixing license checks  Co-authored-by: Rahul Gidwani <r_gidwani@apple.com>\",\n",
      "\t\t\"author_name\": \"Dr. Sizzles\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 28 May 2022 17:01:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"79f86a051103991a164af5757ecf5cab5a30fe46\",\n",
      "\t\t\"parent\": \"d0c9c37e354df3b4cd8c580c528026ebabb79968\",\n",
      "\t\t\"subject\": \"Upgrade ORC to 1.7.4 (#12572)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-ORC-to-1.7.4-12572\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This commit upgrades Apache ORC library from 1.7.2 to 1.7.4. Apache ORC 1.7.4 is the maintenance release with the following bug fixes.  https://orc.apache.org/news/2022/04/15/ORC-1.7.4/ https://github.com/apache/orc/releases/tag/v1.7.4\",\n",
      "\t\t\"author_name\": \"Dongjoon Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 28 May 2022 17:44:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d0c9c37e354df3b4cd8c580c528026ebabb79968\",\n",
      "\t\t\"parent\": \"9f9faeec816fee7bc8936dc3cb4aa1b91450e6c3\",\n",
      "\t\t\"subject\": \"make query context changes backwards compatible (#12564)\",\n",
      "\t\t\"sanitized_subject_line\": \"make-query-context-changes-backwards-compatible-12564\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Adds a default implementation of getQueryContext, which was added to the Query interface in #12396. Query is marked with @ExtensionPoint, and lately we have been trying to be less volatile on these interfaces by providing default implementations to be more chill for extension writers.  The way this default implementation is done in this PR is a bit strange due to the way that getQueryContext is used (mutated with system default and system generated keys); the default implementation has a specific object that it returns, and I added another temporary default method isLegacyContext that checks if the getQueryContext returns that object or not. If not, callers fall back to using getContext and withOverriddenContext to set these default and system values.  I am open to other ideas as well, but this way should work at least without exploding, and added some tests to ensure that it is wired up correctly for QueryLifecycle, including the context authorization stuff.  The added test shows the strange behavior if query context authorization is enabled, mainly that the system default and system generated query context keys also need to be granted as permissions for things to function correctly. This is not great, so I mentioned it in the javadocs as well. Not sure if it needs to be called out anywhere else.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 May 2022 15:24:41 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9f9faeec816fee7bc8936dc3cb4aa1b91450e6c3\",\n",
      "\t\t\"parent\": \"b10eb4cbd4b9a1f4d40bb182aef128601d08b6d3\",\n",
      "\t\t\"subject\": \"object[] handling for DimensionHandlers for arrays (#12552)\",\n",
      "\t\t\"sanitized_subject_line\": \"object-handling-for-DimensionHandlers-for-arrays-12552\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Description Fixes a bug when running q's like   SELECT cntarray,        Count(*) FROM   (SELECT dim1,                dim2,                Array_agg(cnt) AS cntarray         FROM   (SELECT dim1,                        dim2,                        dim3,                        Count(*) AS cnt                 FROM   foo                 GROUP  BY 1,                           2,                           3)         GROUP  BY 1,                   2) GROUP  BY 1   This generates an error:  org.apache.druid.java.util.common.ISE: Unable to convert type [Ljava.lang.Object; to org.apache.druid.segment.data.ComparableList         at org.apache.druid.segment.DimensionHandlerUtils.convertToList(DimensionHandlerUtils.java:405) ~[druid-xx] Because it's an array of numbers it looks like it does the convertToList call, which looks like:    @Nullable   public static ComparableList convertToList(Object obj)   {     if (obj == null) {       return null;     }     if (obj instanceof List) {       return new ComparableList((List) obj);     }     if (obj instanceof ComparableList) {       return (ComparableList) obj;     }     throw new ISE(\\\"Unable to convert type %s to %s\\\", obj.getClass().getName(), ComparableList.class.getName());   } I.e. it doesn't know about arrays. Added the array handling as part of this PR.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 25 May 2022 15:24:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b10eb4cbd4b9a1f4d40bb182aef128601d08b6d3\",\n",
      "\t\t\"parent\": \"32fe4d132426592584d08a785f14943d639cdcb2\",\n",
      "\t\t\"subject\": \"Suppress false CVE on druid-indexing-hadoop artifact (#12562)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-false-CVE-on-druid-indexing-hadoop-artifact-12562\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 24 May 2022 16:00:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"32fe4d132426592584d08a785f14943d639cdcb2\",\n",
      "\t\t\"parent\": \"2f3d7a4c076316797b1cef5fc31c4ab5ac67cf59\",\n",
      "\t\t\"subject\": \"Use a different repository to download sigar artifacts. (#12561)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-a-different-repository-to-download-sigar-artifacts.-12561\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 24 May 2022 14:42:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2f3d7a4c076316797b1cef5fc31c4ab5ac67cf59\",\n",
      "\t\t\"parent\": \"5063eca5b9592215afc9913f091b2acc03a5797b\",\n",
      "\t\t\"subject\": \"Emit state of replace and append for native batch tasks (#12488)\",\n",
      "\t\t\"sanitized_subject_line\": \"Emit-state-of-replace-and-append-for-native-batch-tasks-12488\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Emit state of replace and append for native batch tasks  * Emit count of one depending on batch ingestion mode (APPEND, OVERWRITE, REPLACE)  * Add metric to compaction job  * Avoid null ptr exc when null emitter  * Coverage  * Emit tombstone & segment counts  * Tasks need a type  * Spelling  * Integrate BatchIngestionMode in batch ingestion tasks functionality  * Typos  * Remove batch ingestion type from metric since it is already in a dimension. Move IngestionMode to AbstractTask to facilitate having mode as a dimension. Add metrics to streaming. Add missing coverage.  * Avoid inner class referenced by sub-class inspection. Refactor computation of IngestionMode to make it more robust to null IOConfig and fix test.  * Spelling  * Avoid polluting the Task interface  * Rename computeCompaction methods to avoid ambiguous java compiler error if they are passed null. Other minor cleanup.\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 May 2022 12:32:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5063eca5b9592215afc9913f091b2acc03a5797b\",\n",
      "\t\t\"parent\": \"6d85ba4c00411b5333507e75daab1cd9b53dc505\",\n",
      "\t\t\"subject\": \"Add error message for incorrectly ordered clause in sql (#12558)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-error-message-for-incorrectly-ordered-clause-in-sql-12558\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In the case that the clustered by is before the partitioned by for an sql query, the error message is a bit confusing.  insert into foo select * from bar clustered by dim1 partitioned by all  Error: SQL parse failed  Encountered \\\"PARTITIONED\\\" at line 1, column 88.  Was expecting one of: <EOF> \\\",\\\" ... \\\"ASC\\\" ... \\\"DESC\\\" ... \\\"NULLS\\\" ... \\\".\\\" ... \\\"NOT\\\" ... \\\"IN\\\" ... \\\"<\\\" ... \\\"<=\\\" ... \\\">\\\" ... \\\">=\\\" ... \\\"=\\\" ... \\\"<>\\\" ... \\\"!=\\\" ... \\\"BETWEEN\\\" ... \\\"LIKE\\\" ... \\\"SIMILAR\\\" ... \\\"+\\\" ... \\\"-\\\" ... \\\"*\\\" ... \\\"/\\\" ... \\\"%\\\" ... \\\"||\\\" ... \\\"AND\\\" ... \\\"OR\\\" ... \\\"IS\\\" ... \\\"MEMBER\\\" ... \\\"SUBMULTISET\\\" ... \\\"CONTAINS\\\" ... \\\"OVERLAPS\\\" ... \\\"EQUALS\\\" ... \\\"PRECEDES\\\" ... \\\"SUCCEEDS\\\" ... \\\"IMMEDIATELY\\\" ... \\\"MULTISET\\\" ... \\\"[\\\" ... \\\"FORMAT\\\" ... \\\"(\\\" ... Less...  org.apache.calcite.sql.parser.SqlParseException This is a bit confusing and adding a check could be added to throw a more user friendly message stating that the order should be reversed.  Add error message for incorrectly ordered clause in sql.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 May 2022 12:41:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6d85ba4c00411b5333507e75daab1cd9b53dc505\",\n",
      "\t\t\"parent\": \"37853f8de4ba801a5f6c429ccceeb58b58762109\",\n",
      "\t\t\"subject\": \"Suppress CVEs (#12553)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVEs-12553\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 23 May 2022 12:35:23 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37853f8de4ba801a5f6c429ccceeb58b58762109\",\n",
      "\t\t\"parent\": \"5073cee73f786808436187242680947263752dbb\",\n",
      "\t\t\"subject\": \"ConcurrentGrouper: Add mergeThreadLocal option, fix bug around the switch to spilling. (#12513)\",\n",
      "\t\t\"sanitized_subject_line\": \"ConcurrentGrouper-Add-mergeThreadLocal-option-fix-bug-around-the-switch-to-spilling.-12513\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* ConcurrentGrouper: Add option to always slice up merge buffers thread-locally.  Normally, the ConcurrentGrouper shares merge buffers across processing threads until spilling starts, and then switches to a thread-local model. This minimizes memory use and reduces likelihood of spilling, which is good, but it creates thread contention. The new mergeThreadLocal option causes a query to start in thread-local mode immediately, and allows us to experiment with the relative performance of the two modes.  * Fix grammar in docs.  * Fix race in ConcurrentGrouper.  * Fix issue with timeouts.  * Remove unused import.  * Add \\\"tradeoff\\\" to dictionary.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 21 May 2022 10:28:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5073cee73f786808436187242680947263752dbb\",\n",
      "\t\t\"parent\": \"2d8dbb53e039f065716220c97d997f458cdae0f6\",\n",
      "\t\t\"subject\": \"Fix zookeeper spelling (#12556)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-zookeeper-spelling-12556\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 21 May 2022 16:14:02 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d8dbb53e039f065716220c97d997f458cdae0f6\",\n",
      "\t\t\"parent\": \"c23622790568e1fca2eeaae308903d3199093ece\",\n",
      "\t\t\"subject\": \"update to latest lz4 1.8.0 (#12557)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-to-latest-lz4-1.8.0-12557\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 21 May 2022 16:02:20 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c23622790568e1fca2eeaae308903d3199093ece\",\n",
      "\t\t\"parent\": \"f9bdb3b236c01a32eecd98f13e42fce0e1e5c3d4\",\n",
      "\t\t\"subject\": \"Deal with potential cardinality estimate being negative and add logging to hash determine partitions phase (#12443)\",\n",
      "\t\t\"sanitized_subject_line\": \"Deal-with-potential-cardinality-estimate-being-negative-and-add-logging-to-hash-determine-partitions-phase-12443\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Deal with potential cardinality estimate being negative and add logging  * Fix typo in name  * Refine and minimize logging  * Make it info based on code review  * Create a named constant for the magic number\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 20 May 2022 10:51:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f9bdb3b236c01a32eecd98f13e42fce0e1e5c3d4\",\n",
      "\t\t\"parent\": \"69aac6c8dd5588ed19f0cf90f11025317133df57\",\n",
      "\t\t\"subject\": \"Fix usage of maxColumnsToMerge in auto-compaction tuning config (#12551)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-usage-of-maxColumnsToMerge-in-auto-compaction-tuning-config-12551\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Issue:  Even though `CompactionTuningConfig` allows a `maxColumnsToMerge` config (to optimize memory usage, particulary for datasources with many dimensions), the corresponding client object `ClientCompactionTaskQueryTuningConfig` (used by the coordinator duty `CompactSegments` to trigger auto-compaction) does not contain this field. Thus, the value of `maxColumnsToMerge` specified in any datasource compaction config is ignored.  Changes: - Add field `maxColumnsToMerge` in `ClientCompactionTaskQueryTuningConfig`   and `UserCompactionTaskQueryTuningConfig` - Fix tests\",\n",
      "\t\t\"author_name\": \"superivaj\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 20 May 2022 22:23:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"69aac6c8dd5588ed19f0cf90f11025317133df57\",\n",
      "\t\t\"parent\": \"a235aca2b3f89d3ce46232461410ae7e07d2d61f\",\n",
      "\t\t\"subject\": \"Direct UTF-8 access for \\\"in\\\" filters. (#12517)\",\n",
      "\t\t\"sanitized_subject_line\": \"Direct-UTF-8-access-for-in-filters.-12517\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Direct UTF-8 access for \\\"in\\\" filters.  Directly related:  1) InDimFilter: Store stored Strings (in ValuesSet) plus sorted UTF-8    ByteBuffers (in valuesUtf8). Use valuesUtf8 whenever possible. If    necessary, the input set is copied into a ValuesSet. Much logic is    simplified, because we always know what type the values set will be.    I think that there won't even be an efficiency loss in most cases.    InDimFilter is most frequently created by deserialization, and this    patch updates the JsonCreator constructor to deserialize    directly into a ValuesSet.  2) Add Utf8ValueSetIndex, which InDimFilter uses to avoid UTF-8 decodes    during index lookups.  3) Add unsigned comparator to ByteBufferUtils and use it in    GenericIndexed.BYTE_BUFFER_STRATEGY. This is important because UTF-8    bytes can be compared as bytes if, and only if, the comparison    is unsigned.  4) Add specialization to GenericIndexed.singleThreaded().indexOf that    avoids needless ByteBuffer allocations.  5) Clarify that objects returned by ColumnIndexSupplier.as are not    thread-safe. DictionaryEncodedStringIndexSupplier now calls    singleThreaded() on all relevant GenericIndexed objects, saving    a ByteBuffer allocation per access.  Also:  1) Fix performance regression in LikeFilter: since #12315, it applied    the suffix matcher to all values in range even for type MATCH_ALL.  2) Add ObjectStrategy.canCompare() method. This fixes LikeFilterBenchmark,    which was broken due to calls to strategy.compare in    GenericIndexed.fromIterable.  * Add like-filter implementation tests.  * Add in-filter implementation tests.  * Add tests, fix issues.  * Fix style.  * Adjustments from review.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 20 May 2022 01:51:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a235aca2b3f89d3ce46232461410ae7e07d2d61f\",\n",
      "\t\t\"parent\": \"5f95cc61fe676694e6ee496547eb7db6d2a1ce88\",\n",
      "\t\t\"subject\": \"Web console: fix go to segments not working (#12541)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-fix-go-to-segments-not-working-12541\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use correct filter syntax  * fix tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 14:34:03 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5f95cc61fe676694e6ee496547eb7db6d2a1ce88\",\n",
      "\t\t\"parent\": \"65a1375b67dfa470d0eeefd078b4252e4427d74e\",\n",
      "\t\t\"subject\": \"RemoteTaskRunner: Fix NPE in streamTaskReports. (#12006)\",\n",
      "\t\t\"sanitized_subject_line\": \"RemoteTaskRunner-Fix-NPE-in-streamTaskReports.-12006\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* RemoteTaskRunner: Fix NPE in streamTaskReports.  It is possible for a work item to drop out of runningTasks after the ZkWorker is retrieved. In this case, the current code would throw an NPE.  * Additional tests and additional fixes.  * Fix import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 14:23:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65a1375b67dfa470d0eeefd078b4252e4427d74e\",\n",
      "\t\t\"parent\": \"90531fd53fafd3af37b4d403b3bb8eea5d13e456\",\n",
      "\t\t\"subject\": \"SQL: Add is_active to sys.segments, update examples and docs. (#11550)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Add-is_active-to-sys.segments-update-examples-and-docs.-11550\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Add is_active to sys.segments, update examples and docs.  is_active is short for:    (is_published = 1 AND is_overshadowed = 0) OR is_realtime = 1  It's important because this represents \\\"all the segments that should be queryable, whether or not they actually are right now\\\". Most of the time, this is the set of segments that people will want to look at.  The web console already adds this filter to a lot of its queries, proving its usefulness.  This patch also reworks the caveat at the bottom of the sys.segments section, so its information is mixed into the description of each result field. This should make it more likely for people to see the information.  * Wording updates.  * Adjustments for spellcheck.  * Adjust IT.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 14:23:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90531fd53fafd3af37b4d403b3bb8eea5d13e456\",\n",
      "\t\t\"parent\": \"ec41dfb535ceaa65405757baad6e5ee1b0793a29\",\n",
      "\t\t\"subject\": \"Do not alter query timeout in ScanQueryEngine (#12271)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-alter-query-timeout-in-ScanQueryEngine-12271\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add test to detect timeout mutability\",\n",
      "\t\t\"author_name\": \"machine424\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 09:24:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ec41dfb535ceaa65405757baad6e5ee1b0793a29\",\n",
      "\t\t\"parent\": \"1d258d2108f8ba40d3cb77fe2e602585b1ddfce5\",\n",
      "\t\t\"subject\": \"upgrade core Apache Kafka dependencies to 3.2.0 (#12538)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-core-Apache-Kafka-dependencies-to-3.2.0-12538\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Announcement: https://blogs.apache.org/kafka/entry/what-s-new-in-apache8 Release notes: https://downloads.apache.org/kafka/3.2.0/RELEASE_NOTES.html\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 09:04:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d258d2108f8ba40d3cb77fe2e602585b1ddfce5\",\n",
      "\t\t\"parent\": \"485de6a14a5f04a9996cdec2563d66577c162ea5\",\n",
      "\t\t\"subject\": \"Slightly improve RTR log messages. (#12540)\",\n",
      "\t\t\"sanitized_subject_line\": \"Slightly-improve-RTR-log-messages.-12540\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"1) Align \\\"Assigning task\\\" log messages between RTR and HRTR.  2) Remove confusing reference to \\\"Coordinator\\\".  3) Move \\\"Not assigning task\\\" message from INFO to DEBUG. It's not super    important to see this message: we mainly want to see what _does_ get    assigned.  4) Reword \\\"Task switched from pending to running\\\" message to better    match the structure of the  \\\"Assigning task\\\" message from the same    method.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 07:43:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"485de6a14a5f04a9996cdec2563d66577c162ea5\",\n",
      "\t\t\"parent\": \"4631cff2a9b8cdf5850e39e7d889d951a895a468\",\n",
      "\t\t\"subject\": \"Add builder for TaskToolbox. (#12539)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-builder-for-TaskToolbox.-12539\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add builder for TaskToolbox.  The main purpose of this change is to make it easier to create TaskToolboxes in tests. However, the builder is used in production too, by TaskToolboxFactory.  * Fix imports, adjust formatting.  * Fix import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 07:43:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4631cff2a9b8cdf5850e39e7d889d951a895a468\",\n",
      "\t\t\"parent\": \"c877d8a98119f2240c1335bb052a3d90e9649a86\",\n",
      "\t\t\"subject\": \"Free ByteBuffers in tests and fix some bugs. (#12521)\",\n",
      "\t\t\"sanitized_subject_line\": \"Free-ByteBuffers-in-tests-and-fix-some-bugs.-12521\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Ensure ByteBuffers allocated in tests get freed.  Many tests had problems where a direct ByteBuffer would be allocated and then not freed. This is bad because it causes flaky tests.  To fix this:  1) Add ByteBufferUtils.allocateDirect(size), which returns a ResourceHolder.    This makes it easy to free the direct buffer. Currently, it's only used    in tests, because production code seems OK.  2) Update all usages of ByteBuffer.allocateDirect (off-heap) in tests either    to ByteBuffer.allocate (on-heap, which are garbaged collected), or to    ByteBufferUtils.allocateDirect (wherever it seemed like there was a good    reason for the buffer to be off-heap). Make sure to close all direct    holders when done.  * Changes based on CI results.  * A different approach.  * Roll back BitmapOperationTest stuff.  * Try additional surefire memory.  * Revert \\\"Roll back BitmapOperationTest stuff.\\\"  This reverts commit 49f846d9e3d0904df6c685d403766c07531b15e5.  * Add TestBufferPool.  * Revert Xmx change in tests.  * Better behaved NestedQueryPushDownTest. Exit tests on OOME.  * Fix TestBufferPool.  * Remove T1C from ARM tests.  * Somewhat safer.  * Fix tests.  * Fix style stuff.  * Additional debugging.  * Reset null / expr configs better.  * ExpressionLambdaAggregatorFactory thread-safety.  * Alter forkNode to try to get better info when a JVM crashes.  * Fix buffer retention in ExpressionLambdaAggregatorFactory.  * Remove unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 07:42:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c877d8a98119f2240c1335bb052a3d90e9649a86\",\n",
      "\t\t\"parent\": \"215b90d1a4132de3524c98fe129e79dd12329e24\",\n",
      "\t\t\"subject\": \"Updates default inputSegmentSizeBytes in Compaction config (#12534)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updates-default-inputSegmentSizeBytes-in-Compaction-config-12534\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes Cannot serialize BigInt value as JSON error while loading compaction config in console.  \",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 14:43:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"215b90d1a4132de3524c98fe129e79dd12329e24\",\n",
      "\t\t\"parent\": \"3e8d7a6d9f43f889df7d73dedb2a94e03574615e\",\n",
      "\t\t\"subject\": \"CVE suppression (#12535)\",\n",
      "\t\t\"sanitized_subject_line\": \"CVE-suppression-12535\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 19 May 2022 11:21:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3e8d7a6d9f43f889df7d73dedb2a94e03574615e\",\n",
      "\t\t\"parent\": \"177638f171e26718da13aa20a2a6811268ac2ce7\",\n",
      "\t\t\"subject\": \"Sql docs items (#12530)\",\n",
      "\t\t\"sanitized_subject_line\": \"Sql-docs-items-12530\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* touch up sql refactor  * brush up SQL refactor  * incorporate feedback  * reorder sql  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 May 2022 16:56:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"177638f171e26718da13aa20a2a6811268ac2ce7\",\n",
      "\t\t\"parent\": \"fcb1c0b7bfc737d76e7dd956b5f4ff49055007c7\",\n",
      "\t\t\"subject\": \"Fix typo, add comma (#12529)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-typo-add-comma-12529\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 May 2022 16:42:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fcb1c0b7bfc737d76e7dd956b5f4ff49055007c7\",\n",
      "\t\t\"parent\": \"b23ddc5939d2537a51896a5082c610bf2c2bee9e\",\n",
      "\t\t\"subject\": \"Add cluster by support for replace syntax (#12524)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-cluster-by-support-for-replace-syntax-12524\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add cluster by support for replace syntax  * Add unit test for with list\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 May 2022 15:15:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b23ddc5939d2537a51896a5082c610bf2c2bee9e\",\n",
      "\t\t\"parent\": \"0fd4f1e3863f8f33bec69fc77dcb1ea118a42ed4\",\n",
      "\t\t\"subject\": \"print replication levels in coordinator segment logs (#12511)\",\n",
      "\t\t\"sanitized_subject_line\": \"print-replication-levels-in-coordinator-segment-logs-12511\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* print replication levels in coordinator segment logs  * add served segment count to stats  * also for drops\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 May 2022 02:24:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0fd4f1e3863f8f33bec69fc77dcb1ea118a42ed4\",\n",
      "\t\t\"parent\": \"fdfecfd9968dda992cce34b381020b1204bc5f8f\",\n",
      "\t\t\"subject\": \"Improve error messages from SQL REPLACE syntax (#12523)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-error-messages-from-SQL-REPLACE-syntax-12523\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"- Add user friendly error messages for missing or incorrect OVERWRITE clause for REPLACE SQL query - Move validation of missing OVERWRITE clause at code level instead of parser for custom error message \",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 17 May 2022 09:55:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fdfecfd9968dda992cce34b381020b1204bc5f8f\",\n",
      "\t\t\"parent\": \"985640f103cbced6434123dfc239b57abf60350b\",\n",
      "\t\t\"subject\": \"Improved docs for range partitioning. (#12350)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improved-docs-for-range-partitioning.-12350\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improved docs for range partitioning.  1) Clarify the benefits of range partitioning. 2) Clarify which filters support pruning. 3) Include the fact that multi-value dimensions cannot be used for partitioning.  * Additional clarification.  * Update other section.  * Another adjustment.  * Updates from review.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 09:42:31 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"985640f103cbced6434123dfc239b57abf60350b\",\n",
      "\t\t\"parent\": \"351e57bdb68dcb0fa8f423fd3a3808fba4a846de\",\n",
      "\t\t\"subject\": \"Clarify the use of the Lookup API (#12088)\",\n",
      "\t\t\"sanitized_subject_line\": \"Clarify-the-use-of-the-Lookup-API-12088\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update lookups.md  * Update docs/querying/lookups.md  Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>  * Update docs/querying/lookups.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: 317brian <53799971+317brian@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Hellmar Becker\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 07:50:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"351e57bdb68dcb0fa8f423fd3a3808fba4a846de\",\n",
      "\t\t\"parent\": \"5b6727f3195ac9bad906e3416bf8997b069c222f\",\n",
      "\t\t\"subject\": \"docs(fix): clarify how worker.version and minWorkerVersion comparison works (#12459)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-clarify-how-worker.version-and-minWorkerVersion-comparison-works-12459\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs(fix): clarify how worker.version and minWorkerVersion comparison works  * Revert \\\"docs(fix): clarify how worker.version and minWorkerVersion comparison works\\\"  This reverts commit cadd1fdc604de414379bffe9986ae64b9cf51fc6.  * docs(fix): clarify how worker.version and minWorkerVersion comparison works  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/configuration/index.md  fix spelling  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 07:48:33 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5b6727f3195ac9bad906e3416bf8997b069c222f\",\n",
      "\t\t\"parent\": \"c33ff1c745def3844c5f78007999a2bbdf676ba1\",\n",
      "\t\t\"subject\": \"Enable vectorized virtual column processing by default. (#12520)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-vectorized-virtual-column-processing-by-default.-12520\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In the majority of cases, this improves performance.  There's only one case I'm aware of where this may be a net negative: for time_floor(__time, <period>) where there are many repeated __time values. In nonvectorized processing, SingleLongInputCachingExpressionColumnValueSelector implements an optimization to avoid computing the time_floor function on every row. There is no such optimization in vectorized processing.  IMO, we shouldn't mention this in the docs. Rationale: It's too fiddly of a thing: it's not guaranteed that nonvectorized processing will be faster due to the optimization, because it would have to overcome the inherent speed advantage of vectorization. So it'd always require testing to determine the best setting for a specific dataset. It would be bad if users disabled vectorization thinking it would speed up their queries, and it actually slowed them down. And even if users do their own testing, at some point in the future we'll implement the optimization for vectorized processing too, and it's likely that users that explicitly disabled vectorization will continue to have it disabled. I'd like to avoid this outcome by encouraging all users to enable vectorization at all times. Really advanced users would be following development activity anyway, and can read this issue \",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 15:43:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c33ff1c745def3844c5f78007999a2bbdf676ba1\",\n",
      "\t\t\"parent\": \"ff253fd8a32af4f74387bad14e8a4563af5c2bc0\",\n",
      "\t\t\"subject\": \"Enforce console logging for peon process (#12067)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enforce-console-logging-for-peon-process-12067\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently all Druid processes share the same log4j2 configuration file located in _common directory. Since peon processes are spawned by middle manager process, they derivate the environment variables from the middle manager. These variables include those in the log4j2.xml controlling to which file the logger writes the log.  But current task logging mechanism requires the peon processes to output the log to console so that the middle manager can redirect the console output to a file and upload this file to task log storage.  So, this PR imposes this requirement to peon processes, whatever the configuration is in the shared log4j2.xml, peon processes always write the log to console.  \",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 15:07:21 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ff253fd8a32af4f74387bad14e8a4563af5c2bc0\",\n",
      "\t\t\"parent\": \"bb1a6def9dee55528907999e99ecf1b6c0c5f741\",\n",
      "\t\t\"subject\": \"Add setProcessingThreadNames context parameter. (#12514)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-setProcessingThreadNames-context-parameter.-12514\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"setting thread names takes a measurable amount of time in the case where segment scans are very quick. In high-QPS testing we found a slight performance boost from turning off processing thread renaming. This option makes that possible.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 16 May 2022 13:42:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bb1a6def9dee55528907999e99ecf1b6c0c5f741\",\n",
      "\t\t\"parent\": \"7ab21708021cb534ad34608b3fb06cb0273c2cd2\",\n",
      "\t\t\"subject\": \"Task queue unblock (#12099)\",\n",
      "\t\t\"sanitized_subject_line\": \"Task-queue-unblock-12099\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* concurrency: introduce GuardedBy to TaskQueue  * perf: Introduce TaskQueueScaleTest to test performance of TaskQueue with large task counts  This introduces a test case to confirm how long it will take to launch and manage (aka shutdown) a large number of threads in the TaskQueue.  h/t to @gianm for main implementation.  * perf: improve scalability of TaskQueue with large task counts  * linter fixes, expand test coverage  * pr feedback suggestion; swap to different linter  * swap to use SuppressWarnings  * Fix TaskQueueScaleTest.  Co-authored-by: Gian Merlino <gian@imply.io>\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 14 May 2022 16:44:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7ab21708021cb534ad34608b3fb06cb0273c2cd2\",\n",
      "\t\t\"parent\": \"39b3487aa9829d1d5b19733ef76319d8133dcb38\",\n",
      "\t\t\"subject\": \"Use datasketches version 3.2.0 (#12509)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-datasketches-version-3.2.0-12509\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Use apache datasketches version 3.2.0. - Remove unsafe reflection-based usage of datasketch internals added in #12022\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 13 May 2022 11:28:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"39b3487aa9829d1d5b19733ef76319d8133dcb38\",\n",
      "\t\t\"parent\": \"9177515be224269dc0299eae809591cb373d83a0\",\n",
      "\t\t\"subject\": \"Add replace statement to sql parser (#12386)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-replace-statement-to-sql-parser-12386\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Relevant Issue: #11929  - Add custom replace statement to Druid SQL parser. - Edit DruidPlanner to convert relevant fields to Query Context. - Refactor common code with INSERT statements to reuse them for REPLACE where possible.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 13 May 2022 10:56:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9177515be224269dc0299eae809591cb373d83a0\",\n",
      "\t\t\"parent\": \"9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2\",\n",
      "\t\t\"subject\": \"Add IPAddress java library as dependency and migrate IPv4 functions to use the new library. (#11634)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-IPAddress-java-library-as-dependency-and-migrate-IPv4-functions-to-use-the-new-library.-11634\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add ipaddress library as dependency.  * IPv4 functions to use the inet.ipaddr package.  * Remove unused imports.  * Add new function.  * Minor rename.  * Add more unit tests.  * IPv4 address expr utils unit tests and address options.  * Adjust the IPv4Util functions.  * Move the UTs a bit around.  * Javadoc comments.  * Add license info for IPAddress.  * Fix groupId, artifact and version in license.yaml.  * Remove redundant subnet in messages - fixes UT.  * Remove unused commons-net dependency for /processing project.  * Make class and methods public so it can be accessed.  * Add initial version of benchmark  * Add subnetutils package for benchmarks.  * Auto generate ip addresses.  * Add more v4 address representations in setup to avoid bias.  * Use ThreadLocalRandom to avoid forbidden API usage.  * Adjust IPv4AddressBenchmark to adhere to codestyle rules.  * Update ipaddress library to latest 5.3.4  * Add ipaddress package dependency to benchmarks project.\",\n",
      "\t\t\"author_name\": \"Abhishek Radhakrishnan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 May 2022 22:06:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9e5a940cf1fc04b00f9cb0216ec8766d8fed0ee2\",\n",
      "\t\t\"parent\": \"deb69d1bc03aef784a563260bed1d21505495439\",\n",
      "\t\t\"subject\": \"remake column indexes and query processing of filters (#12388)\",\n",
      "\t\t\"sanitized_subject_line\": \"remake-column-indexes-and-query-processing-of-filters-12388\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Following up on #12315, which pushed most of the logic of building ImmutableBitmap into BitmapIndex in order to hide the details of how column indexes are implemented from the Filter implementations, this PR totally refashions how Filter consume indexes. The end result, while a rather dramatic reshuffling of the existing code, should be extraordinarily flexible, eventually allowing us to model any type of index we can imagine, and providing the machinery to build the filters that use them, while also allowing for other column implementations to implement the built-in index types to provide adapters to make use indexing in the current set filters that Druid provides. \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 May 2022 11:57:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"deb69d1bc03aef784a563260bed1d21505495439\",\n",
      "\t\t\"parent\": \"60b4fa0f753043bddb45bb508aadb2dd55433584\",\n",
      "\t\t\"subject\": \"Allow coordinator to be configured to kill segments in future (#10877)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-coordinator-to-be-configured-to-kill-segments-in-future-10877\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Allow a Druid cluster to kill segments whose interval_end is a date in the future. This can be done by setting druid.coordinator.kill.durationToRetain to a negative period. For example PT-24H would allow segments to be killed if their interval_end date was 24 hours or less into the future at the time that the kill task is generated by the system.  A cluster operator can also disregard the druid.coordinator.kill.durationToRetain entirely by setting a new configuration, druid.coordinator.kill.ignoreDurationToRetain=true. This ignores interval_end date when looking for segments to kill, and instead is capable of killing any segment marked unused. This new configuration is off by default, and a cluster operator should fully understand and accept the risks if they enable it.\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 11 May 2022 07:35:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"60b4fa0f753043bddb45bb508aadb2dd55433584\",\n",
      "\t\t\"parent\": \"75836a5a06b7d41b4151eca41b83d580cdd8486f\",\n",
      "\t\t\"subject\": \"Docs: Fix column name in ingestion rollup doc (#12036)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Fix-column-name-in-ingestion-rollup-doc-12036\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fix the referred column name from \\\"count\\\" to \\\"num_rows\\\" as \\\"count\\\" vs. \\\"COUNT(*)\\\" might be a little confusing in this example.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 May 2022 17:35:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"75836a5a06b7d41b4151eca41b83d580cdd8486f\",\n",
      "\t\t\"parent\": \"c68388ebcd6cc2a77d2f6c41320906b32a5f6028\",\n",
      "\t\t\"subject\": \"Add feature flag for sql planning of TimeBoundary queries (#12491)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-feature-flag-for-sql-planning-of-TimeBoundary-queries-12491\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add feature flag for sql planning of TimeBoundary queries  * fixup! Add feature flag for sql planning of TimeBoundary queries  * Add documentation for enableTimeBoundaryPlanning  * fixup! Add documentation for enableTimeBoundaryPlanning\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 10 May 2022 15:23:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c68388ebcd6cc2a77d2f6c41320906b32a5f6028\",\n",
      "\t\t\"parent\": \"2dd073c2cdd1a969a703612b433e4d7820bedc8b\",\n",
      "\t\t\"subject\": \"Vectorized version of string last aggregator (#12493)\",\n",
      "\t\t\"sanitized_subject_line\": \"Vectorized-version-of-string-last-aggregator-12493\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Vectorized version of string last aggregator  * Updating string last and adding testcases  * Updating code and adding testcases for serializable pairs  * Addressing review comments\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 9 May 2022 17:02:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2dd073c2cdd1a969a703612b433e4d7820bedc8b\",\n",
      "\t\t\"parent\": \"eb6de94e1f1a9d5e38f6ef16971be8d3763a83d8\",\n",
      "\t\t\"subject\": \"Pass metrics object for Scan, Timeseries and GroupBy queries during cursor creation (#12484)\",\n",
      "\t\t\"sanitized_subject_line\": \"Pass-metrics-object-for-Scan-Timeseries-and-GroupBy-queries-during-cursor-creation-12484\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Pass metrics object for Scan, Timeseries and GroupBy queries during cursor creation  * fixup! Pass metrics object for Scan, Timeseries and GroupBy queries during cursor creation  * Document vectorized dimension\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 9 May 2022 10:40:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb6de94e1f1a9d5e38f6ef16971be8d3763a83d8\",\n",
      "\t\t\"parent\": \"2d8eb117c0bc59aa79016ed0e28519f6b7aa7afc\",\n",
      "\t\t\"subject\": \"Add daily stats to console (#12329)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-daily-stats-to-console-12329\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 5 May 2022 15:31:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d8eb117c0bc59aa79016ed0e28519f6b7aa7afc\",\n",
      "\t\t\"parent\": \"0206a2da5c6211caf451751876d847f40c2e7755\",\n",
      "\t\t\"subject\": \"Web console: add a button to get out of restricted mode, make capability detection more robust (#12503)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-add-a-button-to-get-out-of-restricted-mode-make-capability-detection-more-robust-12503\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* allow unrestrict  * update tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 5 May 2022 15:06:59 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0206a2da5c6211caf451751876d847f40c2e7755\",\n",
      "\t\t\"parent\": \"35a7d863b77a692908d90ba529714210859f3f8b\",\n",
      "\t\t\"subject\": \"Update automatic compaction docs with consistent terminology (#12416)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-automatic-compaction-docs-with-consistent-terminology-12416\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* specify automatic compaction where applicable  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * update for style and consistency  * implement suggested feedback  * remove duplicate example  * Apply suggestions from code review  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/compaction.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/api-reference.md  * update .spelling  * Adopt review suggestions  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 May 2022 16:22:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"35a7d863b77a692908d90ba529714210859f3f8b\",\n",
      "\t\t\"parent\": \"fb08bac01a20723988b0be31452ce14a87a12207\",\n",
      "\t\t\"subject\": \"add aws-java-sdk-sts to aws-common classpath (#12482)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-aws-java-sdk-sts-to-aws-common-classpath-12482\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes #11303  WebIdentityTokenProvider in the defaultAWSCredentialsProviderChain can not actually be used because the aws-java-sdk-sts jar is not in the classpath of S3 extension at runtime, since each extension has its own classpath. This results in the inability to assume STS role before generating authentication token. The error message from getCredentials() is:  \\\"Unable to load credentials from WebIdentityTokenCredentialsProvider: To use assume role profiles the aws-java-sdk-sts module must be on the class path\\\"  This PR will fix multiple authentication modules that are dependent on the WebIdentityTokenProvider, including AWS IAM based RDS authentication and S3 authentication.\",\n",
      "\t\t\"author_name\": \"Naya Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 May 2022 12:25:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fb08bac01a20723988b0be31452ce14a87a12207\",\n",
      "\t\t\"parent\": \"de14f511d68fe9f8282164f53a7401bbf67011da\",\n",
      "\t\t\"subject\": \"Web console: Misc table fixes (#12489)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Misc-table-fixes-12489\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Misc table fixes  * extract default className  * table spacing updates  * fix e2e action selector  * try more times  * make the web console exist again\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 May 2022 12:08:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de14f511d68fe9f8282164f53a7401bbf67011da\",\n",
      "\t\t\"parent\": \"770ad951693f30e6b56af4db430f88f0408d10d5\",\n",
      "\t\t\"subject\": \"Fix broken ForkingTaskRunnerTest (#12499)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-broken-ForkingTaskRunnerTest-12499\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"A recent commit broke this test. This pr fixes the test.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 3 May 2022 04:00:36 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"770ad951693f30e6b56af4db430f88f0408d10d5\",\n",
      "\t\t\"parent\": \"785a1eeb9f4e70984b76a4e8900dc5e3e15acc4f\",\n",
      "\t\t\"subject\": \"Add a metric for task duration in the pending queue (#12492)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-metric-for-task-duration-in-the-pending-queue-12492\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR is to measure how long a task stays in the pending queue and emits the value with the metric task/pending/time. The metric is measured in RemoteTaskRunner and HttpRemoteTaskRunner.  An example of the metric:  ``` 2022-04-26T21:59:09,488 INFO [rtr-pending-tasks-runner-0] org.apache.druid.java.util.emitter.core.LoggingEmitter - {\\\"feed\\\":\\\"metrics\\\",\\\"timestamp\\\":\\\"2022-04-26T21:59:09.487Z\\\",\\\"service\\\":\\\"druid/coordinator\\\",\\\"host\\\":\\\"localhost:8081\\\",\\\"version\\\":\\\"2022.02.0-iap-SNAPSHOT\\\",\\\"metric\\\":\\\"task/pending/time\\\",\\\"value\\\":8,\\\"dataSource\\\":\\\"wikipedia\\\",\\\"taskId\\\":\\\"index_parallel_wikipedia_gecpcglg_2022-04-26T21:59:09.432Z\\\",\\\"taskType\\\":\\\"index_parallel\\\"} ```  ------------------------------------------ Key changed/added classes in this PR      Emit metric task/pending/time in classes RemoteTaskRunner and HttpRemoteTaskRunner.     Update related factory classes and tests. \",\n",
      "\t\t\"author_name\": \"Rocky Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 2 May 2022 23:47:25 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"785a1eeb9f4e70984b76a4e8900dc5e3e15acc4f\",\n",
      "\t\t\"parent\": \"39e7191f03b41580d95b28713a6f0e2cd9df52a1\",\n",
      "\t\t\"subject\": \"Update maven assembly plugin for druid-benchmarks (#12487)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-maven-assembly-plugin-for-druid-benchmarks-12487\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Nishant Bangarwa\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 2 May 2022 09:43:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"39e7191f03b41580d95b28713a6f0e2cd9df52a1\",\n",
      "\t\t\"parent\": \"dd8781f5b06b898280ecf15d6a44509441c566a8\",\n",
      "\t\t\"subject\": \"Add authentication call before cleaning up intermediate files in hadoop ingestions (#12030)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-authentication-call-before-cleaning-up-intermediate-files-in-hadoop-ingestions-12030\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add authentication call before cleaning up intermediate files in hadoop ingestions  * fix checkstyle  * remove debug log\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 2 May 2022 08:40:44 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dd8781f5b06b898280ecf15d6a44509441c566a8\",\n",
      "\t\t\"parent\": \"b97f273d5a4366c38e2d9b988d2eb51cadb2c022\",\n",
      "\t\t\"subject\": \"Upgrade dependency-check-maven to 7.0.4 (#12441)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-dependency-check-maven-to-7.0.4-12441\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"aggarwalakshay\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 1 May 2022 22:45:58 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b97f273d5a4366c38e2d9b988d2eb51cadb2c022\",\n",
      "\t\t\"parent\": \"bb080693a9c5b4475101a9783924cbe163405b3b\",\n",
      "\t\t\"subject\": \"docs: fix typo (#12494)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-typo-12494\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 1 May 2022 22:44:31 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bb080693a9c5b4475101a9783924cbe163405b3b\",\n",
      "\t\t\"parent\": \"1d1f53e7d5c3cd7f0e3c9e8e189b063be0fc50ac\",\n",
      "\t\t\"subject\": \"Improve build performance of modules (#12486)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-build-performance-of-modules-12486\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* improve build performance of modules  * improve build performance of modules  * Update pom.xml  * improve build performance of modules\",\n",
      "\t\t\"author_name\": \"MC-JY\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 1 May 2022 22:43:11 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d1f53e7d5c3cd7f0e3c9e8e189b063be0fc50ac\",\n",
      "\t\t\"parent\": \"529b983ad0ad8ee5b5cdcdfe81fe840fc3bd0427\",\n",
      "\t\t\"subject\": \"Improve error messages when URI points to a file that doesn't exist (#12490)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-error-messages-when-URI-points-to-a-file-that-doesn-t-exist-12490\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 1 May 2022 11:26:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"529b983ad0ad8ee5b5cdcdfe81fe840fc3bd0427\",\n",
      "\t\t\"parent\": \"42fa5c26e1f4e09692c9752ccba6126a9ae96905\",\n",
      "\t\t\"subject\": \"GroupBy: Reduce allocations by reusing entry and key holders. (#12474)\",\n",
      "\t\t\"sanitized_subject_line\": \"GroupBy-Reduce-allocations-by-reusing-entry-and-key-holders.-12474\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* GroupBy: Reduce allocations by reusing entry and key holders.  Two main changes:  1) Reuse Entry objects returned by various implementations of    Grouper.iterator.  2) Reuse key objects contained within those Entry objects.  This is allowed by the contract, which states that entries must be processed and immediately discarded. However, not all call sites respected this, so this patch also updates those call sites.  One particularly sneaky way that the old code retained entries too long is due to Guava's MergingIterator and CombiningIterator. Internally, these both advance to the next value prior to returning the current value. So, this patch addresses that in two ways:  1) For merging, we have our own implementation MergeIterator already,    although it had the same problem. So, this patch updates our    implementation to return the current item prior to advancing to the    next item. It also adds a forbidden-api entry to ensure that this    safer implementation is used instead of Guava's.  2) For combining, we address the problem in a different way: by copying    the key when creating the new, combined entry.  * Attempt to fix test.  * Remove unused import.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 28 Apr 2022 23:21:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"42fa5c26e1f4e09692c9752ccba6126a9ae96905\",\n",
      "\t\t\"parent\": \"df074f2f965c71d9abfc3f5aed6d189357ce600f\",\n",
      "\t\t\"subject\": \"remove arbitrary granularity spec from docs (#12460)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-arbitrary-granularity-spec-from-docs-12460\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove arbitrary granularity spec from docs  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 28 Apr 2022 16:36:54 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"df074f2f965c71d9abfc3f5aed6d189357ce600f\",\n",
      "\t\t\"parent\": \"7b89682bbecc0feffb1996f90f6d8905458c054b\",\n",
      "\t\t\"subject\": \"Improve exception message for native binary operators (#12335)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-exception-message-for-native-binary-operators-12335\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve exception message  * Update message\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 28 Apr 2022 10:20:16 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7b89682bbecc0feffb1996f90f6d8905458c054b\",\n",
      "\t\t\"parent\": \"a2bad0b3a2c80a5ffb704ec8c4a0e18734455d38\",\n",
      "\t\t\"subject\": \"DimensionRangeShardSpec speed boost. (#12477)\",\n",
      "\t\t\"sanitized_subject_line\": \"DimensionRangeShardSpec-speed-boost.-12477\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* DimensionRangeShardSpec speed boost.  Calling isEmpty() and equals() on RangeSets is expensive, because these fall back on default implementations that call size(). And size() is _also_ a default implementation that iterates the entire collection.  * Fix and test from code review.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 14:20:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a2bad0b3a2c80a5ffb704ec8c4a0e18734455d38\",\n",
      "\t\t\"parent\": \"2e42d04038a27863e0c8f3bb7704c1a362ede27e\",\n",
      "\t\t\"subject\": \"Reduce allocations due to Jackson serialization. (#12468)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-allocations-due-to-Jackson-serialization.-12468\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Reduce allocations due to Jackson serialization.  This patch attacks two sources of allocations during Jackson serialization:  1) ObjectMapper.writeValue and JsonGenerator.writeObject create a new    DefaultSerializerProvider instance for each call. It has lots of    fields and creates pressure on the garbage collector. So, this patch    adds helper functions in JacksonUtils that enable reuse of    SerializerProvider objects and updates various call sites to make    use of this.  2) GroupByQueryToolChest copies the ObjectMapper for every query to    install a special module that supports backwards compatibility with    map-based rows. This isn't needed if resultAsArray is set and    all servers are running Druid 0.16.0 or later. This release was a    while ago. So, this patch disables backwards compatibility by default,    which eliminates the need to copy the heavyweight ObjectMapper. The    patch also introduces a configuration option that allows admins to    explicitly enable backwards compatibility.  * Add test.  * Update additional call sites and add to forbidden APIs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 14:17:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2e42d04038a27863e0c8f3bb7704c1a362ede27e\",\n",
      "\t\t\"parent\": \"72d15ab321851e8b97ac10fcd6c71c5828af3ab6\",\n",
      "\t\t\"subject\": \"SQL: Create millisecond precision timestamp literals. (#12407)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Create-millisecond-precision-timestamp-literals.-12407\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Create millisecond precision timestamp literals.  Fixes a bug where implicit casts of strings to timestamps would use seconds precision rather than milliseconds. The new test case testCountStarWithBetweenTimeFilterUsingMillisecondsInStringLiterals exercises this.  * Update sql/src/main/java/org/apache/druid/sql/calcite/planner/Calcites.java  Co-authored-by: Frank Chen <frankchen@apache.org>  * Correct precision handling.  - Set default precision to 3 (millis) for things involving timestamps. - Respect precision specified in types when available.  * Silence, checkstyle.  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 14:17:07 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"72d15ab321851e8b97ac10fcd6c71c5828af3ab6\",\n",
      "\t\t\"parent\": \"e7e49ec9c857641efe1548f438e2d203248de7ea\",\n",
      "\t\t\"subject\": \"JvmMonitor: Handle more generation and collector scenarios. (#12469)\",\n",
      "\t\t\"sanitized_subject_line\": \"JvmMonitor-Handle-more-generation-and-collector-scenarios.-12469\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* JvmMonitor: Handle more generation and collector scenarios.  ZGC on Java 11 only has a generation 1 (there is no 0). This causes a NullPointerException when trying to extract the spacesCount for generation 0. In addition, ZGC on Java 15 has a collector number 2 but no spaces in generation 2, which breaks the assumption that collectors always have same-numbered spaces.  This patch adjusts things to be more robust, enabling the JvmMonitor to work properly for ZGC on both Java 11 and 15.  * Test adjustments.  * Improve surefire arglines.  * Need a placeholder\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 11:18:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e7e49ec9c857641efe1548f438e2d203248de7ea\",\n",
      "\t\t\"parent\": \"2fe053c5cbc0845e09a8f27580e42b097a4227e8\",\n",
      "\t\t\"subject\": \"For the various Yielder objects, don't create new Yielders and instead mutate state. (#12475)\",\n",
      "\t\t\"sanitized_subject_line\": \"For-the-various-Yielder-objects-don-t-create-new-Yielders-and-instead-mutate-state.-12475\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: imply-cheddar <86940447+imply-cheddar@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 10:52:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2fe053c5cbc0845e09a8f27580e42b097a4227e8\",\n",
      "\t\t\"parent\": \"1306965c9ea3c4a4a90667cdbd2b048467c2cb8d\",\n",
      "\t\t\"subject\": \"Bump up the versions (#12480)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-up-the-versions-12480\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 14:28:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1306965c9ea3c4a4a90667cdbd2b048467c2cb8d\",\n",
      "\t\t\"parent\": \"027935dcffd3f83b7faa94c187ab0572f16981c6\",\n",
      "\t\t\"subject\": \"Validate select columns for insert statement (#12431)\",\n",
      "\t\t\"sanitized_subject_line\": \"Validate-select-columns-for-insert-statement-12431\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Unnamed columns in the select part of insert SQL statements currently create a table with the column name such as \\\"EXPR$3\\\". This PR adds a check for this.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Apr 2022 12:25:49 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"027935dcffd3f83b7faa94c187ab0572f16981c6\",\n",
      "\t\t\"parent\": \"564d6defd47749d55dd07e5549d7264cbc1c4019\",\n",
      "\t\t\"subject\": \"Vectorize numeric latest aggregators (#12439)\",\n",
      "\t\t\"sanitized_subject_line\": \"Vectorize-numeric-latest-aggregators-12439\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Vectorizing Latest aggregator Part 1  * Updating benchmark tests  * Changing appropriate logic for vectors for null handling  * Introducing an abstract class and moving the commonalities there  * Adding vectorization for StringLast aggregator (initial version)  * Updated bufferized version of numeric aggregators  * Adding some javadocs  * Making sure this PR vectorizes numeric latest agg only  * Adding another benchmarking test  * Fixing intellij inspections  * Adding tests for double  * Adding test cases for long and float  * Updating testcases  * Checkstyle oops..  * One tiny change in test case  * Fixing spotbug and rhs not being used\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Apr 2022 11:33:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"564d6defd47749d55dd07e5549d7264cbc1c4019\",\n",
      "\t\t\"parent\": \"4868ef952977e2cb527900eff59188687a2b2183\",\n",
      "\t\t\"subject\": \"Worker level task metrics (#12446)\",\n",
      "\t\t\"sanitized_subject_line\": \"Worker-level-task-metrics-12446\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* * fix metric name inconsistency  * * add task slot metrics for middle managers  * * add new WorkerTaskCountStatsMonitor to report task count metrics   from worker  * * more stuff  * * remove unused variable  * * more stuff  * * add javadocs  * * fix checkstyle  * * fix hadoop test failure  * * cleanup  * * add more code coverage in tests  * * fix test failure  * * add docs  * * increase code coverage  * * fix spelling  * * fix failing tests  * * remove dead code  * * fix spelling\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Apr 2022 11:44:44 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4868ef952977e2cb527900eff59188687a2b2183\",\n",
      "\t\t\"parent\": \"95694b5afa505aea906f05db41c8901559b8bd2b\",\n",
      "\t\t\"subject\": \"Enable Arm builds (#12451)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-Arm-builds-12451\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR enables ARM builds on Travis. I've ported over the changes from @martin-g on reducing heap requirements for some of the tests to ensure they run well on Travis arm instances.  \",\n",
      "\t\t\"author_name\": \"Will Xu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Apr 2022 20:14:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"95694b5afa505aea906f05db41c8901559b8bd2b\",\n",
      "\t\t\"parent\": \"b47316b8442fb6f1f440c1418d63a5809559a2f4\",\n",
      "\t\t\"subject\": \"Convert simple min/max SQL queries on __time to timeBoundary queries (#12472)\",\n",
      "\t\t\"sanitized_subject_line\": \"Convert-simple-min-max-SQL-queries-on-__time-to-timeBoundary-queries-12472\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support array based results in timeBoundary query  * Fix bug with query interval in timeBoundary  * Convert min(__time) and max(__time) SQL queries to timeBoundary  * Add tests for timeBoundary backed SQL queries  * Fix query plans for existing tests  * fixup! Convert min(__time) and max(__time) SQL queries to timeBoundary  * fixup! Add tests for timeBoundary backed SQL queries  * fixup! Fix bug with query interval in timeBoundary\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Apr 2022 08:18:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b47316b8442fb6f1f440c1418d63a5809559a2f4\",\n",
      "\t\t\"parent\": \"4781af9921a5ed1ffe88aa9083cb93265e0ec8ba\",\n",
      "\t\t\"subject\": \"Update native-batch.md (#12478)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-native-batch.md-12478\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixed indent on the Granularity Spec section and removed some superfluous tabbings.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Apr 2022 21:44:17 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4781af9921a5ed1ffe88aa9083cb93265e0ec8ba\",\n",
      "\t\t\"parent\": \"2473de2552ee277dda47835daacf23eecd1fb80c\",\n",
      "\t\t\"subject\": \"Fix formatting in stats.md (#12470)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-formatting-in-stats.md-12470\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix formatting in stats.md  * Update stats.md  * Update docs/development/extensions-core/stats.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/development/extensions-core/stats.md  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Apoorv Gupta\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Apr 2022 11:35:08 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2473de2552ee277dda47835daacf23eecd1fb80c\",\n",
      "\t\t\"parent\": \"b7621226d28493899c1331f7bf45469706c248c5\",\n",
      "\t\t\"subject\": \"Metrics for shenandoah based on this source code: https://github.com/openjdk/jdk/blob/554caf33a01ac9ca2e3e9170557e8348750f3971/src/hotspot/share/gc/shenandoah/shenandoahMonitoringSupport.cpp#L65 (#12369)\",\n",
      "\t\t\"sanitized_subject_line\": \"Metrics-for-shenandoah-based-on-this-source-code-https-github.com-openjdk-jdk-blob-554caf33a01ac9ca2e3e9170557e8348750f3971-src-hotspot-share-gc-shenandoah-shenandoahMonitoringSupport.cpp-L65-12369\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Didip Kerabat <didip@apple.com>\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Apr 2022 11:44:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b7621226d28493899c1331f7bf45469706c248c5\",\n",
      "\t\t\"parent\": \"63a993c33a306c40b92738cbe46b09749103304f\",\n",
      "\t\t\"subject\": \"QueryScheduler: Log per-query message at DEBUG level. (#12467)\",\n",
      "\t\t\"sanitized_subject_line\": \"QueryScheduler-Log-per-query-message-at-DEBUG-level.-12467\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"We generally want to avoid having any routine per-query messages at INFO level, because they pollute logs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Apr 2022 11:22:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"63a993c33a306c40b92738cbe46b09749103304f\",\n",
      "\t\t\"parent\": \"f95447070ed2ccfa45c44075b2b5e94dfd175369\",\n",
      "\t\t\"subject\": \"stringFirst and stringLast supported in ingestion (#12466)\",\n",
      "\t\t\"sanitized_subject_line\": \"stringFirst-and-stringLast-supported-in-ingestion-12466\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Apr 2022 10:28:49 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f95447070ed2ccfa45c44075b2b5e94dfd175369\",\n",
      "\t\t\"parent\": \"65d00c705cc56185c6dd9678f860b3d0415caba6\",\n",
      "\t\t\"subject\": \"updated docs for sql query context (#12406)\",\n",
      "\t\t\"sanitized_subject_line\": \"updated-docs-for-sql-query-context-12406\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 11:19:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65d00c705cc56185c6dd9678f860b3d0415caba6\",\n",
      "\t\t\"parent\": \"73ce5df22dc64a675be2ec5e6b86b1b6ad211808\",\n",
      "\t\t\"subject\": \"Supress CVE 2022 26612 (#12463)\",\n",
      "\t\t\"sanitized_subject_line\": \"Supress-CVE-2022-26612-12463\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* supress CVE-2022-26612  * adding packageUrl  * suppressing CVE-2022-26612  * adding packageUrl  * moving to hadoop section\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 08:48:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"73ce5df22dc64a675be2ec5e6b86b1b6ad211808\",\n",
      "\t\t\"parent\": \"4c6ba73823bc0561dad1ea9c0088238922438f23\",\n",
      "\t\t\"subject\": \"Add support for authorizing query context params (#12396)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-support-for-authorizing-query-context-params-12396\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The query context is a way that the user gives a hint to the Druid query engine, so that they enforce a certain behavior or at least let the query engine prefer a certain plan during query planning. Today, there are 3 types of query context params as below.  Default context params. They are set via druid.query.default.context in runtime properties. Any user context params can be default params. User context params. They are set in the user query request. See https://druid.apache.org/docs/latest/querying/query-context.html for parameters. System context params. They are set by the Druid query engine during query processing. These params override other context params. Today, any context params are allowed to users. This can cause  1) a bad UX if the context param is not matured yet or  2) even query failure or system fault in the worst case if a sensitive param is abused, ex) maxSubqueryRows.  This PR adds an ability to limit context params per user role. That means, a query will fail if you have a context param set in the query that is not allowed to you. To do that, this PR adds a new built-in resource type, QUERY_CONTEXT. The resource to authorize has a name of the context param (such as maxSubqueryRows) and the type of QUERY_CONTEXT. To allow a certain context param for a user, the user should be granted WRITE permission on the context param resource. Here is an example of the permission.  {   \\\"resourceAction\\\" : {     \\\"resource\\\" : {       \\\"name\\\" : \\\"maxSubqueryRows\\\",       \\\"type\\\" : \\\"QUERY_CONTEXT\\\"     },     \\\"action\\\" : \\\"WRITE\\\"   },   \\\"resourceNamePattern\\\" : \\\"maxSubqueryRows\\\" } Each role can have multiple permissions for context params. Each permission should be set for different context params.  When a query is issued with a query context X, the query will fail if the user who issued the query does not have WRITE permission on the query context X. In this case,  HTTP endpoints will return 403 response code. JDBC will throw ForbiddenException. Note: there is a context param called brokerService that is used only by the router. This param is used to pin your query to run it in a specific broker. Because the authorization is done not in the router, but in the broker, if you have brokerService set in your query without a proper permission, your query will fail in the broker after routing is done. Technically, this is not right because the authorization is checked after the context param takes effect. However, this should not cause any user-facing issue and thus should be OK. The query will still fail if the user doesn\\u2019t have permission for brokerService.  The context param authorization can be enabled using druid.auth.authorizeQueryContextParams. This is disabled by default to avoid any hassle when someone upgrades his cluster blindly without reading release notes.\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 14:21:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4c6ba73823bc0561dad1ea9c0088238922438f23\",\n",
      "\t\t\"parent\": \"177e1856cdaf3e5aa7a5754d129fc1945b9f7c72\",\n",
      "\t\t\"subject\": \"Emit vectorized metric dimension by default (#12464)\",\n",
      "\t\t\"sanitized_subject_line\": \"Emit-vectorized-metric-dimension-by-default-12464\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 20 Apr 2022 21:14:55 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"177e1856cdaf3e5aa7a5754d129fc1945b9f7c72\",\n",
      "\t\t\"parent\": \"5099f5aa70baf679f3b29162eaa2c6846bdf776d\",\n",
      "\t\t\"subject\": \"Fix GCS based ingestion if bucket name contains underscores (#12445)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-GCS-based-ingestion-if-bucket-name-contains-underscores-12445\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"GCP allows bucket names to contain underscores. When a location in such a bucket is mapped to `java.net.URI`, `URI.getHost()` returns null. `URI.getHost()` is used as the bucket name in `CloudObjectLocation`, leading to an NPE.  This commit uses `URI.getAuthority()` as the bucket name if `URI.getHost()` is null.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 09:22:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5099f5aa70baf679f3b29162eaa2c6846bdf776d\",\n",
      "\t\t\"parent\": \"341c65738d7ac15889a3a07d119029d91a527935\",\n",
      "\t\t\"subject\": \"update httpclient due to cve (#12422)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-httpclient-due-to-cve-12422\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"https://github.com/apache/druid/issues/12421\",\n",
      "\t\t\"author_name\": \"PJ Fanning\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 10:12:19 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"341c65738d7ac15889a3a07d119029d91a527935\",\n",
      "\t\t\"parent\": \"2db02876cf95f2179c3cc2a7a443e250c3fe451a\",\n",
      "\t\t\"subject\": \"issue-12426 upgrade k8s client due to cve (#12427)\",\n",
      "\t\t\"sanitized_subject_line\": \"issue-12426-upgrade-k8s-client-due-to-cve-12427\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* issue-12426 upgrade k8s client due to cve  * compile issues  * try to fix license check\",\n",
      "\t\t\"author_name\": \"PJ Fanning\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Apr 2022 10:11:55 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2db02876cf95f2179c3cc2a7a443e250c3fe451a\",\n",
      "\t\t\"parent\": \"691e26d2429cd81afef092dbda32e24ad56bb510\",\n",
      "\t\t\"subject\": \"Updating an error msg (#12450)\",\n",
      "\t\t\"sanitized_subject_line\": \"Updating-an-error-msg-12450\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Updating an error msg  * Added an extra [] so removing it\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 20 Apr 2022 07:56:09 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"691e26d2429cd81afef092dbda32e24ad56bb510\",\n",
      "\t\t\"parent\": \"0edc22179cc834f296a3b2f3a06db7bff27467c9\",\n",
      "\t\t\"subject\": \"Suppress CVE-2021-43138 (#12437)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-CVE-2021-43138-12437\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Suppress CVE-2021-43138  * revert netty 3.10.5.Final\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 20:00:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0edc22179cc834f296a3b2f3a06db7bff27467c9\",\n",
      "\t\t\"parent\": \"2677d279e2df3e3cdbe68007bfe2cf89820e09db\",\n",
      "\t\t\"subject\": \"Document expression post-aggregators (#11896)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-expression-post-aggregators-11896\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Document expression post-aggregators  * Update docs/querying/post-aggregations.md  Co-authored-by: Frank Chen <frankchen@apache.org>  Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"jacobtolar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Apr 2022 10:36:19 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2677d279e2df3e3cdbe68007bfe2cf89820e09db\",\n",
      "\t\t\"parent\": \"7b3b71f1d5eb9cc883cb96b8b69fb71635ba781b\",\n",
      "\t\t\"subject\": \"Remove h2 database from dependency (#12447)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-h2-database-from-dependency-12447\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Apr 2022 10:25:17 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7b3b71f1d5eb9cc883cb96b8b69fb71635ba781b\",\n",
      "\t\t\"parent\": \"c86c48203edf67a696a6e64c677a4792ff26079e\",\n",
      "\t\t\"subject\": \"Document running it tests from intellij IDE (#12440)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-running-it-tests-from-intellij-IDE-12440\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* document running IT tests in intellij  * clean up unnecessary changes  * address comments\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Apr 2022 10:24:46 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c86c48203edf67a696a6e64c677a4792ff26079e\",\n",
      "\t\t\"parent\": \"5167d328b10c5b0fd858c06c79bc8eb253bd5a39\",\n",
      "\t\t\"subject\": \"recommendation for comparing strings and numbers (#12442)\",\n",
      "\t\t\"sanitized_subject_line\": \"recommendation-for-comparing-strings-and-numbers-12442\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 09:28:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5167d328b10c5b0fd858c06c79bc8eb253bd5a39\",\n",
      "\t\t\"parent\": \"408b46ae9fdb44b0eee22d99440db0317e8e553a\",\n",
      "\t\t\"subject\": \"Docs - query caching (#11584)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-query-caching-11584\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update caching.md  Knowledge from https://the-asf.slack.com/archives/CJ8D1JTB8/p1597781107153900  Update caching.md  A few additional updates OTBO https://the-asf.slack.com/archives/CJ8D1JTB8/p1608669046041300  * Update caching.md  Typos  * Amendments on the segment cache  Significant updates on content around the segment cache, pull process, and in-memory cache  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/basic-cluster-tuning.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/basic-cluster-tuning.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update basic-cluster-tuning.md  typo  * Update docs/querying/caching.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Whole-query caching update  Made more succinct and removed specific config to change.  * Update docs/design/historical.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 17:00:21 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"408b46ae9fdb44b0eee22d99440db0317e8e553a\",\n",
      "\t\t\"parent\": \"de9f12b5c6d6b1a6096c0eec04097101e4792878\",\n",
      "\t\t\"subject\": \"Fixes a small typo in ingestion spec doc (#12143)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixes-a-small-typo-in-ingestion-spec-doc-12143\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* small typo  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: sthetland <steve.hetland@imply.io>  Co-authored-by: sthetland <steve.hetland@imply.io>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 16:53:50 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de9f12b5c6d6b1a6096c0eec04097101e4792878\",\n",
      "\t\t\"parent\": \"1201c9b2e56fd39d3b5a4120360c115c2c4347fc\",\n",
      "\t\t\"subject\": \"Fail fast incase a lookup load fails (#12397)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fail-fast-incase-a-lookup-load-fails-12397\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently while loading a lookup for the first time, loading threads blocks for `waitForFirstRunMs` incase the lookup failed to load. If the `waitForFirstRunMs` is long (like 10 minutes), such blocking can slow down the loading of other lookups.  This commit allows the thread to progress as soon as the loading of the lookup fails.\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 13:14:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1201c9b2e56fd39d3b5a4120360c115c2c4347fc\",\n",
      "\t\t\"parent\": \"9f2b37f2509aa369400a187174c9b3238fcd9e8b\",\n",
      "\t\t\"subject\": \"Docs - added another common config property to tuningConfig (#11935)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-added-another-common-config-property-to-tuningConfig-11935\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update ingestion-spec.md  Added indexSpecForIntermediatePersists as a common configuration property.  * Update ingestion-spec.md  Amended to remove \\\"below\\\" and add link to the table.  * Update ingestion-spec.md  Removed passive.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 13:41:39 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9f2b37f2509aa369400a187174c9b3238fcd9e8b\",\n",
      "\t\t\"parent\": \"c25a5568275c506115914cc5622a829c89f8e384\",\n",
      "\t\t\"subject\": \"Update tutorial-compaction.md to change an unclear statement (#11988)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-tutorial-compaction.md-to-change-an-unclear-statement-11988\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update tutorial-compaction.md  Unclear statement on the explanation of tuningConfig section.  * Update docs/tutorials/tutorial-compaction.md  Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Kashif Faraz <kashif.faraz@gmail.com>\",\n",
      "\t\t\"author_name\": \"Alexandre BERTHIOT\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Apr 2022 13:25:09 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c25a5568275c506115914cc5622a829c89f8e384\",\n",
      "\t\t\"parent\": \"0460d45e92a15ebdadb4455afa16a7d977f74388\",\n",
      "\t\t\"subject\": \"Fix bug in auto compaction preserveExistingMetrics feature (#12438)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bug-in-auto-compaction-preserveExistingMetrics-feature-12438\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix bug  * fix test  * fix IT\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Apr 2022 15:47:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0460d45e92a15ebdadb4455afa16a7d977f74388\",\n",
      "\t\t\"parent\": \"a22d4137250b7f074fe596396755494905617e99\",\n",
      "\t\t\"subject\": \"Make tombstones ingestible by having them return an empty result set. (#12392)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-tombstones-ingestible-by-having-them-return-an-empty-result-set.-12392\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make tombstones ingestible by having them return an empty result set.  * Spotbug  * Coverage  * Coverage  * Remove unnecessary exception (checkstyle)  * Fix integration test and add one more to test dropExisting set to false over tombstones  * Force dropExisting to true in auto-compaction when the interval contains only tombstones  * Checkstyle, fix unit test  * Changed flag by mistake, fixing it  * Remove method from interface since this method is specific to only DruidSegmentInputentity  * Fix typo  * Adapt to latest code  * Update comments when only tombstones to compact  * Move empty iterator to a new DruidTombstoneSegmentReader  * Code review feedback  * Checkstyle  * Review feedback  * Coverage\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Apr 2022 09:08:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a22d4137250b7f074fe596396755494905617e99\",\n",
      "\t\t\"parent\": \"cd6fba2f6cf6e189ba26097c73b9dbe4f1d0edbc\",\n",
      "\t\t\"subject\": \"Use binary search to improve DimensionRangeShardSpec lookup (#12417)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-binary-search-to-improve-DimensionRangeShardSpec-lookup-12417\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"If there are many shards, mapper of IndexGeneratorJob seems to spend a lot of time in calling DimensionRangeShardSpec.isInChunk to lookup target shard. This can be significantly improved by using binary search instead of comparing an input row to every shardSpec.  Changes: * Add `BaseDimensionRangeShardSpec` which provides a binary-search-based    implementation for `createLookup` * `DimensionRangeShardSpec`, `SingleDimensionShardSpec`, and     `DimensionRangeBucketShardSpec` now extend `BaseDimensionRangeShardSpec`\",\n",
      "\t\t\"author_name\": \"hqx871\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Apr 2022 21:37:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cd6fba2f6cf6e189ba26097c73b9dbe4f1d0edbc\",\n",
      "\t\t\"parent\": \"a72cc28959a5dfa639d1bff069597a97ea5d4eba\",\n",
      "\t\t\"subject\": \"Handling planning with alias for time for group by and order by (#12418)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handling-planning-with-alias-for-time-for-group-by-and-order-by-12418\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"An outer scan query, that requires ordering on a column, should be considered an invalid query. \",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Apr 2022 10:29:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a72cc28959a5dfa639d1bff069597a97ea5d4eba\",\n",
      "\t\t\"parent\": \"5824ab9608dc05aa6d04152e9b0357585c6823bf\",\n",
      "\t\t\"subject\": \"good stuff (#12435)\",\n",
      "\t\t\"sanitized_subject_line\": \"good-stuff-12435\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Apr 2022 00:23:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5824ab9608dc05aa6d04152e9b0357585c6823bf\",\n",
      "\t\t\"parent\": \"5d37d9f9d81cfc1d30c4f5f542fd264964cddd33\",\n",
      "\t\t\"subject\": \"fix issue with boolean expression input (#12429)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issue-with-boolean-expression-input-12429\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Apr 2022 16:34:01 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5d37d9f9d81cfc1d30c4f5f542fd264964cddd33\",\n",
      "\t\t\"parent\": \"5e5625f3ae9fa663697214f49e66b5c296d342fb\",\n",
      "\t\t\"subject\": \"Add docs to metric spec for auto compaction (#12415)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-docs-to-metric-spec-for-auto-compaction-12415\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add docs  * Update docs/configuration/index.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update index.md  * Update docs/configuration/index.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Apr 2022 13:27:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5e5625f3ae9fa663697214f49e66b5c296d342fb\",\n",
      "\t\t\"parent\": \"f24e9c68620e0e3ed81450f57081b8f75eeaac64\",\n",
      "\t\t\"subject\": \"Fix indexMerger to respect the includeAllDimensions flag (#12428)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-indexMerger-to-respect-the-includeAllDimensions-flag-12428\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix indexMerger to respect flag includeAllDimensions flag; jsonInputFormat should set keepNullColumns if useFieldDiscovery is set  * address comments\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Apr 2022 12:43:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f24e9c68620e0e3ed81450f57081b8f75eeaac64\",\n",
      "\t\t\"parent\": \"a139cd22aa81d7b6e0de98a01002b0f8f00f28c6\",\n",
      "\t\t\"subject\": \"Add Kinesis ListShards permission (#12387)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Kinesis-ListShards-permission-12387\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add Kinesis permission  * List Kinesis IAM permissions  * Adopt review suggestions  * Fix merge conflicts\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 13 Apr 2022 15:29:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a139cd22aa81d7b6e0de98a01002b0f8f00f28c6\",\n",
      "\t\t\"parent\": \"2c79d28bb772567893433602c9a39acb0d188e10\",\n",
      "\t\t\"subject\": \"Web console: Misc fixes and improvements  (#12361)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Misc-fixes-and-improvements-12361\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Misc fixes  * pad column numbers  * make shard_type filterable\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 12 Apr 2022 22:20:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2c79d28bb772567893433602c9a39acb0d188e10\",\n",
      "\t\t\"parent\": \"665c926824375fd096db805e7140d4be1d361dc1\",\n",
      "\t\t\"subject\": \"Copy of #11309 with fixes (#12402)\",\n",
      "\t\t\"sanitized_subject_line\": \"Copy-of-11309-with-fixes-12402\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Optionally load segment index files into page cache on bootstrap and new segment download  * Fix unit test failure  * Fix test case  * fix spelling  * fix spelling  * fix test and test coverage issues  Co-authored-by: Jian Wang <wjhypo@gmail.com>\",\n",
      "\t\t\"author_name\": \"Parag Jain\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Apr 2022 21:05:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"665c926824375fd096db805e7140d4be1d361dc1\",\n",
      "\t\t\"parent\": \"d2a6754692af3d14ba7622f8c7ad6a8b06eb461a\",\n",
      "\t\t\"subject\": \"Fix zulu8 set-up Dockerfile for hadoop and hadoop3 in hadoop ingestion tutorial (#12248)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-zulu8-set-up-Dockerfile-for-hadoop-and-hadoop3-in-hadoop-ingestion-tutorial-12248\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fix errors related to zulu8 installation for building the Hadoop Docker image in the Load From Apache Hadoop tutorial.  The steps to download zulu8 in the Dockerfile and setup-zulu-repo.sh were replaced with the steps in the Dockerfile released by zulu-openjdk: https://github.com/zulu-openjdk/zulu-openjdk/blob/be45d20302e42df5aa95d2de078bb5e4214f5dba/centos/8u282-8.52.0.23/Dockerfile.\",\n",
      "\t\t\"author_name\": \"Tiffany Yeh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 11 Apr 2022 20:28:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d2a6754692af3d14ba7622f8c7ad6a8b06eb461a\",\n",
      "\t\t\"parent\": \"b74cb7624df15aff61c0c979dac9236f3a53bb45\",\n",
      "\t\t\"subject\": \"Bump PostgreSQL JDBC driver to 42.3.3 (CVE-2022-21724) (#12410)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-PostgreSQL-JDBC-driver-to-42.3.3-CVE-2022-21724-12410\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump PostgreSQL JDBC driver to 42.3.3 (CVE-2022-21724)  * update license file\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Apr 2022 15:38:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b74cb7624df15aff61c0c979dac9236f3a53bb45\",\n",
      "\t\t\"parent\": \"36e17a20ea69881540cf8c9e01f1ca288310ba6a\",\n",
      "\t\t\"subject\": \"Make error messages for insert statements consistent with select statements (#12414)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-error-messages-for-insert-statements-consistent-with-select-statements-12414\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"For a query like INSERT INTO tablename SELECT channel, added as count FROM wikipedia the error message is Encountered \\\"as count\\\". However, for the insert statement INSERT INTO t SELECT channel, added as count FROM wikipedia PARTITIONED BY ALL returns INSERT statements must specify PARTITIONED BY clause explictly (incorrectly). This PR corrects this.  Add EOF to end of Druid SQL Insert statements Rename SQL Insert statements in the parser to reflect the behaviour change\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Apr 2022 12:21:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36e17a20ea69881540cf8c9e01f1ca288310ba6a\",\n",
      "\t\t\"parent\": \"8edea5a82dfdb34c3177c0efd7a79bae54751ab8\",\n",
      "\t\t\"subject\": \"Improve metrics for Auto Compaction (#12413)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-metrics-for-Auto-Compaction-12413\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add docs  * fix\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Apr 2022 20:14:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8edea5a82dfdb34c3177c0efd7a79bae54751ab8\",\n",
      "\t\t\"parent\": \"bf96ddf5bac50e5e9ae778eb28ee300fea6fc62f\",\n",
      "\t\t\"subject\": \"Add a new flag for ingestion to preserve existing metrics (#12185)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-new-flag-for-ingestion-to-preserve-existing-metrics-12185\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add impl  * fix checkstyle  * add impl  * add unit test  * fix stuff  * fix stuff  * fix stuff  * add unit test  * add more unit tests  * add more unit tests  * add IT  * add IT  * add IT  * add IT  * add ITs  * address comments  * fix test  * fix test  * fix test  * address comments  * address comments  * address comments  * fix conflict  * fix checkstyle  * address comments  * fix test  * fix checkstyle  * fix test  * fix test  * fix IT\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Apr 2022 11:02:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bf96ddf5bac50e5e9ae778eb28ee300fea6fc62f\",\n",
      "\t\t\"parent\": \"df48e446b04ce0272a7d0c9e0a70dc5cedb07076\",\n",
      "\t\t\"subject\": \"Update index.md (#12390)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-index.md-12390\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Added guidance on when to increase druid.indexer.storage.recentlyFinishedThreshold.\",\n",
      "\t\t\"author_name\": \"mark-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Apr 2022 18:01:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"df48e446b04ce0272a7d0c9e0a70dc5cedb07076\",\n",
      "\t\t\"parent\": \"d98cbd90f06576b0c89eb3d82a92abbfe09f53a8\",\n",
      "\t\t\"subject\": \"Fix the other 2 python scripts that generates license. (#12340)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-other-2-python-scripts-that-generates-license.-12340\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes YAML.load_all issues on two of the Python scripts that generate license.  The broken Python files interfere with some of the Maven tasks.\",\n",
      "\t\t\"author_name\": \"Didip Kerabat\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Apr 2022 16:43:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d98cbd90f06576b0c89eb3d82a92abbfe09f53a8\",\n",
      "\t\t\"parent\": \"d82a8185d1d4db68791658e75562e5780dc3f5ea\",\n",
      "\t\t\"subject\": \"Update basic-cluster-tuning.md (#12412)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-basic-cluster-tuning.md-12412\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changed \\\"Other useful JVM flags\\\" to \\\"Other generally useful JVM flags\\\" in order to align with the introduction to the doc.\",\n",
      "\t\t\"author_name\": \"mark-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Apr 2022 15:29:55 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d82a8185d1d4db68791658e75562e5780dc3f5ea\",\n",
      "\t\t\"parent\": \"a8e97efea9a80ca6538d9ab00f443ba36072cc12\",\n",
      "\t\t\"subject\": \"fix(docs): clarify what s3 permissions are needed based on the access management type (#12405)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-docs-clarify-what-s3-permissions-are-needed-based-on-the-access-management-type-12405\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix(docs): clarify what s3 permissions are needed based on the permissions model  * fix typo  * Update docs/development/extensions-core/s3.md  Co-authored-by: Jihoon Son <jihoonson@apache.org>  Co-authored-by: Jihoon Son <jihoonson@apache.org>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Apr 2022 16:22:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8e97efea9a80ca6538d9ab00f443ba36072cc12\",\n",
      "\t\t\"parent\": \"7d10e02463156a0f8bbb755eeaa95a90ec4394ad\",\n",
      "\t\t\"subject\": \"Bump minimist from 1.2.5 to 1.2.6 in /website (#12400)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-minimist-from-1.2.5-to-1.2.6-in-website-12400\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6. - [Release notes](https://github.com/substack/minimist/releases) - [Commits](https://github.com/substack/minimist/compare/1.2.5...1.2.6)  --- updated-dependencies: - dependency-name: minimist   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Apr 2022 03:08:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7d10e02463156a0f8bbb755eeaa95a90ec4394ad\",\n",
      "\t\t\"parent\": \"e8635df9e729ba7f05e3b5c5ed4b676925b1e87f\",\n",
      "\t\t\"subject\": \"Bump minimist from 1.2.5 to 1.2.6 in /web-console (#12401)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-minimist-from-1.2.5-to-1.2.6-in-web-console-12401\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6. - [Release notes](https://github.com/substack/minimist/releases) - [Commits](https://github.com/substack/minimist/compare/1.2.5...1.2.6)  --- updated-dependencies: - dependency-name: minimist   dependency-type: indirect ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Apr 2022 16:55:14 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e8635df9e729ba7f05e3b5c5ed4b676925b1e87f\",\n",
      "\t\t\"parent\": \"e6229b76a68add5dd02165b5ade78a37189173eb\",\n",
      "\t\t\"subject\": \"clean up some bp3 classes (#12403)\",\n",
      "\t\t\"sanitized_subject_line\": \"clean-up-some-bp3-classes-12403\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Apr 2022 15:27:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e6229b76a68add5dd02165b5ade78a37189173eb\",\n",
      "\t\t\"parent\": \"ac6c24793e23672fa575d855d0cb5a3ba610f2bb\",\n",
      "\t\t\"subject\": \"Document data format and example for featureSpec (#12394)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-data-format-and-example-for-featureSpec-12394\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add data format and example for featureSpec  * add second feature in example  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Apr 2022 15:17:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ac6c24793e23672fa575d855d0cb5a3ba610f2bb\",\n",
      "\t\t\"parent\": \"d326c681c1c43724266f84d3ede31ac8299cafe8\",\n",
      "\t\t\"subject\": \"docs(fix): add clarity around granularitySpec (#12362)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-fix-add-clarity-around-granularitySpec-12362\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix: add clarify around granularitySpec  * fix spacing  * Update docs/ingestion/compaction.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"317brian\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Apr 2022 09:24:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d326c681c1c43724266f84d3ede31ac8299cafe8\",\n",
      "\t\t\"parent\": \"7d5666109c9d4952fc66af170c7d46918d7378dd\",\n",
      "\t\t\"subject\": \"Document config for ingesting null columns (#12389)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-config-for-ingesting-null-columns-12389\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* config for ingesting null columns  * add link  * edit .spelling  * what happens if storeEmptyColumns is disabled\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Apr 2022 09:15:42 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7d5666109c9d4952fc66af170c7d46918d7378dd\",\n",
      "\t\t\"parent\": \"2cc2088720e82339ecbe1a510b6312f3aa9d4c23\",\n",
      "\t\t\"subject\": \"upgrade surefire 3.0.0-M6 (#12395)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-surefire-3.0.0-M6-12395\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* upgrade surefire 3.0.0-M6  * increasing memory\",\n",
      "\t\t\"author_name\": \"aggarwalakshay\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 23:56:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2cc2088720e82339ecbe1a510b6312f3aa9d4c23\",\n",
      "\t\t\"parent\": \"90680543d0086a7692101072cf804241f5a883dd\",\n",
      "\t\t\"subject\": \"Method to specify eternity in the scan query builder (#12223)\",\n",
      "\t\t\"sanitized_subject_line\": \"Method-to-specify-eternity-in-the-scan-query-builder-12223\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Method to specify eternity in the scan query builder  * Fix checkstyle issue  * Renamed eterity() to eternityInterval()  * Minor fixes\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 15:11:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90680543d0086a7692101072cf804241f5a883dd\",\n",
      "\t\t\"parent\": \"067254b7782cad0b27abf5815771981a4fcf3cda\",\n",
      "\t\t\"subject\": \"Blueprint 4 (#12391)\",\n",
      "\t\t\"sanitized_subject_line\": \"Blueprint-4-12391\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update blueprint dependencies & LICENSES  * Switch to bp4 namespace; use bp-ns variable in overrides  * Add webpack alias for colors.scss  * Snapshots  * Update selectors in e2e tests\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 10:34:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"067254b7782cad0b27abf5815771981a4fcf3cda\",\n",
      "\t\t\"parent\": \"984904779bea348905d96c95e1c3f05f44883af8\",\n",
      "\t\t\"subject\": \"Package kinesis client jar within the extension (#12370)\",\n",
      "\t\t\"sanitized_subject_line\": \"Package-kinesis-client-jar-within-the-extension-12370\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"amazon-kinesis-client was not covered undered the apache license and required separate insertion in the kinesis extension. This can now be avoided since it is covered, and including it within druid helps prevent incompatibilities.  Allows enabling of deaggregation out of the box by packaging amazon-kinesis-client (1.14.4) with druid for kinesis ingestion.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 21:31:18 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"984904779bea348905d96c95e1c3f05f44883af8\",\n",
      "\t\t\"parent\": \"c5531be553caa037f4caf92361abc5252a61e202\",\n",
      "\t\t\"subject\": \"Increase default DatasourceCompactionConfig.inputSegmentSizeBytes to Long.MAX_VALUE (#12381)\",\n",
      "\t\t\"sanitized_subject_line\": \"Increase-default-DatasourceCompactionConfig.inputSegmentSizeBytes-to-Long.MAX_VALUE-12381\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The current default value of inputSegmentSizeBytes is 400MB, which is pretty low for most compaction use cases. Thus most users are forced to override the default.  The default value is now increased to Long.MAX_VALUE.\",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 16:28:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c5531be553caa037f4caf92361abc5252a61e202\",\n",
      "\t\t\"parent\": \"a1ea6581156bf415fe991cebf74182b24d5b2994\",\n",
      "\t\t\"subject\": \"Add feature flag for Kinesis listShards API usage (#12383)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-feature-flag-for-Kinesis-listShards-API-usage-12383\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"listShards API was used to get all the shards for kinesis ingestion to improve its resiliency as part of #12161.  However, this may require additional permissions in the IAM policy where the stream is present. (Please refer to: https://docs.aws.amazon.com/kinesis/latest/APIReference/API_ListShards.html).  A dynamic configuration useListShards has been added to KinesisSupervisorTuningConfig to control the usage of this API and prevent issues upon upgrade. It can be safely turned on (and is recommended when using kinesis ingestion) by setting this configuration to true.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Apr 2022 14:58:10 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a1ea6581156bf415fe991cebf74182b24d5b2994\",\n",
      "\t\t\"parent\": \"f1841c644408fe5d3bf801e2ab695a75dc100da9\",\n",
      "\t\t\"subject\": \"Introducing a new config to ignore nulls while computing String Cardinality (#12345)\",\n",
      "\t\t\"sanitized_subject_line\": \"Introducing-a-new-config-to-ignore-nulls-while-computing-String-Cardinality-12345\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Counting nulls in String cardinality with a config  * Adding tests for the new config  * Wrapping the vectorize part to allow backward compatibility  * Adding different tests, cleaning the code and putting the check at the proper position, handling hasRow() and hasValue() changes  * Updating testcase and code  * Adding null handling test to improve coverage  * Checkstyle fix  * Adding 1 more change in docs  * Making docs clearer\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Mar 2022 14:31:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f1841c644408fe5d3bf801e2ab695a75dc100da9\",\n",
      "\t\t\"parent\": \"b9a968e7ff5b10a06298c6564ebb7a2c011a5a1e\",\n",
      "\t\t\"subject\": \"Docs - S3 masking and nav update to S3 page (#11490)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-S3-masking-and-nav-update-to-S3-page-11490\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Docs: Masking S3 creds and some rewording  Knowledge transfer from https://groups.google.com/g/druid-user/c/FydcpFrA688  * Removed bold in one of the quote sections  * Update s3.md  * Update s3.md  Quick grammar change  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update s3.md  Typo  * Update docs/development/extensions-core/s3.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update s3.md  Active lang  * Update s3.md  LAng nit  * Update native-batch.md  LAng nit  * Update docs/ingestion/native-batch.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Grammar tidy-up and link fix  Corrected 2 x links to old page H2s, resolved the question around precedence, and some other grammatical changes.  * Update docs/development/extensions-core/s3.md  * Update s3.md  Removed an Erroneous E  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Mar 2022 09:13:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b9a968e7ff5b10a06298c6564ebb7a2c011a5a1e\",\n",
      "\t\t\"parent\": \"3c55565398356d1eaa503f55b1cec514188a8448\",\n",
      "\t\t\"subject\": \"Docs \\u2013 expressions link back and timestamp hint (#11674)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-expressions-link-back-and-timestamp-hint-11674\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update math-expr.md  Link back to transformSpec  * Update ingestion-spec.md  Moved info about using the timestamp inside transforms into the actual timestamp section.  * Update ingestion-spec.md  Active language.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Mar 2022 09:12:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c55565398356d1eaa503f55b1cec514188a8448\",\n",
      "\t\t\"parent\": \"49a3f4291a667ee33797ddcc83b3a274da333c2d\",\n",
      "\t\t\"subject\": \"Update ingestion-spec.md (#12371)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ingestion-spec.md-12371\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update ingestion-spec.md  Added best practice point to dimensions description.  * Update docs/ingestion/ingestion-spec.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"mark-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 29 Mar 2022 09:12:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"49a3f4291a667ee33797ddcc83b3a274da333c2d\",\n",
      "\t\t\"parent\": \"9ed7aa33ecaf9e9eab09a7a5f769afcd58209d6a\",\n",
      "\t\t\"subject\": \"Add an integration test for null-only columns (#12365)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-an-integration-test-for-null-only-columns-12365\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* integration test for null-only-columns  * metadata query  * fix test\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Mar 2022 16:40:45 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9ed7aa33ecaf9e9eab09a7a5f769afcd58209d6a\",\n",
      "\t\t\"parent\": \"f2495a67d206534b6ee79b083ce49b3131165192\",\n",
      "\t\t\"subject\": \"Docs for request logging (#12363)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-for-request-logging-12363\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add docs for request logging  * remove stray character  * Update docs/operations/request-logging.md  Co-authored-by: TSFenwick <tsfenwick@gmail.com>  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: TSFenwick <tsfenwick@gmail.com> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Mar 2022 14:09:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f2495a67d206534b6ee79b083ce49b3131165192\",\n",
      "\t\t\"parent\": \"9c6b9abcdef1b0e995142f9819345ea270f79f67\",\n",
      "\t\t\"subject\": \"fix messageGap metric (#12337)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-messageGap-metric-12337\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Yuanli Han\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Mar 2022 09:21:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9c6b9abcdef1b0e995142f9819345ea270f79f67\",\n",
      "\t\t\"parent\": \"ee44fe45c66c10af0746bf053faed2a61df6168b\",\n",
      "\t\t\"subject\": \"Use javaOptsArray provided in task context (#12326)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-javaOptsArray-provided-in-task-context-12326\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The `javaOpts` property is being read from task context but not `javaOptsArray`. Changes: - Read `javaOptsArray` from task context in `ForkingTaskRunner`. - Add test to verify that `javaOptsArray` in task context takes precedence over `javaOpts`\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Mar 2022 16:33:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ee44fe45c66c10af0746bf053faed2a61df6168b\",\n",
      "\t\t\"parent\": \"ea51d8a16c77dbb4074f5f665bbefb1cdc9e3406\",\n",
      "\t\t\"subject\": \"Bump java-dogstatsd-client from 2.13.0 to 4.0.0 (#12353)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-java-dogstatsd-client-from-2.13.0-to-4.0.0-12353\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump java-dogstatsd-client from 2.13.0 to 4.0.0 Bumps [java-dogstatsd-client](https://github.com/DataDog/java-dogstatsd-client) from 2.13.0 to 4.0.0. - [Release notes](https://github.com/DataDog/java-dogstatsd-client/releases) - [Changelog](https://github.com/DataDog/java-dogstatsd-client/blob/master/CHANGELOG.md) - [Commits](https://github.com/DataDog/java-dogstatsd-client/compare/v2.13.0...v4.0.0)  * migrate statsd-emitter tests from easymock to mockito * add simple init test to make diff coverage happy  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com> Co-authored-by: Xavier L\\u00e9aut\\u00e9 <xvrl@apache.org>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 26 Mar 2022 16:25:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ea51d8a16c77dbb4074f5f665bbefb1cdc9e3406\",\n",
      "\t\t\"parent\": \"b6eeef31e586c62853c69ade67848d31f0af18cd\",\n",
      "\t\t\"subject\": \"Duties in Indexing group (such as Auto Compaction) does not report metrics (#12352)\",\n",
      "\t\t\"sanitized_subject_line\": \"Duties-in-Indexing-group-such-as-Auto-Compaction-does-not-report-metrics-12352\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add unit tests  * fix checkstyle  * address comments  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Mar 2022 18:18:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b6eeef31e586c62853c69ade67848d31f0af18cd\",\n",
      "\t\t\"parent\": \"d7308e929076b2170ba34fd1b731aa0309e09e90\",\n",
      "\t\t\"subject\": \"Store null columns in the segments (#12279)\",\n",
      "\t\t\"sanitized_subject_line\": \"Store-null-columns-in-the-segments-12279\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Store null columns in the segments  * fix test  * remove NullNumericColumn and unused dependency  * fix compile failure  * use guava instead of apache commons  * split new tests  * unused imports  * address comments\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Mar 2022 16:54:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7308e929076b2170ba34fd1b731aa0309e09e90\",\n",
      "\t\t\"parent\": \"0867ca75e12f20934c92a8a3ed02bad3e740684f\",\n",
      "\t\t\"subject\": \"Added support in urls, and grouped metrics (#12296)\",\n",
      "\t\t\"sanitized_subject_line\": \"Added-support-in-urls-and-grouped-metrics-12296\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"syacobovitz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Mar 2022 11:22:05 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0867ca75e12f20934c92a8a3ed02bad3e740684f\",\n",
      "\t\t\"parent\": \"ef45a1551e96dc1a0528bfdba2b29e97fe1d1a42\",\n",
      "\t\t\"subject\": \"Fix OOM failures in dimension distribution phase of parallel indexing (#12331)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-OOM-failures-in-dimension-distribution-phase-of-parallel-indexing-12331\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Parallel indexing with range partitioning can often cause OOM in the `ParallelIndexSupervisorTask` during the dimension distribution phase. This typically happens because of too many `StringSketch` objects obtained from the different `partial_dimension_distribution` sub-tasks.  We need not keep any of the sketches in memory until we need to compute the PartitionBoundaries for the respective interval.  Changes - Extract `StringDistribution` from `DimensionDistributionReport`s when they are received   and write to disk inside the task/temp/distributions - After all the subtasks have finished, iterate over all the intervals one by one - For each interval, read the distributions from disk, merge them and create `PartitionBoundaries`. - Cleanup task/temp/distributions directory when all `PartitionBoundaries` have been determined\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Mar 2022 19:28:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ef45a1551e96dc1a0528bfdba2b29e97fe1d1a42\",\n",
      "\t\t\"parent\": \"1f0447e613906425d863b8d7a2152cc41fedbf0e\",\n",
      "\t\t\"subject\": \"Convert inQueryThreshold into query context parameter. (#12357)\",\n",
      "\t\t\"sanitized_subject_line\": \"Convert-inQueryThreshold-into-query-context-parameter.-12357\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Added Calcites InQueryThreshold as a query context parameter. Setting this parameter appropriately reduces the time taken for queries with large number of values in their IN conditions.\",\n",
      "\t\t\"author_name\": \"Adarsh Sanjeev\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Mar 2022 18:33:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f0447e613906425d863b8d7a2152cc41fedbf0e\",\n",
      "\t\t\"parent\": \"c3377bf744d875011cde602337c5c77600144044\",\n",
      "\t\t\"subject\": \"fix use of deprecated initMocks method (#12351)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-use-of-deprecated-initMocks-method-12351\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"follow-up to #12341 - fix use of deprecated initMocks methods and properly close mocks on teardown\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 19 Mar 2022 10:19:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c3377bf744d875011cde602337c5c77600144044\",\n",
      "\t\t\"parent\": \"4ed1abca94b3e99c6fbddff89a93a80bfaa95fc2\",\n",
      "\t\t\"subject\": \"upgrade maven-pmd-plugin to fix warning (#12349)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-maven-pmd-plugin-to-fix-warning-12349\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"we sometimes see warnings similar to the one mentioned https://issues.apache.org/jira/browse/MPMD-325  Upgrading the plugin should hopefully reduce occurrence of those.\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 19 Mar 2022 10:18:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ed1abca94b3e99c6fbddff89a93a80bfaa95fc2\",\n",
      "\t\t\"parent\": \"dbb9518f50d87f2a0512e8262ebc85a9f9f0e575\",\n",
      "\t\t\"subject\": \"Bump slf4j.version from 1.7.12 to 1.7.36 (#11594)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-slf4j.version-from-1.7.12-to-1.7.36-11594\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bump slf4j.version from 1.7.12 to 1.7.36  - [Release notes](Release notes: https://www.slf4j.org/news.html)  Updates `jcl-over-slf4j` from 1.7.12 to 1.7.36 - [Commits](https://github.com/qos-ch/slf4j/compare/v_1.7.12...v_1.7.36)  Updates `slf4j-simple` from 1.7.12 to 1.7.36 - [Commits](https://github.com/qos-ch/slf4j/compare/v_1.7.12...v_1.7.36)  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com> Co-authored-by: Suneet Saldanha <suneet@apache.org> Co-authored-by: Xavier L\\u00e9aut\\u00e9 <xvrl@apache.org>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Mar 2022 13:45:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dbb9518f50d87f2a0512e8262ebc85a9f9f0e575\",\n",
      "\t\t\"parent\": \"6f0e5f25fa5dbeda28102efbc1f61dec1469e7bb\",\n",
      "\t\t\"subject\": \"Fix auto compaction by adjusting compaction task's interval to align with segmentGranularity when segmentGranularity is set (#12334)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-auto-compaction-by-adjusting-compaction-task-s-interval-to-align-with-segmentGranularity-when-segmentGranularity-is-set-12334\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add ITs  * address comments  * address comments  * address comments  * fix failure  * fix checkstyle  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Mar 2022 12:46:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f0e5f25fa5dbeda28102efbc1f61dec1469e7bb\",\n",
      "\t\t\"parent\": \"c33fa116690b164454766dca69bfed2ab70e9645\",\n",
      "\t\t\"subject\": \"update surefire plugin to 3.0.0-M4 (#12342)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-surefire-plugin-to-3.0.0-M4-12342\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"stay on surefire 3.0.0-M4 until we can upgrade to 3.0.0-M6 with a fix for https://issues.apache.org/jira/browse/SUREFIRE-1815 causing issues in RetryUtilsTest.\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Mar 2022 08:20:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c33fa116690b164454766dca69bfed2ab70e9645\",\n",
      "\t\t\"parent\": \"8f3a631cbf1d4ab94759070bda6cc5b09390c3d6\",\n",
      "\t\t\"subject\": \"improve test compatibility with Java 17 and remove deprecated methods (#12341)\",\n",
      "\t\t\"sanitized_subject_line\": \"improve-test-compatibility-with-Java-17-and-remove-deprecated-methods-12341\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove use of reflection in EnvironmentVariableDynamicConfigProvider for Java 17 compatibility * fix mocks mock objects not getting closed properly, causing issues with Java 17 * remove use of deprecated methods and rules in tests\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Mar 2022 08:19:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8f3a631cbf1d4ab94759070bda6cc5b09390c3d6\",\n",
      "\t\t\"parent\": \"192e41124995861b5ee75e2243449918ee430c9b\",\n",
      "\t\t\"subject\": \"Fix missing conversionFactor in prometheus emitter (#12338)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-missing-conversionFactor-in-prometheus-emitter-12338\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"query/node/ttfb metrics are in milliseconds.\",\n",
      "\t\t\"author_name\": \"Aur\\u00e9lien Dunand\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Mar 2022 21:46:06 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"192e41124995861b5ee75e2243449918ee430c9b\",\n",
      "\t\t\"parent\": \"a5dfb911de2df2d056dacc710ff955738e8683e5\",\n",
      "\t\t\"subject\": \"fix build due to com.nimbusds:lang-tag update (#12348)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-build-due-to-com.nimbusds-lang-tag-update-12348\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"the version of com.nimbusds:oauth2-oidc-sdk we depend on does not specific an exact version dependency for com.nimbusds:lang-tag, and instead uses a version range (see     https://search.maven.org/artifact/com.nimbusds/oauth2-oidc-sdk/6.5/jar)  Recently a new version of lang-tag was released requiring us to update the license file accordingly.\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Mar 2022 17:44:08 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a5dfb911de2df2d056dacc710ff955738e8683e5\",\n",
      "\t\t\"parent\": \"5e23674fe53339308ba1caaca48a80e7c9680da7\",\n",
      "\t\t\"subject\": \"Bump maven-site-plugin from 3.1 to 3.11.0 (#12310)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-maven-site-plugin-from-3.1-to-3.11.0-12310\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Bumps [maven-site-plugin](https://github.com/apache/maven-site-plugin) from 3.1 to 3.11.0. - [Release notes](https://github.com/apache/maven-site-plugin/releases) - [Commits](https://github.com/apache/maven-site-plugin/compare/maven-site-plugin-3.1...maven-site-plugin-3.11.0)  --- updated-dependencies: - dependency-name: org.apache.maven.plugins:maven-site-plugin   dependency-type: direct:production   update-type: version-update:semver-minor ...  Signed-off-by: dependabot[bot] <support@github.com>  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Mar 2022 15:17:29 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5e23674fe53339308ba1caaca48a80e7c9680da7\",\n",
      "\t\t\"parent\": \"d745d0b3384f4649a07195ee317a6a086f91329f\",\n",
      "\t\t\"subject\": \"Fix a race condition in the '/tasks' Overlord API (#12330)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-a-race-condition-in-the-tasks-Overlord-API-12330\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* finds complete and active tasks from the same snapshot  * overlord resource  * unit test  * integration test  * javadoc and cleanup  * more cleanup  * fix test and add more\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Mar 2022 10:47:45 +0900\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d745d0b3384f4649a07195ee317a6a086f91329f\",\n",
      "\t\t\"parent\": \"69f928f50e849b7c97e7cd1958d9c2505acf070f\",\n",
      "\t\t\"subject\": \"Add JDK 11 (#12333)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-JDK-11-12333\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Mar 2022 15:03:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"69f928f50e849b7c97e7cd1958d9c2505acf070f\",\n",
      "\t\t\"parent\": \"5d02a91faa58aaaf8a89deec4ea985b01f9bca21\",\n",
      "\t\t\"subject\": \"Adding k8s support for human readable parsing (#12316)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-k8s-support-for-human-readable-parsing-12316\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding k8s support for human readable parsing  * Update docs/configuration/human-readable-byte.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/configuration/human-readable-byte.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update core/src/main/java/org/apache/druid/java/util/common/HumanReadableBytes.java  Co-authored-by: Frank Chen <frankchen@apache.org>  * Changes per review  Co-authored-by: Rahul Gidwani <r_gidwani@apple.com> Co-authored-by: Frank Chen <frankchen@apache.org>\",\n",
      "\t\t\"author_name\": \"Dr. Sizzles\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Mar 2022 11:18:47 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5d02a91faa58aaaf8a89deec4ea985b01f9bca21\",\n",
      "\t\t\"parent\": \"b5195c5095a1088cb06ed602704fce110232f109\",\n",
      "\t\t\"subject\": \"upgrade Error Prone to 2.11 (requires Java 11) (#12306)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-Error-Prone-to-2.11-requires-Java-11-12306\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The latest version of Error Prone now requires Java 11. Upgrading means we can remove a lot of the maven profile complexity required to run checks with Java 8. This also requires switching our strict build to use Java 11.  * update error-prone to 2.11 * remove need for specific maven profiles for Java 8 and Java 15 * fix additional Error Prone warnings with Java 11 * update strict build to use Java 11\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Mar 2022 19:40:48 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b5195c5095a1088cb06ed602704fce110232f109\",\n",
      "\t\t\"parent\": \"3de12729269e8446b994881bd507bc0d1422e98e\",\n",
      "\t\t\"subject\": \"Graceful null handling and correctness in DoubleMean Aggregator (#12320)\",\n",
      "\t\t\"sanitized_subject_line\": \"Graceful-null-handling-and-correctness-in-DoubleMean-Aggregator-12320\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding null handling for double mean aggregator  * Updating code to handle nulls in DoubleMean aggregator  * oops last one should have checkstyle issues. fixed  * Updating some code and test cases  * Checking on object is null in case of numeric aggregator  * Adding one more test to improve coverage  * Changing one test as asked in the review  * Changing one test as asked in the review for nulls\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Mar 2022 16:52:47 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3de12729269e8446b994881bd507bc0d1422e98e\",\n",
      "\t\t\"parent\": \"db91961af70c61ebe1cbe7c42c12309e85c477fb\",\n",
      "\t\t\"subject\": \"bug fix: merge results of group by limit push down (#11969)\",\n",
      "\t\t\"sanitized_subject_line\": \"bug-fix-merge-results-of-group-by-limit-push-down-11969\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"mchades\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Mar 2022 09:04:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"db91961af70c61ebe1cbe7c42c12309e85c477fb\",\n",
      "\t\t\"parent\": \"cb2b2b696d9ff391d4814552918ea6c5e94a6fc6\",\n",
      "\t\t\"subject\": \"kubernetes: restart watch on null response (#12233)\",\n",
      "\t\t\"sanitized_subject_line\": \"kubernetes-restart-watch-on-null-response-12233\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* kubernetes: restart watch on null response  Kubernetes watches allow a client to efficiently processes changes to resources. However, they have some idiosyncrasies. In particular, they can error out for various reasons leading to what would normally be seen as an invalid result.  The Druid kubernetes node discovery subsystem does not handle a certain case properly. The watch can return an item with a null object.  These leads to a null pointer exception. When this happens, the provider needs to restart the watch, because rerunning the watch from the same resource version leads to the same result: yet another null pointer exception.  This commit changes the provider to handle null objects by restarting the watch.  * review: add more coverage  This adds a bit more coverage to the K8sDruidNodeDiscoveryProvider watch loop, and removes an unnecessay return.  * kubernetes: reduce logging verbosity  The log messages about items being NULL don't really deserve to be at a level other than DEBUG since they are not actionable, particularly since we automatically recover now. Move them to the DEBUG level.\",\n",
      "\t\t\"author_name\": \"Kyle Larose\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Mar 2022 12:56:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb2b2b696d9ff391d4814552918ea6c5e94a6fc6\",\n",
      "\t\t\"parent\": \"2efb74ff1e4a9921e236a21475978822be57fe11\",\n",
      "\t\t\"subject\": \"Fix error message for groupByEnableMultiValueUnnesting. (#12325)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-error-message-for-groupByEnableMultiValueUnnesting.-12325\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix error message for groupByEnableMultiValueUnnesting.  It referred to the incorrect context parameter.  Also, create a dedicated exception class, to allow easier detection of this specific error.  * Fix other test.  * More better error messages.  * Test getDimensionName method.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Mar 2022 11:37:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2efb74ff1e4a9921e236a21475978822be57fe11\",\n",
      "\t\t\"parent\": \"d89d4ff58894a69eda1e584628acec8eafe93168\",\n",
      "\t\t\"subject\": \"fix supervisor auto scaler config serde bug (#12317)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-supervisor-auto-scaler-config-serde-bug-12317\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Parag Jain\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 16:17:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d89d4ff58894a69eda1e584628acec8eafe93168\",\n",
      "\t\t\"parent\": \"6346b9561df7a92557acb51a56585084a0eb8633\",\n",
      "\t\t\"subject\": \"Git hooks should fail on errors; pass args to git hooks (#12322)\",\n",
      "\t\t\"sanitized_subject_line\": \"Git-hooks-should-fail-on-errors-pass-args-to-git-hooks-12322\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Git hooks should fail on errors  * don't set shell to pass args\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Mar 2022 09:07:50 +0900\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6346b9561df7a92557acb51a56585084a0eb8633\",\n",
      "\t\t\"parent\": \"9cfb23935ffc3eace79b526dd84d912d129a9b1c\",\n",
      "\t\t\"subject\": \"Reuse the InputEntityReader in SettableByteEntityReader (#12269)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reuse-the-InputEntityReader-in-SettableByteEntityReader-12269\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Reuse the InputEntityReader in SettableByteEntityReader  * Fix logic  * Fix kafka streaming ingestion  * Add Tests for kafka input format change  * Address review comments\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 14:38:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9cfb23935ffc3eace79b526dd84d912d129a9b1c\",\n",
      "\t\t\"parent\": \"9f6a930462c77a96beb793b5809d878534998742\",\n",
      "\t\t\"subject\": \"push value range and set index get operations into BitmapIndex (#12315)\",\n",
      "\t\t\"sanitized_subject_line\": \"push-value-range-and-set-index-get-operations-into-BitmapIndex-12315\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* push value range and set index get operations into BitmapIndex  * fix bug  * oops, fix better  * better like, fix test, javadocs  * fix checkstyle  * simplify and fixes  * cache  * fix tests  * move indexOf into GenericIndexed  * oops  * fix tests\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 13:30:58 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9f6a930462c77a96beb793b5809d878534998742\",\n",
      "\t\t\"parent\": \"dc0372a28e3b22d7e35047ab60925fa1734d7d16\",\n",
      "\t\t\"subject\": \"Fix join query incase of filter explosion during CNF conversion (#12324)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-join-query-incase-of-filter-explosion-during-CNF-conversion-12324\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 12:43:09 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dc0372a28e3b22d7e35047ab60925fa1734d7d16\",\n",
      "\t\t\"parent\": \"7bf1d8c5c0adda27b94000f29113ad8915a23a4a\",\n",
      "\t\t\"subject\": \"improve FileWriteOutBytes.readFully (#12323)\",\n",
      "\t\t\"sanitized_subject_line\": \"improve-FileWriteOutBytes.readFully-12323\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* improve FileWriteOutBytes.readFully  * no need to flush if out of bounds\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 11:45:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7bf1d8c5c0adda27b94000f29113ad8915a23a4a\",\n",
      "\t\t\"parent\": \"56fbd2af6f9878c0f90303cf28e110d8226672b0\",\n",
      "\t\t\"subject\": \"Facilitate lazy initialization of connections to mitigate overwhelming of Coordinator (#12298)\",\n",
      "\t\t\"sanitized_subject_line\": \"Facilitate-lazy-initialization-of-connections-to-mitigate-overwhelming-of-Coordinator-12298\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add config for eager / lazy connection initialization in ResourcePool  Description Currently, when multiple tasks are launched, each of them eagerly initializes a full pool's worth of connections to the coordinator.  While this is acceptable when the parameter for number of eagerConnections (== maxSize) is small, this can be problematic in environments where it's a large value (say 1000) and multiple tasks are launched simultaneously, which can cause a large number of connections to be created to the coordinator, thereby overwhelming it.  Patch Nodes like the broker may require eager initialization of resources and do not create connections with the Coordinator. It is unnecessary to do this with other types of nodes.  A config parameter eagerInitialization is added, which when set to true, initializes the max permissible connections when ResourcePool is initialized.  If set to false, lazy initialization of connection resources takes place.  NOTE: All nodes except the broker have this new parameter set to false in the quickstart as part of this PR  Algorithm The current implementation relies on the creation of maxSize resources eagerly.  The new implementation's behaviour is as follows:  If a resource has been previously created and is available, lend it. Else if the number of created resources is less than the allowed parameter, create and lend it. Else, wait for one of the lent resources to be returned.\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 23:17:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"56fbd2af6f9878c0f90303cf28e110d8226672b0\",\n",
      "\t\t\"parent\": \"0600772cceec633a7754a68d6b4ff5ed21af8795\",\n",
      "\t\t\"subject\": \"Guard against exponential increase of filters during CNF conversion (#12314)\",\n",
      "\t\t\"sanitized_subject_line\": \"Guard-against-exponential-increase-of-filters-during-CNF-conversion-12314\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, the CNF conversion of a filter is unbounded, which means that it can create as many filters as possible thereby also leading to OOMs in historical heap. We should throw an error or disable CNF conversion if the filter count starts getting out of hand. There are ways to do CNF conversion with linear increase in filters as well but that has been left out of the scope of this change since those algorithms add new variables in the predicate - which can be contentious. \",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 13:19:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0600772cceec633a7754a68d6b4ff5ed21af8795\",\n",
      "\t\t\"parent\": \"abe76ccb90b8d620b49564c025c59341a8d271bd\",\n",
      "\t\t\"subject\": \"use a non-concurrent map for lookups-cached-global unless incremental updates are actually required (#12293)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-a-non-concurrent-map-for-lookups-cached-global-unless-incremental-updates-are-actually-required-12293\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use a non-concurrent map for lookups-cached-global unless incremental updates are actually required * adjustments * fix test\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Mar 2022 21:54:25 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"abe76ccb90b8d620b49564c025c59341a8d271bd\",\n",
      "\t\t\"parent\": \"dae53ae36a357919698cb8bb3e90934ee64b9fcf\",\n",
      "\t\t\"subject\": \"Batch ingestion replace (#12137)\",\n",
      "\t\t\"sanitized_subject_line\": \"Batch-ingestion-replace-12137\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Tombstone support for replace functionality  * A used segment interval is the interval of a current used segment that overlaps any of the input intervals for the spec  * Update compaction test to match replace behavior  * Adapt ITAutoCompactionTest to work with tombstones rather than dropping segments. Add support for tombstones in the broker.  * Style plus simple queriableindex test  * Add segment cache loader tombstone test  * Add more tests  * Add a method to the LogicalSegment to test whether it has any data  * Test filter with some empty logical segments  * Refactor more compaction/dropexisting tests  * Code coverage  * Support for all empty segments  * Skip tombstones when looking-up broker's timeline. Discard changes made to tool chest to avoid empty segments since they will no longer have empty segments after lookup because we are skipping over them.  * Fix null ptr when segment does not have a queriable index  * Add support for empty replace interval (all input data has been filtered out)  * Fixed coverage & style  * Find tombstone versions from lock versions  * Test failures & style  * Interner was making this fail since the two segments were consider equal due to their id's being equal  * Cleanup tombstone version code  * Force timeChunkLock whenever replace (i.e. dropExisting=true) is being used  * Reject replace spec when input intervals are empty  * Documentation  * Style and unit test  * Restore test code deleted by mistake  * Allocate forces TIME_CHUNK locking and uses lock versions. TombstoneShardSpec added.  * Unused imports. Dead code. Test coverage.  * Coverage.  * Prevent killer from throwing an exception for tombstones. This is the killer used in the peon for killing segments.  * Fix OmniKiller + more test coverage.  * Tombstones are now marked using a shard spec  * Drop a segment factory.json in the segment cache for tombstones  * Style  * Style + coverage  * style  * Add TombstoneLoadSpec.class to mapper in test  * Update core/src/main/java/org/apache/druid/segment/loading/TombstoneLoadSpec.java  Typo  Co-authored-by: Jonathan Wei <jon-wei@users.noreply.github.com>  * Update docs/configuration/index.md  Missing  Co-authored-by: Jonathan Wei <jon-wei@users.noreply.github.com>  * Typo  * Integrated replace with an existing test since the replace part was redundant and more importantly, the test file was very close or exceeding the 10 min default \\\"no output\\\" CI Travis threshold.  * Range does not work with multi-dim  Co-authored-by: Jonathan Wei <jon-wei@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Mar 2022 20:07:02 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dae53ae36a357919698cb8bb3e90934ee64b9fcf\",\n",
      "\t\t\"parent\": \"0e097ead36a1aa044def1e85ed2ccf52eb5a25d4\",\n",
      "\t\t\"subject\": \"adjust topn heap operation when string is dictionary encoded, but not uniquely (#12291)\",\n",
      "\t\t\"sanitized_subject_line\": \"adjust-topn-heap-operation-when-string-is-dictionary-encoded-but-not-uniquely-12291\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add topn heap optimization when string is dictionary encoded, but not uniquely  * use array instead  * is same  * fix javadoc  * fix  * Update StringTopNColumnAggregatesProcessor.java\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Mar 2022 14:32:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0e097ead36a1aa044def1e85ed2ccf52eb5a25d4\",\n",
      "\t\t\"parent\": \"875e0696e01c4348fa31c77ec6fa333a324a53d8\",\n",
      "\t\t\"subject\": \"Add git hooks that can run multiple scripts (#12300)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-git-hooks-that-can-run-multiple-scripts-12300\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add git hooks that can run multiple scripts  * scripts to install/uninstall hooks  * better message for uninstall; support pre-push params\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Mar 2022 07:16:47 +0900\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"875e0696e01c4348fa31c77ec6fa333a324a53d8\",\n",
      "\t\t\"parent\": \"baea3ec61406ce86d187330e264a819d7e9e0bb2\",\n",
      "\t\t\"subject\": \"GroupBy: Cap dictionary-building selector memory usage. (#12309)\",\n",
      "\t\t\"sanitized_subject_line\": \"GroupBy-Cap-dictionary-building-selector-memory-usage.-12309\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* GroupBy: Cap dictionary-building selector memory usage.  New context parameter \\\"maxSelectorDictionarySize\\\" controls when the per-segment processing code should return early and trigger a trip to the merge buffer.  Includes:  - Vectorized and nonvectorized implementations. - Adjustments to GroupByQueryRunnerTest to exercise this code in   the v2SmallDictionary suite. (Both the selector dictionary and   the merging dictionary will be small in that suite.) - Tests for the new config parameter.  * Fix issues from tests.  * Add \\\"pre-existing\\\" to dictionary.  * Simplify GroupByColumnSelectorStrategy interface by removing one of the writeToKeyBuffer methods.  * Adjustments from review comments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Mar 2022 13:13:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"baea3ec61406ce86d187330e264a819d7e9e0bb2\",\n",
      "\t\t\"parent\": \"28f8bcce9b304fd123126073619ffd5f60f59f20\",\n",
      "\t\t\"subject\": \"Break up parallel indexing unit test to reduce test times (#12313)\",\n",
      "\t\t\"sanitized_subject_line\": \"Break-up-parallel-indexing-unit-test-to-reduce-test-times-12313\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Break up parallel indexing unit test to reduce test times  * Fix checkstyle\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Mar 2022 16:26:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"28f8bcce9b304fd123126073619ffd5f60f59f20\",\n",
      "\t\t\"parent\": \"903174de2045449e12f94d00bdca09ecaf780e64\",\n",
      "\t\t\"subject\": \"Always reopen stream in FileUtils.copyLarge, RetryingInputStream. (#12307)\",\n",
      "\t\t\"sanitized_subject_line\": \"Always-reopen-stream-in-FileUtils.copyLarge-RetryingInputStream.-12307\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Always reopen stream in FileUtils.copyLarge, RetryingInputStream.  When an InputStream throws an exception from one of its read methods, we should assume it's bad and reopen it.  The main changes here are:  - In FileUtils.copyLarge, replace InputStream with InputStreamSupplier. - In RetryingInputStream, collapse retryCondition and resetCondition   into a single condition. Also, make it required, since every usage   is passing in a specific condition anyway.  * Test fixes.  * Fix read impl.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 5 Mar 2022 14:39:14 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"903174de2045449e12f94d00bdca09ecaf780e64\",\n",
      "\t\t\"parent\": \"3b373114dcc29e377e5926d1fcea0a580fe45b87\",\n",
      "\t\t\"subject\": \"correct errors on compaction doc (#12308)\",\n",
      "\t\t\"sanitized_subject_line\": \"correct-errors-on-compaction-doc-12308\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 15:33:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3b373114dcc29e377e5926d1fcea0a580fe45b87\",\n",
      "\t\t\"parent\": \"ada3ae08dfc432f34e4ef1ec87f9800c91ba2c54\",\n",
      "\t\t\"subject\": \"Officially support Java 11. (#12232)\",\n",
      "\t\t\"sanitized_subject_line\": \"Officially-support-Java-11.-12232\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"There aren't any changes in this patch that improve Java 11 compatibility; these changes have already been done separately. This patch merely updates documentation and explicit Java version checks.  The log message adjustments in DruidProcessingConfig are there to make things a little nicer when running in Java 11, where we can't measure direct memory _directly_, and so we may auto-size processing buffers incorrectly.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 14:15:45 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ada3ae08dfc432f34e4ef1ec87f9800c91ba2c54\",\n",
      "\t\t\"parent\": \"61e1ffc7f782ab5d83b4cbb2fcca45c34b8c6bb2\",\n",
      "\t\t\"subject\": \"Retain order in TaskReport. (#12005)\",\n",
      "\t\t\"sanitized_subject_line\": \"Retain-order-in-TaskReport.-12005\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 08:06:20 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"61e1ffc7f782ab5d83b4cbb2fcca45c34b8c6bb2\",\n",
      "\t\t\"parent\": \"36bc41855d4d368ab6fbe0d5019bb27ba9c48440\",\n",
      "\t\t\"subject\": \"add a new query laning metrics to visualize lane assignment (#12111)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-a-new-query-laning-metrics-to-visualize-lane-assignment-12111\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add a new query laning metrics to visualize lane assignment  * fixes :spotbugs check  * Update docs/operations/metrics.md  Co-authored-by: Benedict Jin <asdf2014@apache.org>  * Update server/src/main/java/org/apache/druid/server/QueryScheduler.java  Co-authored-by: Benedict Jin <asdf2014@apache.org>  * Update server/src/main/java/org/apache/druid/server/QueryScheduler.java  Co-authored-by: Benedict Jin <asdf2014@apache.org>  Co-authored-by: Benedict Jin <asdf2014@apache.org>\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 15:21:17 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36bc41855d4d368ab6fbe0d5019bb27ba9c48440\",\n",
      "\t\t\"parent\": \"58d05d70144867b07af9617e163e1210f74b7c63\",\n",
      "\t\t\"subject\": \"Set Content-Type for String based response (#12295)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-Content-Type-for-String-based-response-12295\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 15:17:03 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58d05d70144867b07af9617e163e1210f74b7c63\",\n",
      "\t\t\"parent\": \"a1cdee2a3a3367d7187e60bd626d3edd2e9e3e50\",\n",
      "\t\t\"subject\": \"Fix ci (#12304)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-ci-12304\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Samarth Jain\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Mar 2022 23:05:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a1cdee2a3a3367d7187e60bd626d3edd2e9e3e50\",\n",
      "\t\t\"parent\": \"1c004ea47e3eeacc7d7379b34a825019b6709948\",\n",
      "\t\t\"subject\": \"Bump jersey.version from 1.19.3 to 1.19.4 (#12290)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-jersey.version-from-1.19.3-to-1.19.4-12290\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Bump jersey.version from 1.19.3 to 1.19.4  Bumps `jersey.version` from 1.19.3 to 1.19.4.  Updates `jersey-client` from 1.19.3 to 1.19.4  Updates `jersey-core` from 1.19.3 to 1.19.4  Updates `jersey-grizzly2` from 1.19.3 to 1.19.4  Updates `jersey-guice` from 1.19.3 to 1.19.4  Updates `jersey-server` from 1.19.3 to 1.19.4  Updates `jersey-servlet` from 1.19.3 to 1.19.4  Updates `jersey-json` from 1.19.3 to 1.19.4  Updates `jersey-test-framework-core` from 1.19.3 to 1.19.4  Updates `jersey-test-framework-grizzly2` from 1.19.3 to 1.19.4  --- updated-dependencies: - dependency-name: com.sun.jersey:jersey-client   dependency-type: direct:development   update-type: version-update:semver-patch - dependency-name: com.sun.jersey:jersey-core   dependency-type: direct:development   update-type: version-update:semver-patch - dependency-name: com.sun.jersey:jersey-grizzly2   dependency-type: direct:development   update-type: version-update:semver-patch - dependency-name: com.sun.jersey.contribs:jersey-guice   dependency-type: direct:production   update-type: version-update:semver-patch - dependency-name: com.sun.jersey:jersey-server   dependency-type: direct:production   update-type: version-update:semver-patch - dependency-name: com.sun.jersey:jersey-servlet   dependency-type: direct:production   update-type: version-update:semver-patch - dependency-name: com.sun.jersey:jersey-json   dependency-type: direct:production   update-type: version-update:semver-patch - dependency-name: com.sun.jersey.jersey-test-framework:jersey-test-framework-core   dependency-type: direct:development   update-type: version-update:semver-patch - dependency-name: com.sun.jersey.jersey-test-framework:jersey-test-framework-grizzly2   dependency-type: direct:development   update-type: version-update:semver-patch ...  Signed-off-by: dependabot[bot] <support@github.com>  * Update licenses.yaml  * Update licenses.yaml  Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com> Co-authored-by: Clint Wylie <cwylie@apache.org>\",\n",
      "\t\t\"author_name\": \"dependabot[bot]\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Mar 2022 09:57:20 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c004ea47e3eeacc7d7379b34a825019b6709948\",\n",
      "\t\t\"parent\": \"36193955b6d8a03fe247157dddebea0365c7e501\",\n",
      "\t\t\"subject\": \"use virtual columns for sql simple aggregators instead of inline expressions (#12251)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-virtual-columns-for-sql-simple-aggregators-instead-of-inline-expressions-12251\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use virtual columns for sql simple aggregators instead of inline expressions  * fixes  * always use virtual columns  * add more tests\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Mar 2022 15:05:28 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36193955b6d8a03fe247157dddebea0365c7e501\",\n",
      "\t\t\"parent\": \"f594e7ac243f21acd0b9cb5dd795b6088cad6b27\",\n",
      "\t\t\"subject\": \"perf: eliminate expensive log construction in remote-task-runner shutdown (#12097)\",\n",
      "\t\t\"sanitized_subject_line\": \"perf-eliminate-expensive-log-construction-in-remote-task-runner-shutdown-12097\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Mar 2022 13:38:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f594e7ac243f21acd0b9cb5dd795b6088cad6b27\",\n",
      "\t\t\"parent\": \"1af4c9c933cd62804d106c9a2974dc0b3cf75780\",\n",
      "\t\t\"subject\": \"perf: improve RemoteTaskRunner task assignment loop performance (#12096)\",\n",
      "\t\t\"sanitized_subject_line\": \"perf-improve-RemoteTaskRunner-task-assignment-loop-performance-12096\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* perf: improve ZkWorker task lookup performance  This improves the performance of the ZkWorker task lookup loop by eliminating repeat calls to getRunningTasks() in toImmutable(), and reduces the work performed in isRunningTask() to stream-parse the id field instead of entire JSON blob.\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Mar 2022 09:38:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1af4c9c933cd62804d106c9a2974dc0b3cf75780\",\n",
      "\t\t\"parent\": \"50038d9344fb745bfe47c81a59bdc29ae3dcff1d\",\n",
      "\t\t\"subject\": \"Display row stats for multiphase parallel indexing tasks (#12280)\",\n",
      "\t\t\"sanitized_subject_line\": \"Display-row-stats-for-multiphase-parallel-indexing-tasks-12280\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Row stats are reported for single phase tasks in the `/liveReports` and `/rowStats` APIs and are also a part of the overall task report. This commit adds changes to report row stats for multiphase tasks too.  Changes: - Add `TaskReport` in `GeneratedPartitionsReport` generated during hash and range partitioning - Collect the reports for `index_generate` phase in `ParallelIndexSupervisorTask`  \",\n",
      "\t\t\"author_name\": \"Tejaswini Bandlamudi\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Mar 2022 10:10:31 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"50038d9344fb745bfe47c81a59bdc29ae3dcff1d\",\n",
      "\t\t\"parent\": \"3f709db173d779db1466e57a1564a5f557b4b0cf\",\n",
      "\t\t\"subject\": \"latest datasketches-java-3.1.0 (#12224)\",\n",
      "\t\t\"sanitized_subject_line\": \"latest-datasketches-java-3.1.0-12224\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"These changes are to use the latest datasketches-java-3.1.0 and also to restore support for quantile and HLL4 sketches to be able to grow larger than a given buffer in a buffer aggregator and move to heap in rare cases. This was discussed in #11544.  Co-authored-by: AlexanderSaydakov <AlexanderSaydakov@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Alexander Saydakov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Mar 2022 17:14:42 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3f709db173d779db1466e57a1564a5f557b4b0cf\",\n",
      "\t\t\"parent\": \"d105519558951aa289992d05043194b8b7ceaee4\",\n",
      "\t\t\"subject\": \"Make ParseExceptions more informative (#12259)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-ParseExceptions-more-informative-12259\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR aims to make the ParseExceptions in Druid more informative, by adding additional information (metadata) to the ParseException, which can contain additional information about the exception. For example - the path of the file generating the issue, the line number (where it can be easily fetched - like CsvReader)  Following changes are addressed in this PR:  A new class CloseableIteratorWithMetadata has been created which is like CloseableIterator but also has a metadata method that returns a context Map<String, Object> about the current element returned by next(). IntermediateRowParsingReader#read() now attaches the InputEntity and the \\\"record number\\\" which created the exception (while parsing them), and IntermediateRowParsingReader#sample attaches the InputEntity (but not the \\\"record number\\\"). TextReader (and its subclasses), which is a specific implementation of the IntermediateRowParsingReader also include the line number which caused the generation of the error. This will also help in triaging the issues when InputSourceReader generates ParseException because it can point to the specific InputEntity which caused the exception (while trying to read it).\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 28 Feb 2022 22:31:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d105519558951aa289992d05043194b8b7ceaee4\",\n",
      "\t\t\"parent\": \"1434197ee179955987462c5c7f4030ca0bc43edb\",\n",
      "\t\t\"subject\": \"Replace use of PowerMock with Mockito (#12282)\",\n",
      "\t\t\"sanitized_subject_line\": \"Replace-use-of-PowerMock-with-Mockito-12282\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Mockito now supports all our needs and plays much better with recent Java versions. Migrating to Mockito also simplifies running the kind of tests that required PowerMock in the past.   * replace all uses of powermock with mockito-inline * upgrade mockito to 4.3.1 and fix use of deprecated methods * import mockito bom to align all our mockito dependencies * add powermock to forbidden-apis to avoid accidentally reintroducing it in the future\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 27 Feb 2022 22:47:09 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1434197ee179955987462c5c7f4030ca0bc43edb\",\n",
      "\t\t\"parent\": \"4c61878f9c16ca3ec9b55814dd974d71ef00fead\",\n",
      "\t\t\"subject\": \"update airline dependency to 2.x (#12270)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-airline-dependency-to-2.x-12270\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* upgrade Airline to Airline 2   https://github.com/airlift/airline is no longer maintained, updating to   https://github.com/rvesse/airline (Airline 2) to use an actively   maintained version, while minimizing breaking changes.    Note, this is a backwards incompatible change, and extensions relying on   the CliCommandCreator extension point will also need to be updated.  * fix dependency checks where jakarta.inject is now resolved first instead   of javax.inject, due to Airline 2 using jakarta\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 27 Feb 2022 15:19:28 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4c61878f9c16ca3ec9b55814dd974d71ef00fead\",\n",
      "\t\t\"parent\": \"a080fcdd7bec7010039d5e83c16215621301d18d\",\n",
      "\t\t\"subject\": \"Reduce use of mocking and simplify some tests (#12283)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-use-of-mocking-and-simplify-some-tests-12283\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove use of mocks for ServiceMetricEvent * simplify KafkaEmitterTests by moving to Mockito * speed up KafkaEmitterTest by adjusting reporting frequency in tests * remove unnecessary easymock and JUnitParams dependencies\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 26 Feb 2022 17:23:09 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a080fcdd7bec7010039d5e83c16215621301d18d\",\n",
      "\t\t\"parent\": \"e5ad862665d0b5ad400dbc66cec18e217810bb4a\",\n",
      "\t\t\"subject\": \"Fixing hadoop 3 Dockerfile (#12284)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-hadoop-3-Dockerfile-12284\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 26 Feb 2022 19:18:29 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e5ad862665d0b5ad400dbc66cec18e217810bb4a\",\n",
      "\t\t\"parent\": \"eb1b53b7f8966f20c5e4973fbbae443a10b1e494\",\n",
      "\t\t\"subject\": \"A new includeAllDimension flag for dimensionsSpec (#12276)\",\n",
      "\t\t\"sanitized_subject_line\": \"A-new-includeAllDimension-flag-for-dimensionsSpec-12276\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* includeAllDimensions in dimensionsSpec  * doc  * address comments  * unused import and doc spelling\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 25 Feb 2022 18:27:48 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb1b53b7f8966f20c5e4973fbbae443a10b1e494\",\n",
      "\t\t\"parent\": \"b86f2d4c2e935346d600e51b22403150ebd1501d\",\n",
      "\t\t\"subject\": \"perf: indexing: Introduce a bulk getValuesInto function to read values (#12105)\",\n",
      "\t\t\"sanitized_subject_line\": \"perf-indexing-Introduce-a-bulk-getValuesInto-function-to-read-values-12105\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* perf: indexing: Introduce a bulk getValuesInto function to read values in bulk  If large number of values are required from DimensionDictionary during indexing, fetch them all in a single lock/unlock instead of lock/unlock each individual item.  * refactor: rename key to keys in function args  * fix: check explicitly that argument length on arrays match  * refactor: getValuesInto renamed to getValues, now creates and returns a new T[] rather than filling\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 25 Feb 2022 12:19:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b86f2d4c2e935346d600e51b22403150ebd1501d\",\n",
      "\t\t\"parent\": \"009dd9e09a574a44b095e29c27626a70b1e6baad\",\n",
      "\t\t\"subject\": \"Performance fixes in proto readers (#12267)\",\n",
      "\t\t\"sanitized_subject_line\": \"Performance-fixes-in-proto-readers-12267\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 24 Feb 2022 23:21:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"009dd9e09a574a44b095e29c27626a70b1e6baad\",\n",
      "\t\t\"parent\": \"b1640a72ee1090bd3c90240bf47a5bfd5b690f5a\",\n",
      "\t\t\"subject\": \"upgrade core Apache Kafka dependencies to 3.1.0 (#12203)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-core-Apache-Kafka-dependencies-to-3.1.0-12203\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Announcement: https://blogs.apache.org/kafka/entry/what-s-new-in-apache7 Release notes: https://dist.apache.org/repos/dist/release/kafka/3.1.0/RELEASE_NOTES.html  * upgrade core Apache Kafka dependencies to 3.1.0 * fix use of private Kafka APIs * remove deprecated test rules * remove mock calls that weren't verified in the first place * remove the need for powermock in KafkaLookupExtractorFactoryTest * align curator-test version with curator itself * update easymock to 4.3.0\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 23 Feb 2022 18:42:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b1640a72ee1090bd3c90240bf47a5bfd5b690f5a\",\n",
      "\t\t\"parent\": \"b94390ba33fe4e1cb5588f166edeb94d76b2edcf\",\n",
      "\t\t\"subject\": \"Re-enable segment metadata cache when using external schema (#12264)\",\n",
      "\t\t\"sanitized_subject_line\": \"Re-enable-segment-metadata-cache-when-using-external-schema-12264\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Feb 2022 19:50:29 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b94390ba33fe4e1cb5588f166edeb94d76b2edcf\",\n",
      "\t\t\"parent\": \"6e2eded277bec907466ce0b7823ce70fae6e388e\",\n",
      "\t\t\"subject\": \"Adding Shared Access resource support for azure (#12266)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-Shared-Access-resource-support-for-azure-12266\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Azure Blob storage has multiple modes of authentication. One of them is Shared access resource . This is very useful in cases when we do not want to add the account key in the druid properties .  \",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 22 Feb 2022 18:27:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6e2eded277bec907466ce0b7823ce70fae6e388e\",\n",
      "\t\t\"parent\": \"1ec57cb935bd0b04d3123dfbb26a962a984422c7\",\n",
      "\t\t\"subject\": \"Allow coordinator run auto compaction duty period to be configured separately from other indexing duties (#12263)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-coordinator-run-auto-compaction-duty-period-to-be-configured-separately-from-other-indexing-duties-12263\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add impl  * add unit tests  * add impl  * add impl  * add serde test  * add tests  * add docs  * fix test  * fix test  * fix docs  * fix docs  * fix spelling\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Feb 2022 23:02:57 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1ec57cb935bd0b04d3123dfbb26a962a984422c7\",\n",
      "\t\t\"parent\": \"70c40c4281d28d17b25ee19691cbfdf11a951bb2\",\n",
      "\t\t\"subject\": \"Improve kinesis task assignment after resharding (#12235)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-kinesis-task-assignment-after-resharding-12235\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Problem: - When a kinesis stream is resharded, the original shards are closed.    Any intermediate shard created in the process is eventually closed as well. - If a shard is closed before any record is put into it, it can be safely ignored for ingestion. - It is expensive to determine if a closed shard is empty, since it requires a call to the Kinesis cluster.  Changes: - Maintain a cache of closed empty and closed non-empty shards in `KinesisSupervisor` - Add config `skipIngorableShards` to `KinesisSupervisorTuningConfig` - The caches are used and updated only when `skipIgnorableShards = true`\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 18 Feb 2022 12:37:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"70c40c4281d28d17b25ee19691cbfdf11a951bb2\",\n",
      "\t\t\"parent\": \"575874705f8138e002ec9ade3400f93e4d59fcfb\",\n",
      "\t\t\"subject\": \"Fix long overflow in SegmentCostCache.Bucket.toLocalInterval (#12257)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-long-overflow-in-SegmentCostCache.Bucket.toLocalInterval-12257\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Problem: When using a `CachingCostBalancerStrategy` with segments of granularity ALL, no segment gets loaded. - With granularity ALL, segments of eternity interval are created which have    `start = Long.MIN_VALUE / 2` and `end = Long.MAX_VALUE / 2`. - For cost calculation in the balancer strategy, `toLocalInterval()` method is invoked where   `Long.MIN_VALUE / 2` or `Long.MAX_VALUE / 2` cause an overflow thus resulting in no overlap. - The strategy is unable to find any eligible server for loading a given segment.  Fix: - Reverse order of operations to divide by `MILLIS_FACTOR` (~10^8) first,    then do the subtraction to prevent Long overflow.\",\n",
      "\t\t\"author_name\": \"tejaswini-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Feb 2022 15:13:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"575874705f8138e002ec9ade3400f93e4d59fcfb\",\n",
      "\t\t\"parent\": \"5794331eb132b16ed6bffe34c38be12a9cf4bcec\",\n",
      "\t\t\"subject\": \"Fix the flakiness in getLockedIntervals test (#12172)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-flakiness-in-getLockedIntervals-test-12172\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fix the flakiness in getLockedIntervals test\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 17 Feb 2022 12:08:46 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5794331eb132b16ed6bffe34c38be12a9cf4bcec\",\n",
      "\t\t\"parent\": \"8fc0e5c95c79c5ef0e8050534b3689cc405e7c9b\",\n",
      "\t\t\"subject\": \"Adding new config for disabling group by on multiValue column (#12253)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-new-config-for-disabling-group-by-on-multiValue-column-12253\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"As part of #12078 one of the followup's was to have a specific config which does not allow accidental unnesting of multi value columns if such columns become part of the grouping key. Added a config groupByEnableMultiValueUnnesting which can be set in the query context.  The default value of groupByEnableMultiValueUnnesting is true, therefore it does not change the current engine behavior. If groupByEnableMultiValueUnnesting is set to false, the query will fail if it encounters a multi-value column in the grouping key.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 16 Feb 2022 20:53:26 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8fc0e5c95c79c5ef0e8050534b3689cc405e7c9b\",\n",
      "\t\t\"parent\": \"eae163a7970c18003810ba495f77118a9133024b\",\n",
      "\t\t\"subject\": \"Explain plan for custom insert syntax (#12243)\",\n",
      "\t\t\"sanitized_subject_line\": \"Explain-plan-for-custom-insert-syntax-12243\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Initial commit, explain plan for custom insert syntax working  * Cleanup separate SqlInsert handling\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Feb 2022 21:48:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eae163a7970c18003810ba495f77118a9133024b\",\n",
      "\t\t\"parent\": \"26bc4b734597480bf1185559baf7644086f24d52\",\n",
      "\t\t\"subject\": \"Moving in filter check to broker (#12195)\",\n",
      "\t\t\"sanitized_subject_line\": \"Moving-in-filter-check-to-broker-12195\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Moving in filter check to broker  * Adding more unit tests, making error message meaningful  * Spelling and doc changes  * Updating default to -1 and making this feature hide by default. The number of IN filters can grow upto a max limit of 100  * Removing upper limit of 100, updated docs  * Making documentation more meaningful  * Moving check outside to PlannerConfig, updating test cases and adding back max limit  * Updated with some additional code comments  * Missed removing one line during the checkin  * Addressing doc changes and one forbidden API correction  * Final doc change  * Adding a speling exception, correcting a testcase  * Reading entire filter tree to address combinations of ANDs and ORs  * Specifying in docs that, this case works only for ORs  * Revert \\\"Reading entire filter tree to address combinations of ANDs and ORs\\\"  This reverts commit 81ca8f8496777eec41907899957b39ca99ccbada.  * Covering a class cast exception and updating docs  * Counting changed  Co-authored-by: Jihoon Son <jihoonson@apache.org>\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Feb 2022 20:45:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"26bc4b734597480bf1185559baf7644086f24d52\",\n",
      "\t\t\"parent\": \"34bc3619536c0e1b7487bd48a6ab1c53e353cf41\",\n",
      "\t\t\"subject\": \"perf: cache row if it is a transformed row (#12113)\",\n",
      "\t\t\"sanitized_subject_line\": \"perf-cache-row-if-it-is-a-transformed-row-12113\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* perf: cache row if it is a transformed row  * perf: cache row if it is a transformed row (also cache DateTime object)\",\n",
      "\t\t\"author_name\": \"Jason Koch\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Feb 2022 10:08:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"34bc3619536c0e1b7487bd48a6ab1c53e353cf41\",\n",
      "\t\t\"parent\": \"393e9b68a8875e07942528720a533bc26580abb8\",\n",
      "\t\t\"subject\": \"Update ORC to 1.7.2 (#12084)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-ORC-to-1.7.2-12084\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"William Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Feb 2022 10:04:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"393e9b68a8875e07942528720a533bc26580abb8\",\n",
      "\t\t\"parent\": \"47153cd7bd600135289062c009f6405a4c83f640\",\n",
      "\t\t\"subject\": \"Add config to limit task slots for parallel indexing tasks (#12221)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-config-to-limit-task-slots-for-parallel-indexing-tasks-12221\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In extreme cases where many parallel indexing jobs are submitted together, it is possible that the `ParallelIndexSupervisorTasks` take up all slots leaving no slot to schedule their own sub-tasks thus stalling progress of all the indexing jobs.  Key changes: - Add config `druid.indexer.runner.parallelIndexTaskSlotRatio` to limit the task slots   for `ParallelIndexSupervisorTasks` per worker - `ratio = 1` implies supervisor tasks can use all slots on a worker if needed (default behavior) - `ratio = 0` implies supervisor tasks can not use any slot on a worker    (actually, at least 1 slot is always available to ensure progress of parallel indexing jobs) - `ImmutableWorkerInfo.canRunTask()` - `WorkerHolder`, `ZkWorker`, `WorkerSelectUtils`\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 15 Feb 2022 23:15:09 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"47153cd7bd600135289062c009f6405a4c83f640\",\n",
      "\t\t\"parent\": \"033989eb1d8f4f91268b2d7d4d3dc73af7bf2c3f\",\n",
      "\t\t\"subject\": \"Increase retries for Kinesis sharding integration tests. (#12255)\",\n",
      "\t\t\"sanitized_subject_line\": \"Increase-retries-for-Kinesis-sharding-integration-tests.-12255\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This fixes intermittent, spurious failures that we've observed in the Kinesis sharding integration tests due to Kinesis taking longer than the code expected to start a sharding operation. The method that's changed is part of the integration test suite and only used by the test cases that we've seen are flaky.  Prior to this change, the tests expected a sharding operation to start in 9 seconds (30 retries * 300ms delay/retry). This change bumps the number of retries to 100, giving Kinesis 30 seconds to start the sharding.  This PR also makes a small, clarifying change to the condition used to determine if sharding has started. Instead of checking if the number of shards has increased (which was technically correct even if the test is reducing the number of shards due to a Kinesis implementation detail), we now just check if the shard count has changed.\",\n",
      "\t\t\"author_name\": \"Daniel Koepke\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 14 Feb 2022 23:33:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"033989eb1d8f4f91268b2d7d4d3dc73af7bf2c3f\",\n",
      "\t\t\"parent\": \"c61b19d443bdffd9bd36409d245efa5df064846b\",\n",
      "\t\t\"subject\": \"Adding vectorized time_shift (#12254)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-vectorized-time_shift-12254\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Adding vectorized time_shift  * Vectorize time shift, addressing review comments  * Remove an unused import\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Feb 2022 14:44:52 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c61b19d443bdffd9bd36409d245efa5df064846b\",\n",
      "\t\t\"parent\": \"5bd646e10a120a675bf70911b832d1eb1f51ae75\",\n",
      "\t\t\"subject\": \"Refactor SQL docs (#12239)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-SQL-docs-12239\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* refactor and link fixes  * add sql docs to left nav  * code format for needle  * updated web console script  * link fixes  * update earliest/latest functions  * edits for grammar and style  * more link fixes  * another link  * update with #12226  * update .spelling file\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Feb 2022 14:43:30 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5bd646e10a120a675bf70911b832d1eb1f51ae75\",\n",
      "\t\t\"parent\": \"95b388d2d1d3d211cf142667a607a9f16241fde1\",\n",
      "\t\t\"subject\": \"Surface a user friendly error when PARTITIONED BY is omitted (#12246)\",\n",
      "\t\t\"sanitized_subject_line\": \"Surface-a-user-friendly-error-when-PARTITIONED-BY-is-omitted-12246\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"#12163 makes PARTITIONED BY a required clause in INSERT queries. While this is required, if a user accidentally omits the clause, it emits a JavaCC/Calcite error, since it's syntactically incorrect. The error message is cryptic. Since it's a custom clause, this PR aims to make the clause optional on the syntactic side, but move the validation to DruidSqlInsert where we can surface a friendlier error.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 11 Feb 2022 11:49:00 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"95b388d2d1d3d211cf142667a607a9f16241fde1\",\n",
      "\t\t\"parent\": \"3ee66bb492381ea1721c3355a7a5fc404a93d852\",\n",
      "\t\t\"subject\": \"Assign partitionIds in the same order as bucketIds (#12236)\",\n",
      "\t\t\"sanitized_subject_line\": \"Assign-partitionIds-in-the-same-order-as-bucketIds-12236\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"When `ParallelIndexSupervisorTask` converts `BucketNumberedShardSpecs` to corresponding `BuildingShardSpecs`, the bucketId order gets lost. Particularly, for range partitioning, this results in the partitionIds not being in the same order as increasing partition boundaries.  Changes - Refactor `ParallelIndexSupervisorTask.groupGenericPartitionLocationsPerPartition()`\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 10 Feb 2022 11:08:39 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3ee66bb492381ea1721c3355a7a5fc404a93d852\",\n",
      "\t\t\"parent\": \"33bc9226f08d3fd013a557c85d80fb629956f2ab\",\n",
      "\t\t\"subject\": \"allow optimizing sql expressions and virtual columns (#12241)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-optimizing-sql-expressions-and-virtual-columns-12241\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* rework sql planner expression and virtual column handling  * simplify a bit  * add back and deprecate old methods, more tests, fix multi-value string coercion bug and associated tests  * spotbugs  * fix bugs with multi-value string array expression handling  * javadocs and adjust test  * better  * fix tests\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Feb 2022 14:55:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"33bc9226f08d3fd013a557c85d80fb629956f2ab\",\n",
      "\t\t\"parent\": \"0d237138626b58879974fdbb735ba19cb92ddf2f\",\n",
      "\t\t\"subject\": \"Move task creation under stateChangeLock in SeekableStreamSupervisor (#12178)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-task-creation-under-stateChangeLock-in-SeekableStreamSupervisor-12178\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 9 Feb 2022 13:24:46 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0d237138626b58879974fdbb735ba19cb92ddf2f\",\n",
      "\t\t\"parent\": \"ab3d994a1769f2b87939e4b104ceeee0f67a8318\",\n",
      "\t\t\"subject\": \"Web console: update dev dependencies (#12240)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-update-dev-dependencies-12240\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update dependencies  * Set \\\"allowFunctions: true\\\" for react/jsx-no-bind  * Prettify  * npm audit fix  * Bump playwright, set testEnvironment=node  * Bump node and npm  * Revert \\\"Bump node and npm\\\"  This reverts commit e93c8e00e75587524539310772f09bd3b37774ed.  * Minor/patch bump node@14, npm@6\",\n",
      "\t\t\"author_name\": \"John Gozde\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Feb 2022 16:37:36 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ab3d994a1769f2b87939e4b104ceeee0f67a8318\",\n",
      "\t\t\"parent\": \"4add2510edaeef2cbbd565f1c20517f4a3d039b2\",\n",
      "\t\t\"subject\": \"Lazy instantiation for segmentKillers, segmentMovers, and segmentArchivers (#12207)\",\n",
      "\t\t\"sanitized_subject_line\": \"Lazy-instantiation-for-segmentKillers-segmentMovers-and-segmentArchivers-12207\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* working  * Lazily load segmentKillers, segmentMovers, and segmentArchivers  * more tests  * test-jar plugin  * more coverage  * lazy client  * clean up changes  * checkstyle  * i did not change the branch condition  * adjust failure rate to run tests faster  * javadocs  * checkstyle\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Feb 2022 13:02:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4add2510edaeef2cbbd565f1c20517f4a3d039b2\",\n",
      "\t\t\"parent\": \"ae71e05fc5d0cec8f7ae78df25ccf4a45cfecfda\",\n",
      "\t\t\"subject\": \"Add syntax support for PARTITIONED BY/CLUSTERED BY in INSERT queries  (#12163)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-syntax-support-for-PARTITIONED-BY-CLUSTERED-BY-in-INSERT-queries-12163\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR aims to add parser changes for supporting PARTITIONED BY and CLUSTERED BY as proposed in the issue #11929.  \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 8 Feb 2022 16:23:15 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ae71e05fc5d0cec8f7ae78df25ccf4a45cfecfda\",\n",
      "\t\t\"parent\": \"090c429c8cfd0667fb6f3526eb10e6b7b91be0a5\",\n",
      "\t\t\"subject\": \"array_concat_agg and array_agg support for array inputs (#12226)\",\n",
      "\t\t\"sanitized_subject_line\": \"array_concat_agg-and-array_agg-support-for-array-inputs-12226\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* array_concat_agg and array_agg support for array inputs changes: * added array_concat_agg to aggregate arrays into a single array * added array_agg support for array inputs to make nested array * added 'shouldAggregateNullInputs' and 'shouldCombineAggregateNullInputs' to fix a correctness issue with STRING_AGG and ARRAY_AGG when merging results, with dual purpose of being an optimization for aggregating  * fix test  * tie capabilities type to legacy mode flag about coercing arrays to strings  * oops  * better javadoc\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Feb 2022 19:59:30 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"090c429c8cfd0667fb6f3526eb10e6b7b91be0a5\",\n",
      "\t\t\"parent\": \"ced1389d4cd64a23a196015d9890202d18147ea4\",\n",
      "\t\t\"subject\": \"Web console: make it possible to namespace local storage, auto flatten spec generator should deal better with bad data (#12238)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-make-it-possible-to-namespace-local-storage-auto-flatten-spec-generator-should-deal-better-with-bad-data-12238\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* improve computeFlattenExprsForData  * allow local storage namespacing  * add test\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Feb 2022 18:52:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ced1389d4cd64a23a196015d9890202d18147ea4\",\n",
      "\t\t\"parent\": \"2b8e7fc0b4ab76af836594d3b14e9213fa64cff0\",\n",
      "\t\t\"subject\": \"Enable auto kill segments by default (#12187)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-auto-kill-segments-by-default-12187\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Enable auto-kill by default  * tests  * wip  * test  * fix IT  * fix it  * remove from docs  * make coverage bot happy\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 7 Feb 2022 06:57:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b8e7fc0b4ab76af836594d3b14e9213fa64cff0\",\n",
      "\t\t\"parent\": \"159f97dcb025dfa5c8aabe04a923e637331ae8d5\",\n",
      "\t\t\"subject\": \"Add a flag to allow auto compaction task slot ratio to consider auto scaler slots (#12228)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-flag-to-allow-auto-compaction-task-slot-ratio-to-consider-auto-scaler-slots-12228\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * fix checkstyle  * add unit tests  * checkstyle  * add IT  * fix IT  * add comments  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 6 Feb 2022 20:46:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"159f97dcb025dfa5c8aabe04a923e637331ae8d5\",\n",
      "\t\t\"parent\": \"de82c611de82f91f2f5e36fefc67b981d0408a4d\",\n",
      "\t\t\"subject\": \"Update docs for druid.processing.numThreads in brokers (#12231)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-docs-for-druid.processing.numThreads-in-brokers-12231\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update docs for druid.processing.numThreads  * error msg  * one more reference\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Feb 2022 17:34:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"de82c611de82f91f2f5e36fefc67b981d0408a4d\",\n",
      "\t\t\"parent\": \"290130b1faf5a474f731687deb92b9c8cc68bc6a\",\n",
      "\t\t\"subject\": \"Harmonize implementations of \\\"visit\\\" for Exprs from ExprMacros. (#12230)\",\n",
      "\t\t\"sanitized_subject_line\": \"Harmonize-implementations-of-visit-for-Exprs-from-ExprMacros.-12230\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Harmonize implementations of \\\"visit\\\" for Exprs from ExprMacros.  Many of them had bugs where they would not visit all of the original arguments. I don't think this has user-visible consequences right now, but it's possible it would in a future world where \\\"visit\\\" is used for more stuff than it is today.  So, this patch all updates all implementations to a more consistent style that emphasizes reapplying the macro to the shuttled args.  * Test fixes, test coverage, PR review comments.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Feb 2022 08:08:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"290130b1faf5a474f731687deb92b9c8cc68bc6a\",\n",
      "\t\t\"parent\": \"a3affe1471ec3e4c92e5c3305b55f5fa7e150850\",\n",
      "\t\t\"subject\": \"Fix bug while adding `Range` header in HttpEntity (#12215)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bug-while-adding-Range-header-in-HttpEntity-12215\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Changes: - Add `Range` header to the request before opening the connection - Use header `Content-Range` instead of `Accept-Ranges` as `Content-Range` is guaranteed to be populated if the server is returning a partial response\",\n",
      "\t\t\"author_name\": \"tejaswini-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 4 Feb 2022 18:17:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a3affe1471ec3e4c92e5c3305b55f5fa7e150850\",\n",
      "\t\t\"parent\": \"8fd587b28cc5ee3562362682555d7f843f4d4a68\",\n",
      "\t\t\"subject\": \"make EncodedKeyComponent constructor public, remove nullable from DimensionIndexer.processRowValsToUnsortedEncodedKeyComponent  (#12229)\",\n",
      "\t\t\"sanitized_subject_line\": \"make-EncodedKeyComponent-constructor-public-remove-nullable-from-DimensionIndexer.processRowValsToUnsortedEncodedKeyComponent-12229\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Feb 2022 15:02:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8fd587b28cc5ee3562362682555d7f843f4d4a68\",\n",
      "\t\t\"parent\": \"37176936330d4241947ea2de48f13441e6b2933e\",\n",
      "\t\t\"subject\": \"remove duplicate Broker ServerInventoryView, improve HttpServerInventoryView logging (#12209)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-duplicate-Broker-ServerInventoryView-improve-HttpServerInventoryView-logging-12209\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* changes: * remove SystemSchema duplicate ServerInventoryView in broker * suppress duplicate segment added/removed warnings in HttpServerInventoryView when doing a full sync  * fixes\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Feb 2022 12:57:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37176936330d4241947ea2de48f13441e6b2933e\",\n",
      "\t\t\"parent\": \"fc76b014d15caf5662800706237eb336aef426e4\",\n",
      "\t\t\"subject\": \"Fix java.lang.ClassCastException error when using useApproximateCountDistinct false for aggregation query (#12216)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-java.lang.ClassCastException-error-when-using-useApproximateCountDistinct-false-for-aggregation-query-12216\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add imply  * add test  * add unit test  * add test\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Feb 2022 12:01:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fc76b014d15caf5662800706237eb336aef426e4\",\n",
      "\t\t\"parent\": \"e648b01afba52ee5b980d28b16b636e346a86819\",\n",
      "\t\t\"subject\": \"Web console: fix supervisor stats table pagination (#12227)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-fix-supervisor-stats-table-pagination-12227\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fixes #11627 supervisor stats table pagination  * use spread instead of assign\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Feb 2022 00:09:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e648b01afba52ee5b980d28b16b636e346a86819\",\n",
      "\t\t\"parent\": \"bc408bacc8d70d9769c30494fa84eda5b0e3f8aa\",\n",
      "\t\t\"subject\": \"Improve memory estimates in Aggregator and DimensionIndexer (#12073)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-memory-estimates-in-Aggregator-and-DimensionIndexer-12073\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes #12022    ### Description The current implementations of memory estimation in `OnHeapIncrementalIndex` and `StringDimensionIndexer` tend to over-estimate which leads to more persistence cycles than necessary.  This PR replaces the max estimation mechanism with getting the incremental memory used by the aggregator or indexer at each invocation of `aggregate` or `encode` respectively.  ### Changes - Add new flag `useMaxMemoryEstimates` in the task context. This overrides the same flag in DefaultTaskConfig i.e. `druid.indexer.task.default.context` map - Add method `AggregatorFactory.factorizeWithSize()` that returns an `AggregatorAndSize` which contains   the aggregator instance and the estimated initial size of the aggregator - Add method `Aggregator.aggregateWithSize()` which returns the incremental memory used by this aggregation step - Update the method `DimensionIndexer.processRowValsToKeyComponent()` to return the encoded key component as well as its effective size in bytes - Update `OnHeapIncrementalIndex` to use the new estimations only if `useMaxMemoryEstimates = false`\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 3 Feb 2022 10:34:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bc408bacc8d70d9769c30494fa84eda5b0e3f8aa\",\n",
      "\t\t\"parent\": \"801d9e7f1b3a4720718362194f651e11e1f6818d\",\n",
      "\t\t\"subject\": \"Web console: Adding a shard detail column to the segments view (#12212)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Adding-a-shard-detail-column-to-the-segments-view-12212\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* shard spec details  * improve pattern match  * refactor spec cleanup  * better format detection  * update JSONbig  * add multiline option to autoform\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Feb 2022 18:46:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"801d9e7f1b3a4720718362194f651e11e1f6818d\",\n",
      "\t\t\"parent\": \"f47e1e0dcc0640feebbe4893a37b54c9a00148eb\",\n",
      "\t\t\"subject\": \"[Web Console] fix deprecated keyboard event method \\\"keyCode\\\" with \\\"key\\\" (#11947)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-Console-fix-deprecated-keyboard-event-method-keyCode-with-key-11947\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* 11946 fix keyboard event keyCode method  * fix with key and respective cases  * e.which method required since it's anyway deprecated too.  * updated as per feedback\",\n",
      "\t\t\"author_name\": \"AshishKapoor\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 2 Feb 2022 18:26:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f47e1e0dcc0640feebbe4893a37b54c9a00148eb\",\n",
      "\t\t\"parent\": \"f9b406c8f2c2bc84f54d2e8f5f2a2720f49eeba3\",\n",
      "\t\t\"subject\": \"Reduce RemoteTaskRunnerTest flakiness (#12211)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-RemoteTaskRunnerTest-flakiness-12211\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* * add more logging to start / stop of RemoteTaskRunner  * * add more logging  * Increase timeout on RemoteTaskRunnerTest  * Apply suggestions from code review  Co-authored-by: Suneet Saldanha <suneet@apache.org>  Co-authored-by: Suneet Saldanha <suneet@apache.org>\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Feb 2022 15:35:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f9b406c8f2c2bc84f54d2e8f5f2a2720f49eeba3\",\n",
      "\t\t\"parent\": \"978b8f7ddee7fcad822975e93d053779f69591ef\",\n",
      "\t\t\"subject\": \"add backwards compatibility mode for multi-value string array null value coercion (#12210)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-backwards-compatibility-mode-for-multi-value-string-array-null-value-coercion-12210\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 31 Jan 2022 22:38:15 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"978b8f7ddee7fcad822975e93d053779f69591ef\",\n",
      "\t\t\"parent\": \"c4fa3ccfc4a8df0da3968b817dbb057e4ada79fc\",\n",
      "\t\t\"subject\": \"do not explode if mysql transient exception class does not exist (#12213)\",\n",
      "\t\t\"sanitized_subject_line\": \"do-not-explode-if-mysql-transient-exception-class-does-not-exist-12213\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Follow up to #12205 to allow druid-mysql-extensions to work with mysql connector/j 8.x again, which does not contain MySQLTransientException, and while would have had the same problem as mariadb if a transient exception was checked, the new check eagerly loads the class when starting up, causing immediate failure.  \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 1 Feb 2022 09:06:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c4fa3ccfc4a8df0da3968b817dbb057e4ada79fc\",\n",
      "\t\t\"parent\": \"fe8530dac40b77a05e76fc213064c84d2968d728\",\n",
      "\t\t\"subject\": \"Fix load-drop-load sequence for same segment and historical in http loadqueue peon (#11717)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-load-drop-load-sequence-for-same-segment-and-historical-in-http-loadqueue-peon-11717\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes an issue where a load-drop-load sequence for a segment and historical doesn't work correctly for http based load queue peon. The first cycle of load-drop works fine - the problem comes when there is an attempt to reload the segment. The historical caches load success for some recent segments and makes the reload as a no-op. But it doesn't consider that fact that the segment was also dropped in between the load requests. This change invalidates the cache after a client tries to fetch a success result.\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 31 Jan 2022 13:16:58 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fe8530dac40b77a05e76fc213064c84d2968d728\",\n",
      "\t\t\"parent\": \"eeed156dc006510a9e944e50a992ddc65b2b6836\",\n",
      "\t\t\"subject\": \"Change link to Apache Druid Slack (#12206)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-link-to-Apache-Druid-Slack-12206\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 21:10:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eeed156dc006510a9e944e50a992ddc65b2b6836\",\n",
      "\t\t\"parent\": \"99a5c2f3d393cc1e980340679879765c12c4ec6d\",\n",
      "\t\t\"subject\": \"Fix compile error in VirtualizedColumnSelectorFactoryTest (#12208)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-compile-error-in-VirtualizedColumnSelectorFactoryTest-12208\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 17:35:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"99a5c2f3d393cc1e980340679879765c12c4ec6d\",\n",
      "\t\t\"parent\": \"5d2291991ea08c8b474364c084bdafc1e3b45f33\",\n",
      "\t\t\"subject\": \"Harmonize behavior when virtual columns reference each other. (#11955)\",\n",
      "\t\t\"sanitized_subject_line\": \"Harmonize-behavior-when-virtual-columns-reference-each-other.-11955\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* VirtualizedColumnSelectorFactory: Allow virtual columns to reference each other.  This matches the behavior of QueryableIndex and IncrementalIndex based cursors.  * Fixes to getColumnCapabilities.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 14:31:48 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5d2291991ea08c8b474364c084bdafc1e3b45f33\",\n",
      "\t\t\"parent\": \"24716bfedcfffe8dc79070e70c174e1543cb1b72\",\n",
      "\t\t\"subject\": \"use reflection to check for mysql transient exception type (#12205)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-reflection-to-check-for-mysql-transient-exception-type-12205\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use reflection to check for mysql transient exception type  * better  * oops\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 13:13:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"24716bfedcfffe8dc79070e70c174e1543cb1b72\",\n",
      "\t\t\"parent\": \"fac6a48a8ffe7018dd84e7a2b41e225bd47744d3\",\n",
      "\t\t\"subject\": \"Doc updates for metadata cleanup and storage (#12190)\",\n",
      "\t\t\"sanitized_subject_line\": \"Doc-updates-for-metadata-cleanup-and-storage-12190\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* doc updates for metadata storage/cleanup  * Add comments for disabling cleanup  * Apply suggestions from code review  * updated for https://github.com/apache/druid/pull/12201  * Apply suggestions from code review  Co-authored-by: Maytas Monsereenusorn <maytasm@apache.org>  * move retention period line earlier; more concise text  * fix typo  Co-authored-by: Maytas Monsereenusorn <maytasm@apache.org>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 11:40:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fac6a48a8ffe7018dd84e7a2b41e225bd47744d3\",\n",
      "\t\t\"parent\": \"f906f2f577144ff20e5487c98c15c3abaa8680f5\",\n",
      "\t\t\"subject\": \"add impl (#12201)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-impl-12201\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 11:39:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f906f2f577144ff20e5487c98c15c3abaa8680f5\",\n",
      "\t\t\"parent\": \"1b8808cce8b4880f92d9e8e7dda5be7b65a24b19\",\n",
      "\t\t\"subject\": \"Fix HttpRemoteTaskRunner LifecycleStart / LifecycleStop race condition (#12184)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-HttpRemoteTaskRunner-LifecycleStart-LifecycleStop-race-condition-12184\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* * stop workers, remove listener, and call exitStop() on HttpRemoteTaskRunner @LifecycleStop  * * fix test failure\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 13:15:14 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1b8808cce8b4880f92d9e8e7dda5be7b65a24b19\",\n",
      "\t\t\"parent\": \"a813816fb13713e338fe2364a915239783f1070e\",\n",
      "\t\t\"subject\": \"Fix SQL queries for inline datasource with null values (#12092)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-SQL-queries-for-inline-datasource-with-null-values-12092\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes a bug because of which some SQL queries cannot be parsed using druid convention. Specifically, these queries translate to an inline datasource and have some null values. Calcite internally uses NULL as SQL type for these literals and that is not supported by the druid. I am now allowing null column types to be returned while building RowSignature in org.apache.druid.sql.calcite.table.RowSignatures#fromRelDataType. RowSignature already allows null column type for any column. Doing so should also fix bindable queries such as select (1,2). When such queries are run with headers set to true, we get an exception in org.apache.druid.sql.http.ArrayWriter#writeHeader. This is again a similar exception to the one addressed in this PR. Because SQL type for the result column is RECORD and that doesn't have a corresponding columnType.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 27 Jan 2022 18:04:12 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a813816fb13713e338fe2364a915239783f1070e\",\n",
      "\t\t\"parent\": \"96b3498a4048b4f8d2d72a06ceda2df1868db799\",\n",
      "\t\t\"subject\": \"add module test for QueryableModule to allow for better runtime.properties testing (#12202)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-module-test-for-QueryableModule-to-allow-for-better-runtime.properties-testing-12202\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"added a default GetRequestLoggerProviderTest and GetEmitterRequestLoggerProviderTest\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Jan 2022 22:26:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"96b3498a4048b4f8d2d72a06ceda2df1868db799\",\n",
      "\t\t\"parent\": \"8ae5de5114f1758ac7699236b3a0995851022cf7\",\n",
      "\t\t\"subject\": \"Grouping on arrays as arrays (#12078)\",\n",
      "\t\t\"sanitized_subject_line\": \"Grouping-on-arrays-as-arrays-12078\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* init multiValue column group by  * Changing sorting to Lexicographic as default  * Adding initial tests  * 1.Fixing test cases adding 2.Optimized inmem structs  * Linking SQL layer to native layer  * Adding multiDimension support to group by column strategy  * 1. Removing array coercion in Calcite layer 2. Removing ResultRowDeserializer  * 1. Supporting all primitive array types 2. Removing dimension spec as part of columnSelector  * 1. Supporting all primitive array types 2. Removing dimension spec as part of columnSelector  * 1. Checkstyle things 2. Removing flag  * Minor naming things  * CheckStyle Things  * Fixing test case  * Fixing hashing  * 1. Adding the MV function 2. Added few test cases  * 1. Adding MV function test cases  * Adding Selector strategy function test cases  * Fixing ClientQuerySegmentWalkerTest  * Adding GroupByQueryRunnerTest test cases  * Fixing test cases  * Adding few more test cases  * Fixing Exception asset statement and intellij inspection  * Adding null compatibility tests  * Review comments  * Fixing few failing tests  * Fixing few failing tests  * Do no convert to topN Q incase of group by on array  * Fixing checkstyle  * Fixing differences between jdk's class cast exception message  * 1. Fixing ordering if the grouping key is an array  * Fixing DefaultLimitSpec  * Fixing CalciteArraysQueryTest  * Dummy commit for LGTM  * changes: * only coerce multi-value string null values when `ExpressionPlan.Trait.NEEDS_APPLIED` is set * correct return type inference for ARRAY_APPEND,ARRAY_PREPEND,ARRAY_SLICE,ARRAY_CONCAT * fix bug with ExprEval.ofType when actual type of object from binding doesn't match its claimed type  * Review comments  * Fixing test cases  * Fixing spot bugs  * Fixing strict compile  Co-authored-by: Clint Wylie <cwylie@apache.org>\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Jan 2022 20:30:56 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ae5de5114f1758ac7699236b3a0995851022cf7\",\n",
      "\t\t\"parent\": \"fce62b26434cc9ce533857f4f91e1da2816df992\",\n",
      "\t\t\"subject\": \"Web console: fix multi-value dimension column detection and tidy up (#12160)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-fix-multi-value-dimension-column-detection-and-tidy-up-12160\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* streamline services view query  * better column type detection  * fix query view page size bug  * fill out MetricSpec interface  * fix pagination in status dialog  * update tests  * adjust pagination  * better type guessing  * better test fixtures  * add Avg. row size to segments view\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Jan 2022 15:46:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fce62b26434cc9ce533857f4f91e1da2816df992\",\n",
      "\t\t\"parent\": \"20347e0c86375693c7a23489559ff199299b7a45\",\n",
      "\t\t\"subject\": \"fix StringAnyAggregatorFactory to use single value selector for non-existent columns (#12194)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-StringAnyAggregatorFactory-to-use-single-value-selector-for-non-existent-columns-12194\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Jan 2022 12:52:30 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"20347e0c86375693c7a23489559ff199299b7a45\",\n",
      "\t\t\"parent\": \"2b32d86f3bcbee83b800614f9862f7130635cd92\",\n",
      "\t\t\"subject\": \"Wait for datasource to be ready for SQL in integration tests (#12189)\",\n",
      "\t\t\"sanitized_subject_line\": \"Wait-for-datasource-to-be-ready-for-SQL-in-integration-tests-12189\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Wait for datasource to be ready for SQL in integration tests  * add limit to the check query\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 25 Jan 2022 10:14:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2b32d86f3bcbee83b800614f9862f7130635cd92\",\n",
      "\t\t\"parent\": \"cc8b9c0b6e0e631d0c1cdfd512006bdd36039431\",\n",
      "\t\t\"subject\": \"Enable automatic metdata cleanup by default (#12188)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-automatic-metdata-cleanup-by-default-12188\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 24 Jan 2022 20:04:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc8b9c0b6e0e631d0c1cdfd512006bdd36039431\",\n",
      "\t\t\"parent\": \"dc1703d5f9723634bae123e9a11a6899b2abf05a\",\n",
      "\t\t\"subject\": \"Handling OOM error in ExpressionVector setup by reducing number of rows (#12186)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handling-OOM-error-in-ExpressionVector-setup-by-reducing-number-of-rows-12186\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Handling OOM error in ExpressionVector setup by reducing number of rows  * Removing row size to 10K in sanity tests\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 24 Jan 2022 08:37:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"dc1703d5f9723634bae123e9a11a6899b2abf05a\",\n",
      "\t\t\"parent\": \"ac87bdd7366c4b39001e364eb46a923fdd4d1a86\",\n",
      "\t\t\"subject\": \"Change value of `druid.sql.planner.useGroupingSetForExactDistinct` in common.runtime.properties (#12182)\",\n",
      "\t\t\"sanitized_subject_line\": \"Change-value-of-druid.sql.planner.useGroupingSetForExactDistinct-in-common.runtime.properties-12182\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR changes the value of the property `druid.sql.planner.useGroupingSetForExactDistinct` from `false` to `true` in the runtime.properties files, so that newer installations have this property as `true`, while the default still remains as `false`.  The flag determines how queries which contain an aggregation over `DISTINCT` like `SELECT COUNT(DISTINCT foo.dim1) FILTER(WHERE foo.cnt = 1), SUM(foo.cnt) FROM druid.foo` get planned by Calcite. With the flag being set to false, it plans it via joins, whereas with it being set to true, the query is set using grouping sets.  There is a known issue with Calcite (https://github.com/apache/druid/issues/7953), where an NPE is thrown while planning the above query with joins. There is no such issue while planning the query using grouping sets.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 24 Jan 2022 14:00:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ac87bdd7366c4b39001e364eb46a923fdd4d1a86\",\n",
      "\t\t\"parent\": \"1f63b447c45cb852924d5d3101a1005b670a054b\",\n",
      "\t\t\"subject\": \"fix typo in materialized view (#12174)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-typo-in-materialized-view-12174\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"JoyKing\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 22 Jan 2022 11:32:22 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f63b447c45cb852924d5d3101a1005b670a054b\",\n",
      "\t\t\"parent\": \"376d7c069de3b87b21db262cca4b72ddc49e3b66\",\n",
      "\t\t\"subject\": \"Mitigate Kinesis stream LimitExceededException by using listShards API (#12161)\",\n",
      "\t\t\"sanitized_subject_line\": \"Mitigate-Kinesis-stream-LimitExceededException-by-using-listShards-API-12161\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Makes kinesis ingestion resilient to `LimitExceededException` caused by resharding. Replace `describeStream` with `listShards` (recommended) to get shard related info. `describeStream` has a limit (100) to the number of shards returned per call and a low default TPS limit of 10. `listShards` returns the info for at most 1000 shards and has a higher TPS limit of 100 as well.  Key changed/added classes in this PR  * `KinesisRecordSupplier`  * `KinesisAdminClient`\",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 21 Jan 2022 10:15:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"376d7c069de3b87b21db262cca4b72ddc49e3b66\",\n",
      "\t\t\"parent\": \"6ce14e6b17fa227c51407eecbcbecf71191156bb\",\n",
      "\t\t\"subject\": \"Close provisioner during HttpRemotetaskRunner LifecycleStop (#12176)\",\n",
      "\t\t\"sanitized_subject_line\": \"Close-provisioner-during-HttpRemotetaskRunner-LifecycleStop-12176\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixed an issue where the provisionerService which can be used to spawn resources as needed is left running on a non-leader coordinator/overlord, after it is removed from leadership. Provisioning should only be done by the leader. To fix the issue, a call to stop the provisionerService was added to the stop() method of HttpRemoteTaskRunner class. The provisionerService was properly closed on other TaskRunner types.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Jan 2022 13:32:08 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ce14e6b17fa227c51407eecbcbecf71191156bb\",\n",
      "\t\t\"parent\": \"1f7dd6d86c68d26e2466fc40b7d593455e0b632d\",\n",
      "\t\t\"subject\": \"allow W in durations (#12175)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-W-in-durations-12175\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 20 Jan 2022 09:17:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f7dd6d86c68d26e2466fc40b7d593455e0b632d\",\n",
      "\t\t\"parent\": \"cacfcfcdabe9c54e610e9a48370474b8022dd591\",\n",
      "\t\t\"subject\": \"Forbiddenapis: Split the guava16-only signatures file from main signatures file (#12170)\",\n",
      "\t\t\"sanitized_subject_line\": \"Forbiddenapis-Split-the-guava16-only-signatures-file-from-main-signatures-file-12170\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Uwe Schindler\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 19 Jan 2022 17:50:28 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cacfcfcdabe9c54e610e9a48370474b8022dd591\",\n",
      "\t\t\"parent\": \"cc2ffc6c0f6f542718e1bb1cdf1063db7cc79021\",\n",
      "\t\t\"subject\": \"ignore hadoop-gcs directory already exists error for integration tests (#12169)\",\n",
      "\t\t\"sanitized_subject_line\": \"ignore-hadoop-gcs-directory-already-exists-error-for-integration-tests-12169\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 19 Jan 2022 09:35:50 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cc2ffc6c0f6f542718e1bb1cdf1063db7cc79021\",\n",
      "\t\t\"parent\": \"53c0e489c2f2f804e218600e4e87432c8f8a83ce\",\n",
      "\t\t\"subject\": \"Fix node discovery to ignore unknown DruidServices (#12157)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-node-discovery-to-ignore-unknown-DruidServices-12157\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix node discovery to ignore unknown DruidServices  * ignore all runtime exceptions  * fix test  * add custom deserializer  * custom serializer  * log host for unparseable druidService\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Jan 2022 22:08:59 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"53c0e489c2f2f804e218600e4e87432c8f8a83ce\",\n",
      "\t\t\"parent\": \"cf7191d2bc52f61cd9a81f7830c1c89f9f3c826e\",\n",
      "\t\t\"subject\": \"Fix infinite retrying during task pausing (#12167)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-infinite-retrying-during-task-pausing-12167\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This fixes a bug that causes TaskClient in overlord to continuously retry to pause tasks. This can happen when a task is not responding to the pause command. Ideally, in such a case when the task is unresponsive, the overlord would have given up after a few retries and would have killed the task. However, due to this bug, retries go on forever.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 19 Jan 2022 09:03:36 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cf7191d2bc52f61cd9a81f7830c1c89f9f3c826e\",\n",
      "\t\t\"parent\": \"7bdb9ebdf1b072924d62855e028f3de3aa8c851e\",\n",
      "\t\t\"subject\": \"Validate target dataSource for INSERT. (#12129)\",\n",
      "\t\t\"sanitized_subject_line\": \"Validate-target-dataSource-for-INSERT.-12129\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Jan 2022 09:34:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7bdb9ebdf1b072924d62855e028f3de3aa8c851e\",\n",
      "\t\t\"parent\": \"bd7fe45da0f16cfc2b80d934110c1248aff94e02\",\n",
      "\t\t\"subject\": \"Suppress Avro CVEs (#12166)\",\n",
      "\t\t\"sanitized_subject_line\": \"Suppress-Avro-CVEs-12166\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 18 Jan 2022 21:09:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bd7fe45da0f16cfc2b80d934110c1248aff94e02\",\n",
      "\t\t\"parent\": \"b55f7a25febec8979263e4edf1d8b4ec7692f968\",\n",
      "\t\t\"subject\": \"Support adding metrics in Auto Compaction (#12125)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-adding-metrics-in-Auto-Compaction-12125\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add impl  * add unit tests  * add unit tests  * add unit tests  * add unit tests  * add unit tests  * add integration tests  * add integration tests  * fix LGTM  * fix test  * remove doc\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 17 Jan 2022 20:19:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b55f7a25febec8979263e4edf1d8b4ec7692f968\",\n",
      "\t\t\"parent\": \"d2ac14636535a2293171166dee4019e7210d69a8\",\n",
      "\t\t\"subject\": \"Fix forbiddenapis causing travis failing (#12158)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-forbiddenapis-causing-travis-failing-12158\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix forbiddenapis causing travis failing  * Use failOnUnresolvableSignatures instead\",\n",
      "\t\t\"author_name\": \"Benedict Jin\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Jan 2022 16:13:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d2ac14636535a2293171166dee4019e7210d69a8\",\n",
      "\t\t\"parent\": \"6a938725861f0cafbe97e5ff8c3417fe65405cca\",\n",
      "\t\t\"subject\": \"Docs for cluster tiering to improve query concurrency (#12128)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-for-cluster-tiering-to-improve-query-concurrency-12128\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add new doc  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * reorder query laning properties  * rename doc  * new name in doc header  * organize material into \\\"service tiering\\\" section  * text edits and update sidebars.json  * update query laning  * how queries get assigned to lanes  * add more details to intro; use more consistent terminology  * more content  * Apply suggestions from code review  Co-authored-by: Jihoon Son <jihoonson@apache.org>  * Update docs/operations/mixed-workloads.md  * Apply suggestions from code review  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * typo  Co-authored-by: Charles Smith <techdocsmith@gmail.com> Co-authored-by: Jihoon Son <jihoonson@apache.org>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Jan 2022 12:22:08 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6a938725861f0cafbe97e5ff8c3417fe65405cca\",\n",
      "\t\t\"parent\": \"e0c4c568cba8a149fd5ae51321ffc6e483c5d011\",\n",
      "\t\t\"subject\": \"OpenTelemetry emitter extension (#12015)\",\n",
      "\t\t\"sanitized_subject_line\": \"OpenTelemetry-emitter-extension-12015\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add OpenTelemetry emitter extension  * Fix build  * Fix checkstyle  * Add used undeclared dependencies  * Ignore unused declared dependencies\",\n",
      "\t\t\"author_name\": \"Ivan Vankovich\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 15 Jan 2022 12:18:04 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e0c4c568cba8a149fd5ae51321ffc6e483c5d011\",\n",
      "\t\t\"parent\": \"eb4fafe08fd0827ff88937a0e3c07910c59f9b65\",\n",
      "\t\t\"subject\": \"fix incorrect ColumnInspector in IncrementalIndex.makeColumnSelectorFactory (#12155)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-incorrect-ColumnInspector-in-IncrementalIndex.makeColumnSelectorFactory-12155\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jan 2022 18:09:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb4fafe08fd0827ff88937a0e3c07910c59f9b65\",\n",
      "\t\t\"parent\": \"74c876e57804617ccb3af2b5af026cacd0320ff4\",\n",
      "\t\t\"subject\": \"Upgrading follow-redirects to 1.14.7 (#12153)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrading-follow-redirects-to-1.14.7-12153\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Upgrading follow-redirects to 1.14.7  * removed the existing follow-redirects i.e. 1.14.4 from package-lock.json\",\n",
      "\t\t\"author_name\": \"aggarwalakshay\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jan 2022 14:01:36 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"74c876e57804617ccb3af2b5af026cacd0320ff4\",\n",
      "\t\t\"parent\": \"1dba089a6218ecfc3387c445b564b6179d4962a6\",\n",
      "\t\t\"subject\": \"Throw parse exceptions on schema get errors for SchemaRegistryBasedAvroBytesDecoder (#12080)\",\n",
      "\t\t\"sanitized_subject_line\": \"Throw-parse-exceptions-on-schema-get-errors-for-SchemaRegistryBasedAvroBytesDecoder-12080\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add option to throw parse exceptions on schema get errors for SchemaRegistryBasedAvroBytesDecoder  * Remove option\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jan 2022 12:36:51 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1dba089a6218ecfc3387c445b564b6179d4962a6\",\n",
      "\t\t\"parent\": \"e56ea3169778d25bd6b13053d902070f4e5a9b25\",\n",
      "\t\t\"subject\": \"fix array type strategy write size tracking (#12150)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-array-type-strategy-write-size-tracking-12150\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix array type strategy write size tracking  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 13 Jan 2022 10:22:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e56ea3169778d25bd6b13053d902070f4e5a9b25\",\n",
      "\t\t\"parent\": \"58378aa9675a7e37ab1627824f605f9235652058\",\n",
      "\t\t\"subject\": \"follow-up to fix formatting broken in #12147 (#12148)\",\n",
      "\t\t\"sanitized_subject_line\": \"follow-up-to-fix-formatting-broken-in-12147-12148\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"follow-up to #12147 to fix the build\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 20:59:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58378aa9675a7e37ab1627824f605f9235652058\",\n",
      "\t\t\"parent\": \"168187e6df714a04a2a80dffc892a49fce8cb217\",\n",
      "\t\t\"subject\": \"Move gcs-connector from lib to hadoop-dependencies for integration test (#12144)\",\n",
      "\t\t\"sanitized_subject_line\": \"Move-gcs-connector-from-lib-to-hadoop-dependencies-for-integration-test-12144\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 16:47:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"168187e6df714a04a2a80dffc892a49fce8cb217\",\n",
      "\t\t\"parent\": \"9cd52ed914cbf4ecb6e0cd3f4451eb44ed78d1f8\",\n",
      "\t\t\"subject\": \"avoid unnecessary String.format calls in IdUtils.validateId (#12147)\",\n",
      "\t\t\"sanitized_subject_line\": \"avoid-unnecessary-String.format-calls-in-IdUtils.validateId-12147\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Based on profiling data, about 25% of the time de-serializing DataSchema is spent on formatting strings in validateId.  This can add up quickly, especially when de-serializing task information in the overlord, where in can consume almost 2% of CPU if there are many tasks.  Since the formatting is unnecessary unless the checks fail, we can leverage the built-in formatting of Preconditions.checkArgument instead to avoid the cost.\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 16:34:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9cd52ed914cbf4ecb6e0cd3f4451eb44ed78d1f8\",\n",
      "\t\t\"parent\": \"f2ce76966cf06134dbe712782edf46a7c8d72563\",\n",
      "\t\t\"subject\": \"Web console: make range partitioning a first class citizen of the console (#12146)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-make-range-partitioning-a-first-class-citizen-of-the-console-12146\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* first class support for range partitioning  * update e2e tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 03:50:10 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f2ce76966cf06134dbe712782edf46a7c8d72563\",\n",
      "\t\t\"parent\": \"fae73800a7791e386c2b0c6bce3de06f85b525d3\",\n",
      "\t\t\"subject\": \"add EARLIEST_BY/LATEST_BY to make EARLIEST/LATEST function signatures less ambiguous (#12145)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-EARLIEST_BY-LATEST_BY-to-make-EARLIEST-LATEST-function-signatures-less-ambiguous-12145\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add EARLIEST_BY/LATEST_BY to make EARLIEST/LATEST function signatures unambiguous  * switcheroo  * EARLIEST_BY/LATEST_BY use timestamp instead of numeric types, update docs  * revert unintended change  * fix docs  * fix docs better\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 03:48:53 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fae73800a7791e386c2b0c6bce3de06f85b525d3\",\n",
      "\t\t\"parent\": \"81f0aba6cb2fa8fecc3f9daff341f88cfc2c692b\",\n",
      "\t\t\"subject\": \"Set plannerContext error when cannot query external datasources and when insert is not supported.  (#12136)\",\n",
      "\t\t\"sanitized_subject_line\": \"Set-plannerContext-error-when-cannot-query-external-datasources-and-when-insert-is-not-supported.-12136\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR aims to add plannerContext.setPlanningError whenever external table scan rule is invoked, without the queryMaker having the ability to do so.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 12 Jan 2022 15:11:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"81f0aba6cb2fa8fecc3f9daff341f88cfc2c692b\",\n",
      "\t\t\"parent\": \"b153cb2342cd5f33c79c063db3ae49ebaf498bb1\",\n",
      "\t\t\"subject\": \"Use ListFilteredVirtualColumn for left/fact table expression in join condition (#12127)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-ListFilteredVirtualColumn-for-left-fact-table-expression-in-join-condition-12127\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Pass VirtualColumnRegistry in PlannerContext for join expression planning  * Allow for including VCs from join fact table expression  * Optmize MV_FILTER functions to use a VC when in join fact table expression  * fixup! Allow for including VCs from join fact table expression  * Address review comments\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jan 2022 14:47:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b153cb2342cd5f33c79c063db3ae49ebaf498bb1\",\n",
      "\t\t\"parent\": \"08fea7a46a0dddbf9449b791bca8c9e783054642\",\n",
      "\t\t\"subject\": \"Add a small LRU cache and use utf8 bytes in ArrayOfDoubles (#12130)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-a-small-LRU-cache-and-use-utf8-bytes-in-ArrayOfDoubles-12130\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add a small LRU cache and use utf8 bytes in ArrayOfDoubles  * Add tests for extra branches  * Even more tests for branch coverage  * Fix Style\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jan 2022 13:04:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"08fea7a46a0dddbf9449b791bca8c9e783054642\",\n",
      "\t\t\"parent\": \"eb0bae49eca5013c7121994e20f9cd8146df8424\",\n",
      "\t\t\"subject\": \"input type validation for datasketches hll \\\"build\\\" aggregator factory (#12131)\",\n",
      "\t\t\"sanitized_subject_line\": \"input-type-validation-for-datasketches-hll-build-aggregator-factory-12131\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Ingestion will fail for HLLSketchBuild instead of creating with incorrect values  * Addressing review comments for HLL< updated error message introduced test case\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jan 2022 12:00:14 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"eb0bae49eca5013c7121994e20f9cd8146df8424\",\n",
      "\t\t\"parent\": \"7cf9192765a47d9a63cdd87c12e964de78a08d2f\",\n",
      "\t\t\"subject\": \"Update PostAggregator to be backwards compat (#12138)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-PostAggregator-to-be-backwards-compat-12138\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This change mimics what was done in PR #11917 to fix the incompatibilities produced by #11713. #11917 fixed it with AggregatorFactory by creating default methods to allow for extensions built against old jars to still work.  This does the same for PostAggregator\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jan 2022 02:18:14 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7cf9192765a47d9a63cdd87c12e964de78a08d2f\",\n",
      "\t\t\"parent\": \"c8ddf60851a6ac59a15ee93964f2314f13b7aba0\",\n",
      "\t\t\"subject\": \"fix delegated smoosh writer and some new facilities for segment writeout medium (#12132)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-delegated-smoosh-writer-and-some-new-facilities-for-segment-writeout-medium-12132\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix delegated smoosh writer and some new facilities for segment writeout medium changes: * fixed issue with delegated `SmooshedWriter` when writing files that look like paths, causing `NoSuchFileException` exceptions when attempting to open a channel to the file * `FileSmoosher.addWithSmooshedWriter` when _not_ delegating now checks that it is still open when closing, making it a no-op if already closed (allowing column serializers to add additional files and avoid delegated mode if they are finished writing out their own content and ned to add additional files) * add `makeChildWriteOutMedium` to `SegmentWriteOutMedium` interface, which allows users of a shared medium to clean up `WriteOutBytes` if they fully control the lifecycle. there are no callers of this yet, adding for future functionality * `OnHeapByteBufferWriteOutBytes` now can be marked as not open so it `OnHeapMemorySegmentWriteOutMedium` can now behave identically to other medium implementations  * fix to address nit - use AtomicLong\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Jan 2022 22:25:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c8ddf60851a6ac59a15ee93964f2314f13b7aba0\",\n",
      "\t\t\"parent\": \"e5830332319e680f2475f541840ee1a23d289117\",\n",
      "\t\t\"subject\": \"Upgrade RSA Key from 1024 bit to 4096 to eliminate warnings (#11743)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-RSA-Key-from-1024-bit-to-4096-to-eliminate-warnings-11743\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* eliminate warnings  * Change the keyStore type to PKCS12\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 11 Jan 2022 13:24:09 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e5830332319e680f2475f541840ee1a23d289117\",\n",
      "\t\t\"parent\": \"2a41b7bffa176c48b1d11edfac65e29c6cb01a3b\",\n",
      "\t\t\"subject\": \"add 'TypeStrategy' to types (#11888)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-TypeStrategy-to-types-11888\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add TypeStrategy - value comparators and binary serialization for any TypeSignature\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Jan 2022 17:12:14 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2a41b7bffa176c48b1d11edfac65e29c6cb01a3b\",\n",
      "\t\t\"parent\": \"7c17341caa7d8255389128eb99f24863593abcbd\",\n",
      "\t\t\"subject\": \"Web console: correctly cancel JSON shaped SQL queries (#12134)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-correctly-cancel-JSON-shaped-SQL-queries-12134\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* misc fixes  * type typo\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 10 Jan 2022 14:24:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7c17341caa7d8255389128eb99f24863593abcbd\",\n",
      "\t\t\"parent\": \"2299eb321e092748d6c192c663cb9ea771bbc1a9\",\n",
      "\t\t\"subject\": \"Return empty result when a group by gets optimized to a timeseries query (#12065)\",\n",
      "\t\t\"sanitized_subject_line\": \"Return-empty-result-when-a-group-by-gets-optimized-to-a-timeseries-query-12065\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Related to #11188  The above mentioned PR allowed timeseries queries to return a default result, when queries of type: select count(*) from table where dim1=\\\"_not_present_dim_\\\" were executed. Before the PR, it returned no row, after the PR, it would return a row with value of count(*) as 0 (as expected by SQL standards of different dbs).  In Grouping#applyProject, we can sometimes perform optimization of a groupBy query to a timeseries query if possible (when the keys of the groupBy are constants, as generated by automated tools). For example, in select count(*) from table where dim1=\\\"_present_dim_\\\" group by \\\"dummy_key\\\", the groupBy clause can be removed. However, in the case when the filter doesn't return anything, i.e. select count(*) from table where dim1=\\\"_not_present_dim_\\\" group by \\\"dummy_key\\\", the behavior of general databases would be to return nothing, while druid (due to above change) returns an empty row. This PR aims to fix this divergence of behavior.  Example cases:  select count(*) from table where dim1=\\\"_not_present_dim_\\\" group by \\\"dummy_key\\\". CURRENT: Returns a row with count(*) = 0 EXPECTED: Return no row  select 'A', dim1 from foo where m1 = 123123 and dim1 = '_not_present_again_' group by dim1 CURRENT: Returns a row with ('A', 'wat') EXPECTED: Return no row  To do this, a boolean droppedDimensionsWhileApplyingProject has been added to Grouping which is true whenever we make changes to the original shape with optimization. Hence if a timeseries query has a grouping with this set to true, we set skipEmptyBuckets=true in the query context (i.e. donot return any row).  \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 7 Jan 2022 21:53:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2299eb321e092748d6c192c663cb9ea771bbc1a9\",\n",
      "\t\t\"parent\": \"c28b2834a11e88c020fcb5411424a89be1030eef\",\n",
      "\t\t\"subject\": \"Standardizing SQL function docs (#12091)\",\n",
      "\t\t\"sanitized_subject_line\": \"Standardizing-SQL-function-docs-12091\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix typos in SQL function docs  * more code  * Update docs/querying/sql.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/querying/sql.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/querying/sql.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/querying/sql.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * Update docs/querying/sql.md  Co-authored-by: Frank Chen <frankchen@apache.org>  * a few more expr, fixes  * more fixes  * quote TIME_SHIFT  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/querying/sql.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * undo header change  Co-authored-by: Frank Chen <frankchen@apache.org> Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jan 2022 23:57:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c28b2834a11e88c020fcb5411424a89be1030eef\",\n",
      "\t\t\"parent\": \"4a74c5adccf71bc5098da06638bc5dcd3473914b\",\n",
      "\t\t\"subject\": \"Add http response status code to org.eclipse.jetty.server.RequestLog (#12116)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-http-response-status-code-to-org.eclipse.jetty.server.RequestLog-12116\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add http response status code to org.eclipse.jetty.server.RequestLog  * http response code is expressed as an int. Set log msg interpolation based on digit  * trying to add an unit test to verify if the logger.debug method is called  * trying to add an unit test to verify if the logger.debug method is called  * fix compilation issues  * remove test\",\n",
      "\t\t\"author_name\": \"Marcelo R Costa\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 6 Jan 2022 20:10:01 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4a74c5adccf71bc5098da06638bc5dcd3473914b\",\n",
      "\t\t\"parent\": \"6846622080f00270e0722bd77dbbecb15f060ec3\",\n",
      "\t\t\"subject\": \"Use Druid's extension loading for integration test instead of maven (#12095)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-Druid-s-extension-loading-for-integration-test-instead-of-maven-12095\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use Druid's extension loading for integration test instead of maven  * fix maven command  * override config path  * load input format extensions and kafka by default; add prepopulated-data group  * all docker-composes are overridable  * fix s3 configs  * override config for all  * fix docker_compose_args  * fix security tests  * turn off debug logs for overlord api calls  * clean up stuff  * revert docker-compose.yml  * fix override config for query error test; fix circular dependency in docker compose  * add back some dependencies in docker compose  * new maven profile for integration test  * example file filter\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Jan 2022 23:33:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6846622080f00270e0722bd77dbbecb15f060ec3\",\n",
      "\t\t\"parent\": \"b53e7f4d12f9c4922e7ef8f540b178d0dbc21410\",\n",
      "\t\t\"subject\": \"Docs: add FILTER to sql query syntax (#12093)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-add-FILTER-to-sql-query-syntax-12093\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs: add FILTER to sql query syntax  * Update docs/querying/sql.md  * Update docs/querying/sql.md  * Update docs/querying/sql.md  * Update docs/querying/sql.md  * move and update FILTER section\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 5 Jan 2022 12:59:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b53e7f4d12f9c4922e7ef8f540b178d0dbc21410\",\n",
      "\t\t\"parent\": \"fe71fc414fbe0627290487cce59055dd65794ff8\",\n",
      "\t\t\"subject\": \"Support overlapping segment intervals in auto compaction (#12062)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-overlapping-segment-intervals-in-auto-compaction-12062\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add impl  * fix more bugs  * add tests  * fix checkstyle  * address comments  * address comments  * fix test\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 4 Jan 2022 11:47:38 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fe71fc414fbe0627290487cce59055dd65794ff8\",\n",
      "\t\t\"parent\": \"476d0bf4be4199e97695bd568d165cda98523d37\",\n",
      "\t\t\"subject\": \"Update log4j2 to 2.17.1 (#12106)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-log4j2-to-2.17.1-12106\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Signed-off-by: frank chen <frank.chen021@outlook.com>\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 30 Dec 2021 19:18:16 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"476d0bf4be4199e97695bd568d165cda98523d37\",\n",
      "\t\t\"parent\": \"37112d24e27a1d54db64889353dade198ff76da6\",\n",
      "\t\t\"subject\": \"Web console: remove console.log (#12094)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-remove-console.log-12094\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* rm console.log  * force path-parse to 1.0.7\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Dec 2021 19:31:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"37112d24e27a1d54db64889353dade198ff76da6\",\n",
      "\t\t\"parent\": \"9b598407c1a0fced304f2cfe59d16a0973ba4245\",\n",
      "\t\t\"subject\": \"Web console: new Ace, diff view, and cleanup. Decorating the console for the holidays \\u2728 \\ud83c\\udf81  (#12085)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-new-Ace-diff-view-and-cleanup.-Decorating-the-console-for-the-holidays-12085\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add diff view and upgrade AceEditor  * fix test  * function doc parsing fixes  * escape args  * allowKeys  * everyone gets a diff  * update snapshot\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Dec 2021 16:31:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9b598407c1a0fced304f2cfe59d16a0973ba4245\",\n",
      "\t\t\"parent\": \"1871a1ab18067c3db1e65e52538a861af2f5800d\",\n",
      "\t\t\"subject\": \"Add interface for external schema provider to Druid SQL (#12043)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-interface-for-external-schema-provider-to-Druid-SQL-12043\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add interfce for external schema provider to Druid SQL  * Add annotations\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 22 Dec 2021 22:17:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1871a1ab18067c3db1e65e52538a861af2f5800d\",\n",
      "\t\t\"parent\": \"c267b65f97998f7e6b43b102a0e16c331825fb14\",\n",
      "\t\t\"subject\": \"ARRAY_AGG and STRING_AGG will through errors if invoked on a complex datatype (#12089)\",\n",
      "\t\t\"sanitized_subject_line\": \"ARRAY_AGG-and-STRING_AGG-will-through-errors-if-invoked-on-a-complex-datatype-12089\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Dec 2021 17:41:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c267b65f97998f7e6b43b102a0e16c331825fb14\",\n",
      "\t\t\"parent\": \"f34575936091f7e6944e4458b91396e904620727\",\n",
      "\t\t\"subject\": \"Removing unused processing threadpool on broker (#12070)\",\n",
      "\t\t\"sanitized_subject_line\": \"Removing-unused-processing-threadpool-on-broker-12070\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Thread pool for broker  * Updating two tests to improve coverage for new method added  * Updating druidProcessingConfigTest to cover coverage  * Adding missed spelling errors caused in doc  * Adding test to cover lines of new function added\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 21 Dec 2021 13:07:53 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f34575936091f7e6944e4458b91396e904620727\",\n",
      "\t\t\"parent\": \"c0b15141778ffd9fd7141027d64755618597ed27\",\n",
      "\t\t\"subject\": \"Update to 2.17.0 (#12081)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-to-2.17.0-12081\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 19 Dec 2021 20:27:08 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c0b15141778ffd9fd7141027d64755618597ed27\",\n",
      "\t\t\"parent\": \"5d043cefbc63c9d1e18936dcdd4426ceaaaed431\",\n",
      "\t\t\"subject\": \"Segment pruning for multi-dim partitioning given query domain (#12046)\",\n",
      "\t\t\"sanitized_subject_line\": \"Segment-pruning-for-multi-dim-partitioning-given-query-domain-12046\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Segment pruning for multi-dim partitioning for a given query  DimensionRangeShardSpec#possibleInDomain has been modified to enhance pruning when multi-dim partitioning is used.  Idea While iterating through each dimension,  If query domain doesn't overlap with the set of permissible values in the segment, the segment is pruned. If the overlap happens on a boundary, consider the next dimensions. If there is an overlap within the segment boundaries, the segment cannot be pruned. \",\n",
      "\t\t\"author_name\": \"AmatyaAvadhanula\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 17 Dec 2021 12:44:43 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5d043cefbc63c9d1e18936dcdd4426ceaaaed431\",\n",
      "\t\t\"parent\": \"acbeae23b828db0856fcb360a31f163f89746335\",\n",
      "\t\t\"subject\": \"Fix test in ResponseContextTest (#12077)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-test-in-ResponseContextTest-12077\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Dec 2021 22:51:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"acbeae23b828db0856fcb360a31f163f89746335\",\n",
      "\t\t\"parent\": \"60a3a802b6a4fdda243ec27f1ccfa26d29f5cb79\",\n",
      "\t\t\"subject\": \"New doc for troubleshooting query execution (#12075)\",\n",
      "\t\t\"sanitized_subject_line\": \"New-doc-for-troubleshooting-query-execution-12075\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* new doc for troubleshooting query execution  * add doc to sidebar  * Apply suggestions from code review\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Dec 2021 17:34:34 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"60a3a802b6a4fdda243ec27f1ccfa26d29f5cb79\",\n",
      "\t\t\"parent\": \"0cc998d8a1dad781cf509a739229cc07fbf74641\",\n",
      "\t\t\"subject\": \"Modifying index from druid_segments(datasource, used, end) to druid_segments(datasource, used, end, start) to support kill task (#11894)\",\n",
      "\t\t\"sanitized_subject_line\": \"Modifying-index-from-druid_segments-datasource-used-end-to-druid_segments-datasource-used-end-start-to-support-kill-task-11894\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This index helps in faster query results during kill task's query on interval based unused segment listing. This can become a bottleneck in some production loads causing coordinator to wait longer for metadata db replies and impacting  Kafka ingestion. The modified index has helped reduce the query times for such queries.\",\n",
      "\t\t\"author_name\": \"lokesh-lingarajan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 16 Dec 2021 10:28:20 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0cc998d8a1dad781cf509a739229cc07fbf74641\",\n",
      "\t\t\"parent\": \"3f794535060ec2011a5c02653edad298712d35bf\",\n",
      "\t\t\"subject\": \"improve spec upgrading (#12072)\",\n",
      "\t\t\"sanitized_subject_line\": \"improve-spec-upgrading-12072\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Dec 2021 10:28:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3f794535060ec2011a5c02653edad298712d35bf\",\n",
      "\t\t\"parent\": \"377edff0423b25e0ac5f6f67ec646d165040d778\",\n",
      "\t\t\"subject\": \"Lock count guardrail for parallel single phase/sequential task (#12052)\",\n",
      "\t\t\"sanitized_subject_line\": \"Lock-count-guardrail-for-parallel-single-phase-sequential-task-12052\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Lock count guardrail for parallel single phase/sequential task  * PR comments\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Dec 2021 11:12:21 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"377edff0423b25e0ac5f6f67ec646d165040d778\",\n",
      "\t\t\"parent\": \"16642fb2780b11ade62c8d46d3dd7f90e424add4\",\n",
      "\t\t\"subject\": \"Ingestion metrics doc fix (#12066)\",\n",
      "\t\t\"sanitized_subject_line\": \"Ingestion-metrics-doc-fix-12066\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Ingestion metrics doc fix.  * Fixing typo  * Adding missed keywords in ignore list\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Dec 2021 12:51:53 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"16642fb2780b11ade62c8d46d3dd7f90e424add4\",\n",
      "\t\t\"parent\": \"4ede3bbff69a9eb1e7f3108f3a46d180d783aba7\",\n",
      "\t\t\"subject\": \"Fix incorrect type conversion in DruidLogicalValueRule (#11923)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-incorrect-type-conversion-in-DruidLogicalValueRule-11923\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"DruidLogicalValuesRule while transforming to DruidRel can return incorrect values, if during the creation of the literal it was created from a float value. The BigDecimal representation stores 123.0, and it seems that using RexLiteral's method while conversion returns the inflated value (which is 1230). I am unsure if this is intentional from Calcite's perspective, and the actual change should be done somewhere else.  Extract the values of INT/LONG from the RexLiteral in the DruidLogicalValuesRule, via BigDecimal.longValue() method.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 15 Dec 2021 10:44:35 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4ede3bbff69a9eb1e7f3108f3a46d180d783aba7\",\n",
      "\t\t\"parent\": \"d917e0433ed7bf5e2068c7914f5e7d21bf58c1b6\",\n",
      "\t\t\"subject\": \"Docs updates (#12069)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-updates-12069\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* minor updates to docs  * remove en.json\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 14 Dec 2021 14:38:18 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d917e0433ed7bf5e2068c7914f5e7d21bf58c1b6\",\n",
      "\t\t\"parent\": \"e77bdfa70dff767056ee9f29e5ab285dfd9b2d62\",\n",
      "\t\t\"subject\": \"Update to log4j 2.16.0. (#12061)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-to-log4j-2.16.0.-12061\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update to log4j 2.16.0.  * Update licenses.yaml\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Dec 2021 19:06:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e77bdfa70dff767056ee9f29e5ab285dfd9b2d62\",\n",
      "\t\t\"parent\": \"e53c3e80ca246c0bc9efd18d23858b791eb6e1a2\",\n",
      "\t\t\"subject\": \"Document query context parameters related to join filters (#12057)\",\n",
      "\t\t\"sanitized_subject_line\": \"Document-query-context-parameters-related-to-join-filters-12057\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs update for query context and filters  * updates from review  * Update docs/querying/filters.md \",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 13 Dec 2021 17:47:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e53c3e80ca246c0bc9efd18d23858b791eb6e1a2\",\n",
      "\t\t\"parent\": \"761fe9f144d56e8c7c2f0a8e4838dc3f2c2d5d31\",\n",
      "\t\t\"subject\": \"set log4j2.is.webapp to false if not set so that shutdown hooks are run (#12056)\",\n",
      "\t\t\"sanitized_subject_line\": \"set-log4j2.is.webapp-to-false-if-not-set-so-that-shutdown-hooks-are-run-12056\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* set log4j2.is.webapp to false if not set so that shutdown hooks are run \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Dec 2021 21:55:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"761fe9f144d56e8c7c2f0a8e4838dc3f2c2d5d31\",\n",
      "\t\t\"parent\": \"ffa4783ce8924ac02441817793e88c2acc790f04\",\n",
      "\t\t\"subject\": \"Add new metric that quantifies how long batch ingest jobs waited for segment availability and whether or not that wait was successful (#12002)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-new-metric-that-quantifies-how-long-batch-ingest-jobs-waited-for-segment-availability-and-whether-or-not-that-wait-was-successful-12002\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add a unit test that tests that new metric is emitted  * remove unused import  * clarify in doc that this is for batch tasks  * fix IndexTaskTest\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Dec 2021 11:40:52 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffa4783ce8924ac02441817793e88c2acc790f04\",\n",
      "\t\t\"parent\": \"19316018b842126514cf3479cd14223422492d0e\",\n",
      "\t\t\"subject\": \"Adjust log4j version in licenses.yaml. (#12053)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adjust-log4j-version-in-licenses.yaml.-12053\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Gian Merlino <gian@imply.io>\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Dec 2021 08:12:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"19316018b842126514cf3479cd14223422492d0e\",\n",
      "\t\t\"parent\": \"244c2559e991038c52401fd45d4c7606cb55bf36\",\n",
      "\t\t\"subject\": \"update log4j to 2.15.0 to address security vulnerabilities (#12051)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-log4j-to-2.15.0-to-address-security-vulnerabilities-12051\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 22:34:54 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"244c2559e991038c52401fd45d4c7606cb55bf36\",\n",
      "\t\t\"parent\": \"25ac04e067ce86fe2fb3d1d348f8f57ddd2ce239\",\n",
      "\t\t\"subject\": \"fix IncrementalIndex performance regression (#12048)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-IncrementalIndex-performance-regression-12048\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * IncrementalIndex is now a ColumnInspector * fixes performance regression from using map of ColumnCapabilities from IncrementalIndex as a RowSignature\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 22:04:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"25ac04e067ce86fe2fb3d1d348f8f57ddd2ce239\",\n",
      "\t\t\"parent\": \"58245b46173959bde30376ead92a3765614f5309\",\n",
      "\t\t\"subject\": \"MySqlFirehoseDatabaseConnector uses configured driver class name (#12049)\",\n",
      "\t\t\"sanitized_subject_line\": \"MySqlFirehoseDatabaseConnector-uses-configured-driver-class-name-12049\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Suneet Saldanha\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 20:58:55 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"58245b46173959bde30376ead92a3765614f5309\",\n",
      "\t\t\"parent\": \"a8b916576dc8be48ea49c4b7e22fd1f53140261b\",\n",
      "\t\t\"subject\": \"Support JsonPath functions in JsonPath expressions (#11722)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-JsonPath-functions-in-JsonPath-expressions-11722\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add jsonPath functions support  * Add jsonPath function test for Avro  * Add jsonPath function length() to Orc  * Add jsonPath function length() to Parquet  * Add more tests to ORC format  * update doc  * Fix exception during ingestion  * Add IT test case  * Revert \\\"Fix exception during ingestion\\\"  This reverts commit 5a5484b9ea9d984622149c8113a566269cc10842.  * update IT test case  * Add 'keys()'  * Commit IT test case  * Fix UT\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 10 Dec 2021 10:53:23 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8b916576dc8be48ea49c4b7e22fd1f53140261b\",\n",
      "\t\t\"parent\": \"229f82a6f0d339f13508985b5e3fd5da5082a6b5\",\n",
      "\t\t\"subject\": \"Allow for appending tasks to co-exist with each other. (#12041)\",\n",
      "\t\t\"sanitized_subject_line\": \"Allow-for-appending-tasks-to-co-exist-with-each-other.-12041\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Allow for appending tasks to co-exist with each other.  Add a config parameter for appending tasks to allow them to use a SHARED lock.  This will allow multiple appending tasks to add segments to the same datasource at the same time.  This config should actually be the default, but it is added as a config to enable a smooth transition/validation in production settings before forcing it as the default behavior going forward.  This change leverages the TaskLockType.SHARED that existed previously, this used to carry the semantics of a READ lock, which was \\\"escalated\\\" when the task wanted to actually persist the segment.  As of many moons before this diff, the SHARED lock had stopped being used but was still piped into the code.  It turns out that with a few tweaks, it can be adjusted to be a shared lock for append tasks to allow them all to write to the same datasource, so that is what this does.  * Can only reuse the shared lock if using the same groupId  * Need to serialize out the task lock type  * Adjust Unit tests to expect new field in JSON\",\n",
      "\t\t\"author_name\": \"imply-cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 16:46:40 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"229f82a6f0d339f13508985b5e3fd5da5082a6b5\",\n",
      "\t\t\"parent\": \"ffc5ade5066f6f145846f7b42ab8491da81c69aa\",\n",
      "\t\t\"subject\": \"Add parse error list API for stream supervisors, use structured object for parse exceptions, simplify parse exception message (#11961)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-parse-error-list-API-for-stream-supervisors-use-structured-object-for-parse-exceptions-simplify-parse-exception-message-11961\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add parse error list API for stream supervisors, simplify parse exception message  * Add input string to parse exception  * Use structured ParseExceptionReport  * Fix tests  * Add test  * PR comments, add ParseExceptionReport equals verifier  * Fix test\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 15:42:55 -0600\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffc5ade5066f6f145846f7b42ab8491da81c69aa\",\n",
      "\t\t\"parent\": \"6ac4e2dbb8d2e390f0f4a9c0130ce2fb223c297b\",\n",
      "\t\t\"subject\": \"Remove use of deprecated PMD ruleset (#12044)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-use-of-deprecated-PMD-ruleset-12044\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove use of deprecated PMD ruleset  This fixes annoying warnings we were getting during build.  - Use a custom PMD ruleset, since the built-in one uses deprecated rules. - UnnecessaryImport replaces most of the deprecated rules - Update maven-pmd-plugin to 3.15 - Exclude ancient asm version from caliper, since this was causing   incompatibility warnings with PMD and could also affect our tests runs   in unexpected ways\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 9 Dec 2021 13:04:27 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6ac4e2dbb8d2e390f0f4a9c0130ce2fb223c297b\",\n",
      "\t\t\"parent\": \"25c9eba2f7fafb6db244974f4be32b3b65ecbb68\",\n",
      "\t\t\"subject\": \"Web console: use query actions in query view (#12037)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-use-query-actions-in-query-view-12037\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use query actions  * feedback fixes\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Dec 2021 13:01:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"25c9eba2f7fafb6db244974f4be32b3b65ecbb68\",\n",
      "\t\t\"parent\": \"7abf847eaefbab84500b7fa245106a30f10bf5c8\",\n",
      "\t\t\"subject\": \"clarify time format for intervals (#12035)\",\n",
      "\t\t\"sanitized_subject_line\": \"clarify-time-format-for-intervals-12035\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"shallada\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Dec 2021 08:31:21 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7abf847eaefbab84500b7fa245106a30f10bf5c8\",\n",
      "\t\t\"parent\": \"ca260dfef6161d6cfb4856e88a779b7a58b4294d\",\n",
      "\t\t\"subject\": \"Return 400 when SQL query cannot be planned (#12033)\",\n",
      "\t\t\"sanitized_subject_line\": \"Return-400-when-SQL-query-cannot-be-planned-12033\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In this PR, we will now return 400 instead of 500 when SQL query cannot be planned. I also fixed a bug where error messages were not getting sent to the users in case the rules throw UnsupportSQLQueryException.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Dec 2021 21:49:54 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ca260dfef6161d6cfb4856e88a779b7a58b4294d\",\n",
      "\t\t\"parent\": \"45be2be3681a31724bc7a8a362fcf9ddd146473c\",\n",
      "\t\t\"subject\": \"Intern RowSignature in DruidSchema to reduce its memory footprint (#12001)\",\n",
      "\t\t\"sanitized_subject_line\": \"Intern-RowSignature-in-DruidSchema-to-reduce-its-memory-footprint-12001\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"DruidSchema consists of a concurrent HashMap of DataSource -> Segement -> AvailableSegmentMetadata. AvailableSegmentMetadata contains RowSignature of the segment, and for each segment, a new object is getting created. RowSignature is an immutable class, and hence it can be interned, and this can lead to huge savings of memory being used in broker, since a lot of the segments of a table would potentially have same RowSignature.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Dec 2021 15:11:13 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45be2be3681a31724bc7a8a362fcf9ddd146473c\",\n",
      "\t\t\"parent\": \"0565f0e6a1aa809697174346662b32ac62e6d3d5\",\n",
      "\t\t\"subject\": \"fix issues with multi-value string constant expressions (#12025)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-issues-with-multi-value-string-constant-expressions-12025\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add specialized constant selector for multi-valued string constants\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 8 Dec 2021 00:10:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0565f0e6a1aa809697174346662b32ac62e6d3d5\",\n",
      "\t\t\"parent\": \"150902b95ccac2cca7f77185f7f578d0bacf3b0f\",\n",
      "\t\t\"subject\": \"fix build warnings for forbidden-apis (#12034)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-build-warnings-for-forbidden-apis-12034\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* replace deprecated forbidden-apis config failOnUnresolvableSignatures with ignoreSignaturesOfMissingClasses which avoids warnings for classes not present in a particular sub-module  * fix incorrect signature for Files.createTempDirectory\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 22:21:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"150902b95ccac2cca7f77185f7f578d0bacf3b0f\",\n",
      "\t\t\"parent\": \"a8815f671eb88d24f264d07f5d8dd7bd2277c886\",\n",
      "\t\t\"subject\": \"clean up the balancing code around the batched vs deprecated way of sampling segments to balance (#11960)\",\n",
      "\t\t\"sanitized_subject_line\": \"clean-up-the-balancing-code-around-the-batched-vs-deprecated-way-of-sampling-segments-to-balance-11960\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* clean up the balancing code around the batched vs deprecated way of sampling segments to balance  * fix docs, clarify comments, add deprecated annotations to legacy code  * remove unused variable  * update dynamic config dialog in console to state percentOfSegmentsToConsiderPerMove deprecated  * fix dynamic config text for percentOfSegmentsToConsiderPerMove  * run prettier to cleanup coordinator-dynamic-config.tsx changes  * update jest snapshot  * update documentation per review feedback\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 14:47:46 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8815f671eb88d24f264d07f5d8dd7bd2277c886\",\n",
      "\t\t\"parent\": \"1d3c8c187b9c07ee1adc6a6669f756421ec9f324\",\n",
      "\t\t\"subject\": \"Fix druid client timeout zero (#12023)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-druid-client-timeout-zero-12023\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* fix bug where queries fail immediately when timeout is 0 instead of using default timeout  * fix to use serverside max  * more better  * less flaky test  * oops\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 12:41:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d3c8c187b9c07ee1adc6a6669f756421ec9f324\",\n",
      "\t\t\"parent\": \"0b3f0bbbd81cc3ec33e1a4716ee33b149d1a2940\",\n",
      "\t\t\"subject\": \"Web console: query view improvements and other fixes (#12031)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-query-view-improvements-and-other-fixes-12031\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* don't copy commas  * use numeric type information  * add VALUES keyword  * propogate rollup config into spec  * fix  * cleanup  * understand range partitioning  * update snapshots  * better comp apis  * fix segment pages  * update snapshots\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 10:16:16 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0b3f0bbbd81cc3ec33e1a4716ee33b149d1a2940\",\n",
      "\t\t\"parent\": \"c209db3a1de153604d33c3f8afdcdf38b454573a\",\n",
      "\t\t\"subject\": \"Docs - Metrics docs layout and info about query/bytes (#11481)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Metrics-docs-layout-and-info-about-query-bytes-11481\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Metrics docs layout and info about query/bytes  Knowledge transfer from https://groups.google.com/g/druid-user/c/8fiflmSEoTQ - updated the layout of the Metrics part, adding links between docs pages.  Update index.md  Amended typo  * Update docs/configuration/index.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/metrics.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/metrics.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/operations/metrics.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Feedback applied  Http --> HTTP and moved content / removed >  * Update docs/configuration/index.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/configuration/index.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 09:45:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c209db3a1de153604d33c3f8afdcdf38b454573a\",\n",
      "\t\t\"parent\": \"d7463c99e9c743a3d3159902fb93442962829d31\",\n",
      "\t\t\"subject\": \"Docs - roll-up tip (#11677)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-roll-up-tip-11677\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update rollup.md  Added SE tip around roll-up.  * Update docs/ingestion/rollup.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 09:17:36 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d7463c99e9c743a3d3159902fb93442962829d31\",\n",
      "\t\t\"parent\": \"65cadbe42a23fc4dca0d1f703b755293f54f15c4\",\n",
      "\t\t\"subject\": \"Docs - Task ref logs correction (#11746)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Task-ref-logs-correction-11746\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update tasks.md  Removed confusing backreference  * Update tasks.md  Changed silly grammar.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 09:15:19 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"65cadbe42a23fc4dca0d1f703b755293f54f15c4\",\n",
      "\t\t\"parent\": \"834aae096a9315ea924847ffebca6ec9fb743d59\",\n",
      "\t\t\"subject\": \"Fix bad lookup config fails task (#12021)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bad-lookup-config-fails-task-12021\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR fixes an issue in which if a lookup is configured incorreclty; does not serialize properly when being pulled by peon node, it causes the task to fail. The failure occurs because the peon and other leaf nodes (broker, historical), have retry logic that continues to retry the lookup loading for 3 minutes by default. The http listener thread on the peon task is not started until lookup loading completes, by default, the overlord waits 1 minute by default, to communicate with the peon task to get the task status, after which is orders the task to shut down, causing the ingestion task to fail.  To fix the issue, we catch the exception serialization error, and do not retry. Also fixed an issue in which a bad lookup config interferes with any other good lookup configs from being loaded.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 00:55:34 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"834aae096a9315ea924847ffebca6ec9fb743d59\",\n",
      "\t\t\"parent\": \"34a3d45737c260497ca01eb6904d77bd628b9ee2\",\n",
      "\t\t\"subject\": \"Human-readable and actionable SQL error messages (#11911)\",\n",
      "\t\t\"sanitized_subject_line\": \"Human-readable-and-actionable-SQL-error-messages-11911\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR does two things  1. It adds the capability to surface missing features in SQL to users - The calcite planner will explore through multiple rules to convert a logical SQL query to a druid native query. Some rules change the shape of the query itself, optimize it and some rules are responsible for translating the query into a druid native query. These are DruidQueryRule, DruidOuterQueryRule, DruidJoinRule, DruidUnionDataSourceRule, DruidUnionRule etc. These rules will look at SQL and will do the necessary transformation. But if the rule can't transform the query, it returns back the control to the calcite planner without recording why was it not able to transform. E.g. there is a join query with a non-equal join condition. DruidJoinRule will look at the condition, see that it is not supported, and return back the control. The reason can be that a query can be planned in many different ways so if one rule can't parse it, the query may still be parseable by other rules. In this PR, we are intercepting these gaps and passing them back to the user if the query could not be planned at all.  2. The said capability has been used to generate actionable errors for some common unsupported SQL features. However, not all possible errors are covered and we can keep adding more in the future.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 09:44:08 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"34a3d45737c260497ca01eb6904d77bd628b9ee2\",\n",
      "\t\t\"parent\": \"44b2fb71abeafd874c1ba3b67fb977551f56c13d\",\n",
      "\t\t\"subject\": \"Refactor ResponseContext (#11828)\",\n",
      "\t\t\"sanitized_subject_line\": \"Refactor-ResponseContext-11828\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor ResponseContext  Fixes a number of issues in preparation for request trailers and the query profile.  * Converts keys from an enum to classes for smaller code * Wraps stored values in functions for easier capture for other uses * Reworks the \\\"header squeezer\\\" to handle types other than arrays. * Uses metadata for visibility, and ability to compress,   to replace ad-hoc code. * Cleans up JSON serialization for the response context. * Other miscellaneous cleanup.  * Handle unknown keys in deserialization  Also, make \\\"Visibility\\\" into a boolean.  * Revised comment  * Renamd variable\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Dec 2021 17:03:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44b2fb71abeafd874c1ba3b67fb977551f56c13d\",\n",
      "\t\t\"parent\": \"590cf993c0e9e9286008978e1ab282518d8dc78c\",\n",
      "\t\t\"subject\": \"Fix the error case when there are multi top level unions (#12017)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-error-case-when-there-are-multi-top-level-unions-12017\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This is a follow up to the PR #11908. This fixes the bug in top level union all queries when there are more than 2 SQL subqueries are present.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 7 Dec 2021 01:12:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"590cf993c0e9e9286008978e1ab282518d8dc78c\",\n",
      "\t\t\"parent\": \"2539b7a748a7f24b72a1e21c4ded334c3125e1f8\",\n",
      "\t\t\"subject\": \"Replace source call to make scripts more portable (#12014)\",\n",
      "\t\t\"sanitized_subject_line\": \"Replace-source-call-to-make-scripts-more-portable-12014\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Fixes #10744  Fixes: ./bin/node.sh: 44: ./bin/node.sh: source: not found Could not find java - please run /opt/druid/apache-druid-0.20.0/bin/verify-java to confirm it is installed.\",\n",
      "\t\t\"author_name\": \"Michka Popoff\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Dec 2021 13:41:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2539b7a748a7f24b72a1e21c4ded334c3125e1f8\",\n",
      "\t\t\"parent\": \"1f052b43c5d7b6e0ca578e8c2597e687a6a8ab92\",\n",
      "\t\t\"subject\": \"Adding ToString() to ExceptionEvent (#12027)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-ToString-to-ExceptionEvent-12027\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"For readable output for exception events, while generating the report in SeekableStreamSupervisor\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 6 Dec 2021 13:37:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f052b43c5d7b6e0ca578e8c2597e687a6a8ab92\",\n",
      "\t\t\"parent\": \"76d281d64fe9615f022167f9d7cafbbe83a881ea\",\n",
      "\t\t\"subject\": \"Better serverView exec name; remove SingleServerInventoryView (#11770)\",\n",
      "\t\t\"sanitized_subject_line\": \"Better-serverView-exec-name-remove-SingleServerInventoryView-11770\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Druid currently has 2 serverViews, regular serverView and filtered serverView. The regular serverView is used to monitor all segment announcements from all data nodes (historicals, tasks, indexers). The filtered serverView is used when you want to watch segment announcements from particular tiers. Since these server views keep track of different sets of druidServers and segments in memory, they should be maintained separately. However, they currently share the same name for their executorService, which can cause confusion and make debugging harder especially in the broker since it is using both serverViews, the filtered view for normal query processing and the regular view to serve the servers table (I'm unsure whether this is intended or whether this is a good behavior). This PR changes it to a more obvious name.  This PR also removes SingleServerInventoryView. This view was deprecated a long time ago and has not been documented at least since 0.13 (#6127). I also don't think this can be better in any case than BatchServerInventoryView. Finally, I merged AbstractCuratorServerInventoryView and BatchServerInventoryView as we no longer need AbstractCuratorServerInventoryView after SingleServerInventoryView is removed.\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 4 Dec 2021 18:43:05 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"76d281d64fe9615f022167f9d7cafbbe83a881ea\",\n",
      "\t\t\"parent\": \"bc2cc47db6f26313d6249594aef5a58e0b512ef8\",\n",
      "\t\t\"subject\": \"Enable allocating segments at ALL granularity. (#12003)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enable-allocating-segments-at-ALL-granularity.-12003\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Enable allocating segments at ALL granularity.  The main change is that Granularity.granularitiesFinerThan will return ALL if ALL is passed in.  Allocating segments at ALL granularity is somewhat unconventional, but there is nothing wrong with it, and it actually makes a lot of sense for tables that are meant to be used for lookups or dimensions rather than main fact tables. This change enables ALL segmentGranularity to work properly in appendToExisting mode.  Also clarifies behavior in javadocs and tests.  * Move tests to improve coverage.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 14:15:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bc2cc47db6f26313d6249594aef5a58e0b512ef8\",\n",
      "\t\t\"parent\": \"fc9513b6cd71aff57a542ad892f5ae859bfeee76\",\n",
      "\t\t\"subject\": \"SeekableStreamSupervisor: Coalesce adjacent RunNotices. (#12018)\",\n",
      "\t\t\"sanitized_subject_line\": \"SeekableStreamSupervisor-Coalesce-adjacent-RunNotices.-12018\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The idea is that if multiple notices come in around the same time due to rapid task status changes, we only need to execute one of them.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 13:42:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fc9513b6cd71aff57a542ad892f5ae859bfeee76\",\n",
      "\t\t\"parent\": \"e0e05aad995d82d40fb54b960120d6c7d1050932\",\n",
      "\t\t\"subject\": \"Make NodeRole available during binding; add support for dynamic registration of DruidService (#12012)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-NodeRole-available-during-binding-add-support-for-dynamic-registration-of-DruidService-12012\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make nodeRole available during binding; add support for dynamic registration of DruidService  * fix checkstyle and test  * fix customRole test  * address comments  * add more javadoc\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 11:59:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e0e05aad995d82d40fb54b960120d6c7d1050932\",\n",
      "\t\t\"parent\": \"f7f55056312ccb1bd3d12b7736f6f311a6adbc89\",\n",
      "\t\t\"subject\": \"Enhancements to IndexTaskClient. (#12011)\",\n",
      "\t\t\"sanitized_subject_line\": \"Enhancements-to-IndexTaskClient.-12011\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Enhancements to IndexTaskClient.  1) Ability to use handlers other than StringFullResponseHandler. This    functionality is not used in production code yet, but is useful    because it will allow tasks to communicate with each other in    non-string-based formats and in streaming fashion. In the future,    we'll be able to use this to make task-to-task communication    more efficient.  2) Truncate server errors at 1KB, so long errors do not pollute logs.  3) Change error log level for retryable errors from WARN to INFO. (The    final error is still WARN.)  4) Harmonize log and exception messages to have a more consistent format.  * Additional tests and improvements.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 09:14:32 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f7f55056312ccb1bd3d12b7736f6f311a6adbc89\",\n",
      "\t\t\"parent\": \"c2cea25a6b4f1d1a85692d83e92d277fba79f673\",\n",
      "\t\t\"subject\": \"Add avro_ocf to supported Kafka/Kinesis InputFormats (#11865)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-avro_ocf-to-supported-Kafka-Kinesis-InputFormats-11865\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update docs - Kinesis InputFormat ingestion  * Add avro_ocf to list of supported Kafka InputFormats  * Remove extra whitespace.  * Update kafka-supervisor-reference.md  * Delete extra whitespace.\",\n",
      "\t\t\"author_name\": \"jacobtolar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 07:57:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c2cea25a6b4f1d1a85692d83e92d277fba79f673\",\n",
      "\t\t\"parent\": \"4631a66723d9a4123a92c61cab5b7fbf4b81153e\",\n",
      "\t\t\"subject\": \"Improve exception message when loading data from web-console (#11723)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-exception-message-when-loading-data-from-web-console-11723\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Improve exception handling  * Revert some changes  * Resolve comments  * Update indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerExceptionMapper.java  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>  * Update indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerExceptionMapper.java  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>  * Address review comments  Co-authored-by: Karan Kumar <karankumar1100@gmail.com>\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 21:33:49 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4631a66723d9a4123a92c61cab5b7fbf4b81153e\",\n",
      "\t\t\"parent\": \"7ed46800c398cf61b38d9b2acb80117fc3c09c58\",\n",
      "\t\t\"subject\": \"Support rolling log files (#10147)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-rolling-log-files-10147\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* apply log file rolling strategy  * fix doc  Signed-off-by: frank chen <frank.chen021@outlook.com>  * Use absolute log path and allow spaces in log path  * Update log4j2 configuration  * apply FileAppender to ZooKeeper  * DO NOT redirect application's console log to file in supervisor\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 21:32:01 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7ed46800c398cf61b38d9b2acb80117fc3c09c58\",\n",
      "\t\t\"parent\": \"503384569aea81bc20b786e050bb47de37c898f2\",\n",
      "\t\t\"subject\": \"Docs: Add multi-dimension partitioning doc; refactor native batch and separate into smaller topics. (#11983)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Add-multi-dimension-partitioning-doc-refactor-native-batch-and-separate-into-smaller-topics.-11983\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Adds documentation for multi-dimension partitioning. cc: @kfaraz Refactors the native batch partitioning topic as follows:  Native batch ingestion covers parallel-index Native batch simple task indexing covers index Native batch input sources covers ioSource Native batch ingestion with firehose covers deprecated firehose\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 16:37:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"503384569aea81bc20b786e050bb47de37c898f2\",\n",
      "\t\t\"parent\": \"af6541a2368a3730483b76ad750b7f4b9f6e97a4\",\n",
      "\t\t\"subject\": \"Fix classNotFoundException when connecting to secure LDAP (#11978)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-classNotFoundException-when-connecting-to-secure-LDAP-11978\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR fixes a problem where the com.sun.jndi.ldap.Connection tries to build BasicSecuritySSLSocketFactory when calling LDAPCredentialsValidator.validateCredentials since BasicSecuritySSLSocketFactory is in extension class loader and not visible to system classloader.\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 3 Dec 2021 12:08:19 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"af6541a2368a3730483b76ad750b7f4b9f6e97a4\",\n",
      "\t\t\"parent\": \"84b4bf56d8be710cf793d26106b2c475fa901469\",\n",
      "\t\t\"subject\": \"allow `DruidSchema` to fallback to segment metadata 'type' if 'typeSignature' is null (#12016)\",\n",
      "\t\t\"sanitized_subject_line\": \"allow-DruidSchema-to-fallback-to-segment-metadata-type-if-typeSignature-is-null-12016\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* allow `DruidSchema` to fallback to segment metadata type if typeSignature is null, to avoid producing incorrect SQL schema if broker is upgraded to 0.23 before historicals  * mmm, forbidden tests\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Dec 2021 17:42:01 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"84b4bf56d8be710cf793d26106b2c475fa901469\",\n",
      "\t\t\"parent\": \"f47afd7b98221e08acd41787402d403ad0ee5556\",\n",
      "\t\t\"subject\": \"vectorize logical operators and boolean functions (#11184)\",\n",
      "\t\t\"sanitized_subject_line\": \"vectorize-logical-operators-and-boolean-functions-11184\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"changes: * adds new config, druid.expressions.useStrictBooleans which make longs the official boolean type of all expressions * vectorize logical operators and boolean functions, some only if useStrictBooleans is true \",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Dec 2021 16:40:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f47afd7b98221e08acd41787402d403ad0ee5556\",\n",
      "\t\t\"parent\": \"1f95a42bb8b32c314934e8e2ecdeb6569c7e8db3\",\n",
      "\t\t\"subject\": \"HttpResponseHandler: Fill out truncated javadoc. (#12004)\",\n",
      "\t\t\"sanitized_subject_line\": \"HttpResponseHandler-Fill-out-truncated-javadoc.-12004\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Dec 2021 14:05:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1f95a42bb8b32c314934e8e2ecdeb6569c7e8db3\",\n",
      "\t\t\"parent\": \"ffa553593f84a65f32dd2e32d3ce7fb6f9cdf801\",\n",
      "\t\t\"subject\": \"Web console: updated the explain dialog to use new explain output (#12009)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-updated-the-explain-dialog-to-use-new-explain-output-12009\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This is the UI followup to the work done in #11908  Updated the Explain dialog to use the new output format.\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 2 Dec 2021 00:18:11 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffa553593f84a65f32dd2e32d3ce7fb6f9cdf801\",\n",
      "\t\t\"parent\": \"11746b8536b1eea36e832a2a084f46dd9223b827\",\n",
      "\t\t\"subject\": \"Use one factory in json reader (#11999)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-one-factory-in-json-reader-11999\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 1 Dec 2021 16:17:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"11746b8536b1eea36e832a2a084f46dd9223b827\",\n",
      "\t\t\"parent\": \"a66f10eea1001bc1710fb538ca63b7cba5039c4f\",\n",
      "\t\t\"subject\": \"Update datasketches-hll.md (#12010)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-datasketches-hll.md-12010\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"under \\\"Aggregators\\\", about the lgK setting, it said \\\"Must be a power of 2 from 4 to 21 inclusively.\\\"  21 is not a power of 2, nor is 12, the given default.  I think there may have been confusion because lgK represents log2 of K.  We could say \\\"K must be a power of 2...\\\", or just say lgK must be between 4 and 21.\",\n",
      "\t\t\"author_name\": \"benkrug\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Nov 2021 18:52:00 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a66f10eea1001bc1710fb538ca63b7cba5039c4f\",\n",
      "\t\t\"parent\": \"f6e6ca2893f726201c55f33d2fffedddcf427c70\",\n",
      "\t\t\"subject\": \"Code cleanup from query profile project (#11822)\",\n",
      "\t\t\"sanitized_subject_line\": \"Code-cleanup-from-query-profile-project-11822\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Code cleanup from query profile project  * Fix spelling errors * Fix Javadoc formatting * Abstract out repeated test code * Reuse constants in place of some string literals * Fix up some parameterized types * Reduce warnings reported by Eclipse  * Reverted change due to lack of tests\",\n",
      "\t\t\"author_name\": \"Paul Rogers\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 30 Nov 2021 11:35:38 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f6e6ca2893f726201c55f33d2fffedddcf427c70\",\n",
      "\t\t\"parent\": \"f536f31229cc4b842762646fa9ec0ba28148b1ed\",\n",
      "\t\t\"subject\": \"Use intermediate-persist IndexSpec during multiphase merge. (#11940)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-intermediate-persist-IndexSpec-during-multiphase-merge.-11940\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use intermediate-persist IndexSpec during multiphase merge.  The main change is the addition of an intermediate-persist IndexSpec to the main \\\"merge\\\" method in IndexMerger. There are also a few minor adjustments to the IndexMerger interface to encourage more harmonious usage of its methods in the future.  * Additional changes inspired by the test coverage checker.  - Remove unused-in-production IndexMerger methods \\\"append\\\" and \\\"convert\\\". - Add additional unit tests to UnifiedIndexerAppenderatorsManager.  * Additional adjustments.  * Even more additional adjustments.  * Test fixes.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 29 Nov 2021 15:08:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f536f31229cc4b842762646fa9ec0ba28148b1ed\",\n",
      "\t\t\"parent\": \"93aeaf4801f65826f01cac0a3eedb4b4d3fdecef\",\n",
      "\t\t\"subject\": \"clarify avro support & general style improvements (#11975)\",\n",
      "\t\t\"sanitized_subject_line\": \"clarify-avro-support-general-style-improvements-11975\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* clarify avro support & general style improvements  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/avro.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update avro.md  remove redundancy  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 28 Nov 2021 16:10:18 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"93aeaf4801f65826f01cac0a3eedb4b4d3fdecef\",\n",
      "\t\t\"parent\": \"8eff6334f7750f1be00a283456d7a78c031317d4\",\n",
      "\t\t\"subject\": \"Improve on-heap aggregator footprint estimates. (#11950)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-on-heap-aggregator-footprint-estimates.-11950\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add a \\\"guessAggregatorHeapFootprint\\\" method to AggregatorFactory that mitigates #6743 by enabling heap footprint estimates based on a specific number of rows. The idea is that at ingestion time, the number of rows that go into an aggregator will be 1 (if rollup is off) or will likely be a small number (if rollup is on).  It's a heuristic, because of course nothing guarantees that the rollup ratio is a small number. But it's a common case, and I expect this logic to go wrong much less often than the current logic. Also, when it does go wrong, users can fix it by lowering maxRowsInMemory or maxBytesInMemory. The current situation is unintuitive: when the estimation goes wrong, users get an OOME, but actually they need to *raise* these limits to fix it.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 28 Nov 2021 13:21:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8eff6334f7750f1be00a283456d7a78c031317d4\",\n",
      "\t\t\"parent\": \"9bc18a93a29f1eea699894733fdd50035ce473e5\",\n",
      "\t\t\"subject\": \"AWS \\\"Data read has a different length than the expected\\\" error should reset stream and try again (#11941)\",\n",
      "\t\t\"sanitized_subject_line\": \"AWS-Data-read-has-a-different-length-than-the-expected-error-should-reset-stream-and-try-again-11941\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add support for custom reset condition & support for other args to have defaults to make the method api consistent  * Add support for custom reset condition to InputEntity  * Fix test names  * Clarifying comments to why we need to read the message's content to identify S3's resettable exception  * Add unit test to verify custom resettable condition for S3Entity  * Provide a way to customize retries since they are expensive to test\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 26 Nov 2021 12:45:34 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9bc18a93a29f1eea699894733fdd50035ce473e5\",\n",
      "\t\t\"parent\": \"b48f5a576b300149e92167e16ecf70b8c6c34b27\",\n",
      "\t\t\"subject\": \"warn when segment cannot be loaded by Historical nodes (#11849)\",\n",
      "\t\t\"sanitized_subject_line\": \"warn-when-segment-cannot-be-loaded-by-Historical-nodes-11849\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 26 Nov 2021 17:27:17 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b48f5a576b300149e92167e16ecf70b8c6c34b27\",\n",
      "\t\t\"parent\": \"c381cae51b93251e8ae6e5bd84d15a6bd30e8d28\",\n",
      "\t\t\"subject\": \"Fix: Do not require time condition on InlineDataSource (#11982)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-Do-not-require-time-condition-on-InlineDataSource-11982\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"For queries on logical values, e.g. SELECT 1337, we need not check for a filter on __time column even if requireTimeCondition is true.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Nov 2021 21:10:06 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c381cae51b93251e8ae6e5bd84d15a6bd30e8d28\",\n",
      "\t\t\"parent\": \"98957be0443b669cc7464886ef9ee21d3d21f762\",\n",
      "\t\t\"subject\": \"Improve the output of SQL explain message (#11908)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-the-output-of-SQL-explain-message-11908\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Currently, when we try to do EXPLAIN PLAN FOR, it returns the structure of the SQL parsed (via Calcite's internal planner util), which is verbose (since it tries to explain about the nodes in the SQL, instead of the Druid Query), and not representative of the native Druid query which will get executed on the broker side.  This PR aims to change the format when user tries to EXPLAIN PLAN FOR for queries which are executed by converting them into Druid's native queries (i.e. not sys schemas).\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Nov 2021 21:08:33 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"98957be0443b669cc7464886ef9ee21d3d21f762\",\n",
      "\t\t\"parent\": \"2c08055962f1c23e2749ba4e647ec85853723e5b\",\n",
      "\t\t\"subject\": \"Return HTTP 404 instead of 400 for supervisor/task endpoints (#11724)\",\n",
      "\t\t\"sanitized_subject_line\": \"Return-HTTP-404-instead-of-400-for-supervisor-task-endpoints-11724\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use 404 instead of 400  * Use 404 instead of 400  * Add UT test cases  * Add IT testcases  * add UT for task resource filter  Signed-off-by: frank chen <frank.chen021@outlook.com>  * Using org.testing.Assert instead of org.junit.Assert  * Resolve comments and fix test  * Fix test  * Fix tests  * Resolve comments\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Nov 2021 13:09:47 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2c08055962f1c23e2749ba4e647ec85853723e5b\",\n",
      "\t\t\"parent\": \"3d72e66f5677f01e835f2594ad3db9abd9f39f34\",\n",
      "\t\t\"subject\": \"Specify time column for first/last aggregators (#11949)\",\n",
      "\t\t\"sanitized_subject_line\": \"Specify-time-column-for-first-last-aggregators-11949\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add the ability to pass time column in first/last aggregator (and latest/earliest SQL functions). It is to support cases where the time to query upon is stored as a part of a column different than __time. Also, some other logical time column can be specified.\",\n",
      "\t\t\"author_name\": \"Rohan Garg\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 25 Nov 2021 09:44:14 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3d72e66f5677f01e835f2594ad3db9abd9f39f34\",\n",
      "\t\t\"parent\": \"12e2228510fa9bccb9321f7ac987b0408e0ac29c\",\n",
      "\t\t\"subject\": \"Consolidate a bunch of ad-hoc segments metadata SQL; fix some bugs. (#11582)\",\n",
      "\t\t\"sanitized_subject_line\": \"Consolidate-a-bunch-of-ad-hoc-segments-metadata-SQL-fix-some-bugs.-11582\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Consolidate a bunch of ad-hoc segments metadata SQL; fix some bugs.  This patch gathers together a variety of SQL from SqlSegmentsMetadataManager and IndexerSQLMetadataStorageCoordinator into a new class SqlSegmentsMetadataQuery. It focuses on SQL related to retrieving segment payloads and marking segments used and unused.  In addition to cleaning up the code a bit, this patch also fixes a bug with years before 0 or after 9999. The prior SQL did not work properly because dates outside this range cannot be compared as strings. The new code does work for these far-past and far-future years.  So, if you're ever interested in using Druid to analyze things from ancient Babylon, you better apply this patch first!  * Fix test compiling.  * Fixes and improvements.  * Fix forbidden API.  * Additional fixes.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 14:51:53 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"12e2228510fa9bccb9321f7ac987b0408e0ac29c\",\n",
      "\t\t\"parent\": \"5e168b861a333c68141cacceca155b280fdc427a\",\n",
      "\t\t\"subject\": \"RowBasedGrouperHelper: Set hasMultipleValues = false in capabilities. (#11954)\",\n",
      "\t\t\"sanitized_subject_line\": \"RowBasedGrouperHelper-Set-hasMultipleValues-false-in-capabilities.-11954\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Useful because it enables anything that consumes groupBy results to potentially operate more efficiently.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 13:14:58 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5e168b861a333c68141cacceca155b280fdc427a\",\n",
      "\t\t\"parent\": \"0354407655db335d6a99da3f7d81bd6aeae81fa0\",\n",
      "\t\t\"subject\": \"StorageAdapter: Add getRowSignature method. (#11953)\",\n",
      "\t\t\"sanitized_subject_line\": \"StorageAdapter-Add-getRowSignature-method.-11953\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Simplifies logic for callers that only want to get a list of all the column names, or column names and types. Updated callers SegmentAnalyzer, HashJoinSegmentStorageAdapter, and DruidSegmentReader.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 13:14:25 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0354407655db335d6a99da3f7d81bd6aeae81fa0\",\n",
      "\t\t\"parent\": \"bb3d2a433ac24aa28d84fa386523a5f98f9c923a\",\n",
      "\t\t\"subject\": \"SQL INSERT planner support. (#11959)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-INSERT-planner-support.-11959\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL INSERT planner support.  The main changes are:  1) DruidPlanner is able to validate and authorize INSERT queries. They    require WRITE permission on the target datasource.  2) QueryMaker is now an interface, and there is a QueryMakerFactory that    creates instances of it. There is only one production implementation    of each (NativeQueryMaker and NativeQueryMakerFactory), which    together behave the same way as the former QueryMaker class. But this    opens the door to executing queries in ways other than the Druid    query stack, and is used by unit tests (CalciteInsertDmlTest) to    test the INSERT planning functionality.  3) Adds an EXTERN table macro that allows references external data using    InputSource and InputFormat from Druid's batch ingestion API. This is    not exposed in production yet, but is used by unit tests.  4) Adds a QueryFeature concept that enables the planner to change its    behavior slightly depending on the capabilities of the execution    system.  5) Adds an \\\"AuthorizableOperator\\\" concept that enables SqlOperators    to require additional permissions. This is used by the EXTERN table    macro.  Related odds and ends:  - Add equals, hashCode, toString methods to InlineInputSource. Aids in   the \\\"from external\\\" tests in CalciteInsertDmlTest. - Add JSON-serializability to RowSignature. - Move the SQL string inside PlannerContext so it is \\\"baked into\\\" the   planner when the planner is created. Cleans up the code a bit, since   in practice, the same query is passed in every time to the   same planner anyway.  * Fix up calls to CalciteTests.createMockQueryLifecycleFactory.  * Fix checkstyle issues.  * Adjustments for CI.  * Adjust DruidAvaticaHandlerTest for stricter test authorizations.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 12:14:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bb3d2a433ac24aa28d84fa386523a5f98f9c923a\",\n",
      "\t\t\"parent\": \"48dbe0ea45aca63b352ce599a832ae2bec889957\",\n",
      "\t\t\"subject\": \"Support filtering data in Auto Compaction (#11922)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-filtering-data-in-Auto-Compaction-11922\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * fix checkstyle  * add test  * add test  * add unit tests  * fix unit tests  * fix unit tests  * fix unit tests  * add IT  * add IT  * add comments  * fix spelling\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 10:56:38 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"48dbe0ea45aca63b352ce599a832ae2bec889957\",\n",
      "\t\t\"parent\": \"e6570cadc4eee13b450810b26d24bb52944829d0\",\n",
      "\t\t\"subject\": \"Handle null values in Range Partition dimension distribution (#11973)\",\n",
      "\t\t\"sanitized_subject_line\": \"Handle-null-values-in-Range-Partition-dimension-distribution-11973\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR adds support for handling null dimension values while creating partition boundaries in range partitioning.  This means that we can now have partition boundaries like [null, \\\"abc\\\"] or [\\\"abc\\\", null, \\\"def\\\"].\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 14:30:02 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e6570cadc4eee13b450810b26d24bb52944829d0\",\n",
      "\t\t\"parent\": \"b6a0fbc8b6d677b391115c4ff7467774b0a5fb7c\",\n",
      "\t\t\"subject\": \"Update LifecycleModule.java (#11972)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-LifecycleModule.java-11972\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Update the javadoc on LifecycleModule to be more clear about why the register methods exist and why they should always be used instead of Guice's eager instantiation.\",\n",
      "\t\t\"author_name\": \"cheddar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Nov 2021 17:03:37 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b6a0fbc8b6d677b391115c4ff7467774b0a5fb7c\",\n",
      "\t\t\"parent\": \"311d9a2370884f97599805cfdcf87c66107d4d50\",\n",
      "\t\t\"subject\": \"Break down CalciteQueryTest  (#11979)\",\n",
      "\t\t\"sanitized_subject_line\": \"Break-down-CalciteQueryTest-11979\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Refactor calciteQueryTest  * Move more tests to CalciteJoinQueryTest\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 24 Nov 2021 00:15:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"311d9a2370884f97599805cfdcf87c66107d4d50\",\n",
      "\t\t\"parent\": \"6607e4cc7538761dd0065a68e311f03e1a1ecd94\",\n",
      "\t\t\"subject\": \"Log correct hydrant count (#11976)\",\n",
      "\t\t\"sanitized_subject_line\": \"Log-correct-hydrant-count-11976\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Nov 2021 08:22:17 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6607e4cc7538761dd0065a68e311f03e1a1ecd94\",\n",
      "\t\t\"parent\": \"e22abb68b07487c0cd736ac3c0738420bcedf924\",\n",
      "\t\t\"subject\": \"Docs: Remove reference to deprecated field `targetPartitionSize` (#11974)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Remove-reference-to-deprecated-field-targetPartitionSize-11974\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove reference to deprecated field `targetPartitionSize`  * Fix spelling of LeaderLatch\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Nov 2021 15:32:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e22abb68b07487c0cd736ac3c0738420bcedf924\",\n",
      "\t\t\"parent\": \"b5a25f24f238e409efc514dbf87fa915a49a1800\",\n",
      "\t\t\"subject\": \"Update .spelling (#11977)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-.spelling-11977\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 22:28:51 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b5a25f24f238e409efc514dbf87fa915a49a1800\",\n",
      "\t\t\"parent\": \"ed0606db6964d0a0a34b2974841b113c4a20b5fa\",\n",
      "\t\t\"subject\": \"Improve the DruidRexExecutor w.r.t handling of numeric arrays (#11968)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-the-DruidRexExecutor-w.r.t-handling-of-numeric-arrays-11968\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"DruidRexExecutor while reducing Arrays, specially numeric arrays, doesn't convert the value from ExprResult's type to BigDecimal, which causes makeLiteral to cast the values. Also, if NaN or Infinite values are present in the array, the error is a generic NumberFormatException. For example:  SELECT ARRAY[1.11, 2.22] returns [1, 2] SELECT SQRT(-1) throws a generic NumberFormatException instead of IAE  This PR introduces change to cast the numeric values to BigDecimal since Calcite's library understands that easily, and doesn't perform casts.  \",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 23 Nov 2021 11:40:59 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ed0606db6964d0a0a34b2974841b113c4a20b5fa\",\n",
      "\t\t\"parent\": \"706d057ccca2f794a3aaf22d4ccfc08e5b369255\",\n",
      "\t\t\"subject\": \"Docs - Corrected admonition issue (#11926)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Corrected-admonition-issue-11926\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Corrected admonition issue  * Update data-formats.md  Removed all admonition bits, and took out sf linebreaks.  * Update data-formats.md  Changed the shocker line into something a little more practical.\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 12:14:30 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"706d057ccca2f794a3aaf22d4ccfc08e5b369255\",\n",
      "\t\t\"parent\": \"35b610ada76fb678bd79f797f47ffdbe0b49d58e\",\n",
      "\t\t\"subject\": \"corrected leaderlatch name (#11966)\",\n",
      "\t\t\"sanitized_subject_line\": \"corrected-leaderlatch-name-11966\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 11:58:42 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"35b610ada76fb678bd79f797f47ffdbe0b49d58e\",\n",
      "\t\t\"parent\": \"d6507c9428b5db6cba929d72b40197279aa3ea65\",\n",
      "\t\t\"subject\": \"QueryableIndexColumnSelectorFactory: Double-check cached column class. (#11957)\",\n",
      "\t\t\"sanitized_subject_line\": \"QueryableIndexColumnSelectorFactory-Double-check-cached-column-class.-11957\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Important because an earlier call to getCachedColumn may have been done with a different class, leading to a ClassCastException on the second call. In the prior code, this could happen if a complex column had makeDimensionSelector called on it after makeColumnValueSelector had already been called.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 11:31:24 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d6507c9428b5db6cba929d72b40197279aa3ea65\",\n",
      "\t\t\"parent\": \"a4cb1de87a53c12d235920c35ec397331e8a36b7\",\n",
      "\t\t\"subject\": \"PrioritizedExecutorService: Properly wrap on direct calls to \\\"execute\\\". (#11956)\",\n",
      "\t\t\"sanitized_subject_line\": \"PrioritizedExecutorService-Properly-wrap-on-direct-calls-to-execute-.-11956\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Usually, \\\"execute\\\" is called by methods defined in the superclass AbstractExecutorService, and the passed-in Runnable has been wrapped by newTaskFor inside a PrioritizedListenableFutureTask. But this method can also be called directly, and if so, the same wrapping is necessary for the delegate to get a Runnable that can be entered into a priority queue with the others.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 10:30:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a4cb1de87a53c12d235920c35ec397331e8a36b7\",\n",
      "\t\t\"parent\": \"0a9a90803140f67cbf6dee02f06476d18022904f\",\n",
      "\t\t\"subject\": \"get rid of class cast exception and add a new testcase for that issue (#11951)\",\n",
      "\t\t\"sanitized_subject_line\": \"get-rid-of-class-cast-exception-and-add-a-new-testcase-for-that-issue-11951\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 08:44:20 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0a9a90803140f67cbf6dee02f06476d18022904f\",\n",
      "\t\t\"parent\": \"b1de56a3beb4ffc242784c54254811b5ba1904ce\",\n",
      "\t\t\"subject\": \"Add inline native query example to tutorial (#11642)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-inline-native-query-example-to-tutorial-11642\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add inline native query example to tutorial  Minor change to the tutorial that adds an example of a native HTTP query request body, and adds a link to the more detailed \\\"native query over HTTP\\\" documentation.  * cleanup  * Apply suggestions from code review.  Co-authored-by: sthetland <steve.hetland@imply.io>  Co-authored-by: sthetland <steve.hetland@imply.io>\",\n",
      "\t\t\"author_name\": \"jacobtolar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:35:05 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b1de56a3beb4ffc242784c54254811b5ba1904ce\",\n",
      "\t\t\"parent\": \"f1cf1c8f39c271cc0f0086cdb56dcc997b769821\",\n",
      "\t\t\"subject\": \"update Druid Chart README doc and removes unnecessary lock file (#11945)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-Druid-Chart-README-doc-and-removes-unnecessary-lock-file-11945\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update Druid Chart README doc and removes unnecessary lock file  * update Druid Chart README doc and removes unnecessary lock file\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:34:26 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f1cf1c8f39c271cc0f0086cdb56dcc997b769821\",\n",
      "\t\t\"parent\": \"0c0001579d7cd19685ff00c838887418b7085d7b\",\n",
      "\t\t\"subject\": \"update count distinct tests (#11927)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-count-distinct-tests-11927\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: wangxiao060 <wangxiao060@ke.com>\",\n",
      "\t\t\"author_name\": \"XIAO WANG\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:34:00 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"0c0001579d7cd19685ff00c838887418b7085d7b\",\n",
      "\t\t\"parent\": \"3aee5d9ec32eaa31bccb7f5174de72d76774fbd2\",\n",
      "\t\t\"subject\": \"Update compaction.md (#11937)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-compaction.md-11937\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Removed superfluous tabs that caused issues in rendering Added nav to the `inputSpec`\",\n",
      "\t\t\"author_name\": \"Peter Marshall\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:33:47 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3aee5d9ec32eaa31bccb7f5174de72d76774fbd2\",\n",
      "\t\t\"parent\": \"e77938b205559827ed67ed82d72ae010088746b1\",\n",
      "\t\t\"subject\": \"Fix: invalid JSON in ingestion spec doc example (#11880)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-invalid-JSON-in-ingestion-spec-doc-example-11880\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix: invalid JSON in ingestion spec doc example  * Update ingestion-spec.md\",\n",
      "\t\t\"author_name\": \"jacobtolar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:33:26 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"e77938b205559827ed67ed82d72ae010088746b1\",\n",
      "\t\t\"parent\": \"cfd60f1222e68181fe031d8c75ef99b0beaa4b6b\",\n",
      "\t\t\"subject\": \"Add thread count to pre-push hook to speed up checking (#11808)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-thread-count-to-pre-push-hook-to-speed-up-checking-11808\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add thread count to accelerate checking  * add comment\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:33:01 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cfd60f1222e68181fe031d8c75ef99b0beaa4b6b\",\n",
      "\t\t\"parent\": \"b13f07a05744ad1662b84bb9714b7fa51b798d53\",\n",
      "\t\t\"subject\": \"Improve README for integration test (#11860)\",\n",
      "\t\t\"sanitized_subject_line\": \"Improve-README-for-integration-test-11860\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Optimize IT readme  * Resolve comments\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 22 Nov 2021 21:32:36 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b13f07a05744ad1662b84bb9714b7fa51b798d53\",\n",
      "\t\t\"parent\": \"cb0a2af6441fbcfed46934a70f834105f01775d8\",\n",
      "\t\t\"subject\": \"Harmonize local input sources; fix batch index integration test. (#11965)\",\n",
      "\t\t\"sanitized_subject_line\": \"Harmonize-local-input-sources-fix-batch-index-integration-test.-11965\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Make LocalInputSource.files a List instead of Set and adjust wikipedia_index_task to use file list.  Rationale: the behavior of wikipedia_index_task.json is order-dependent with regard to its input files; some orders produce 4 segments and some produce 5 segments. Some integration tests, like ITSystemTableBatchIndexTaskTest and ITAutoCompactionTest, are written assuming that the 4-segment case will always happen. Providing the file list in a specific order ensures that this will happen as expected by the tests.  I didn't see a specific reason why the LocalInputSource.files parameter needed to be a Set, so changing it to a List was the simplest way to achieve the consistent ordering. I think it will also make the behavior make more sense if someone does specify the same input file multiple times in a spec: I think they'd expect it to be loaded multiple times instead of deduped. This is consistent with the behavior of other input sources like S3, GCS, HTTP.  * Sort files in LocalFirehoseFactory.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 21 Nov 2021 22:26:31 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb0a2af6441fbcfed46934a70f834105f01775d8\",\n",
      "\t\t\"parent\": \"2e3767bef07e2e7ab8f1858a55708e83a76ea7d1\",\n",
      "\t\t\"subject\": \"TestKafkaExtractionCluster: Shut down Kafka, ZK in @After. (#11963)\",\n",
      "\t\t\"sanitized_subject_line\": \"TestKafkaExtractionCluster-Shut-down-Kafka-ZK-in-After.-11963\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 20 Nov 2021 15:17:05 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2e3767bef07e2e7ab8f1858a55708e83a76ea7d1\",\n",
      "\t\t\"parent\": \"b3502c3e50d7dc5e0f685e07e2fe2eb8ad22ef1d\",\n",
      "\t\t\"subject\": \"Use the last ip as docker host ip (#11742)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-the-last-ip-as-docker-host-ip-11742\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 20 Nov 2021 13:31:39 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b3502c3e50d7dc5e0f685e07e2fe2eb8ad22ef1d\",\n",
      "\t\t\"parent\": \"f260bbed23c32edf7ae3f8caf30bbb1368053e27\",\n",
      "\t\t\"subject\": \"DruidViewMacro: Remove unused escalator field. (#11931)\",\n",
      "\t\t\"sanitized_subject_line\": \"DruidViewMacro-Remove-unused-escalator-field.-11931\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* DruidViewMacro: Remove unused escalator field.  * Remove additional unused fields.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 Nov 2021 16:06:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f260bbed23c32edf7ae3f8caf30bbb1368053e27\",\n",
      "\t\t\"parent\": \"36ee0367ffa567c3af5d01fb33dbdf9870a39f8f\",\n",
      "\t\t\"subject\": \"restore and deprecate AggregatorFactory methods (#11917)\",\n",
      "\t\t\"sanitized_subject_line\": \"restore-and-deprecate-AggregatorFactory-methods-11917\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add back and deprecate aggregator factory methods so i can say i told you so when i delete these later  * rename to make less ambiguous, fix fill method  * adjust\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 Nov 2021 15:59:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"36ee0367ffa567c3af5d01fb33dbdf9870a39f8f\",\n",
      "\t\t\"parent\": \"3c511360989a5710e47f7d40cdaa5873f60652d5\",\n",
      "\t\t\"subject\": \"Scan: Add \\\"orderBy\\\" parameter. (#11930)\",\n",
      "\t\t\"sanitized_subject_line\": \"Scan-Add-orderBy-parameter.-11930\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Scan: Add \\\"orderBy\\\" parameter.  This patch adds an API for requesting non-time orderings, although it does not actually add the ability to execute such queries.  The changes are done in such a way that no matter how Scan query objects are constructed, they will have a correct \\\"getOrderBy\\\". This will enable us to switch the execution to exclusively use \\\"getOrderBy\\\" later on when it's implemented.  Scan queries are serialized such that they only include \\\"order\\\" (time order) if the ordering is time-based, and they only include \\\"orderBy\\\" if the ordering is non-time-based. This maximizes compatibility with the existing API while also providing a clean look for formatted queries.  Because this patch does not include execution logic, if someone actually tries to run a query with non-time ordering, then they will get an error like \\\"Cannot execute query with orderBy [quality ASC]\\\".  * SQL module fixes.  * Add spotbugs-exclude.  * Remove unused method.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 19 Nov 2021 08:19:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c511360989a5710e47f7d40cdaa5873f60652d5\",\n",
      "\t\t\"parent\": \"a4353aa1f42a51a1d218547b3a033550e49e5025\",\n",
      "\t\t\"subject\": \"Add worker category dimension (#11554)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-worker-category-dimension-11554\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add worker category as dimension in TaskSlotCountStatsMonitor  * Change description  * Add workerConfig as field  * Modify HttpRemoteTaskRunnerTest to test worker category in taskslot metrics  * Fixing tests  * Fixing alerts  * Adding unit test in SingleTaskBackgroundRunnerTest for task slot metrics APIs  * Resolving false positive spell check  * addressing comments  * throw UnsupportedOperationException for tasklotmetrics APIs in SingleTaskBackgroundRunner  Co-authored-by: Nikhil Navadiya <nnavadiya@twitter.com>\",\n",
      "\t\t\"author_name\": \"Nikhil Navadiya\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Nov 2021 22:59:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a4353aa1f42a51a1d218547b3a033550e49e5025\",\n",
      "\t\t\"parent\": \"a04f99a95047fa417b9effeca109ed334cbbfa74\",\n",
      "\t\t\"subject\": \"Fix bug Unrecognized token 'No': was expecting (JSON String,...) when\\u2026 (#11934)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-bug-Unrecognized-token-No-was-expecting-JSON-String-.-when-11934\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix bug Unrecognized token 'No': was expecting (JSON String,...) when calling the API /druid/indexer/v1/task/taskId/reports and the report is not found  * Also log other non-OK statuses\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Nov 2021 10:29:28 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a04f99a95047fa417b9effeca109ed334cbbfa74\",\n",
      "\t\t\"parent\": \"29710789a438bd2c16bf2d1e556b96f8ccb57611\",\n",
      "\t\t\"subject\": \"Indexer: Demote WARN to DEBUG for tasks that don't register Appenderators. (#11939)\",\n",
      "\t\t\"sanitized_subject_line\": \"Indexer-Demote-WARN-to-DEBUG-for-tasks-that-don-t-register-Appenderators.-11939\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 18 Nov 2021 07:54:43 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"29710789a438bd2c16bf2d1e556b96f8ccb57611\",\n",
      "\t\t\"parent\": \"d76e6467004094aef7279903e64532515fde1e95\",\n",
      "\t\t\"subject\": \"Adding safe divide function (#11904)\",\n",
      "\t\t\"sanitized_subject_line\": \"Adding-safe-divide-function-11904\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* IMPLY-4344: Adding safe divide function along with testcases and documentation updates  * Changing based on review comments  * Addressing review comments, fixing coding style, docs and spelling  * Checkstyle passes for all code  * Fixing expected results for infinity  * Revert \\\"Fixing expected results for infinity\\\"  This reverts commit 5fd5cd480dd29706dd6e4b3c736611fe8dc74c85.  * Updating test result and a space in docs\",\n",
      "\t\t\"author_name\": \"somu-imply\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 17 Nov 2021 08:22:41 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d76e6467004094aef7279903e64532515fde1e95\",\n",
      "\t\t\"parent\": \"7f0bede878fbc0365c487235d60837566135333d\",\n",
      "\t\t\"subject\": \"Fix TestServerInventoryView behavioral discrepancy. (#11932)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-TestServerInventoryView-behavioral-discrepancy.-11932\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Unlike a real one, TestServerInventoryView would call segmentRemoved any time _any_ segment was removed. It should only be called when _all_ segments have been removed.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 18:08:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7f0bede878fbc0365c487235d60837566135333d\",\n",
      "\t\t\"parent\": \"00c976a3fe675f56ac6146066892f8a6147ebc5a\",\n",
      "\t\t\"subject\": \"autocompaction support for complex dimensions (#11924)\",\n",
      "\t\t\"sanitized_subject_line\": \"autocompaction-support-for-complex-dimensions-11924\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* autocompaction support for complex dimensions  * more test\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 15:57:44 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"00c976a3fe675f56ac6146066892f8a6147ebc5a\",\n",
      "\t\t\"parent\": \"54fead354612c6bd013a90665c8417426d401a74\",\n",
      "\t\t\"subject\": \"only get bitmap index for string dictionary encoded columns (#11925)\",\n",
      "\t\t\"sanitized_subject_line\": \"only-get-bitmap-index-for-string-dictionary-encoded-columns-11925\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 15:50:02 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"54fead354612c6bd013a90665c8417426d401a74\",\n",
      "\t\t\"parent\": \"1487f558b1261a751c0bbcd3f551278498913c44\",\n",
      "\t\t\"subject\": \"sql skip reduce of complex literal expressions (#11928)\",\n",
      "\t\t\"sanitized_subject_line\": \"sql-skip-reduce-of-complex-literal-expressions-11928\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 15:40:42 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1487f558b1261a751c0bbcd3f551278498913c44\",\n",
      "\t\t\"parent\": \"02b578a3dd0161366788ce5738fdadcdc528d89a\",\n",
      "\t\t\"subject\": \"Use a simple class to sanitize JDBC exceptions and also log them (#11843)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-a-simple-class-to-sanitize-JDBC-exceptions-and-also-log-them-11843\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Use a simple class to sanitize sanitizable errors and log them  The purpose of this is to sanitize JDBC errors, but can sanitize other errors if they implement SanitizableError Interface  add a class to log errors and sanitize them added a simple test that tests out that the error gets sanitized add @NonNull annotation to serverconfig's ErrorResponseTransfromStrategy  * return less information as part of too many connections, and instead only log specific details  This is so an end user gets relevant information but not too much info since they might now how many brokers they have  * return only runtime exceptions  added new error types that need to be sanitized also sanitize deprecated and unsupported exceptions.  * dont reqrewite exceptions unless necessary for checked exceptions  add docs avoid blanket turning all exceptions into runtime exceptions  * address comments, to fix up docs.  add more javadocs add support UOE sanitization  * use try catch instead and sanitize at public methods  * checkstyle fixes  * throw noSuchStatement and NoSuchConnection as Avatica is affected by those  * address comments. move log error back to druid meta  clean up bad formatting and commented code. add missed catch for NoSuchStatementException clean up comments for error handler and add comment explainging not wanting to santize avatica exceptions  * alter test to reflect new error message\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 13:13:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"02b578a3dd0161366788ce5738fdadcdc528d89a\",\n",
      "\t\t\"parent\": \"3abca73ee8d12b3b2777dbcbcaa0a8da897c6fa6\",\n",
      "\t\t\"subject\": \"Fixing a few typos and style issues (#11883)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-a-few-typos-and-style-issues-11883\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* grammar and format work  * light writing touchup  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"sthetland\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 16 Nov 2021 10:13:35 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3abca73ee8d12b3b2777dbcbcaa0a8da897c6fa6\",\n",
      "\t\t\"parent\": \"3042c1776ccb5d54a0fc913cfcef8f60afb252f5\",\n",
      "\t\t\"subject\": \"Upgrade ORC to 1.7.1 (#11919)\",\n",
      "\t\t\"sanitized_subject_line\": \"Upgrade-ORC-to-1.7.1-11919\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"William Hyun\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 15 Nov 2021 09:13:03 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3042c1776ccb5d54a0fc913cfcef8f60afb252f5\",\n",
      "\t\t\"parent\": \"400e90dc93ba2ec3b3286c928afc9721588203b0\",\n",
      "\t\t\"subject\": \"upgrade app version to 0.22.0 (#11872)\",\n",
      "\t\t\"sanitized_subject_line\": \"upgrade-app-version-to-0.22.0-11872\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Benedict Jin <asdf2014@apache.org>\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Nov 2021 22:44:00 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"400e90dc93ba2ec3b3286c928afc9721588203b0\",\n",
      "\t\t\"parent\": \"6f6e88e02ed0a767ed3d08bfeecca9ad16ce1cda\",\n",
      "\t\t\"subject\": \"Remove Druid chart deprecation message and flag (#11897)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-Druid-chart-deprecation-message-and-flag-11897\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Nov 2021 22:38:13 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6f6e88e02ed0a767ed3d08bfeecca9ad16ce1cda\",\n",
      "\t\t\"parent\": \"f91868602d1bf848a6d71b7882c7ae3a79dcf24f\",\n",
      "\t\t\"subject\": \"SQL: Add type headers to response formats. (#11914)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Add-type-headers-to-response-formats.-11914\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This allows clients to interpret the results of SQL queries without having to guess types.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Nov 2021 11:30:57 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f91868602d1bf848a6d71b7882c7ae3a79dcf24f\",\n",
      "\t\t\"parent\": \"33a5cda061234028241f2eb341524eca3646881e\",\n",
      "\t\t\"subject\": \"Remove stale warning for HTTP inputSource (#11907)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-stale-warning-for-HTTP-inputSource-11907\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 13 Nov 2021 10:27:14 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"33a5cda061234028241f2eb341524eca3646881e\",\n",
      "\t\t\"parent\": \"a13a96d5e090e3fc73df3419a19907112efa4fda\",\n",
      "\t\t\"subject\": \"Docs: Splits Kafka topic. Adds detailed example for kafka inputFormat (#11912)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-Splits-Kafka-topic.-Adds-detailed-example-for-kafka-inputFormat-11912\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Splits Kafka topic according to function. Adds detailed example for kafka inputFormat  * Apply suggestions from code review  accept suggestions from review  Co-authored-by: sthetland <steve.hetland@imply.io> Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Apply suggestions from code review  accept suggestions  Co-authored-by: sthetland <steve.hetland@imply.io> Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * accept suggestions  * accept suggestions  * final typos and clarifications  * bringing forward some syntax fixes  Co-authored-by: sthetland <steve.hetland@imply.io> Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 12 Nov 2021 13:02:23 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a13a96d5e090e3fc73df3419a19907112efa4fda\",\n",
      "\t\t\"parent\": \"223c5692a8292a210a770dc0702f75b4484ae347\",\n",
      "\t\t\"subject\": \"Avoid materializing list of segment files when finding a partition file during shuffle (#11903)\",\n",
      "\t\t\"sanitized_subject_line\": \"Avoid-materializing-list-of-segment-files-when-finding-a-partition-file-during-shuffle-11903\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Avoid materializing list of segment files (it can cause OOM/memory pressure) as well as looping over the files.  * Validate subTaskId\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 Nov 2021 10:51:52 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"223c5692a8292a210a770dc0702f75b4484ae347\",\n",
      "\t\t\"parent\": \"fe2f7742f7828b986d63098b9da2aaabdbb5113b\",\n",
      "\t\t\"subject\": \"Add dimension partitioningType to metrics to track usage of different partitioning schemes (#11902)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-dimension-partitioningType-to-metrics-to-track-usage-of-different-partitioning-schemes-11902\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add method ShardSpec.getType() to get name of shard spec type List all names of shard spec types in the interface ShardSpec itself for easy reference and maintenance Add dimension partitioningType to metric segment/added/bytes\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 Nov 2021 18:34:27 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fe2f7742f7828b986d63098b9da2aaabdbb5113b\",\n",
      "\t\t\"parent\": \"57ed5127a783a461ae79098107fc367d3bc4a5c3\",\n",
      "\t\t\"subject\": \"Fix incorrect comparison in RowSignature. (#11905)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-incorrect-comparison-in-RowSignature.-11905\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"PR #11882 introduced a type comparison using ==, but while it was in flight, another PR #11713 changed the type enum to a class. So the comparison should properly be done with \\\"equals\\\".\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 Nov 2021 04:30:42 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"57ed5127a783a461ae79098107fc367d3bc4a5c3\",\n",
      "\t\t\"parent\": \"f9941c12c3f995a170398c74f374f53feff62cec\",\n",
      "\t\t\"subject\": \"Make subquery IDs more comprehensive (#11809)\",\n",
      "\t\t\"sanitized_subject_line\": \"Make-subquery-IDs-more-comprehensive-11809\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"There are 3 types of query IDs - id, subQueryId, sqlQueryId. Currently, whenever a query generates subqueries, the subquery's subQueryId is populated randomly. Also, subquery's Id is not set to the parent query Id. Therefore there is no way of linking the subqueries to the parent query, and one loses the ability to look at end to end view of the query.  This PR aims to implement following couple of things:  Populate the subqueries with it's parent's id (and sqlQueryId if present) Populate the subqueryId such that it forms a hierarchical relationship amongs themselves. For example, if there is a query which launches a subquery, which in turn launches a couple of subqueries, then the ids and subQueryIds should have following structure.\",\n",
      "\t\t\"author_name\": \"Laksh Singla\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 11 Nov 2021 16:31:56 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f9941c12c3f995a170398c74f374f53feff62cec\",\n",
      "\t\t\"parent\": \"5baa22148e7d8c1ff0919e516656ec460457ab6c\",\n",
      "\t\t\"subject\": \"Reduce list operation calls when pulling segments from S3 (#11899)\",\n",
      "\t\t\"sanitized_subject_line\": \"Reduce-list-operation-calls-when-pulling-segments-from-S3-11899\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Lazy lists  * Fix objectsummary init\",\n",
      "\t\t\"author_name\": \"Atul Mohan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 19:13:46 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5baa22148e7d8c1ff0919e516656ec460457ab6c\",\n",
      "\t\t\"parent\": \"cdd1c2876c10b1cae740c6b64d82eb59347f412b\",\n",
      "\t\t\"subject\": \"revert ColumnAnalysis type, add typeSignature and use it for DruidSchema (#11895)\",\n",
      "\t\t\"sanitized_subject_line\": \"revert-ColumnAnalysis-type-add-typeSignature-and-use-it-for-DruidSchema-11895\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* revert ColumnAnalysis type, add typeSignature and use it for DruidSchema  * review stuffs  * maybe null  * better maybe null  * Update docs/querying/segmentmetadataquery.md  * Update docs/querying/segmentmetadataquery.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * fix null right  * sad  * oops  * Update batch_hadoop_queries.json  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 18:46:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cdd1c2876c10b1cae740c6b64d82eb59347f412b\",\n",
      "\t\t\"parent\": \"13bec7468a69b73bf254c0fe21407ee7296ecaf0\",\n",
      "\t\t\"subject\": \"catch throwable because calcite is throwing an error not exception (#11892)\",\n",
      "\t\t\"sanitized_subject_line\": \"catch-throwable-because-calcite-is-throwing-an-error-not-exception-11892\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* catch throwable because calcite is throwing an error not exception  * add test case\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 17:22:04 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"13bec7468a69b73bf254c0fe21407ee7296ecaf0\",\n",
      "\t\t\"parent\": \"14b0b4aee2fde0d0600247c5a2a0f161972da907\",\n",
      "\t\t\"subject\": \"Fix NPE for SQL queries when a query parameter is missing in the mid (#11900)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-NPE-for-SQL-queries-when-a-query-parameter-is-missing-in-the-mid-11900\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix NPE for SQL queries when a query parameter is missing in the mid  * checkstyle  * Throw SqlPlanningException instead of IAE\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 10:02:26 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"14b0b4aee2fde0d0600247c5a2a0f161972da907\",\n",
      "\t\t\"parent\": \"db4d157be6f2f1d3eedbd99fe86fc03a835f7c10\",\n",
      "\t\t\"subject\": \"RowBasedSegment: Use Sequence instead of Iterable. (#11886)\",\n",
      "\t\t\"sanitized_subject_line\": \"RowBasedSegment-Use-Sequence-instead-of-Iterable.-11886\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* RowBasedSegment: Use Sequence instead of Iterable.  The main reason this is good is that Sequences can include baggage that must be closed after iteration is finished. This enables creating RowBasedSegments on top of closeable sequences of rows.  To preserve the optimization that allows reversing a List without copying it, this patch also makes SimpleSequence its own class and allows extracting the Iterable that was used to create it.  * Fix tests.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 06:06:52 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"db4d157be6f2f1d3eedbd99fe86fc03a835f7c10\",\n",
      "\t\t\"parent\": \"d3914c1a78ac4460665c910056b8976a31115483\",\n",
      "\t\t\"subject\": \"Add Finalization option to RowSignature.addAggregators. (#11882)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Finalization-option-to-RowSignature.addAggregators.-11882\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add Finalization option to RowSignature.addAggregators.  This make type signatures more useful when the caller knows whether it will be reading aggregation results in their finalized or intermediate types.  * Fix call site.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 06:05:29 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d3914c1a78ac4460665c910056b8976a31115483\",\n",
      "\t\t\"parent\": \"a8805ab60d2cab7c9835c666a8dbe2f50da36f92\",\n",
      "\t\t\"subject\": \"Ensure backward compatibility of multi dimension partitioning (#11889)\",\n",
      "\t\t\"sanitized_subject_line\": \"Ensure-backward-compatibility-of-multi-dimension-partitioning-11889\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR has changes to ensure backward compatibility of multi dimension partitioning such that if some middle managers are upgraded to a newer version, the cluster still functions normally for single_dim use cases.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 10 Nov 2021 10:23:34 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a8805ab60d2cab7c9835c666a8dbe2f50da36f92\",\n",
      "\t\t\"parent\": \"a36a41da733ebb805b75797f6d2d21cd61c6be87\",\n",
      "\t\t\"subject\": \"add missing json type for ListFilteredVirtualColumn (#11887)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-missing-json-type-for-ListFilteredVirtualColumn-11887\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add missing json type for ListFilteredVirtualColumn, and tests to try to avoid this happening again  * fixes  * ugly, but maybe this  * oops  * too many mappers\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 17:25:12 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a36a41da733ebb805b75797f6d2d21cd61c6be87\",\n",
      "\t\t\"parent\": \"6c196a5ea2100b5b5c5e81fe75b30ad5d3a63f83\",\n",
      "\t\t\"subject\": \"Support routing data through an HTTP proxy (#11891)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-routing-data-through-an-HTTP-proxy-11891\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support routing data through an HTTP proxy  * Support routing data through an HTTP proxy  This adds the ability for the HttpClient to connect through an HTTP proxy.  We augment the channel factory to check if it is supposed to be proxied and, if so, we connect to the proxy host first, issue a CONNECT command through to the final recipient host and *then* give the channel to the normal http client for usage.  * add docs  * address comments  Co-authored-by: imply-cheddar <86940447+imply-cheddar@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 17:24:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6c196a5ea2100b5b5c5e81fe75b30ad5d3a63f83\",\n",
      "\t\t\"parent\": \"324d4374f6b189ff367c24121c4927bb7bd087e6\",\n",
      "\t\t\"subject\": \"Remove StorageAdapter.getColumnTypeName. (#11893)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-StorageAdapter.getColumnTypeName.-11893\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove StorageAdapter.getColumnTypeName.  It was only used by SegmentAnalyzer, and isn't necessary anymore due to the recent improvements to ColumnCapabilities.  Also: tidy ColumnDescriptor.read slightly by removing an instanceof check, and moving the relevant logic into ComplexColumnPartSerde.  * Fix spellings.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 15:18:07 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"324d4374f6b189ff367c24121c4927bb7bd087e6\",\n",
      "\t\t\"parent\": \"babf00f8e3a368e44afdd3eddf7356dad36a67b1\",\n",
      "\t\t\"subject\": \"HashJoinEngine: Fix extraneous advance of left cursor. (#11890)\",\n",
      "\t\t\"sanitized_subject_line\": \"HashJoinEngine-Fix-extraneous-advance-of-left-cursor.-11890\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This could happen for right or full outer joins in certain cases. Tests weren't catching this because existing Cursor implementations generally ignore extraneous calls to \\\"advance\\\". So, to help catch this in tests, extra state validations are also added to RowWalker, which is used by RowBasedSegment.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 11:34:11 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"babf00f8e3a368e44afdd3eddf7356dad36a67b1\",\n",
      "\t\t\"parent\": \"945a341acdf423496483ca611874e46e4f6ecbf5\",\n",
      "\t\t\"subject\": \"Migrate File.mkdirs to FileUtils.mkdirp. (#11879)\",\n",
      "\t\t\"sanitized_subject_line\": \"Migrate-File.mkdirs-to-FileUtils.mkdirp.-11879\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Migrate File.mkdirs to FileUtils.mkdirp.  * Remove unused imports.  * Fix LookupReferencesManager.  * Simplify.  * Also migrate usages of forceMkdir.  * Fix var name.  * Fix incorrect call.  * Update test.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 11:10:49 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"945a341acdf423496483ca611874e46e4f6ecbf5\",\n",
      "\t\t\"parent\": \"ddc68c6a816bb1d0a0d657c80feee5e7fbd199b7\",\n",
      "\t\t\"subject\": \"RowBasedCursor: Add column-value-reuse optimization. (#11884)\",\n",
      "\t\t\"sanitized_subject_line\": \"RowBasedCursor-Add-column-value-reuse-optimization.-11884\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* RowBasedCursor: Add column-value-reuse optimization.  Most of the logic is in RowBasedColumnSelectorFactory, although in this patch its only user is RowBasedCursor. This improves performance of features that use RowBasedSegment, like lookup and inline datasources. It's especially helpful for inline datasources that contain lengthy arrays, due to the fact that the transformed array can be reused.  * Changes from code review.  * Fixes for ColumnCapabilitiesImplTest.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 9 Nov 2021 07:18:09 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ddc68c6a816bb1d0a0d657c80feee5e7fbd199b7\",\n",
      "\t\t\"parent\": \"a5bd0b8cc023b771ef95f1e46c19961f50e05900\",\n",
      "\t\t\"subject\": \"Support changing dimension schema in Auto Compaction  (#11874)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-changing-dimension-schema-in-Auto-Compaction-11874\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add impl  * add unit tests  * fix checkstyle  * add impl  * add impl  * add impl  * add impl  * add impl  * add impl  * fix test  * add IT  * add IT  * fix docs  * add test  * address comments  * fix conflict\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Nov 2021 21:17:08 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a5bd0b8cc023b771ef95f1e46c19961f50e05900\",\n",
      "\t\t\"parent\": \"7237dc837cf335558fa7981c4297d2d3b40a730e\",\n",
      "\t\t\"subject\": \"RowAdapter: Add a default implementation for timestampFunction. (#11885)\",\n",
      "\t\t\"sanitized_subject_line\": \"RowAdapter-Add-a-default-implementation-for-timestampFunction.-11885\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Enables simpler implementations for adapters that want to treat the timestamp as \\\"just another column\\\".\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Nov 2021 10:25:13 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7237dc837cf335558fa7981c4297d2d3b40a730e\",\n",
      "\t\t\"parent\": \"8e7e679984e95465f87dd97dad9022aacd00af04\",\n",
      "\t\t\"subject\": \"complex typed expressions (#11853)\",\n",
      "\t\t\"sanitized_subject_line\": \"complex-typed-expressions-11853\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* complex typed expressions  * add built-in hll collector expressions to get coverage on druid-processing, more types, more better  * rampage!!!  * more javadoc  * adjustments  * oops  * lol  * remove unused dependency  * contradiction?  * more test\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 8 Nov 2021 00:33:06 -0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8e7e679984e95465f87dd97dad9022aacd00af04\",\n",
      "\t\t\"parent\": \"2d77e1a3c6a8b5cec32649d0bd9fc64bff820610\",\n",
      "\t\t\"subject\": \"Add more metrics for Jetty server thread pool usage (#11113)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-more-metrics-for-Jetty-server-thread-pool-usage-11113\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add more metrics for jetty server thread pool usage so we know if we have allocated enough http threads to handle requests.  \",\n",
      "\t\t\"author_name\": \"Jian Wang\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sun, 7 Nov 2021 16:51:44 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2d77e1a3c6a8b5cec32649d0bd9fc64bff820610\",\n",
      "\t\t\"parent\": \"1c12dd97dc39c447027baf578177fd5ea0a989a9\",\n",
      "\t\t\"subject\": \"Add support for multi dimension range partitioning (#11848)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-support-for-multi-dimension-range-partitioning-11848\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This PR adds support for range partitioning on multiple dimensions. It extends on the concept and implementation of single dimension range partitioning.  The new partition type added is range which corresponds to a set of Dimension Range Partition classes. single_dim is now treated as a range type partition with a single partition dimension.  The start and end values of a DimensionRangeShardSpec are represented by StringTuples, where each String in the tuple is the value of a partition dimension.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 6 Nov 2021 12:50:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1c12dd97dc39c447027baf578177fd5ea0a989a9\",\n",
      "\t\t\"parent\": \"897105676375112422bb362f4cc2163fc981a6ca\",\n",
      "\t\t\"subject\": \"Add javadocs to StringUtils.fromUtf8. (#11881)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-javadocs-to-StringUtils.fromUtf8.-11881\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"They clarify that the methods advance the position of the buffer.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 Nov 2021 15:27:24 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"897105676375112422bb362f4cc2163fc981a6ca\",\n",
      "\t\t\"parent\": \"907e4ca0c5624bc35cc81b7b465edb850b739ad5\",\n",
      "\t\t\"subject\": \"Properly count segment references in tests. (#11870)\",\n",
      "\t\t\"sanitized_subject_line\": \"Properly-count-segment-references-in-tests.-11870\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 Nov 2021 12:49:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"907e4ca0c5624bc35cc81b7b465edb850b739ad5\",\n",
      "\t\t\"parent\": \"1d6df48145ca37db9051e623761b56a5587e3081\",\n",
      "\t\t\"subject\": \"use correct DimensionSpec with for column value selectors created from dictionary encoded column indexers (#11873)\",\n",
      "\t\t\"sanitized_subject_line\": \"use-correct-DimensionSpec-with-for-column-value-selectors-created-from-dictionary-encoded-column-indexers-11873\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* use correct dimension spec for column value selectors of dictionary encoded column indexers\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 5 Nov 2021 01:51:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1d6df48145ca37db9051e623761b56a5587e3081\",\n",
      "\t\t\"parent\": \"652e1491e08705b3fb2d73c4704ccf265165d50c\",\n",
      "\t\t\"subject\": \"Warn if cache size of lookup is beyond max size (#11863)\",\n",
      "\t\t\"sanitized_subject_line\": \"Warn-if-cache-size-of-lookup-is-beyond-max-size-11863\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Enhanced the ExtractionNamespace interface in lookups-cached-global core extension with the ability to set a maxHeapPercentage for the cache of the respective namespace. The reason for adding this functionality, is make it easier to detect when a lookup table grows to a size that the underlying service cannot handle, because it does not have enough memory. The default value of maxHeap for the interface is -1, which indicates that no maxHeapPercentage has been set. For the JdbcExtractionNamespace and UriExtractionNamespace implementations, the default value is null, which will cause the respective service that the lookup is loaded in, to warn when its cache is beyond mxHeapPercentage of the service's configured max heap size. If a positive non-null value is set for the namespace's maxHeapPercentage config, this value will be honored for all services that the respective lookup is loaded onto, and consequently log warning messages when the cache of the respective lookup grows beyond this respective percentage of the services configured max heap size. Warnings are logged every time that either Uri based or Jdbc based lookups are regenerated, if the maxHeapPercentage constraint is violated. No other implementations will log warnings at this time. No error is thrown when the size exceeds the maxHeapPercentage at this time, as doing so could break functionality for existing users. Previously the JdbcCacheGenerator generated its cache by materializing all rows of the underling table in memory at once; this made it difficult to log warning messages in the case that the results from the jdbc query were very large and caused the service to run out of memory. To help with this, this pr makes it so that the jdbc query results are instead streamed through an iterator.\",\n",
      "\t\t\"author_name\": \"zachjsh\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 3 Nov 2021 21:32:22 -0400\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"652e1491e08705b3fb2d73c4704ccf265165d50c\",\n",
      "\t\t\"parent\": \"cf27366b35a48d33147536af79decae8260f9fd7\",\n",
      "\t\t\"subject\": \"Update default values for tuning parameters in kinesis data loader (#11867)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-default-values-for-tuning-parameters-in-kinesis-data-loader-11867\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 23:51:28 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cf27366b35a48d33147536af79decae8260f9fd7\",\n",
      "\t\t\"parent\": \"88bbc8e9e1124d8fb31b9db8b38077387951ebfd\",\n",
      "\t\t\"subject\": \"Fixing typos in docker build scripts (#11866)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fixing-typos-in-docker-build-scripts-11866\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 23:50:52 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"88bbc8e9e1124d8fb31b9db8b38077387951ebfd\",\n",
      "\t\t\"parent\": \"a22687ecbebe79196f6a246cb62d2ddb19bbb7a3\",\n",
      "\t\t\"subject\": \"Add info for compation config dialog (#11847)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-info-for-compation-config-dialog-11847\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add-info-for-compation-config-dialog  * correct the info  * remove space typo  * Revert \\\"remove space typo\\\"  This reverts commit 28b28733ae21dda809b03995e804a65555ff9092.  * remove typo space  * update snapshots for jest-test\",\n",
      "\t\t\"author_name\": \"andreacyc\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 10:03:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a22687ecbebe79196f6a246cb62d2ddb19bbb7a3\",\n",
      "\t\t\"parent\": \"5e1dc843d1b6dab41ec814e3acf44a23d3d97260\",\n",
      "\t\t\"subject\": \"Add Broker config `druid.broker.segment.watchRealtimeNodes` (#11732)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Broker-config-druid.broker.segment.watchRealtimeNodes-11732\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The new config is an extension of the concept of \\\"watchedTiers\\\" where the Broker can choose to add the info of only the specified tiers to its timeline. Similarly, with this config, Broker can choose to skip the realtime nodes and thus it would query only Historical processes for any given segment.\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 12:38:42 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"5e1dc843d1b6dab41ec814e3acf44a23d3d97260\",\n",
      "\t\t\"parent\": \"cd6867844f29b50d3931ce90396c2789e374058f\",\n",
      "\t\t\"subject\": \"Fix quickstart link (#11864)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-quickstart-link-11864\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 13:27:53 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cd6867844f29b50d3931ce90396c2789e374058f\",\n",
      "\t\t\"parent\": \"52539de521c891fdc36f5001d4a21670c9fbf535\",\n",
      "\t\t\"subject\": \"docs: update helm flag (#11721)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-update-helm-flag-11721\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"In helm v3 the --name doesn't exist\",\n",
      "\t\t\"author_name\": \"Nolan Emirot\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 13:25:49 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"52539de521c891fdc36f5001d4a21670c9fbf535\",\n",
      "\t\t\"parent\": \"ba2874ee1f022d483961fe77a44b052b801f8902\",\n",
      "\t\t\"subject\": \"fixes data validation error using correct way to comment the license under templates (#11839)\",\n",
      "\t\t\"sanitized_subject_line\": \"fixes-data-validation-error-using-correct-way-to-comment-the-license-under-templates-11839\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 2 Nov 2021 09:32:47 +0800\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ba2874ee1f022d483961fe77a44b052b801f8902\",\n",
      "\t\t\"parent\": \"9bd2ccbb9be47a76f8dc59df8b12af165e01d742\",\n",
      "\t\t\"subject\": \"Support changing query granularity in Auto Compaction (#11856)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-changing-query-granularity-in-Auto-Compaction-11856\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add queryGranularity  * fix checkstyle  * fix test\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 Nov 2021 15:18:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9bd2ccbb9be47a76f8dc59df8b12af165e01d742\",\n",
      "\t\t\"parent\": \"7af36fecff5e4709c0a22d4f7cf06a12ac20ad62\",\n",
      "\t\t\"subject\": \"SqlAggregationModuleTest now extends CalciteTestBase to ensure consistent string encoding (#11861)\",\n",
      "\t\t\"sanitized_subject_line\": \"SqlAggregationModuleTest-now-extends-CalciteTestBase-to-ensure-consistent-string-encoding-11861\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 Nov 2021 15:11:40 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7af36fecff5e4709c0a22d4f7cf06a12ac20ad62\",\n",
      "\t\t\"parent\": \"90640bb316283d7377cb0f1fee3c45dd4b87e68a\",\n",
      "\t\t\"subject\": \"Fix travis' link behind build badge (#11858)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-travis-link-behind-build-badge-11858\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Will Xu\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 1 Nov 2021 07:26:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"90640bb316283d7377cb0f1fee3c45dd4b87e68a\",\n",
      "\t\t\"parent\": \"33d9d9bd74ade384ef5feb31748b989122deb160\",\n",
      "\t\t\"subject\": \"Support for hadoop 3  via maven profiles (#11794)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-for-hadoop-3-via-maven-profiles-11794\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Add support for hadoop 3 profiles . Most of the details are captured in #11791 . We use a combination of maven profiles and resource filtering to achieve this. Hadoop2 is supported by default and a new maven profile with the name hadoop3 is created. This will allow the user to choose the profile which is best suited for the use case.\",\n",
      "\t\t\"author_name\": \"Karan Kumar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 30 Oct 2021 22:46:24 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"33d9d9bd74ade384ef5feb31748b989122deb160\",\n",
      "\t\t\"parent\": \"a96aed021ea544498114359fcddf918a7ea79c21\",\n",
      "\t\t\"subject\": \"Add rollup config to auto and manual compaction (#11850)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-rollup-config-to-auto-and-manual-compaction-11850\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add rollup to auto and manual compaction  * add unit tests  * add unit tests  * add IT  * fix checkstyle\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 29 Oct 2021 10:22:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a96aed021ea544498114359fcddf918a7ea79c21\",\n",
      "\t\t\"parent\": \"9ca8f1ec9768233e9f1bb6716b22db3f0592420b\",\n",
      "\t\t\"subject\": \"Fix indefinite WAITING batch task when lock is revoked (#11788)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-indefinite-WAITING-batch-task-when-lock-is-revoked-11788\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix indefinite WAITING batch task when lock is revoked  * Use revoked property on TaskLock  * Update TimeChunkLockAcquireAction to return TaskLock for revoked locks\",\n",
      "\t\t\"author_name\": \"Jonathan Wei\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Oct 2021 17:49:15 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9ca8f1ec9768233e9f1bb6716b22db3f0592420b\",\n",
      "\t\t\"parent\": \"fc95c928069537b3f3a6baf86f220b893d42fdc5\",\n",
      "\t\t\"subject\": \"Remove IncrementalIndex template modifier (#11160)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-IncrementalIndex-template-modifier-11160\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Liran Funaro <liran.funaro@verizonmedia.com>\",\n",
      "\t\t\"author_name\": \"Liran Funaro\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 27 Oct 2021 13:10:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"fc95c928069537b3f3a6baf86f220b893d42fdc5\",\n",
      "\t\t\"parent\": \"8ea9309168fe0b4e182991d4c71a27467675a769\",\n",
      "\t\t\"subject\": \"Remove OffheapIncrementalIndex and clarify aggregator thread-safety needs. (#11124)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-OffheapIncrementalIndex-and-clarify-aggregator-thread-safety-needs.-11124\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove OffheapIncrementalIndex and clarify aggregator thread-safety needs.  This patch does the following:  - Removes OffheapIncrementalIndex. - Clarifies that Aggregators are required to be thread safe. - Clarifies that BufferAggregators and VectorAggregators are not   required to be thread safe. - Removes thread safety code from some DataSketches aggregators that   had it. (Not all of them did, and that's OK, because it wasn't necessary   anyway.) - Makes enabling \\\"useOffheap\\\" with groupBy v1 an error.  Rationale for removing the offheap incremental index:  - It is only used in one rare scenario: groupBy v1 (which is non-default)   in \\\"useOffheap\\\" mode (also non-default). So you have to go pretty deep   into the wilderness to get this code to activate in production. It is   never used during ingestion. - Its existence complicates developer efforts to reason about how   aggregators get used, because the way it uses buffer aggregators is so   different from how every other query engine uses them. - It doesn't have meaningful testing.  By the way, I do believe that the given way the offheap incremental index works, it actually didn't require buffer aggregators to be thread-safe. It synchronizes on \\\"aggregate\\\" and doesn't call \\\"get\\\" until it has stopped calling \\\"aggregate\\\". Nevertheless, this is a bother to think about, and for the above reasons I think it makes sense to remove the code anyway.  * Remove things that are now unused.  * Revert removal of getFloat, getLong, getDouble from BufferAggregator.  * OAK-related warnings, suppressions.  * Unused item suppressions.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 26 Oct 2021 08:05:56 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8ea9309168fe0b4e182991d4c71a27467675a769\",\n",
      "\t\t\"parent\": \"4baebb231b595ac9d3da22b4fb3647d7470a8aed\",\n",
      "\t\t\"subject\": \"Web console: update typescript 4.4 for faster build speeds (#11725)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-update-typescript-4.4-for-faster-build-speeds-11725\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update typescript  * do not show pagination when there is only one page  * update snapshots  * fix pagination\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 21:53:38 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4baebb231b595ac9d3da22b4fb3647d7470a8aed\",\n",
      "\t\t\"parent\": \"07a232d7b4cad698545bad7e23d58767a288149b\",\n",
      "\t\t\"subject\": \"add `prometheus-emitter` to distribution (#11812)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-prometheus-emitter-to-distribution-11812\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add `prometheus-emitter` to distribution  Signed-off-by: \\u0110\\u1eb7ng Minh D\\u0169ng <dungdm93@live.com>  * add `druid-momentsketch` to distribution  Signed-off-by: \\u0110\\u1eb7ng Minh D\\u0169ng <dungdm93@live.com>\",\n",
      "\t\t\"author_name\": \"\\u0110\\u1eb7ng Minh D\\u0169ng\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 21:16:17 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"07a232d7b4cad698545bad7e23d58767a288149b\",\n",
      "\t\t\"parent\": \"f2106d76219655bc7388fc3d812711adeacd1de2\",\n",
      "\t\t\"subject\": \"Bump netty4 to 4.1.68; suppress CVE-2021-37136 and CVE-2021-37137 for netty3 (#11844)\",\n",
      "\t\t\"sanitized_subject_line\": \"Bump-netty4-to-4.1.68-suppress-CVE-2021-37136-and-CVE-2021-37137-for-netty3-11844\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* bump netty4 to 4.1.68  * suppress CVE-2021-37136 and CVE-2021-37137 for netty3  * license\",\n",
      "\t\t\"author_name\": \"Jihoon Son\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 21:09:15 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f2106d76219655bc7388fc3d812711adeacd1de2\",\n",
      "\t\t\"parent\": \"000a5551fa1d8b46a825c52ad8e1bc753d5ff707\",\n",
      "\t\t\"subject\": \"Web console: Add segment size in bytes column and hide it by default (#11797)\",\n",
      "\t\t\"sanitized_subject_line\": \"Web-console-Add-segment-size-in-bytes-column-and-hide-it-by-default-11797\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add segment size column  * allow hidden default column  * fix tests  * update e2e tests\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 13:24:44 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"000a5551fa1d8b46a825c52ad8e1bc753d5ff707\",\n",
      "\t\t\"parent\": \"8276c031c52af5ab1bc8398c28f4fce2f0d72702\",\n",
      "\t\t\"subject\": \"docker mem reqs (#11827)\",\n",
      "\t\t\"sanitized_subject_line\": \"docker-mem-reqs-11827\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docker mem reqs  * Update docs/tutorials/docker.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Sergio Ferragut <sergio.ferragut@imply.io> Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Sergio Ferragut\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 12:23:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8276c031c52af5ab1bc8398c28f4fce2f0d72702\",\n",
      "\t\t\"parent\": \"43383c73a84006d54022629475053b122994d4f0\",\n",
      "\t\t\"subject\": \"Add druid.sql.approxCountDistinct.function property. (#11181)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-druid.sql.approxCountDistinct.function-property.-11181\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add druid.sql.approxCountDistinct.function property.  The new property allows admins to configure the implementation for APPROX_COUNT_DISTINCT and COUNT(DISTINCT expr) in approximate mode.  The motivation for adding this setting is to enable site admins to switch the default HLL implementation to DataSketches.  For example, an admin can set:    druid.sql.approxCountDistinct.function = APPROX_COUNT_DISTINCT_DS_HLL  * Fixes  * Fix tests.  * Remove erroneous cannotVectorize.  * Remove unused import.  * Remove unused test imports.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 12:16:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"43383c73a84006d54022629475053b122994d4f0\",\n",
      "\t\t\"parent\": \"abac9e39ed878daa06dde1483319c3b9f47ef33a\",\n",
      "\t\t\"subject\": \"refactor BalanceSegments#balanceServers to exit early if there is no work to be done  (#11768)\",\n",
      "\t\t\"sanitized_subject_line\": \"refactor-BalanceSegments-balanceServers-to-exit-early-if-there-is-no-work-to-be-done-11768\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* remove useless call to balanceServers for move from decom servers when there are no decom servers  * refactor approach to this PR but accomplish the same thing\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 10:06:35 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"abac9e39ed878daa06dde1483319c3b9f47ef33a\",\n",
      "\t\t\"parent\": \"10c5fa93f155f4ed0477f00a45c8c791f256b2b8\",\n",
      "\t\t\"subject\": \"Revert permission changes to Supervisor and Task APIs (#11819)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-permission-changes-to-Supervisor-and-Task-APIs-11819\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Revert \\\"Require Datasource WRITE authorization for Supervisor and Task access (#11718)\\\"  This reverts commit f2d6100124dbe7cbc92ad91d28bd12a1800a1f2a.  * Revert \\\"Require DATASOURCE WRITE access in SupervisorResourceFilter and TaskResourceFilter (#11680)\\\"  This reverts commit 6779c4652d531b4d2c7056a69660f4e318f4aef6.  * Fix docs for the reverted commits  * Fix and restore deleted tests  * Fix and restore SystemSchemaTest\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 14:50:38 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"10c5fa93f155f4ed0477f00a45c8c791f256b2b8\",\n",
      "\t\t\"parent\": \"4354e43983c884ff83c6646c9dedf69afc307291\",\n",
      "\t\t\"subject\": \"remove dupe sentence (#11821)\",\n",
      "\t\t\"sanitized_subject_line\": \"remove-dupe-sentence-11821\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 25 Oct 2021 14:48:20 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4354e43983c884ff83c6646c9dedf69afc307291\",\n",
      "\t\t\"parent\": \"d4cace385fa8f314a947aae4d9b55d0ef71cb111\",\n",
      "\t\t\"subject\": \"Use existing queryId if it exists (#11834)\",\n",
      "\t\t\"sanitized_subject_line\": \"Use-existing-queryId-if-it-exists-11834\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Oct 2021 19:02:39 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d4cace385fa8f314a947aae4d9b55d0ef71cb111\",\n",
      "\t\t\"parent\": \"98ecbb21cd5715139da40ede8b24759f8ea4e47a\",\n",
      "\t\t\"subject\": \"SQL: Allow Scans to be used as outer queries. (#11831)\",\n",
      "\t\t\"sanitized_subject_line\": \"SQL-Allow-Scans-to-be-used-as-outer-queries.-11831\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* SQL: Allow Scans to be used as outer queries.  This has been possible in the native query system for a while, but the capability hasn't yet propagated into the SQL layer. One example of where this is useful is a query like:    SELECT * FROM (... LIMIT X) WHERE <filter>  Because this expands the kinds of subquery structures the SQL layer will consider, it was also necessary to improve the cost calculations. These changes appear in PartialDruidQuery and DruidOuterQueryRel. The ideas are:  - Attach per-column penalties to the output signature of each query, instead of to   the initial projection that starts a query. This encourages moving projections   into subqueries instead of leaving them on outer queries. - Only attach penalties to projections if there are actually expressions happening.   So, now, projections that simply reorder or remove fields are free. - Attach a constant penalty to every outer query. This discourages creating them   when they are not needed.  The changes are generally beneficial to the test cases we have in CalciteQueryTest. Most plans are unchanged, or are changed in purely cosmetic ways. Two have changed for the better:  - testUsingSubqueryWithLimit now returns a constant from the subquery, instead of   returning every column. - testJoinOuterGroupByAndSubqueryHasLimit returns a minimal set of columns from   the innermost subquery; two unnecessary columns are no longer there.  * Fix various DS operator conversions.  These were all implemented as direct conversions, which isn't appropriate because they do not actually map onto native functions. These are only usable as post-aggregations.  * Test case adjustment.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Oct 2021 17:18:43 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"98ecbb21cd5715139da40ede8b24759f8ea4e47a\",\n",
      "\t\t\"parent\": \"44a7b091908f8602d28ce4bffe791764e0ee57ad\",\n",
      "\t\t\"subject\": \"Remove CloseQuietly and migrate its usages to other methods. (#10247)\",\n",
      "\t\t\"sanitized_subject_line\": \"Remove-CloseQuietly-and-migrate-its-usages-to-other-methods.-10247\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Remove CloseQuietly and migrate its usages to other methods.  These other methods include:  1) New method CloseableUtils.closeAndWrapExceptions, which wraps IOExceptions    in RuntimeExceptions for callers that just want to avoid dealing with    checked exceptions. Most usages were migrated to this method, because it    looks like they were mainly attempts to avoid declaring a throws clause,    and perhaps were unintentionally suppressing IOExceptions. 2) New method CloseableUtils.closeInCatch, designed to properly close something    in a catch block without losing exceptions. Some usages from catch blocks    were migrated here, when it seemed that they were intended to avoid checked    exception handling, and did not really intend to also suppress IOExceptions. 3) New method CloseableUtils.closeAndSuppressExceptions, which sends all    exceptions to a \\\"chomper\\\" that consumes them. Nothing is thrown or returned.    The behavior is slightly different: with this method, _all_ exceptions are    suppressed, not just IOExceptions. Calls that seemed like they had good    reason to suppress exceptions were migrated here. 4) Some calls were migrated to try-with-resources, in cases where it appeared    that CloseQuietly was being used to avoid throwing an exception in a finally    block.  \\ud83c\\udfb5 You don't have to go home, but you can't stay here... \\ud83c\\udfb5  * Remove unused import.  * Fix up various issues.  * Adjustments to tests.  * Fix null handling.  * Additional test.  * Adjustments from review.  * Fixup style stuff.  * Fix NPE caused by holder starting out null.  * Fix spelling.  * Chomp Throwables too.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Oct 2021 17:03:21 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"44a7b091908f8602d28ce4bffe791764e0ee57ad\",\n",
      "\t\t\"parent\": \"b7a4c79314fb52e88f53f84b56c362e5abc205c2\",\n",
      "\t\t\"subject\": \"Revert \\\"Missing Loader parameter in generate-binary-license and generate-binary-notice py scripts (#11815)\\\" (#11832)\",\n",
      "\t\t\"sanitized_subject_line\": \"Revert-Missing-Loader-parameter-in-generate-binary-license-and-generate-binary-notice-py-scripts-11815-11832\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"This reverts commit a7ee646927cfbdfc7d68f899ac0a0b90fd91812d.\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 23 Oct 2021 08:34:26 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b7a4c79314fb52e88f53f84b56c362e5abc205c2\",\n",
      "\t\t\"parent\": \"cb9bc15e95efdb61916056c0b9331facc5063275\",\n",
      "\t\t\"subject\": \"Null handling fixes for DS HLL and Theta sketches. (#11830)\",\n",
      "\t\t\"sanitized_subject_line\": \"Null-handling-fixes-for-DS-HLL-and-Theta-sketches.-11830\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Null handling fixes for DS HLL and Theta sketches.  For HLL, this fixes an NPE when processing a null in a multi-value dimension.  For both, empty strings are now properly treated as nulls (and ignored) in replace-with-default mode. Behavior in SQL-compatible mode is unchanged.  * Fix expectation.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Oct 2021 19:09:00 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"cb9bc15e95efdb61916056c0b9331facc5063275\",\n",
      "\t\t\"parent\": \"02b205737124f42f5cdebe7beec31dc66cfc9a8a\",\n",
      "\t\t\"subject\": \"Fix task report streaming in https setups. (#11739)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-task-report-streaming-in-https-setups.-11739\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix task report streaming in https setups.  * Trivial change to re-trigger ITs.\",\n",
      "\t\t\"author_name\": \"Gian Merlino\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Oct 2021 19:07:29 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"02b205737124f42f5cdebe7beec31dc66cfc9a8a\",\n",
      "\t\t\"parent\": \"43103632fbd87b672574bc76c66194cacbdf3dbe\",\n",
      "\t\t\"subject\": \"extract generic dictionary encoded column indexing and merging stuffs (#11829)\",\n",
      "\t\t\"sanitized_subject_line\": \"extract-generic-dictionary-encoded-column-indexing-and-merging-stuffs-11829\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* extract generic dictionary encoded column indexing and merging stuffs to pave the path towards supporting other types of dictionary encoded columns  * spotbugs and inspections fixes  * friendlier  * javadoc  * better name  * adjust\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Oct 2021 17:31:22 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"43103632fbd87b672574bc76c66194cacbdf3dbe\",\n",
      "\t\t\"parent\": \"741b4ed516044ef95e685419ef5cf4aa5c0d1e8e\",\n",
      "\t\t\"subject\": \"Docs - add description on time origin (#11826)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-add-description-on-time-origin-11826\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add description on time origin  * reorder parameter descriptions  * add example of origin value\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Oct 2021 14:57:13 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"741b4ed516044ef95e685419ef5cf4aa5c0d1e8e\",\n",
      "\t\t\"parent\": \"df4894afff5efb31264e98f39f4f14dd934ecc3d\",\n",
      "\t\t\"subject\": \"add output type information to ExpressionPostAggregator (#11818)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-output-type-information-to-ExpressionPostAggregator-11818\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add ColumnInspector argument to PostAggregator.getType to allow post-aggs to compute their output type based on input types  * add test for test for coverage  * simplify  * Remove unused imports.  Co-authored-by: Gian Merlino <gian@imply.io>\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 22 Oct 2021 13:52:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"df4894afff5efb31264e98f39f4f14dd934ecc3d\",\n",
      "\t\t\"parent\": \"8cf1cbc4a9e586f0576705a22f2be0570f5c6986\",\n",
      "\t\t\"subject\": \"Fallback to /sys/fs root when looking for cgroups (#11810)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fallback-to-sys-fs-root-when-looking-for-cgroups-11810\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"ProcCgroupDiscoverer builds the cgroup directory by concatenating the proc mounts and proc cgroup paths together. This doesn't seem to work in Kubernetes if the execution context is within the container. Also this isn't consistent across all Linux OSes. The fix is to fallback to / as the root and it seems to work empirically.\",\n",
      "\t\t\"author_name\": \"Arun Ramani\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 21 Oct 2021 09:51:16 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8cf1cbc4a9e586f0576705a22f2be0570f5c6986\",\n",
      "\t\t\"parent\": \"a7ee646927cfbdfc7d68f899ac0a0b90fd91812d\",\n",
      "\t\t\"subject\": \"latest datasketches-java and datasketches-memory (#11773)\",\n",
      "\t\t\"sanitized_subject_line\": \"latest-datasketches-java-and-datasketches-memory-11773\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* latest datasketches-java and datasketches-memory  * updated versions of datasketches-java and datasketches-memory  Co-authored-by: AlexanderSaydakov <AlexanderSaydakov@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Alexander Saydakov\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Oct 2021 23:42:30 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a7ee646927cfbdfc7d68f899ac0a0b90fd91812d\",\n",
      "\t\t\"parent\": \"187df58e303c9338e7c2e107d7725b4638404bb1\",\n",
      "\t\t\"subject\": \"Missing Loader parameter in generate-binary-license and generate-binary-notice py scripts (#11815)\",\n",
      "\t\t\"sanitized_subject_line\": \"Missing-Loader-parameter-in-generate-binary-license-and-generate-binary-notice-py-scripts-11815\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"David Ferlay\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 20 Oct 2021 00:25:17 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"187df58e303c9338e7c2e107d7725b4638404bb1\",\n",
      "\t\t\"parent\": \"17459a84d3bb8ccc4cbdfbb11197de5bdd0d6f32\",\n",
      "\t\t\"subject\": \"better types (#11713)\",\n",
      "\t\t\"sanitized_subject_line\": \"better-types-11713\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* better type system  * needle in a haystack  * ColumnCapabilities is a TypeSignature instead of having one, INFORMATION_SCHEMA support  * fixup merge  * more test  * fixup  * intern  * fix  * oops  * oops again  * ...  * more test coverage  * fix error message  * adjust interning, more javadocs  * oops  * more docs more better\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Oct 2021 01:47:25 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"17459a84d3bb8ccc4cbdfbb11197de5bdd0d6f32\",\n",
      "\t\t\"parent\": \"7d4841471fd271ac24edde376f234abd00010233\",\n",
      "\t\t\"subject\": \"Update link to helm chart quickstart guide (#11801)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-link-to-helm-chart-quickstart-guide-11801\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Sandeep\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Oct 2021 14:10:40 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7d4841471fd271ac24edde376f234abd00010233\",\n",
      "\t\t\"parent\": \"9c15f938fdaa1665f54629d661aaeaf88d3b8908\",\n",
      "\t\t\"subject\": \"Optimize supervisor history retrieval for specific id (#11807)\",\n",
      "\t\t\"sanitized_subject_line\": \"Optimize-supervisor-history-retrieval-for-specific-id-11807\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Optimization. Fetch from the metadata store only the relevant history items for the requested supervisor id.\",\n",
      "\t\t\"author_name\": \"David Bar\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 19 Oct 2021 14:08:25 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"9c15f938fdaa1665f54629d661aaeaf88d3b8908\",\n",
      "\t\t\"parent\": \"938c1493e53f61cb9e16f94616995dade0318b10\",\n",
      "\t\t\"subject\": \"fix test issue where JettyTest would fail if JettyWithResponseFilterEnabledTest ran before it (#11803)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-test-issue-where-JettyTest-would-fail-if-JettyWithResponseFilterEnabledTest-ran-before-it-11803\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"this change ensures that JettyTest is setting the properties it needs in case some other test overwrites them this also changes up the ordering of the call for setProperties to call super's first in case super is setting the same property\",\n",
      "\t\t\"author_name\": \"TSFenwick\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 18 Oct 2021 12:42:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"938c1493e53f61cb9e16f94616995dade0318b10\",\n",
      "\t\t\"parent\": \"6089a168ea65867a0d2f8e2a83069ee34afda9dd\",\n",
      "\t\t\"subject\": \"edits to kafka inputFormat (#11796)\",\n",
      "\t\t\"sanitized_subject_line\": \"edits-to-kafka-inputFormat-11796\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* edits to kafka inputFormat  * revise conflict resolution description  * tweak for clarity  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * style fixes  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/ingestion/data-formats.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 15 Oct 2021 14:01:10 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"6089a168ea65867a0d2f8e2a83069ee34afda9dd\",\n",
      "\t\t\"parent\": \"4f62905be08173366f19dec7d3a8d6dc13f8ab32\",\n",
      "\t\t\"subject\": \"Docs - update dynamic config provider topic (#11795)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-update-dynamic-config-provider-topic-11795\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update dynamic config provider  * update topic  * add examples for dynamic config provider:  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/development/extensions-core/kafka-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  * Update docs/operations/dynamic-config-provider.md  Co-authored-by: Clint Wylie <cjwylie@gmail.com>  * Update kafka-ingestion.md  Co-authored-by: Katya Macedo  <38017980+ektravel@users.noreply.github.com> Co-authored-by: Clint Wylie <cjwylie@gmail.com>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Oct 2021 17:51:32 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"4f62905be08173366f19dec7d3a8d6dc13f8ab32\",\n",
      "\t\t\"parent\": \"887cecf29e8b813029911fb05745764cce155c94\",\n",
      "\t\t\"subject\": \"Fix the travis build (#11799)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-the-travis-build-11799\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Abhishek Agarwal\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 14 Oct 2021 16:31:51 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"887cecf29e8b813029911fb05745764cce155c94\",\n",
      "\t\t\"parent\": \"adb223762867915b8c73a689c45ac70aae154bec\",\n",
      "\t\t\"subject\": \"Simplify ITHttpInputSourceTest to mitigate flakiness (#11751)\",\n",
      "\t\t\"sanitized_subject_line\": \"Simplify-ITHttpInputSourceTest-to-mitigate-flakiness-11751\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Increment retry count to add more time for tests to pass  * Re-enable ITHttpInputSourceTest  * Restore original count  * This test is about input source, hash partitioning takes longer and not required thus changing to dynamic  * Further simplify by removing sketches\",\n",
      "\t\t\"author_name\": \"Agustin Gonzalez\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 12 Oct 2021 11:51:27 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"adb223762867915b8c73a689c45ac70aae154bec\",\n",
      "\t\t\"parent\": \"7352c83e118cb3a0dfceda3087e9a94a5dd0c0bf\",\n",
      "\t\t\"subject\": \"Fix CVE-2021-3749 reported in security vulnerabilities job (#11786)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-CVE-2021-3749-reported-in-security-vulnerabilities-job-11786\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix CVE-2021-3749 reported in security vulnerabilities job  * test why test fail  * update axios  * remove console log for testing\",\n",
      "\t\t\"author_name\": \"andreacyc\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 23:02:58 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"7352c83e118cb3a0dfceda3087e9a94a5dd0c0bf\",\n",
      "\t\t\"parent\": \"b6b42d39367f1ff1d7a1aa7e0064ca0ed9c2e92f\",\n",
      "\t\t\"subject\": \"Do not log sensitive property value if JsonConfigurator fails to parse (#11787)\",\n",
      "\t\t\"sanitized_subject_line\": \"Do-not-log-sensitive-property-value-if-JsonConfigurator-fails-to-parse-11787\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Do not log property value if JsonConfigurator fails to parse  * Add comment to explain log change  * Fix log language\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Sat, 9 Oct 2021 09:59:03 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b6b42d39367f1ff1d7a1aa7e0064ca0ed9c2e92f\",\n",
      "\t\t\"parent\": \"42e44269bee7119af21a99ef9d94b7a5fae6d9de\",\n",
      "\t\t\"subject\": \"Minor processor quota computation fix + docs (#11783)\",\n",
      "\t\t\"sanitized_subject_line\": \"Minor-processor-quota-computation-fix-docs-11783\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* cpu/cpuset cgroup and procfs data gathering  * Renames and default values  * Formatting  * Trigger Build  * Add cgroup monitors  * Return 0 if no period  * Update  * Minor processor quota computation fix + docs  * Address comments  * Address comments  * Fix spellcheck  Co-authored-by: arunramani-imply <84351090+arunramani-imply@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Arun Ramani\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 22:52:03 -0500\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"42e44269bee7119af21a99ef9d94b7a5fae6d9de\",\n",
      "\t\t\"parent\": \"c2c724c0656360a404c8309f8022f032346414a3\",\n",
      "\t\t\"subject\": \"Docs update for druid-basic-security (#11782)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docs-update-for-druid-basic-security-11782\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update druid-basic-security  * typo  * revisions from review\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 14:45:09 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c2c724c0656360a404c8309f8022f032346414a3\",\n",
      "\t\t\"parent\": \"989297edc37e31814d817686f306b8aa2bd76861\",\n",
      "\t\t\"subject\": \"Fix docs to explain that WRITE permissions do not include READ (#11785)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-docs-to-explain-that-WRITE-permissions-do-not-include-READ-11785\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix docs to explain that WRITE and READ are exclusive  * Fix indentation  * Use suggested doc style\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 14:10:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"989297edc37e31814d817686f306b8aa2bd76861\",\n",
      "\t\t\"parent\": \"3ecbd3aec457c0b22410456c436b68345b2db5f0\",\n",
      "\t\t\"subject\": \"Docker copy before env and respect JAVA_OPTS (#11364)\",\n",
      "\t\t\"sanitized_subject_line\": \"Docker-copy-before-env-and-respect-JAVA_OPTS-11364\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Change ordering of config file vs env vars in Docker  Currently if you provide a config file it negates any settings set via environment variables. This change allows use of a config file as a base and allow environment variables to override. Additionally this allows dynamic features such as DRUID_SET_HOST to function correctly when a config file has been provided.  * Custom JAVA_OPTS should override service jvm.config\",\n",
      "\t\t\"author_name\": \"Joseph Glanville\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 14:05:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3ecbd3aec457c0b22410456c436b68345b2db5f0\",\n",
      "\t\t\"parent\": \"f2d6100124dbe7cbc92ad91d28bd12a1800a1f2a\",\n",
      "\t\t\"subject\": \"docs for changes to authorization in #11718 and #11720 (#11779)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-for-changes-to-authorization-in-11718-and-11720-11779\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* security recommendation  * Update docs/operations/security-overview.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/operations/security-user-auth.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update docs/operations/security-user-auth.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update security-user-auth.md  add newline  * Update docs/operations/security-overview.md  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com>  * Update security-overview.md  add suggestion for environment variable dynamic config provider  Co-authored-by: Victoria Lim <vtlim@users.noreply.github.com> Co-authored-by: Clint Wylie <cwylie@apache.org>\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 14:04:04 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f2d6100124dbe7cbc92ad91d28bd12a1800a1f2a\",\n",
      "\t\t\"parent\": \"45d0ecbefbaf82e74ca0c1a6766f17bdf4ca9d3f\",\n",
      "\t\t\"subject\": \"Require Datasource WRITE authorization for Supervisor and Task access (#11718)\",\n",
      "\t\t\"sanitized_subject_line\": \"Require-Datasource-WRITE-authorization-for-Supervisor-and-Task-access-11718\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Follow up PR for #11680  Description Supervisor and Task APIs are related to ingestion and must always require Datasource WRITE authorization even if they are purely informative.  Changes Check Datasource WRITE in SystemSchema for tables \\\"supervisors\\\" and \\\"tasks\\\" Check Datasource WRITE for APIs /supervisor/history and /supervisor/{id}/history Check Datasource for all Indexing Task APIs\",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 8 Oct 2021 10:39:48 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"45d0ecbefbaf82e74ca0c1a6766f17bdf4ca9d3f\",\n",
      "\t\t\"parent\": \"ad6609a606c0ca945c6aa57f1b7c40593ba29f80\",\n",
      "\t\t\"subject\": \"clarify hadoop input paths (#11781)\",\n",
      "\t\t\"sanitized_subject_line\": \"clarify-hadoop-input-paths-11781\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Co-authored-by: Katya Macedo <katya.macedo@imply.io>\",\n",
      "\t\t\"author_name\": \"Katya Macedo\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Oct 2021 20:22:51 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ad6609a606c0ca945c6aa57f1b7c40593ba29f80\",\n",
      "\t\t\"parent\": \"15789137a3f257081044d141f7e92c092d73b46a\",\n",
      "\t\t\"subject\": \"Kafka Input Format for headers, key and payload parsing (#11630)\",\n",
      "\t\t\"sanitized_subject_line\": \"Kafka-Input-Format-for-headers-key-and-payload-parsing-11630\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"### Description  Today we ingest a number of high cardinality metrics into Druid across dimensions. These metrics are rolled up on a per minute basis, and are very useful when looking at metrics on a partition or client basis. Events is another class of data that provides useful information about a particular incident/scenario inside a Kafka cluster. Events themselves are carried inside kafka payload, but nonetheless there are some very useful metadata that is carried in kafka headers that can serve as useful dimension for aggregation and in turn bringing better insights.  PR(https://github.com/apache/druid/pull/10730) introduced support of Kafka headers in InputFormats.  We still need an input format to parse out the headers and translate those into relevant columns in Druid. Until that\\u2019s implemented, none of the information available in the Kafka message headers would be exposed. So first there is a need to write an input format that can parse headers in any given format(provided we support the format) like we parse payloads today. Apart from headers there is also some useful information present in the key portion of the kafka record. We also need a way to expose the data present in the key as druid columns. We need a generic way to express at configuration time what attributes from headers, key and payload need to be ingested into druid. We need to keep the design generic enough so that users can specify different parsers for headers, key and payload.  This PR is designed to solve the above by providing wrapper around any existing input formats and merging the data into a single unified Druid row.  Lets look at a sample input format from the above discussion  \\\"inputFormat\\\": {     \\\"type\\\": \\\"kafka\\\",     // New input format type     \\\"headerLabelPrefix\\\": \\\"kafka.header.\\\",   // Label prefix for header columns, this will avoid collusions while merging columns     \\\"recordTimestampLabelPrefix\\\": \\\"kafka.\\\",  // Kafka record's timestamp is made available in case payload does not carry timestamp     \\\"headerFormat\\\":  // Header parser specifying that values are of type string     {         \\\"type\\\": \\\"string\\\"     },     \\\"valueFormat\\\": // Value parser from json parsing     {         \\\"type\\\": \\\"json\\\",         \\\"flattenSpec\\\": {           \\\"useFieldDiscovery\\\": true,           \\\"fields\\\": [...]         }     },     \\\"keyFormat\\\":  // Key parser also from json parsing     {         \\\"type\\\": \\\"json\\\"     } }  Since we have independent sections for header, key and payload, it will enable parsing each section with its own parser, eg., headers coming in as string and payload as json.   KafkaInputFormat will be the uber class extending inputFormat interface and will be responsible for creating individual parsers for header, key and payload, blend the data resolving conflicts in columns and generating a single unified InputRow for Druid ingestion.   \\\"headerFormat\\\" will allow users to plug parser type for the header values and will add default header prefix as \\\"kafka.header.\\\"(can be overridden) for attributes to avoid collision while merging attributes with payload.  Kafka payload parser will be responsible for parsing the Value portion of the Kafka record. This is where most of the data will come from and we should be able to plugin existing parser. One thing to note here is that if batching is performed, then the code is augmenting header and key values to every record in the batch.  Kafka key parser will handle parsing Key portion of the Kafka record and will ingest the Key with dimension name as \\\"kafka.key\\\".  ## KafkaInputFormat Class:  This is the class that orchestrates sending the consumerRecord to each parser, retrieve rows, merge the columns into one final row for Druid consumption. KafkaInputformat should make sure to release the resources that gets allocated as a part of reader in CloseableIterator<InputRow> during normal and exception cases.  During conflicts in dimension/metrics names, the code will prefer dimension names from payload and ignore the dimension either from headers/key. This is done so that existing input formats can be easily migrated to this new format without worrying about losing information.\",\n",
      "\t\t\"author_name\": \"lokesh-lingarajan\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Thu, 7 Oct 2021 08:56:27 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"15789137a3f257081044d141f7e92c092d73b46a\",\n",
      "\t\t\"parent\": \"8fd17fe0af7a77d4a5385c56c9c0c5b15c9d923a\",\n",
      "\t\t\"subject\": \"Add cpu/cpuset cgroup and procfs data gathering (#11763)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-cpu-cpuset-cgroup-and-procfs-data-gathering-11763\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* cpu/cpuset cgroup and procfs data gathering  * Renames and default values  * Formatting  * Trigger Build  * Add cgroup monitors  * Return 0 if no period  * Update  Co-authored-by: arunramani-imply <84351090+arunramani-imply@users.noreply.github.com>\",\n",
      "\t\t\"author_name\": \"Arun Ramani\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Oct 2021 20:27:36 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"8fd17fe0af7a77d4a5385c56c9c0c5b15c9d923a\",\n",
      "\t\t\"parent\": \"1930ad1f47126210524a1a9b0bd56627355b51e0\",\n",
      "\t\t\"subject\": \"fix a few typos in Kinesis doc (#11776)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-a-few-typos-in-Kinesis-doc-11776\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Oct 2021 19:43:20 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"1930ad1f47126210524a1a9b0bd56627355b51e0\",\n",
      "\t\t\"parent\": \"b688db790bbb8b1f9e6f08fa1ef05550a23eea61\",\n",
      "\t\t\"subject\": \"Implement configurable internally generated query context (#11429)\",\n",
      "\t\t\"sanitized_subject_line\": \"Implement-configurable-internally-generated-query-context-11429\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Add the ability to add a context to internally generated druid broker queries  * fix docs  * changes after first CI failure  * cleanup after merge with master  * change default to empty map and improve unit tests  * add doc info and fix checkstyle  * refactor DruidSchema#runSegmentMetadataQuery and add a unit test\",\n",
      "\t\t\"author_name\": \"Lucas Capistrant\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Oct 2021 09:02:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"b688db790bbb8b1f9e6f08fa1ef05550a23eea61\",\n",
      "\t\t\"parent\": \"104c9a07f0116b781ec509baab603e9023a52af1\",\n",
      "\t\t\"subject\": \"Add Broker config `druid.broker.segment.ignoredTiers` (#11766)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-Broker-config-druid.broker.segment.ignoredTiers-11766\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"The new config is an extension of the concept of \\\"watchedTiers\\\" where the Broker can choose to add the info of only the specified tiers to its timeline. Similarly, with this config, Broker can choose to ignore the segments being served by the specified historical tiers. By default, no tier is ignored.  This config is useful when you want a completely isolated tier amongst many other tiers.  Say there are several tiers of historicals Tier T1, Tier T2 ... Tier Tn and there are several brokers Broker B1, Broker B2 .... Broker Bm  If we want only Broker B1 to query Tier T1, instead of setting a long list of watchedTiers on each of the other Brokers B2 ... Bm, we could just set druid.broker.segment.ignoredTiers=[\\\"T1\\\"] for these Brokers, while Broker B1 could have druid.broker.segment.watchedTiers=[\\\"T1\\\"]  \",\n",
      "\t\t\"author_name\": \"Kashif Faraz\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Oct 2021 10:06:32 +0530\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"104c9a07f0116b781ec509baab603e9023a52af1\",\n",
      "\t\t\"parent\": \"635490d568f89c554c6a84ef5c19d8c243859bed\",\n",
      "\t\t\"subject\": \"Fix broken anchor and heading levels in Kafka/Kinesis ingestion (#11748)\",\n",
      "\t\t\"sanitized_subject_line\": \"Fix-broken-anchor-and-heading-levels-in-Kafka-Kinesis-ingestion-11748\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Fix broken anchor and heading levels  * Fix CI\",\n",
      "\t\t\"author_name\": \"Frank Chen\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 19:30:50 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"635490d568f89c554c6a84ef5c19d8c243859bed\",\n",
      "\t\t\"parent\": \"c1e0e6825f6bed825534b2cd454872c1172bcdf0\",\n",
      "\t\t\"subject\": \"don't throw local storage errors (#11752)\",\n",
      "\t\t\"sanitized_subject_line\": \"don-t-throw-local-storage-errors-11752\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 18:49:16 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"c1e0e6825f6bed825534b2cd454872c1172bcdf0\",\n",
      "\t\t\"parent\": \"2593df5e5bf99b4c3a083d18c3f39e361744bc7b\",\n",
      "\t\t\"subject\": \"auto refresh in foreground only (#11750)\",\n",
      "\t\t\"sanitized_subject_line\": \"auto-refresh-in-foreground-only-11750\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Vadim Ogievetsky\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 18:48:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"2593df5e5bf99b4c3a083d18c3f39e361744bc7b\",\n",
      "\t\t\"parent\": \"621e5ac63fec7a38748d1b2fd0258edc987258fd\",\n",
      "\t\t\"subject\": \"add utility to aid in formatting release notes to be linkable (#11728)\",\n",
      "\t\t\"sanitized_subject_line\": \"add-utility-to-aid-in-formatting-release-notes-to-be-linkable-11728\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add utility to aid in formatting release notes to be linkable  * add docs\",\n",
      "\t\t\"author_name\": \"Clint Wylie\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 18:26:41 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"621e5ac63fec7a38748d1b2fd0258edc987258fd\",\n",
      "\t\t\"parent\": \"f60b3b3babdfbc714c8213b3120ad452a2ff9090\",\n",
      "\t\t\"subject\": \"docs: clarify RealtimeMetricsMonitor, HistoricalMetricsMonitor (#11565)\",\n",
      "\t\t\"sanitized_subject_line\": \"docs-clarify-RealtimeMetricsMonitor-HistoricalMetricsMonitor-11565\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* docs: clarify RealtimeMetricsMonitor, HistoricalMetricsMonitor  * Update docs/configuration/index.md\",\n",
      "\t\t\"author_name\": \"Charles Smith\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 17:38:23 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f60b3b3babdfbc714c8213b3120ad452a2ff9090\",\n",
      "\t\t\"parent\": \"f82baf174e230c6f336096ad62fa81a2f2fa6b91\",\n",
      "\t\t\"subject\": \"fix doc (#11772)\",\n",
      "\t\t\"sanitized_subject_line\": \"fix-doc-11772\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 15:42:11 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"f82baf174e230c6f336096ad62fa81a2f2fa6b91\",\n",
      "\t\t\"parent\": \"bc3b03871276e7228f194ad6089378f635628e14\",\n",
      "\t\t\"subject\": \"Support real query cancelling for web console (#11738)\",\n",
      "\t\t\"sanitized_subject_line\": \"Support-real-query-cancelling-for-web-console-11738\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Support real query cancelling for web console  * use uuid for queryId, create isSql reuse variable, and add catch for rejectionhandled promise  * remove delete api promise.then() response  * slove conflicts  * update read me with debug  * add degub code to test why CI failed  * included a druid extension called druid-testing-tools and it is not build nor loaded by default  * remove unuse variable  * remove debug log\",\n",
      "\t\t\"author_name\": \"andreacyc\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 10:28:49 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"bc3b03871276e7228f194ad6089378f635628e14\",\n",
      "\t\t\"parent\": \"a31d99fb373cc6e7aad1abd79831b551e3fcdfde\",\n",
      "\t\t\"subject\": \"Update Apache Kafka client libraries to 3.0.0 (#11735)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-Apache-Kafka-client-libraries-to-3.0.0-11735\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"Release notes: https://downloads.apache.org/kafka/3.0.0/RELEASE_NOTES.html https://blogs.apache.org/kafka/entry/what-s-new-in-apache6\",\n",
      "\t\t\"author_name\": \"Xavier L\\u00e9aut\\u00e9\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 10:23:19 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"a31d99fb373cc6e7aad1abd79831b551e3fcdfde\",\n",
      "\t\t\"parent\": \"ffbe303828dae2ad3f7ee567a19c92354eb9171c\",\n",
      "\t\t\"subject\": \"update docs with X-Druid-SQL-Query-Id (#11761)\",\n",
      "\t\t\"sanitized_subject_line\": \"update-docs-with-X-Druid-SQL-Query-Id-11761\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* update docs with X-Druid-SQL-Query-Id  * review comments  * update header description  * Update docs/querying/sql.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  * Update docs/querying/sql.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com>  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"Victoria Lim\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Wed, 6 Oct 2021 00:15:05 +0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"ffbe303828dae2ad3f7ee567a19c92354eb9171c\",\n",
      "\t\t\"parent\": \"3c4bba1478dcd95ca087ec161da55420c309875d\",\n",
      "\t\t\"subject\": \"Update balancer strategy recommendations (#11759)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-balancer-strategy-recommendations-11759\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update balancer strategy recommendations  * Update docs/configuration/index.md  * Update docs/configuration/index.md  Co-authored-by: Suneet Saldanha <suneet@apache.org>\",\n",
      "\t\t\"author_name\": \"Caroline1000\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Tue, 5 Oct 2021 09:47:37 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"3c4bba1478dcd95ca087ec161da55420c309875d\",\n",
      "\t\t\"parent\": \"d02d2d9d56f668b9d45c51be4360ad0822fe4710\",\n",
      "\t\t\"subject\": \"Update kinesis-ingestion.md (#11767)\",\n",
      "\t\t\"sanitized_subject_line\": \"Update-kinesis-ingestion.md-11767\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* Update kinesis-ingestion.md  It seems that we are declaring (a final int) recordsPerFetch as 400 and fetchDelayMillis as 0 in https://github.com/implydata/druid/blob/imply-2021.09/extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskIOConfig.java#L36  ``` public static final int DEFAULT_RECORDS_PER_FETCH = 4000; public static final int DEFAULT_FETCH_DELAY_MILLIS = 0; ```  updating `recordsPerFetch` and `fetchDelayMillis` to actual default values as hardcoded above .  * Update docs/development/extensions-core/kinesis-ingestion.md  Co-authored-by: Charles Smith <techdocsmith@gmail.com> \",\n",
      "\t\t\"author_name\": \"Vaibhav\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Oct 2021 11:26:53 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"d02d2d9d56f668b9d45c51be4360ad0822fe4710\",\n",
      "\t\t\"parent\": \"129911a20ee8fcfbe9b693cdc7a5eb2ce63aebe8\",\n",
      "\t\t\"subject\": \"Design/architecture doc touchups (#11762)\",\n",
      "\t\t\"sanitized_subject_line\": \"Design-architecture-doc-touchups-11762\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* rearrange design content  * casing consistency  Co-authored-by: Charles Smith <techdocsmith@gmail.com>\",\n",
      "\t\t\"author_name\": \"sthetland\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Mon, 4 Oct 2021 11:09:35 -0700\"\n",
      "\t},\n",
      "\t{\n",
      "\t\t\"commitHash\": \"129911a20ee8fcfbe9b693cdc7a5eb2ce63aebe8\",\n",
      "\t\t\"parent\": \"1c0b76ba9349e00d330a2ed9c757a6836f79a6ea\",\n",
      "\t\t\"subject\": \"Add documentations for config to filter internal Druid-related messages from error response (#11755)\",\n",
      "\t\t\"sanitized_subject_line\": \"Add-documentations-for-config-to-filter-internal-Druid-related-messages-from-error-response-11755\",\n",
      "\t\t\"commit_notes\": \"\",\n",
      "\t\t\"body\": \"* add doc  * add doc  * address comments  * fix typo  * address comments\",\n",
      "\t\t\"author_name\": \"Maytas Monsereenusorn\",\n",
      "\t\t\"commiter_name\": \"GitHub\",\n",
      "\t\t\"date\": \"Fri, 1 Oct 2021 17:49:02 +0700\"\n",
      "\t}\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mkdir', 'commits'], returncode=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_commit = 100 # int(sys.argv[1]) \n",
    "\n",
    "# Raw      'r' \n",
    "with open('git-log.json', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    raw_data = r'' + data\n",
    "\n",
    "# Raw  JSON \n",
    "try:\n",
    "    json_data = json.loads(raw_data) \n",
    "    print(json.dumps(json_data, indent = '\\t'))\n",
    "    \n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON  : {e}\")\n",
    "\n",
    "subprocess.run(['mkdir', 'commits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d5d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_checkout_file(file):\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except:\n",
    "        print(f\"File Open :\")\n",
    "        content = ''\n",
    "    return content\n",
    "\n",
    "def write_checkout_file(file_path, content):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "    except:\n",
    "        print(f\"File Write \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124ad2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTuningConfigTest.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTuningConfigTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskTuningConfigTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTuningConfigTest.java', 'server/src/main/java/org/apache/druid/segment/indexing/RealtimeTuningConfig.java', 'server/src/test/java/org/apache/druid/segment/indexing/RealtimeTuningConfigTest.java']\n",
      "95ca43034fe661556f56dee7c39b6d7b784a0a2e\n",
      "1 : ['extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTuningConfigTest.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTuningConfigTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskTuningConfigTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTuningConfigTest.java', 'server/src/main/java/org/apache/druid/segment/indexing/RealtimeTuningConfig.java', 'server/src/test/java/org/apache/druid/segment/indexing/RealtimeTuningConfigTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/CalciteSelectJoinQueryMSQTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'processing/src/main/java/org/apache/druid/error/Forbidden.java', 'processing/src/main/java/org/apache/druid/error/QueryExceptionCompat.java', 'processing/src/main/java/org/apache/druid/query/QueryContext.java', 'processing/src/test/java/org/apache/druid/error/ForbiddenTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/NativeSqlEngine.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/SqlEngines.java', 'sql/src/main/java/org/apache/druid/sql/calcite/view/ViewSqlEngine.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/IngestionTestSqlEngine.java']\n",
      "c1c7dff2ad082a110aaab3c2c9dc1678773f1a92\n",
      "2 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/CalciteSelectJoinQueryMSQTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'processing/src/main/java/org/apache/druid/error/Forbidden.java', 'processing/src/main/java/org/apache/druid/error/QueryExceptionCompat.java', 'processing/src/main/java/org/apache/druid/query/QueryContext.java', 'processing/src/test/java/org/apache/druid/error/ForbiddenTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/NativeSqlEngine.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/SqlEngines.java', 'sql/src/main/java/org/apache/druid/sql/calcite/view/ViewSqlEngine.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/IngestionTestSqlEngine.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java']\n",
      "589aac8b317104fd34b5c57e0ca248e6ca3e4703\n",
      "3 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/ImmutableWorkerInfo.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/ZkWorker.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/autoscaling/PendingTaskBasedWorkerProvisioningStrategy.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerRunPendingTasksConcurrencyTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTestUtils.java']\n",
      "450ecd6370d47aff58b4160efd95a82396897d5f\n",
      "4 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/ImmutableWorkerInfo.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/ZkWorker.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/autoscaling/PendingTaskBasedWorkerProvisioningStrategy.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerRunPendingTasksConcurrencyTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTestUtils.java']\n",
      "['processing/src/main/java/org/apache/druid/collections/StupidPool.java', 'processing/src/main/java/org/apache/druid/query/operator/LimitTimeIntervalOperator.java', 'processing/src/main/java/org/apache/druid/query/operator/WindowOperatorQueryQueryRunnerFactory.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/LazilyDecoratedRowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/RowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/SemanticCreator.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/concrete/QueryableIndexRowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/semantic/DefaultNaiveSortMaker.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'sql/src/test/java/org/apache/druid/sql/calcite/DrillWindowQueryTest.java']\n",
      "65e1b27aa709dc3e11ae75993656243377744666\n",
      "5 : ['processing/src/main/java/org/apache/druid/collections/StupidPool.java', 'processing/src/main/java/org/apache/druid/query/operator/LimitTimeIntervalOperator.java', 'processing/src/main/java/org/apache/druid/query/operator/WindowOperatorQueryQueryRunnerFactory.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/LazilyDecoratedRowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/RowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/SemanticCreator.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/concrete/QueryableIndexRowsAndColumns.java', 'processing/src/main/java/org/apache/druid/query/rowsandcols/semantic/DefaultNaiveSortMaker.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'sql/src/test/java/org/apache/druid/sql/calcite/DrillWindowQueryTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarDoublesSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarFloatsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarLongsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/CompressedColumnarIntsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/DecompressingByteBufferObjectStrategy.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java']\n",
      "3711c0d987213a0086053916a23775768f6f0a6b\n",
      "6 : ['processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarDoublesSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarFloatsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarLongsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/CompressedColumnarIntsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSupplier.java', 'processing/src/main/java/org/apache/druid/segment/data/DecompressingByteBufferObjectStrategy.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java']\n",
      "['processing/src/main/java/org/apache/druid/query/aggregation/AggregatorFactory.java']\n",
      "cc8b210e4c6acc4f1ccb0af6fe163209357ddf18\n",
      "7 : ['processing/src/main/java/org/apache/druid/query/aggregation/AggregatorFactory.java']\n",
      "['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactory.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactoryTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/TestDoublesSketchColumnValueSelector.java']\n",
      "8087aa2b803ca21498c7578de3c1e1d8118a63f4\n",
      "8 : ['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactory.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactoryTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/TestDoublesSketchColumnValueSelector.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerStorageParameters.java']\n",
      "30a91be15a4b728d4a3c6e8ff4fb0d8ae554a1a6\n",
      "9 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerStorageParameters.java']\n",
      "['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregatorFactory.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildBufferAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildColumnProcessorFactory.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchUpdater.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java']\n",
      "66cac08a52cc357a4c775dbb64919941f7733c57\n",
      "10 : ['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregatorFactory.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildBufferAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildColumnProcessorFactory.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchUpdater.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java']\n",
      "['processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java', 'server/src/main/java/org/apache/druid/metadata/UnknownSegmentIdsException.java']\n",
      "58a35bf07e6ec20427bd1dbcd5e1ca37d4c7c757\n",
      "11 : ['processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java', 'server/src/main/java/org/apache/druid/metadata/UnknownSegmentIdsException.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java']\n",
      "021a01df4575519dd73aa734804f3a3ad4c1e225\n",
      "12 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/groupby/GroupByQueryKit.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java']\n",
      "9e617373a0cd2467e8565a54335849c9f48b39d0\n",
      "13 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/groupby/GroupByQueryKit.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/CounterSnapshotsTree.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/SegmentGeneratorMetricsWrapper.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Controller.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/MSQTasks.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQIndexingModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerControllerContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerWorkerContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSpec.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleaner.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleanerConfig.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/ControllerChatHandler.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerControllerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerManagerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/WorkerChatHandler.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DataSourceMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DurableStorageMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQSelectDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/TaskReportMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/KeyStatisticsCollectionProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/kernel/StageDefinition.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageQueryResultsInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageStageInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/WorkerInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageQueryResultsOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageTaskOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQParseExceptionsTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DataSourceMSQDestinationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/WorkerChatHandlerTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessorTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/shuffle/DurableStorageOutputChannelFactoryTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'processing/src/main/java/org/apache/druid/frame/util/DurableStorageUtils.java', 'processing/src/main/java/org/apache/druid/storage/NilStorageConnector.java', 'processing/src/test/java/org/apache/druid/frame/util/DurableStorageUtilsTest.java', 'processing/src/test/java/org/apache/druid/storage/NilStorageConnectorTest.java']\n",
      "afa8c7b8abec1337003af76160ea94ef8cd09f0a\n",
      "14 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/CounterSnapshotsTree.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/SegmentGeneratorMetricsWrapper.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Controller.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/MSQTasks.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQIndexingModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerControllerContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerWorkerContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSpec.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleaner.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleanerConfig.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/ControllerChatHandler.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerControllerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerManagerClient.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/WorkerChatHandler.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DataSourceMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DurableStorageMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQSelectDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/TaskReportMSQDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/KeyStatisticsCollectionProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/kernel/StageDefinition.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageQueryResultsInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageStageInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/WorkerInputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageQueryResultsOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageTaskOutputChannelFactory.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQParseExceptionsTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DataSourceMSQDestinationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/WorkerChatHandlerTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessorTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/shuffle/DurableStorageOutputChannelFactoryTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'processing/src/main/java/org/apache/druid/frame/util/DurableStorageUtils.java', 'processing/src/main/java/org/apache/druid/storage/NilStorageConnector.java', 'processing/src/test/java/org/apache/druid/frame/util/DurableStorageUtilsTest.java', 'processing/src/test/java/org/apache/druid/storage/NilStorageConnectorTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/Stats.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockConfigTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueScaleTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsMonitor.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsProvider.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskSlotCountStatsProvider.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java', 'server/src/test/java/org/apache/druid/server/metrics/TaskCountStatsMonitorTest.java']\n",
      "40d0dc9e0e02c89f91762a400ecdd84b950907ca\n",
      "15 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/Stats.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockConfigTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueScaleTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsMonitor.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsProvider.java', 'server/src/main/java/org/apache/druid/server/metrics/TaskSlotCountStatsProvider.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java', 'server/src/test/java/org/apache/druid/server/metrics/TaskCountStatsMonitorTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java', 'server/src/main/java/org/apache/druid/client/HttpServerInventoryView.java', 'server/src/main/java/org/apache/druid/server/coordination/ChangeRequestHttpSyncer.java']\n",
      "1fe61bc869924d51a3e3133a5894afb3896640af\n",
      "16 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java', 'server/src/main/java/org/apache/druid/client/HttpServerInventoryView.java', 'server/src/main/java/org/apache/druid/server/coordination/ChangeRequestHttpSyncer.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java']\n",
      "d63eff3b1b6b15fac1bb278a784ce6c391a52ce2\n",
      "17 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java']\n",
      "['processing/src/main/java/org/apache/druid/segment/column/ColumnSignature.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java']\n",
      "dd78e00dc543609db2c75c23f9546fc46cb86ad8\n",
      "18 : ['processing/src/main/java/org/apache/druid/segment/column/ColumnSignature.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunnerTest.java']\n",
      "037f09bef2224b0912b0f225c7653929dd98af88\n",
      "19 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunnerTest.java']\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtils.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidPlanner.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/IngestHandler.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteReplaceDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtilsTest.java']\n",
      "d02bb8bb6e1e6d0aae3ebdb06f2f1ea335b8ad6d\n",
      "20 : ['sql/src/main/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtils.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidPlanner.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/IngestHandler.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteReplaceDmlTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtilsTest.java']\n",
      "['indexing-hadoop/src/test/java/org/apache/druid/indexer/DetermineHashedPartitionsJobTest.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/Granularity.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/IntervalsByGranularity.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/PeriodGranularity.java', 'server/src/test/java/org/apache/druid/segment/indexing/granularity/UniformGranularityTest.java']\n",
      "277b35725619d6d6b63b5c925a72ffb19a37d703\n",
      "21 : ['indexing-hadoop/src/test/java/org/apache/druid/indexer/DetermineHashedPartitionsJobTest.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/Granularity.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/IntervalsByGranularity.java', 'processing/src/main/java/org/apache/druid/java/util/common/granularity/PeriodGranularity.java', 'server/src/test/java/org/apache/druid/segment/indexing/granularity/UniformGranularityTest.java']\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java']\n",
      "78db7a44148bfba0acdfe6612daa3113914808b7\n",
      "22 : ['sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java']\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "f29a9faa94839bacfaad94bdeb4f439fe379dd18\n",
      "23 : ['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java']\n",
      "609833c97bb44fee50f4fb84e44ad7c6cb053714\n",
      "24 : ['indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java']\n",
      "27a70d569db7a0274e222d5ba1aa32cb587ce529\n",
      "25 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/NativeQueryMaker.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteScanSignatureTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java']\n",
      "2d5b27358e0a1abefcc3c7ddeb3af613ddf88df5\n",
      "26 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/NativeQueryMaker.java', 'sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteScanSignatureTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-670:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\python39\\lib\\subprocess.py\", line 1479, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "UnicodeDecodeError: 'cp949' codec can't decode byte 0xe9 in position 48744: illegal multibyte sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Write \n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Limits.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerMemoryParameters.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/TooManyRowsWithSameKeyFault.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/BroadcastJoinHelper.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/WorkerMemoryParametersTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorTest.java']\n",
      "58f3faf2996051a037555d665da6a8781215e037\n",
      "27 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Limits.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerMemoryParameters.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/TooManyRowsWithSameKeyFault.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/BroadcastJoinHelper.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessor.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorFactory.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/WorkerMemoryParametersTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQFaultsTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/error/MSQFaultSerdeTest.java']\n",
      "048dbcee8846d51a38b228c8aaac88851278277e\n",
      "28 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQFaultsTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/error/MSQFaultSerdeTest.java']\n",
      "['server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java']\n",
      "4b2d87336a56eafe6c28fc93f1040e737013671e\n",
      "29 : ['server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/DataSourcePlan.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'processing/src/main/java/org/apache/druid/query/DataSource.java', 'processing/src/main/java/org/apache/druid/query/UnionQueryRunner.java', 'processing/src/main/java/org/apache/druid/query/planning/DataSourceAnalysis.java', 'processing/src/test/java/org/apache/druid/query/planning/DataSourceAnalysisTest.java', 'server/src/main/java/org/apache/druid/server/ClientQuerySegmentWalker.java', 'server/src/test/java/org/apache/druid/server/TestClusterQuerySegmentWalker.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java']\n",
      "a6cabbe10f02d87f9299490a07dd437a4a559b8c\n",
      "30 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/DataSourcePlan.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'processing/src/main/java/org/apache/druid/query/DataSource.java', 'processing/src/main/java/org/apache/druid/query/UnionQueryRunner.java', 'processing/src/main/java/org/apache/druid/query/planning/DataSourceAnalysis.java', 'processing/src/test/java/org/apache/druid/query/planning/DataSourceAnalysisTest.java', 'server/src/main/java/org/apache/druid/server/ClientQuerySegmentWalker.java', 'server/src/test/java/org/apache/druid/server/TestClusterQuerySegmentWalker.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java']\n",
      "['extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java']\n",
      "c798d3fb2e840df5700615a0fb994f61acbed46e\n",
      "31 : ['extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java']\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/expression/ExpressionsTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTestInjectorBuilder.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/QueryFrameworkUtils.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/AssertionErrorOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/CalciteTestOperatorModule.java', 'sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java']\n",
      "34c55a0bde701e18fbe064bfe574caedb752ff4f\n",
      "32 : ['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/expression/ExpressionsTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTestInjectorBuilder.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/QueryFrameworkUtils.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/AssertionErrorOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/CalciteTestOperatorModule.java', 'sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java']\n",
      "['extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceAggregatorFactory.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/sql/BaseVarianceSqlAggregator.java', 'extensions-core/stats/src/test/java/org/apache/druid/query/aggregation/variance/sql/VarianceSqlAggregatorTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/table/RowSignatures.java']\n",
      "c36f12f1d8bf81cf110dd41853627be175816b00\n",
      "33 : ['extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceAggregatorFactory.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/sql/BaseVarianceSqlAggregator.java', 'extensions-core/stats/src/test/java/org/apache/druid/query/aggregation/variance/sql/VarianceSqlAggregatorTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/table/RowSignatures.java']\n",
      "['processing/src/main/java/org/apache/druid/common/config/NullHandling.java', 'processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/column/StringUtf8DictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/data/CachingIndexed.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexed.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedColumnSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedStringIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/DoubleNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/FloatNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/LongNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexed.java', 'processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedColumnIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedDictionaryEncodedColumnSupplier.java', 'processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/IndexMergerNullHandlingTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarStringColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexedTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexedTest.java']\n",
      "82fbb31c7c55f01629191e5072683f0fdb87c7db\n",
      "34 : ['processing/src/main/java/org/apache/druid/common/config/NullHandling.java', 'processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/column/StringUtf8DictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/data/CachingIndexed.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexed.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedInts.java', 'processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedColumnSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedStringIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/DoubleNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/FloatNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/LongNumericColumnPartSerdeV2.java', 'processing/src/main/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexed.java', 'processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedColumnIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedDictionaryEncodedColumnSupplier.java', 'processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/IndexMergerNullHandlingTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarStringColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexedTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedIntsTest.java', 'processing/src/test/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexedTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSelectDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'integration-tests/src/main/java/org/apache/druid/testing/utils/MsqTestQueryHelper.java']\n",
      "233233c92d906372cff3144e3d03191ab45f32f4\n",
      "35 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSelectDestination.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java', 'integration-tests/src/main/java/org/apache/druid/testing/utils/MsqTestQueryHelper.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/SqlTaskModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertCannotBeEmptyFault.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlStatementState.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypes.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/SqlStatementResult.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlTaskResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypesTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestOverlordServiceClient.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java', 'processing/src/main/java/org/apache/druid/error/DruidException.java', 'processing/src/main/java/org/apache/druid/query/ExecutionMode.java', 'processing/src/main/java/org/apache/druid/query/QueryContexts.java', 'processing/src/test/java/org/apache/druid/query/QueryContextsTest.java', 'server/src/main/java/org/apache/druid/rpc/indexing/OverlordClient.java', 'server/src/main/java/org/apache/druid/rpc/indexing/OverlordClientImpl.java', 'server/src/test/java/org/apache/druid/client/indexing/NoopOverlordClient.java', 'server/src/test/java/org/apache/druid/rpc/indexing/OverlordClientImplTest.java', 'sql/src/main/java/org/apache/druid/sql/DirectStatement.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java', 'sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java']\n",
      "cb3a9d2b5778c568f8a6fad096b95bfd1f36bd21\n",
      "36 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/SqlTaskModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertCannotBeEmptyFault.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlStatementState.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypes.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/SqlStatementResult.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlTaskResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypesTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestOverlordServiceClient.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java', 'processing/src/main/java/org/apache/druid/error/DruidException.java', 'processing/src/main/java/org/apache/druid/query/ExecutionMode.java', 'processing/src/main/java/org/apache/druid/query/QueryContexts.java', 'processing/src/test/java/org/apache/druid/query/QueryContextsTest.java', 'server/src/main/java/org/apache/druid/rpc/indexing/OverlordClient.java', 'server/src/main/java/org/apache/druid/rpc/indexing/OverlordClientImpl.java', 'server/src/test/java/org/apache/druid/client/indexing/NoopOverlordClient.java', 'server/src/test/java/org/apache/druid/rpc/indexing/OverlordClientImplTest.java', 'sql/src/main/java/org/apache/druid/sql/DirectStatement.java', 'sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java', 'sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processing/src/test/java/org/apache/druid/audit/TestAuditManager.java', 'processing/src/test/java/org/apache/druid/common/config/ConfigManagerTest.java', 'processing/src/test/java/org/apache/druid/common/config/TestConfigManagerConfig.java', 'processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageConnector.java', 'processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageTablesConfig.java']\n",
      "fd20bbd30ecee969fd3f38cbe1d45de7d763f531\n",
      "37 : ['processing/src/test/java/org/apache/druid/audit/TestAuditManager.java', 'processing/src/test/java/org/apache/druid/common/config/ConfigManagerTest.java', 'processing/src/test/java/org/apache/druid/common/config/TestConfigManagerConfig.java', 'processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageConnector.java', 'processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageTablesConfig.java']\n",
      "['processing/src/main/java/org/apache/druid/query/aggregation/FilteredAggregator.java', 'processing/src/test/java/org/apache/druid/query/aggregation/FilteredAggregatorTest.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableDoubleColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableFloatColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableLongColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/WrappingDimensionSelectorTest.java']\n",
      "2cfb00b1de928a48a1c61bc04c10cdbccab33866\n",
      "38 : ['processing/src/main/java/org/apache/druid/query/aggregation/FilteredAggregator.java', 'processing/src/test/java/org/apache/druid/query/aggregation/FilteredAggregatorTest.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableDoubleColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableFloatColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/TestNullableLongColumnSelector.java', 'processing/src/test/java/org/apache/druid/segment/WrappingDimensionSelectorTest.java']\n",
      "['processing/src/test/java/org/apache/druid/common/guava/GuavaUtilsTest.java']\n",
      "2f0a43790c22318b9c48ed0f38db7350fef267ef\n",
      "39 : ['processing/src/test/java/org/apache/druid/common/guava/GuavaUtilsTest.java']\n",
      "['processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/main/java/org/apache/druid/segment/column/TypeSignature.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializerV4.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedPathFinder.java', 'processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedPathFinderTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/NestedDataOperatorConversions.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java']\n",
      "6ba10c8b6caf1de5afd782ba70edda406466c892\n",
      "40 : ['processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/main/java/org/apache/druid/segment/column/TypeSignature.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializerV4.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedPathFinder.java', 'processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedPathFinderTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/NestedDataOperatorConversions.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java']\n",
      "['sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "903addf7c281099cb3fd510c0ebebfa5d62c5584\n",
      "41 : ['sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerSketchFetcher.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQReplaceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java']\n",
      "8211379de689d64d60fcaa8aa131b733b186c47d\n",
      "42 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerSketchFetcher.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQReplaceTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-760:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\python39\\lib\\subprocess.py\", line 1479, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "UnicodeDecodeError: 'cp949' codec can't decode byte 0xe2 in position 49: illegal multibyte sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get the changed file list.\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteMultiValueStringQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java']\n",
      "d7c9c2f3671d1e9cefff463eb5cb557e9e882f38\n",
      "43 : ['sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteMultiValueStringQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java']\n",
      "['processing/src/test/java/org/apache/druid/java/util/emitter/core/HttpEmitterConfigTest.java', 'processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java']\n",
      "970288067ac2979dff0ddeed97003cd631ad9ee8\n",
      "44 : ['processing/src/test/java/org/apache/druid/java/util/emitter/core/HttpEmitterConfigTest.java', 'processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java']\n",
      "['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchApproxCountDistinctSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateWithErrorBoundsOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchApproxQuantileSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchApproxCountDistinctSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchSqlAggregatorTest.java', 'extensions-core/testing-tools/src/main/java/org/apache/druid/query/sql/SleepOperatorConversion.java', 'integration-tests-ex/tools/src/main/java/org/apache/druid/testing/tools/SleepOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/OperatorConversions.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/BTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ContainsOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/DateTruncOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LPadOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ParseLongOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RPadOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpLikeOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RoundOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TextcatOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeCeilOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeExtractOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFloorOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFormatOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeParseOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeShiftOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TruncateOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/expression/OperatorConversionsTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidOperatorTableTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidRexExecutorTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/schema/InformationSchemaTest.java']\n",
      "3d19b748fb9fde49f074a8234e797a46bd894d48\n",
      "45 : ['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchApproxCountDistinctSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateWithErrorBoundsOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchApproxQuantileSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchApproxCountDistinctSqlAggregator.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchObjectSqlAggregator.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchSqlAggregatorTest.java', 'extensions-core/testing-tools/src/main/java/org/apache/druid/query/sql/SleepOperatorConversion.java', 'integration-tests-ex/tools/src/main/java/org/apache/druid/testing/tools/SleepOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/OperatorConversions.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/BTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ContainsOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/DateTruncOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LPadOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ParseLongOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RPadOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RTrimOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpLikeOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RoundOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TextcatOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeCeilOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeExtractOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFloorOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFormatOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeParseOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeShiftOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TruncateOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/expression/OperatorConversionsTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidOperatorTableTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidRexExecutorTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/schema/InformationSchemaTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/ServerSideEncryptingAmazonS3.java', 'extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/output/S3StorageConnectorTest.java']\n",
      "ddd0fc1b855b2d9645d052561a1cf4e89544ed8a\n",
      "46 : ['extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/ServerSideEncryptingAmazonS3.java', 'extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/output/S3StorageConnectorTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlTaskStatusTest.java', 'processing/src/main/java/org/apache/druid/error/DruidException.java', 'processing/src/main/java/org/apache/druid/query/BadQueryException.java']\n",
      "7e2cf35d7b0485b5fe5abeb021c5811ee812b0c7\n",
      "47 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskResource.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlTaskStatusTest.java', 'processing/src/main/java/org/apache/druid/error/DruidException.java', 'processing/src/main/java/org/apache/druid/query/BadQueryException.java']\n",
      "['indexing-service/src/test/java/org/apache/druid/indexing/input/DruidSegmentReaderTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/InputRowSchemasTest.java', 'processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java', 'processing/src/test/java/org/apache/druid/query/scan/MultiSegmentScanQueryTest.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java', 'processing/src/test/java/org/apache/druid/segment/join/lookup/LookupJoinableTest.java']\n",
      "31b9d5695d8db387f6422a4e334b43dba4cee6e1\n",
      "48 : ['indexing-service/src/test/java/org/apache/druid/indexing/input/DruidSegmentReaderTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/InputRowSchemasTest.java', 'processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java', 'processing/src/test/java/org/apache/druid/query/scan/MultiSegmentScanQueryTest.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java', 'processing/src/test/java/org/apache/druid/segment/join/lookup/LookupJoinableTest.java']\n",
      "['server/src/main/java/org/apache/druid/server/QueryLifecycle.java', 'server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java']\n",
      "92a7febacbe71f13cdfc2e8b976cadff57606a0f\n",
      "49 : ['server/src/main/java/org/apache/druid/server/QueryLifecycle.java', 'server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java']\n",
      "['server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java']\n",
      "f5cc823d0f8acdf660860fcb75db34e38c039d8f\n",
      "50 : ['server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java']\n",
      "['sql/src/main/java/org/apache/calcite/plan/volcano/DruidVolcanoCost.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/CalciteRulesManager.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidQueryGenerator.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerFactory.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/CostEstimates.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/PartialDruidQuery.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidAggregate.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidFilter.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalConvention.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalNode.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidProject.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidSort.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidTableScan.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidValues.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/DruidLogicalValuesRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateCaseToFilterRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidFilterRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidLogicalRules.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidProjectRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidSortRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidTableScanRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidValuesRule.java', 'sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/DecoupledPlanningCalciteQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/QueryTestBuilder.java']\n",
      "09d6c5a45ed9c737e711403a864903dcbbf22830\n",
      "51 : ['sql/src/main/java/org/apache/calcite/plan/volcano/DruidVolcanoCost.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/CalciteRulesManager.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidQueryGenerator.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerFactory.java', 'sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/CostEstimates.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/PartialDruidQuery.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidAggregate.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidFilter.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalConvention.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalNode.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidProject.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidSort.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidTableScan.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidValues.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/DruidLogicalValuesRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateCaseToFilterRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidFilterRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidLogicalRules.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidProjectRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidSortRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidTableScanRule.java', 'sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidValuesRule.java', 'sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/DecoupledPlanningCalciteQueryTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/QueryTestBuilder.java']\n",
      "['benchmarks/src/test/java/org/apache/druid/server/coordinator/BalancerStrategyBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/server/coordinator/CachingCostBalancerStrategyBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'integration-tests-ex/cases/src/test/java/org/apache/druid/testsEx/utils/DruidClusterAdminClient.java', 'integration-tests/src/main/java/org/apache/druid/testing/utils/DruidClusterAdminClient.java', 'processing/src/main/java/org/apache/druid/query/DruidMetrics.java', 'server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java', 'server/src/main/java/org/apache/druid/server/coordinator/BalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorDynamicConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCluster.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinatorRuntimeParams.java', 'server/src/main/java/org/apache/druid/server/coordinator/ReplicationThrottler.java', 'server/src/main/java/org/apache/druid/server/coordinator/SegmentReplicantLookup.java', 'server/src/main/java/org/apache/druid/server/coordinator/ServerHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerSegmentHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ClusterCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSampler.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ServerCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/TierSegmentBalancer.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/package-info.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/BalanceSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/CompactSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetrics.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/LogUsedSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnused.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/RunRules.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/SegmentCompactionUtil.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/CuratorLoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadPeonCallback.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueueTaskMaster.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/ReplicationThrottler.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/RoundRobinServerSelector.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentAction.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadQueueManager.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadingConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCount.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCountMap.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicationStatus.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentStatusInTier.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/StrategicSegmentAssigner.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/DropRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/ForeverLoadRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/LoadRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/Rule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/SegmentActionHandler.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorStat.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/Dimension.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/RowKey.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/Stats.java', 'server/src/main/java/org/apache/druid/server/http/CoordinatorDynamicConfigsResource.java', 'server/src/main/java/org/apache/druid/server/http/CoordinatorResource.java', 'server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java', 'server/src/main/java/org/apache/druid/server/http/MetadataResource.java', 'server/src/main/java/org/apache/druid/server/http/SegmentListerResource.java', 'server/src/test/java/org/apache/druid/segment/realtime/appenderator/TestUsedSegmentChecker.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsProfiler.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTester.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java', 'server/src/test/java/org/apache/druid/server/coordinator/CuratorDruidCoordinatorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidClusterBuilder.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidClusterTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/HttpLoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/RoundRobinServerSelectorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/ServerHolderTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSamplerTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCacheTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/BalanceSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/CompactSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetricsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/MarkAsUnusedOvershadowedSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnusedTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/NewestSegmentFirstPolicyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/RunRulesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTester.java', 'server/src/test/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRuleTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/rules/LoadRuleTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/BalancingStrategiesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBaseTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBuilder.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/RoundRobinAssignmentTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentBalancingTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingNegativeTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/TestSegmentsMetadataManager.java', 'server/src/test/java/org/apache/druid/server/http/CoordinatorDynamicConfigTest.java', 'server/src/test/java/org/apache/druid/server/http/DataSourcesResourceTest.java', 'server/src/test/java/org/apache/druid/server/http/MetadataResourceTest.java', 'services/src/main/java/org/apache/druid/cli/CliCoordinator.java']\n",
      "50461c3bd58da60ec3cdfbc9a962d4a594ec7c6a\n",
      "52 : ['benchmarks/src/test/java/org/apache/druid/server/coordinator/BalancerStrategyBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/server/coordinator/CachingCostBalancerStrategyBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'integration-tests-ex/cases/src/test/java/org/apache/druid/testsEx/utils/DruidClusterAdminClient.java', 'integration-tests/src/main/java/org/apache/druid/testing/utils/DruidClusterAdminClient.java', 'processing/src/main/java/org/apache/druid/query/DruidMetrics.java', 'server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java', 'server/src/main/java/org/apache/druid/server/coordinator/BalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorDynamicConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCluster.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java', 'server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinatorRuntimeParams.java', 'server/src/main/java/org/apache/druid/server/coordinator/ReplicationThrottler.java', 'server/src/main/java/org/apache/druid/server/coordinator/SegmentReplicantLookup.java', 'server/src/main/java/org/apache/druid/server/coordinator/ServerHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerSegmentHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ClusterCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategyFactory.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSampler.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/ServerCostCache.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/TierSegmentBalancer.java', 'server/src/main/java/org/apache/druid/server/coordinator/balancer/package-info.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/BalanceSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/CompactSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetrics.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/LogUsedSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnused.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/RunRules.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/SegmentCompactionUtil.java', 'server/src/main/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegments.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/CuratorLoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadPeonCallback.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueuePeon.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueueTaskMaster.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/ReplicationThrottler.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/RoundRobinServerSelector.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentAction.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentHolder.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadQueueManager.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadingConfig.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCount.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCountMap.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicationStatus.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentStatusInTier.java', 'server/src/main/java/org/apache/druid/server/coordinator/loading/StrategicSegmentAssigner.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/DropRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/ForeverLoadRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/LoadRule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/Rule.java', 'server/src/main/java/org/apache/druid/server/coordinator/rules/SegmentActionHandler.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorStat.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/Dimension.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/RowKey.java', 'server/src/main/java/org/apache/druid/server/coordinator/stats/Stats.java', 'server/src/main/java/org/apache/druid/server/http/CoordinatorDynamicConfigsResource.java', 'server/src/main/java/org/apache/druid/server/http/CoordinatorResource.java', 'server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java', 'server/src/main/java/org/apache/druid/server/http/MetadataResource.java', 'server/src/main/java/org/apache/druid/server/http/SegmentListerResource.java', 'server/src/test/java/org/apache/druid/segment/realtime/appenderator/TestUsedSegmentChecker.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsProfiler.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTester.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java', 'server/src/test/java/org/apache/druid/server/coordinator/CuratorDruidCoordinatorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidClusterBuilder.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidClusterTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/HttpLoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/RoundRobinServerSelectorTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/ServerHolderTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSamplerTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCacheTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/BalanceSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStatsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/CompactSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetricsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/MarkAsUnusedOvershadowedSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnusedTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/NewestSegmentFirstPolicyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/RunRulesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegmentsTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTester.java', 'server/src/test/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRuleTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/rules/LoadRuleTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/BalancingStrategiesTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBaseTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBuilder.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/RoundRobinAssignmentTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentBalancingTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingNegativeTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/TestSegmentsMetadataManager.java', 'server/src/test/java/org/apache/druid/server/http/CoordinatorDynamicConfigTest.java', 'server/src/test/java/org/apache/druid/server/http/DataSourcesResourceTest.java', 'server/src/test/java/org/apache/druid/server/http/MetadataResourceTest.java', 'services/src/main/java/org/apache/druid/cli/CliCoordinator.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunner.java']\n",
      "bd07c3dd43428608678e337c7935f237a64f533d\n",
      "53 : ['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunner.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQWorkerTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/Task.java']\n",
      "85656a467c66cffbe616dfa5e3646a0ac82b9afc\n",
      "54 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQWorkerTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/Task.java']\n",
      "['extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java', 'processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java']\n",
      "ff5ae4db6c4330b164ad3550c7c9c976699e4ff5\n",
      "55 : ['extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java', 'processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java']\n",
      "['processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java', 'processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java']\n",
      "ca116cf88639cbe8f4705d43b4730dc550272111\n",
      "56 : ['processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java', 'processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java']\n",
      "['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/tuple/ArrayOfDoublesSketchMergeComplexMetricSerde.java']\n",
      "5314db9f85d9768cc881a054dea33a8616fdedfa\n",
      "57 : ['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/tuple/ArrayOfDoublesSketchMergeComplexMetricSerde.java']\n",
      "['processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java', 'processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java']\n",
      "e426d370ea974546fdb7fe6f43e44fba015181d7\n",
      "58 : ['processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java', 'processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java']\n",
      "['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java']\n",
      "76e70654acdce8213bcf66a9943dfb1374fc329f\n",
      "59 : ['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java']\n",
      "['processing/src/main/java/org/apache/druid/utils/JvmUtils.java', 'processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java']\n",
      "be5a6593a946442a57ce9bcd87d977c41b954d33\n",
      "60 : ['processing/src/main/java/org/apache/druid/utils/JvmUtils.java', 'processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java']\n",
      "['extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java', 'processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java']\n",
      "61120dc49a2c7a94f7421c9cbf68bfe88844131f\n",
      "61 : ['extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java', 'processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java']\n",
      "['server/src/main/java/org/apache/druid/metadata/SQLMetadataSupervisorManager.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataSupervisorManagerTest.java']\n",
      "66c3cc139190ed74e1bcc5fdccfd2370ebc9e3ea\n",
      "62 : ['server/src/main/java/org/apache/druid/metadata/SQLMetadataSupervisorManager.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataSupervisorManagerTest.java']\n",
      "['server/src/main/java/org/apache/druid/server/QueryLifecycle.java', 'server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java']\n",
      "8b212e73d75e08db718a1121da0f201fff723cf2\n",
      "63 : ['server/src/main/java/org/apache/druid/server/QueryLifecycle.java', 'server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java']\n",
      "['extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java', 'extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/output/S3StorageConnector.java', 'processing/src/main/java/org/apache/druid/storage/local/LocalFileStorageConnector.java']\n",
      "267cbac6ff6bac1001f72f517f1d27ded9c4ca75\n",
      "64 : ['extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java', 'extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/output/S3StorageConnector.java', 'processing/src/main/java/org/apache/druid/storage/local/LocalFileStorageConnector.java']\n",
      "['extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTest.java', 'extensions-core/mysql-metadata-storage/src/main/java/org/apache/druid/metadata/storage/mysql/MySQLConnector.java', 'extensions-core/mysql-metadata-storage/src/test/java/org/apache/druid/metadata/storage/mysql/MySQLConnectorTest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexPhaseRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/HeapMemoryTaskStorage.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/MetadataTaskStorage.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/http/OverlordResource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java', 'processing/src/main/java/org/apache/druid/common/exception/DruidException.java', 'processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java', 'processing/src/main/java/org/apache/druid/metadata/MetadataStorageConnectorConfig.java', 'processing/src/test/java/org/apache/druid/common/exception/DruidExceptionTest.java', 'processing/src/test/java/org/apache/druid/metadata/EntryExistsExceptionTest.java', 'processing/src/test/java/org/apache/druid/metadata/MetadataStorageConnectorConfigTest.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataStorageActionHandlerTest.java']\n",
      "6e158704cb058e7c50db025eef1afc796ca80780\n",
      "65 : ['extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTest.java', 'extensions-core/mysql-metadata-storage/src/main/java/org/apache/druid/metadata/storage/mysql/MySQLConnector.java', 'extensions-core/mysql-metadata-storage/src/test/java/org/apache/druid/metadata/storage/mysql/MySQLConnectorTest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexPhaseRunner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/HeapMemoryTaskStorage.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/MetadataTaskStorage.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/http/OverlordResource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java', 'processing/src/main/java/org/apache/druid/common/exception/DruidException.java', 'processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java', 'processing/src/main/java/org/apache/druid/metadata/MetadataStorageConnectorConfig.java', 'processing/src/test/java/org/apache/druid/common/exception/DruidExceptionTest.java', 'processing/src/test/java/org/apache/druid/metadata/EntryExistsExceptionTest.java', 'processing/src/test/java/org/apache/druid/metadata/MetadataStorageConnectorConfigTest.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataStorageActionHandlerTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['server/src/test/java/org/apache/druid/query/dimension/LookupDimensionSpecTest.java']\n",
      "23c2dcaf8d294b4cba9d225cae41cb9148131fd6\n",
      "66 : ['server/src/test/java/org/apache/druid/query/dimension/LookupDimensionSpecTest.java']\n",
      "['processing/src/main/java/org/apache/druid/segment/AbstractIndex.java', 'processing/src/main/java/org/apache/druid/segment/SimpleQueryableIndex.java', 'processing/src/main/java/org/apache/druid/segment/data/FixedIndexed.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java', 'processing/src/main/java/org/apache/druid/segment/incremental/IncrementalIndex.java']\n",
      "87149d5975febdffe0509dd095dfb02f9deedfb7\n",
      "67 : ['processing/src/main/java/org/apache/druid/segment/AbstractIndex.java', 'processing/src/main/java/org/apache/druid/segment/SimpleQueryableIndex.java', 'processing/src/main/java/org/apache/druid/segment/data/FixedIndexed.java', 'processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java', 'processing/src/main/java/org/apache/druid/segment/incremental/IncrementalIndex.java']\n",
      "['server/src/main/java/org/apache/druid/server/coordinator/CostBalancerStrategy.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/BlockingExecutorService.java']\n",
      "12e8fa5c97a37ca7636bafda17a0cbb85ff0747f\n",
      "68 : ['server/src/main/java/org/apache/druid/server/coordinator/CostBalancerStrategy.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/simulate/BlockingExecutorService.java']\n",
      "['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchModule.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllPostAggExprMacros.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/SketchModule.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaPostAggMacros.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchSqlAggregatorTest.java']\n",
      "01b22ca0221b2bfa75d98a2605f97fe130dfac15\n",
      "69 : ['extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchModule.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllPostAggExprMacros.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/SketchModule.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaPostAggMacros.java', 'extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchEstimateOperatorConversion.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java', 'extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchSqlAggregatorTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java']\n",
      "5da601c47e8ec49a1413691acde7f56f16c27127\n",
      "70 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java']\n",
      "a0d49baad6a23f58b6591f78358baf2887339364\n",
      "71 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java']\n",
      "['services/src/main/java/org/apache/druid/server/router/TieredBrokerHostSelector.java']\n",
      "139156cf6bd7cf28978b2aae6489ebfe6de020f7\n",
      "72 : ['services/src/main/java/org/apache/druid/server/router/TieredBrokerHostSelector.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSourceTest.java']\n",
      "45014bd5b458851e2a8601101a4fa818cebb3004\n",
      "73 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSourceTest.java']\n",
      "['extensions-contrib/aliyun-oss-extensions/src/main/java/org/apache/druid/data/input/aliyun/OssInputSource.java', 'extensions-contrib/aliyun-oss-extensions/src/test/java/org/apache/druid/data/input/aliyun/OssInputSourceTest.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTask.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTaskModule.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaSamplerSpec.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaSamplerSpecTest.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexTask.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexingServiceModule.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpec.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskSerdeTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpecTest.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/NilInputSource.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/external/NilInputSourceTest.java', 'indexing-service/src/main/java/org/apache/druid/guice/IndexingServiceInputSourceModule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/ArchiveTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/MoveTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/RestoreTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java', 'indexing-service/src/main/java/org/apache/druid/indexing/input/GeneratorInputSource.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpec.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerModule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerResource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/ArchiveTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/MoveTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/RestoreTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/DruidInputSourceTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/GeneratorInputSourceTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpecTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/SamplerResourceTest.java', 'server/src/main/java/org/apache/druid/client/indexing/SamplerSpec.java', 'server/src/test/java/org/apache/druid/client/indexing/SamplerSpecTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteIngestionDmlTest.java']\n",
      "04a82da63d12d400f37d759450851e1034b9c406\n",
      "74 : ['extensions-contrib/aliyun-oss-extensions/src/main/java/org/apache/druid/data/input/aliyun/OssInputSource.java', 'extensions-contrib/aliyun-oss-extensions/src/test/java/org/apache/druid/data/input/aliyun/OssInputSourceTest.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTask.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTaskModule.java', 'extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaSamplerSpec.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java', 'extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaSamplerSpecTest.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexTask.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexingServiceModule.java', 'extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpec.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskSerdeTest.java', 'extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpecTest.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/NilInputSource.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/external/NilInputSourceTest.java', 'indexing-service/src/main/java/org/apache/druid/guice/IndexingServiceInputSourceModule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/ArchiveTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/MoveTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/RestoreTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTask.java', 'indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java', 'indexing-service/src/main/java/org/apache/druid/indexing/input/GeneratorInputSource.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpec.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerModule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerResource.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/ArchiveTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/MoveTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/RestoreTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/DruidInputSourceTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/input/GeneratorInputSourceTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpecTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/SamplerResourceTest.java', 'server/src/main/java/org/apache/druid/client/indexing/SamplerSpec.java', 'server/src/test/java/org/apache/druid/client/indexing/SamplerSpecTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteIngestionDmlTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageAvailabilityChecker.java', 'extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageDruidModule.java']\n",
      "c244c3de5325e479a86c302e5dc8bbdd881c1e74\n",
      "75 : ['extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageAvailabilityChecker.java', 'extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageDruidModule.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientAsyncImpl.java', 'indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientSyncImpl.java', 'indexing-service/src/main/java/org/apache/druid/indexing/worker/executor/ExecutorLifecycle.java']\n",
      "2086ff88bcdbfdba507d52d78bd3c7605beab280\n",
      "76 : ['indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientAsyncImpl.java', 'indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientSyncImpl.java', 'indexing-service/src/main/java/org/apache/druid/indexing/worker/executor/ExecutorLifecycle.java']\n",
      "['server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java']\n",
      "d4cacebf79c9795aa36b5e0776df44ed735b93d0\n",
      "77 : ['server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java', 'server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java', 'server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/table/TableInputSpecSlicer.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/table/TableInputSpecSlicerTest.java']\n",
      "8d256e35b4b67abafd9b923c973bbdb6d68ead2e\n",
      "78 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/table/TableInputSpecSlicer.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/table/TableInputSpecSlicerTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocateRequest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueue.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocateActionTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueueTest.java']\n",
      "0cde3a8b522fbd5c09222069ac51689a614b8ec2\n",
      "79 : ['indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocateRequest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueue.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocateActionTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueueTest.java']\n",
      "['processing/src/main/java/org/apache/druid/math/expr/Exprs.java', 'processing/src/main/java/org/apache/druid/query/expression/LookupExprMacro.java', 'server/src/test/java/org/apache/druid/query/expression/LookupExprMacroTest.java']\n",
      "22ba457d2998caafd9d52cdb781786b385a36016\n",
      "80 : ['processing/src/main/java/org/apache/druid/math/expr/Exprs.java', 'processing/src/main/java/org/apache/druid/query/expression/LookupExprMacro.java', 'server/src/test/java/org/apache/druid/query/expression/LookupExprMacroTest.java']\n",
      "['benchmarks/src/test/java/org/apache/druid/benchmark/FilterPartitionBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/FilteredAggregatorBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/GroupByTypeInterfaceBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/TopNTypeInterfaceBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IncrementalIndexReadBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexIngestionBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexMergeBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexPersistBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/GroupByBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/ScanBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/SearchBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/TimeseriesBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/TopNBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/timecompare/TimeCompareBenchmark.java', 'extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramDruidModule.java', 'extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramFoldingSerde.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/stats/DruidStatsModule.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceSerde.java', 'processing/src/main/java/org/apache/druid/jackson/AggregatorsModule.java', 'processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/HyperUniquesSerde.java', 'processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/PreComputedHyperUniquesSerde.java', 'processing/src/test/java/org/apache/druid/frame/write/FrameWriterTest.java', 'processing/src/test/java/org/apache/druid/frame/write/FrameWritersTest.java', 'processing/src/test/java/org/apache/druid/segment/SchemalessIndexTest.java', 'processing/src/test/java/org/apache/druid/segment/TestIndex.java', 'processing/src/test/java/org/apache/druid/segment/generator/SegmentGenerator.java', 'processing/src/test/java/org/apache/druid/segment/serde/ComplexMetricsTest.java']\n",
      "a5e04d95a47a78dfac54954c1e47727400991797\n",
      "81 : ['benchmarks/src/test/java/org/apache/druid/benchmark/FilterPartitionBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/FilteredAggregatorBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/GroupByTypeInterfaceBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/TopNTypeInterfaceBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IncrementalIndexReadBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexIngestionBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexMergeBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexPersistBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/GroupByBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/ScanBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/SearchBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/TimeseriesBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/TopNBenchmark.java', 'benchmarks/src/test/java/org/apache/druid/benchmark/query/timecompare/TimeCompareBenchmark.java', 'extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramDruidModule.java', 'extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramFoldingSerde.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/stats/DruidStatsModule.java', 'extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceSerde.java', 'processing/src/main/java/org/apache/druid/jackson/AggregatorsModule.java', 'processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/HyperUniquesSerde.java', 'processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/PreComputedHyperUniquesSerde.java', 'processing/src/test/java/org/apache/druid/frame/write/FrameWriterTest.java', 'processing/src/test/java/org/apache/druid/frame/write/FrameWritersTest.java', 'processing/src/test/java/org/apache/druid/segment/SchemalessIndexTest.java', 'processing/src/test/java/org/apache/druid/segment/TestIndex.java', 'processing/src/test/java/org/apache/druid/segment/generator/SegmentGenerator.java', 'processing/src/test/java/org/apache/druid/segment/serde/ComplexMetricsTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesOverlordModule.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactory.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesWorkItem.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/DruidKubernetesClient.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClient.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/LogWatchInputStream.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactoryTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesWorkItemTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClientTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/LogWatchInputStreamTest.java']\n",
      "cb65135b9925711d200716a9e27a3b638db2002f\n",
      "82 : ['extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesOverlordModule.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactory.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesWorkItem.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/DruidKubernetesClient.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClient.java', 'extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/LogWatchInputStream.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactoryTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesWorkItemTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClientTest.java', 'extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/LogWatchInputStreamTest.java']\n",
      "['server/src/main/java/org/apache/druid/server/security/PreResponseAuthorizationCheckFilter.java', 'server/src/test/java/org/apache/druid/server/http/security/PreResponseAuthorizationCheckFilterTest.java']\n",
      "e9fed1445f2124b94fdba5976a90b7b52cd5baff\n",
      "83 : ['server/src/main/java/org/apache/druid/server/security/PreResponseAuthorizationCheckFilter.java', 'server/src/test/java/org/apache/druid/server/http/security/PreResponseAuthorizationCheckFilterTest.java']\n",
      "['processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java', 'processing/src/main/java/org/apache/druid/query/metadata/metadata/ColumnAnalysis.java', 'processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java', 'processing/src/test/java/org/apache/druid/query/metadata/metadata/ColumnAnalysisTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCache.java', 'sql/src/test/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCacheTest.java']\n",
      "d92b9fbfac977cd995d4d0ef9da6f3944f387fb1\n",
      "84 : ['processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java', 'processing/src/main/java/org/apache/druid/query/metadata/metadata/ColumnAnalysis.java', 'processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java', 'processing/src/test/java/org/apache/druid/query/metadata/metadata/ColumnAnalysisTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCache.java', 'sql/src/test/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCacheTest.java']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1080:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\python39\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\python39\\lib\\subprocess.py\", line 1479, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "UnicodeDecodeError: 'cp949' codec can't decode byte 0xe2 in position 225: illegal multibyte sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Write \n",
      "['processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java']\n",
      "96a3c00754223626ff1df3799522277a086ec0a1\n",
      "85 : ['processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/common/TaskLockType.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java']\n",
      "e9913abbbfed82c11d1f876f30f24a768267ab48\n",
      "86 : ['indexing-service/src/main/java/org/apache/druid/indexing/common/TaskLockType.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/DurableStorageCleaner.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/config/TaskConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/DutySchedule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDuty.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutor.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleaner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfig.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutorTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfigTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java', 'processing/src/main/java/org/apache/druid/common/config/Configs.java', 'processing/src/main/java/org/apache/druid/tasklogs/TaskLogKiller.java', 'processing/src/test/java/org/apache/druid/common/config/ConfigsTest.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfig.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfigTest.java', 'services/src/main/java/org/apache/druid/cli/CliOverlord.java']\n",
      "ba11b3d462220c9470f434242e657cc7ce877d9c\n",
      "87 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/DurableStorageCleaner.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java', 'indexing-service/src/main/java/org/apache/druid/indexing/common/config/TaskConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/DutySchedule.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDuty.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutor.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleaner.java', 'indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfig.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutorTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfigTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java', 'processing/src/main/java/org/apache/druid/common/config/Configs.java', 'processing/src/main/java/org/apache/druid/tasklogs/TaskLogKiller.java', 'processing/src/test/java/org/apache/druid/common/config/ConfigsTest.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java', 'server/src/main/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfig.java', 'server/src/test/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfigTest.java', 'services/src/main/java/org/apache/druid/cli/CliOverlord.java']\n",
      "['processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/TestHelper.java']\n",
      "9875090bee7f98e2467c0b2fa45ca3a3121b90c8\n",
      "88 : ['processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/TestHelper.java']\n",
      "['processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java', 'processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteJoinQueryTest.java']\n",
      "f128b9b666abe096c64058db374c974cc16085b3\n",
      "89 : ['processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java', 'processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteJoinQueryTest.java']\n",
      "['processing/src/main/java/org/apache/druid/audit/AuditInfo.java', 'processing/src/test/java/org/apache/druid/audit/AuditInfoTest.java', 'server/src/main/java/org/apache/druid/metadata/MetadataRuleManagerConfig.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataRuleManager.java', 'server/src/main/java/org/apache/druid/server/http/RulesResource.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataRuleManagerTest.java', 'server/src/test/java/org/apache/druid/server/audit/SQLAuditManagerTest.java']\n",
      "64e6283eca37e3197224da23bc71a5d12a190122\n",
      "90 : ['processing/src/main/java/org/apache/druid/audit/AuditInfo.java', 'processing/src/test/java/org/apache/druid/audit/AuditInfoTest.java', 'server/src/main/java/org/apache/druid/metadata/MetadataRuleManagerConfig.java', 'server/src/main/java/org/apache/druid/metadata/SQLMetadataRuleManager.java', 'server/src/main/java/org/apache/druid/server/http/RulesResource.java', 'server/src/test/java/org/apache/druid/metadata/SQLMetadataRuleManagerTest.java', 'server/src/test/java/org/apache/druid/server/audit/SQLAuditManagerTest.java']\n",
      "['indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java']\n",
      "47e48ee65710719c6af1605fedf7a5063c83cc38\n",
      "91 : ['indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java', 'indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/query/NestedDataTestUtils.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java']\n",
      "aaaff747409729ce11dc81e2de75eb6faa0fed76\n",
      "92 : ['processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/query/NestedDataTestUtils.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/external/ExternalInputSliceReader.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/DimensionSchemaUtils.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java']\n",
      "625c4745b120e996494ef364abc5a8f58a00f98f\n",
      "93 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/external/ExternalInputSliceReader.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/DimensionSchemaUtils.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java', 'extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java']\n",
      "['extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/PodTemplateTaskAdapterTest.java']\n",
      "161d12eb445e3f2123020a7d82beea9cd5bb7182\n",
      "94 : ['extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/PodTemplateTaskAdapterTest.java']\n",
      "['processing/src/main/java/org/apache/druid/math/expr/Evals.java', 'processing/src/main/java/org/apache/druid/math/expr/ExprEval.java', 'processing/src/main/java/org/apache/druid/math/expr/ExpressionType.java', 'processing/src/main/java/org/apache/druid/math/expr/Function.java', 'processing/src/main/java/org/apache/druid/math/expr/vector/VectorProcessors.java', 'processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/DoubleVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/FloatVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/LongVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnMerger.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnSchema.java', 'processing/src/main/java/org/apache/druid/segment/column/ColumnBuilder.java', 'processing/src/main/java/org/apache/druid/segment/column/ColumnType.java', 'processing/src/main/java/org/apache/druid/segment/column/RowSignature.java', 'processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/column/StringFrontCodedDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/data/ComparableList.java', 'processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java', 'processing/src/main/java/org/apache/druid/segment/filter/ExpressionFilter.java', 'processing/src/main/java/org/apache/druid/segment/nested/CompressedNestedDataComplexColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/GlobalDictionaryEncodedFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnV5.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataComplexColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ValueDictionary.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantArrayColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantArrayFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/serde/NestedCommonFormatColumnPartSerde.java', 'processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/math/expr/EvalTest.java', 'processing/src/test/java/org/apache/druid/math/expr/FunctionTest.java', 'processing/src/test/java/org/apache/druid/math/expr/VectorExprSanityTest.java', 'processing/src/test/java/org/apache/druid/query/aggregation/AggregationTestHelper.java', 'processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java', 'processing/src/test/java/org/apache/druid/query/filter/vector/VectorValueMatcherColumnProcessorFactoryTest.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedGroupByArrayQueryTest.java', 'processing/src/test/java/org/apache/druid/query/scan/NestedDataScanQueryTest.java', 'processing/src/test/java/org/apache/druid/segment/AutoTypeColumnIndexerTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/IndexIONullColumnsCompatibilityTest.java', 'processing/src/test/java/org/apache/druid/segment/NestedDataColumnIndexerTest.java', 'processing/src/test/java/org/apache/druid/segment/TestHelper.java', 'processing/src/test/java/org/apache/druid/segment/column/ColumnTypeTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/ColumnComparisonFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/ExpressionFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinTestHelper.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierV4Test.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarDoubleColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarLongColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/VariantColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/virtual/ExpressionPlannerTest.java', 'services/src/test/java/org/apache/druid/cli/DumpSegmentTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/DruidExpression.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/Expressions.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayAppendOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayOffsetOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/CastOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java']\n",
      "8805d8d7db61c892c62981e7eec00c6b6037e16d\n",
      "95 : ['processing/src/main/java/org/apache/druid/math/expr/Evals.java', 'processing/src/main/java/org/apache/druid/math/expr/ExprEval.java', 'processing/src/main/java/org/apache/druid/math/expr/ExpressionType.java', 'processing/src/main/java/org/apache/druid/math/expr/Function.java', 'processing/src/main/java/org/apache/druid/math/expr/vector/VectorProcessors.java', 'processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/DoubleVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/FloatVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/query/filter/vector/LongVectorValueMatcher.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnMerger.java', 'processing/src/main/java/org/apache/druid/segment/AutoTypeColumnSchema.java', 'processing/src/main/java/org/apache/druid/segment/column/ColumnBuilder.java', 'processing/src/main/java/org/apache/druid/segment/column/ColumnType.java', 'processing/src/main/java/org/apache/druid/segment/column/RowSignature.java', 'processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/column/StringFrontCodedDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/data/ComparableList.java', 'processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java', 'processing/src/main/java/org/apache/druid/segment/filter/ExpressionFilter.java', 'processing/src/main/java/org/apache/druid/segment/nested/CompressedNestedDataComplexColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/GlobalDictionaryEncodedFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnV5.java', 'processing/src/main/java/org/apache/druid/segment/nested/NestedDataComplexColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarLongFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/ScalarStringFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/ValueDictionary.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantArrayColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantArrayFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumn.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumnAndIndexSupplier.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantColumnSerializer.java', 'processing/src/main/java/org/apache/druid/segment/nested/VariantFieldColumnWriter.java', 'processing/src/main/java/org/apache/druid/segment/serde/NestedCommonFormatColumnPartSerde.java', 'processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java', 'processing/src/test/java/org/apache/druid/math/expr/EvalTest.java', 'processing/src/test/java/org/apache/druid/math/expr/FunctionTest.java', 'processing/src/test/java/org/apache/druid/math/expr/VectorExprSanityTest.java', 'processing/src/test/java/org/apache/druid/query/aggregation/AggregationTestHelper.java', 'processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java', 'processing/src/test/java/org/apache/druid/query/filter/vector/VectorValueMatcherColumnProcessorFactoryTest.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java', 'processing/src/test/java/org/apache/druid/query/groupby/NestedGroupByArrayQueryTest.java', 'processing/src/test/java/org/apache/druid/query/scan/NestedDataScanQueryTest.java', 'processing/src/test/java/org/apache/druid/segment/AutoTypeColumnIndexerTest.java', 'processing/src/test/java/org/apache/druid/segment/IndexBuilder.java', 'processing/src/test/java/org/apache/druid/segment/IndexIONullColumnsCompatibilityTest.java', 'processing/src/test/java/org/apache/druid/segment/NestedDataColumnIndexerTest.java', 'processing/src/test/java/org/apache/druid/segment/TestHelper.java', 'processing/src/test/java/org/apache/druid/segment/column/ColumnTypeTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/ColumnComparisonFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/filter/ExpressionFilterTest.java', 'processing/src/test/java/org/apache/druid/segment/join/JoinTestHelper.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierV4Test.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarDoubleColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/ScalarLongColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/nested/VariantColumnSupplierTest.java', 'processing/src/test/java/org/apache/druid/segment/virtual/ExpressionPlannerTest.java', 'services/src/test/java/org/apache/druid/cli/DumpSegmentTest.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/DruidExpression.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/Expressions.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayAppendOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayOffsetOperatorConversion.java', 'sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/CastOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extensions-contrib/graphite-emitter/src/main/java/org/apache/druid/emitter/graphite/DruidToGraphiteEventConverter.java']\n",
      "3c62c00d4c86ff002480a28c917afd4bc8dd3451\n",
      "96 : ['extensions-contrib/graphite-emitter/src/main/java/org/apache/druid/emitter/graphite/DruidToGraphiteEventConverter.java']\n",
      "['processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java', 'server/src/main/java/org/apache/druid/server/QueryScheduler.java', 'server/src/test/java/org/apache/druid/server/QueryResourceTest.java', 'server/src/test/java/org/apache/druid/server/QuerySchedulerTest.java']\n",
      "a7a4bfd331e320d8925e6f39fdc4861319e5b8bd\n",
      "97 : ['processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java', 'server/src/main/java/org/apache/druid/server/QueryScheduler.java', 'server/src/test/java/org/apache/druid/server/QueryResourceTest.java', 'server/src/test/java/org/apache/druid/server/QuerySchedulerTest.java']\n",
      "['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/CaseOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "4d8feeb279cc144998e06bd2c9ab30044a77862b\n",
      "98 : ['sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/CaseOperatorConversion.java', 'sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java']\n",
      "['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQWorkerTaskLauncher.java']\n",
      "fb38085ddbb439974325b230739e129ebcbf9ba1\n",
      "99 : ['extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java', 'extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQWorkerTaskLauncher.java']\n",
      "['extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/ParseExceptionReport.java']\n",
      "46dabab36dc86d307f3c96bee5b833dfe7be124e\n",
      "100 : ['extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java', 'indexing-service/src/test/java/org/apache/druid/indexing/common/task/ParseExceptionReport.java']\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for commit in json_data:        \n",
    "    files = []\n",
    "    commit['changed_file_list'] = []\n",
    "    \n",
    "    if cnt >= max_commit:\n",
    "        break\n",
    "    \n",
    "    changed_file_list = subprocess.run(['git', 'show', commit['commitHash'], '--name-only', '--pretty=format:%b'], capture_output=True, text=True)\n",
    "    if changed_file_list.returncode == 0 and changed_file_list.stdout:\n",
    "        lines = changed_file_list.stdout.split('\\n')\n",
    "        # Process the rest of the code using the 'lines' variable\n",
    "    else:\n",
    "        # Handle the case when the Git command didn't execute successfully\n",
    "        print(\"Failed to get the changed file list.\")\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.strip() in commit['body']:\n",
    "            continue\n",
    "        elif line.strip() != '':\n",
    "            files.append(line.strip())\n",
    "            \n",
    "    is_all_java = all(file.endswith('.java') for file in files)\n",
    "    \n",
    "    if is_all_java and files != []:\n",
    "        diff = subprocess.run(['git', 'show', commit['commitHash'], '-p'], capture_output=True, text=True)\n",
    "        commit['changed_file_list'] = files\n",
    "        print(files)\n",
    "        cnt += 1\n",
    "        print(commit['commitHash'])\n",
    "        print(cnt, \":\", commit['changed_file_list'])\n",
    "        \n",
    "        file_path = os.path.join('commits', f'{cnt}_diff.txt')\n",
    "        write_checkout_file(file_path, diff.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df86238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTuningConfigTest.java\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTuningConfigTest.java\n",
      "extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskTuningConfigTest.java\n",
      "extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTuningConfigTest.java\n",
      "server/src/main/java/org/apache/druid/segment/indexing/RealtimeTuningConfig.java\n",
      "server/src/test/java/org/apache/druid/segment/indexing/RealtimeTuningConfigTest.java\n",
      "2\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/CalciteSelectJoinQueryMSQTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java\n",
      "processing/src/main/java/org/apache/druid/error/Forbidden.java\n",
      "processing/src/main/java/org/apache/druid/error/QueryExceptionCompat.java\n",
      "processing/src/main/java/org/apache/druid/query/QueryContext.java\n",
      "processing/src/test/java/org/apache/druid/error/ForbiddenTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/run/NativeSqlEngine.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/run/SqlEngines.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/view/ViewSqlEngine.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/IngestionTestSqlEngine.java\n",
      "3\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java\n",
      "4\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/ImmutableWorkerInfo.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/ZkWorker.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/autoscaling/PendingTaskBasedWorkerProvisioningStrategy.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerRunPendingTasksConcurrencyTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/RemoteTaskRunnerTestUtils.java\n",
      "5\n",
      "processing/src/main/java/org/apache/druid/collections/StupidPool.java\n",
      "processing/src/main/java/org/apache/druid/query/operator/LimitTimeIntervalOperator.java\n",
      "processing/src/main/java/org/apache/druid/query/operator/WindowOperatorQueryQueryRunnerFactory.java\n",
      "processing/src/main/java/org/apache/druid/query/rowsandcols/LazilyDecoratedRowsAndColumns.java\n",
      "processing/src/main/java/org/apache/druid/query/rowsandcols/RowsAndColumns.java\n",
      "processing/src/main/java/org/apache/druid/query/rowsandcols/SemanticCreator.java\n",
      "processing/src/main/java/org/apache/druid/query/rowsandcols/concrete/QueryableIndexRowsAndColumns.java\n",
      "processing/src/main/java/org/apache/druid/query/rowsandcols/semantic/DefaultNaiveSortMaker.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexBuilder.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/DrillWindowQueryTest.java\n",
      "6\n",
      "processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarDoublesSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarFloatsSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/BlockLayoutColumnarLongsSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/CompressedColumnarIntsSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/CompressedVSizeColumnarIntsSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/DecompressingByteBufferObjectStrategy.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java\n",
      "7\n",
      "processing/src/main/java/org/apache/druid/query/aggregation/AggregatorFactory.java\n",
      "8\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactory.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/DoublesSketchAggregatorFactoryTest.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/TestDoublesSketchColumnValueSelector.java\n",
      "9\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerStorageParameters.java\n",
      "10\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildAggregatorFactory.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildBufferAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchBuildColumnProcessorFactory.java\n",
      "File Open :\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchUpdater.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\n",
      "11\n",
      "processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java\n",
      "server/src/main/java/org/apache/druid/metadata/UnknownSegmentIdsException.java\n",
      "12\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java\n",
      "13\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/groupby/GroupByQueryKit.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "14\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/CounterSnapshotsTree.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/counters/SegmentGeneratorMetricsWrapper.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Controller.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/MSQTasks.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerImpl.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQIndexingModule.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerControllerContext.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/IndexerWorkerContext.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSpec.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleaner.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/cleaner/DurableStorageCleanerConfig.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/ControllerChatHandler.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerControllerClient.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerClient.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/IndexerWorkerManagerClient.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/client/WorkerChatHandler.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DataSourceMSQDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/DurableStorageMSQDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/MSQSelectDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/destination/TaskReportMSQDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/KeyStatisticsCollectionProcessor.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessor.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/processor/SegmentGeneratorFrameProcessorFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/kernel/StageDefinition.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultFrameProcessorFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessor.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageInputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageQueryResultsInputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/DurableStorageStageInputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/input/WorkerInputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageOutputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageQueryResultsOutputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/shuffle/output/DurableStorageTaskOutputChannelFactory.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQParseExceptionsTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DataSourceMSQDestinationTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/WorkerChatHandlerTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/results/QueryResultsFrameProcessorTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/shuffle/DurableStorageOutputChannelFactoryTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMSQStatementResourcePostTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java\n",
      "processing/src/main/java/org/apache/druid/frame/util/DurableStorageUtils.java\n",
      "processing/src/main/java/org/apache/druid/storage/NilStorageConnector.java\n",
      "processing/src/test/java/org/apache/druid/frame/util/DurableStorageUtilsTest.java\n",
      "processing/src/test/java/org/apache/druid/storage/NilStorageConnectorTest.java\n",
      "15\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/Stats.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockConfigTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueScaleTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskQueueTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java\n",
      "server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsMonitor.java\n",
      "server/src/main/java/org/apache/druid/server/metrics/TaskCountStatsProvider.java\n",
      "server/src/main/java/org/apache/druid/server/metrics/TaskSlotCountStatsProvider.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java\n",
      "server/src/test/java/org/apache/druid/server/metrics/TaskCountStatsMonitorTest.java\n",
      "16\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/WorkerHolder.java\n",
      "server/src/main/java/org/apache/druid/client/HttpServerInventoryView.java\n",
      "server/src/main/java/org/apache/druid/server/coordination/ChangeRequestHttpSyncer.java\n",
      "17\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java\n",
      "18\n",
      "processing/src/main/java/org/apache/druid/segment/column/ColumnSignature.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java\n",
      "19\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/RemoteTaskRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/WorkerTaskRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunner.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/hrtr/HttpRemoteTaskRunnerTest.java\n",
      "20\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtils.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidPlanner.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/IngestHandler.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteReplaceDmlTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/parser/DruidSqlParserUtilsTest.java\n",
      "21\n",
      "indexing-hadoop/src/test/java/org/apache/druid/indexer/DetermineHashedPartitionsJobTest.java\n",
      "processing/src/main/java/org/apache/druid/java/util/common/granularity/Granularity.java\n",
      "processing/src/main/java/org/apache/druid/java/util/common/granularity/IntervalsByGranularity.java\n",
      "processing/src/main/java/org/apache/druid/java/util/common/granularity/PeriodGranularity.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server/src/test/java/org/apache/druid/segment/indexing/granularity/UniformGranularityTest.java\n",
      "22\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/external/ExternalOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteInsertDmlTest.java\n",
      "23\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java\n",
      "24\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java\n",
      "25\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/PageInformation.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java\n",
      "26\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/run/NativeQueryMaker.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteScanSignatureTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java\n",
      "27\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/Limits.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerMemoryParameters.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/TooManyRowsWithSameKeyFault.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/BroadcastJoinHelper.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessor.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorFactory.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/WorkerMemoryParametersTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/querykit/common/SortMergeJoinFrameProcessorTest.java\n",
      "28\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertTimeOutOfBoundsFault.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQFaultsTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/error/MSQFaultSerdeTest.java\n",
      "29\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java\n",
      "server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java\n",
      "30\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/querykit/DataSourcePlan.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "processing/src/main/java/org/apache/druid/query/DataSource.java\n",
      "processing/src/main/java/org/apache/druid/query/UnionQueryRunner.java\n",
      "processing/src/main/java/org/apache/druid/query/planning/DataSourceAnalysis.java\n",
      "processing/src/test/java/org/apache/druid/query/planning/DataSourceAnalysisTest.java\n",
      "server/src/main/java/org/apache/druid/server/ClientQuerySegmentWalker.java\n",
      "server/src/test/java/org/apache/druid/server/TestClusterQuerySegmentWalker.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java\n",
      "31\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java\n",
      "32\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/expression/ExpressionsTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTestInjectorBuilder.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/QueryFrameworkUtils.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/AssertionErrorOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/testoperator/CalciteTestOperatorModule.java\n",
      "sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java\n",
      "33\n",
      "extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceAggregatorFactory.java\n",
      "extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/sql/BaseVarianceSqlAggregator.java\n",
      "extensions-core/stats/src/test/java/org/apache/druid/query/aggregation/variance/sql/VarianceSqlAggregatorTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/table/RowSignatures.java\n",
      "34\n",
      "processing/src/main/java/org/apache/druid/common/config/NullHandling.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/StringUtf8DictionaryEncodedColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/CachingIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnAndIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java\n",
      "File Open :\n",
      "processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarInts.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiInts.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedInts.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedColumnSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/DictionaryEncodedStringIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/DoubleNumericColumnPartSerdeV2.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/FloatNumericColumnPartSerdeV2.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/LongNumericColumnPartSerdeV2.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedColumnIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/StringFrontCodedDictionaryEncodedColumnSupplier.java\n",
      "processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexBuilder.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexMergerNullHandlingTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/ScalarStringColumnSupplierTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoEntriesIndexedTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarIntsTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesColumnarMultiIntsTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/CombineFirstTwoValuesIndexedIntsTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/ReplaceFirstValueWithNullIndexedTest.java\n",
      "35\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQSelectDestination.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/report/MSQResultsReport.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java\n",
      "integration-tests/src/main/java/org/apache/druid/testing/utils/MsqTestQueryHelper.java\n",
      "36\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/SqlTaskModule.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQControllerTask.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/error/InsertCannotBeEmptyFault.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskQueryMaker.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/MSQTaskSqlEngine.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlStatementState.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypes.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/ResultSetInformation.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/entity/SqlStatementResult.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlStatementResource.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/resources/SqlTaskResource.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/SqlStatementResourceHelper.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/MSQControllerTaskTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/report/MSQTaskReportTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlMsqStatementResourcePostTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlStatementResourceTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ColumnNameAndTypesTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/ResultSetInformationTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/entity/SqlStatementResultTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestOverlordServiceClient.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java\n",
      "processing/src/main/java/org/apache/druid/error/DruidException.java\n",
      "processing/src/main/java/org/apache/druid/query/ExecutionMode.java\n",
      "processing/src/main/java/org/apache/druid/query/QueryContexts.java\n",
      "processing/src/test/java/org/apache/druid/query/QueryContextsTest.java\n",
      "server/src/main/java/org/apache/druid/rpc/indexing/OverlordClient.java\n",
      "server/src/main/java/org/apache/druid/rpc/indexing/OverlordClientImpl.java\n",
      "server/src/test/java/org/apache/druid/client/indexing/NoopOverlordClient.java\n",
      "server/src/test/java/org/apache/druid/rpc/indexing/OverlordClientImplTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/DirectStatement.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/util/CalciteTests.java\n",
      "sql/src/test/java/org/apache/druid/sql/http/SqlResourceTest.java\n",
      "37\n",
      "processing/src/test/java/org/apache/druid/audit/TestAuditManager.java\n",
      "processing/src/test/java/org/apache/druid/common/config/ConfigManagerTest.java\n",
      "processing/src/test/java/org/apache/druid/common/config/TestConfigManagerConfig.java\n",
      "processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageConnector.java\n",
      "processing/src/test/java/org/apache/druid/metadata/TestMetadataStorageTablesConfig.java\n",
      "38\n",
      "processing/src/main/java/org/apache/druid/query/aggregation/FilteredAggregator.java\n",
      "processing/src/test/java/org/apache/druid/query/aggregation/FilteredAggregatorTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestNullableDoubleColumnSelector.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestNullableFloatColumnSelector.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestNullableLongColumnSelector.java\n",
      "processing/src/test/java/org/apache/druid/segment/WrappingDimensionSelectorTest.java\n",
      "39\n",
      "processing/src/test/java/org/apache/druid/common/guava/GuavaUtilsTest.java\n",
      "40\n",
      "processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java\n",
      "processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/TypeSignature.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializerV4.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedPathFinder.java\n",
      "processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java\n",
      "processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/NestedPathFinderTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/NestedDataOperatorConversions.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java\n",
      "41\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteQueryTest.java\n",
      "42\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/WorkerSketchFetcher.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQReplaceTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQSelectTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java\n",
      "43\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/run/SqlResults.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteMultiValueStringQueryTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/run/SqlResultsTest.java\n",
      "44\n",
      "processing/src/test/java/org/apache/druid/java/util/emitter/core/HttpEmitterConfigTest.java\n",
      "processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java\n",
      "45\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchApproxCountDistinctSqlAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateWithErrorBoundsOperatorConversion.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchObjectSqlAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchApproxQuantileSqlAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchObjectSqlAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchApproxCountDistinctSqlAggregator.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchObjectSqlAggregator.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/quantiles/sql/DoublesSketchSqlAggregatorTest.java\n",
      "extensions-core/testing-tools/src/main/java/org/apache/druid/query/sql/SleepOperatorConversion.java\n",
      "integration-tests-ex/tools/src/main/java/org/apache/druid/testing/tools/SleepOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/OperatorConversions.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/BTrimOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ContainsOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/DateTruncOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LPadOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/LTrimOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ParseLongOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RPadOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RTrimOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpExtractOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RegexpLikeOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/RoundOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/SubstringOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TextcatOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeCeilOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeExtractOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFloorOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeFormatOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeParseOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TimeShiftOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/TruncateOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/expression/OperatorConversionsTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidOperatorTableTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/planner/DruidRexExecutorTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/schema/InformationSchemaTest.java\n",
      "46\n",
      "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/ServerSideEncryptingAmazonS3.java\n",
      "extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/output/S3StorageConnectorTest.java\n",
      "47\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskResource.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/sql/SqlTaskStatus.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/sql/SqlTaskStatusTest.java\n",
      "processing/src/main/java/org/apache/druid/error/DruidException.java\n",
      "processing/src/main/java/org/apache/druid/query/BadQueryException.java\n",
      "48\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/input/DruidSegmentReaderTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/input/InputRowSchemasTest.java\n",
      "processing/src/test/java/org/apache/druid/common/config/NullHandlingTest.java\n",
      "processing/src/test/java/org/apache/druid/query/scan/MultiSegmentScanQueryTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/join/lookup/LookupJoinableTest.java\n",
      "49\n",
      "server/src/main/java/org/apache/druid/server/QueryLifecycle.java\n",
      "server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java\n",
      "50\n",
      "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java\n",
      "51\n",
      "sql/src/main/java/org/apache/calcite/plan/volcano/DruidVolcanoCost.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/CalciteRulesManager.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/DruidQueryGenerator.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerConfig.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/PlannerFactory.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/planner/QueryHandler.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/CostEstimates.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/PartialDruidQuery.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidAggregate.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidFilter.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalConvention.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidLogicalNode.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidProject.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidSort.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidTableScan.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rel/logical/DruidValues.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/DruidLogicalValuesRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateCaseToFilterRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidAggregateRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidFilterRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidLogicalRules.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidProjectRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidSortRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidTableScanRule.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/rule/logical/DruidValuesRule.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/BaseCalciteQueryTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/DecoupledPlanningCalciteQueryTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/QueryTestBuilder.java\n",
      "52\n",
      "benchmarks/src/test/java/org/apache/druid/server/coordinator/BalancerStrategyBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/server/coordinator/CachingCostBalancerStrategyBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java\n",
      "integration-tests-ex/cases/src/test/java/org/apache/druid/testsEx/utils/DruidClusterAdminClient.java\n",
      "integration-tests/src/main/java/org/apache/druid/testing/utils/DruidClusterAdminClient.java\n",
      "processing/src/main/java/org/apache/druid/query/DruidMetrics.java\n",
      "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/BalancerStrategy.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/CoordinatorDynamicConfig.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/CoordinatorStats.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/DruidCluster.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinatorRuntimeParams.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/ReplicationThrottler.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/SegmentReplicantLookup.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/ServerHolder.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerSegmentHolder.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyFactory.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyConfig.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyFactory.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/ClusterCostCache.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyFactory.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyFactory.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategy.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/RandomBalancerStrategyFactory.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSampler.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCache.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/ServerCostCache.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/TierSegmentBalancer.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/balancer/package-info.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/BalanceSegments.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStats.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/CompactSegments.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetrics.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/LogUsedSegments.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnused.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/RunRules.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/SegmentCompactionUtil.java\n",
      "File Open :\n",
      "server/src/main/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegments.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/CuratorLoadQueuePeon.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeon.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/LoadPeonCallback.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueuePeon.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/LoadQueueTaskMaster.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/ReplicationThrottler.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/RoundRobinServerSelector.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentAction.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentHolder.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadQueueManager.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentLoadingConfig.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCount.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicaCountMap.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentReplicationStatus.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/SegmentStatusInTier.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/loading/StrategicSegmentAssigner.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRule.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/DropRule.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/ForeverLoadRule.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/LoadRule.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/Rule.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/rules/SegmentActionHandler.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorRunStats.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/CoordinatorStat.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/Dimension.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/RowKey.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/stats/Stats.java\n",
      "server/src/main/java/org/apache/druid/server/http/CoordinatorDynamicConfigsResource.java\n",
      "server/src/main/java/org/apache/druid/server/http/CoordinatorResource.java\n",
      "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java\n",
      "server/src/main/java/org/apache/druid/server/http/MetadataResource.java\n",
      "server/src/main/java/org/apache/druid/server/http/SegmentListerResource.java\n",
      "server/src/test/java/org/apache/druid/segment/realtime/appenderator/TestUsedSegmentChecker.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsProfiler.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/BalanceSegmentsTester.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CoordinatorRunStatsTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CoordinatorStatsTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CuratorDruidCoordinatorTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/DruidClusterBuilder.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/DruidClusterTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/HttpLoadQueuePeonTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/RoundRobinServerSelectorTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/RunRulesTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/ServerHolderTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/BalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/CachingCostBalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/CostBalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/DiskNormalizedCostBalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/ReservoirSegmentSamplerTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/balancer/SegmentsCostCacheTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/BalanceSegmentsTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/CollectSegmentAndServerStatsTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/CompactSegmentsTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/EmitClusterStatsAndMetricsTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/MarkAsUnusedOvershadowedSegmentsTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/MarkOvershadowedSegmentsAsUnusedTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/NewestSegmentFirstPolicyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/RunRulesTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/duty/UnloadUnusedSegmentsTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/loading/HttpLoadQueuePeonTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/loading/LoadQueuePeonTester.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/rules/BroadcastDistributionRuleTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/rules/LoadRuleTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/BalancingStrategiesTest.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBaseTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/CoordinatorSimulationBuilder.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/RoundRobinAssignmentTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentBalancingTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingNegativeTest.java\n",
      "File Open :\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/SegmentLoadingTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/TestSegmentsMetadataManager.java\n",
      "server/src/test/java/org/apache/druid/server/http/CoordinatorDynamicConfigTest.java\n",
      "server/src/test/java/org/apache/druid/server/http/DataSourcesResourceTest.java\n",
      "server/src/test/java/org/apache/druid/server/http/MetadataResourceTest.java\n",
      "services/src/main/java/org/apache/druid/cli/CliCoordinator.java\n",
      "53\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunner.java\n",
      "54\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/MSQWorkerTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/Task.java\n",
      "55\n",
      "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java\n",
      "processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java\n",
      "56\n",
      "processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java\n",
      "processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java\n",
      "57\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/tuple/ArrayOfDoublesSketchMergeComplexMetricSerde.java\n",
      "58\n",
      "processing/src/main/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequence.java\n",
      "processing/src/test/java/org/apache/druid/java/util/common/guava/ParallelMergeCombiningSequenceTest.java\n",
      "59\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java\n",
      "60\n",
      "processing/src/main/java/org/apache/druid/utils/JvmUtils.java\n",
      "processing/src/test/java/org/apache/druid/java/util/emitter/core/ParametrizedUriEmitterConfigTest.java\n",
      "61\n",
      "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/data/input/kafkainput/KafkaInputReader.java\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/data/input/kafkainput/KafkaInputFormatTest.java\n",
      "processing/src/main/java/org/apache/druid/data/input/impl/MapInputRowParser.java\n",
      "62\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataSupervisorManager.java\n",
      "server/src/test/java/org/apache/druid/metadata/SQLMetadataSupervisorManagerTest.java\n",
      "63\n",
      "server/src/main/java/org/apache/druid/server/QueryLifecycle.java\n",
      "server/src/test/java/org/apache/druid/server/QueryLifecycleTest.java\n",
      "64\n",
      "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java\n",
      "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/output/S3StorageConnector.java\n",
      "processing/src/main/java/org/apache/druid/storage/local/LocalFileStorageConnector.java\n",
      "65\n",
      "extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorTest.java\n",
      "extensions-core/mysql-metadata-storage/src/main/java/org/apache/druid/metadata/storage/mysql/MySQLConnector.java\n",
      "extensions-core/mysql-metadata-storage/src/test/java/org/apache/druid/metadata/storage/mysql/MySQLConnectorTest.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexPhaseRunner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/HeapMemoryTaskStorage.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/MetadataTaskStorage.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskQueue.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/http/OverlordResource.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java\n",
      "processing/src/main/java/org/apache/druid/common/exception/DruidException.java\n",
      "processing/src/main/java/org/apache/druid/metadata/EntryExistsException.java\n",
      "processing/src/main/java/org/apache/druid/metadata/MetadataStorageConnectorConfig.java\n",
      "processing/src/test/java/org/apache/druid/common/exception/DruidExceptionTest.java\n",
      "processing/src/test/java/org/apache/druid/metadata/EntryExistsExceptionTest.java\n",
      "processing/src/test/java/org/apache/druid/metadata/MetadataStorageConnectorConfigTest.java\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataConnector.java\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java\n",
      "server/src/test/java/org/apache/druid/metadata/SQLMetadataConnectorTest.java\n",
      "server/src/test/java/org/apache/druid/metadata/SQLMetadataStorageActionHandlerTest.java\n",
      "66\n",
      "server/src/test/java/org/apache/druid/query/dimension/LookupDimensionSpecTest.java\n",
      "67\n",
      "processing/src/main/java/org/apache/druid/segment/AbstractIndex.java\n",
      "File Open :\n",
      "processing/src/main/java/org/apache/druid/segment/SimpleQueryableIndex.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/FixedIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/GenericIndexed.java\n",
      "processing/src/main/java/org/apache/druid/segment/incremental/IncrementalIndex.java\n",
      "68\n",
      "server/src/main/java/org/apache/druid/server/coordinator/CostBalancerStrategy.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/simulate/BlockingExecutorService.java\n",
      "69\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/HllSketchModule.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllPostAggExprMacros.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchEstimateOperatorConversion.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/SketchModule.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaPostAggMacros.java\n",
      "extensions-core/datasketches/src/main/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchEstimateOperatorConversion.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java\n",
      "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/theta/sql/ThetaSketchSqlAggregatorTest.java\n",
      "70\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "71\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "72\n",
      "services/src/main/java/org/apache/druid/server/router/TieredBrokerHostSelector.java\n",
      "73\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerConfig.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSource.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/RecordSupplierInputSourceTest.java\n",
      "74\n",
      "extensions-contrib/aliyun-oss-extensions/src/main/java/org/apache/druid/data/input/aliyun/OssInputSource.java\n",
      "extensions-contrib/aliyun-oss-extensions/src/test/java/org/apache/druid/data/input/aliyun/OssInputSourceTest.java\n",
      "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTask.java\n",
      "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaIndexTaskModule.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaSamplerSpec.java\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIndexTaskTest.java\n",
      "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaSamplerSpecTest.java\n",
      "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexTask.java\n",
      "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisIndexingServiceModule.java\n",
      "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpec.java\n",
      "extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisIndexTaskSerdeTest.java\n",
      "extensions-core/kinesis-indexing-service/src/test/java/org/apache/druid/indexing/kinesis/KinesisSamplerSpecTest.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/NilInputSource.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/external/NilInputSourceTest.java\n",
      "indexing-service/src/main/java/org/apache/druid/guice/IndexingServiceInputSourceModule.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AppenderatorDriverRealtimeIndexTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/ArchiveTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/MoveTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/RealtimeIndexTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/RestoreTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTask.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/input/DruidInputSource.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/input/GeneratorInputSource.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpec.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerModule.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/sampler/SamplerResource.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/task/ArchiveTaskTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/task/MoveTaskTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/task/RestoreTaskTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/PartialGenericSegmentMergeTaskTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/input/DruidInputSourceTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/input/GeneratorInputSourceTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/IndexTaskSamplerSpecTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/sampler/SamplerResourceTest.java\n",
      "server/src/main/java/org/apache/druid/client/indexing/SamplerSpec.java\n",
      "server/src/test/java/org/apache/druid/client/indexing/SamplerSpecTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteIngestionDmlTest.java\n",
      "75\n",
      "extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageAvailabilityChecker.java\n",
      "extensions-core/hdfs-storage/src/main/java/org/apache/druid/storage/hdfs/HdfsStorageDruidModule.java\n",
      "76\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientAsyncImpl.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/SeekableStreamIndexTaskClientSyncImpl.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/worker/executor/ExecutorLifecycle.java\n",
      "77\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyBenchmark.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CostBalancerStrategyTest.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CreateDataSegments.java\n",
      "78\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/table/TableInputSpecSlicer.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/input/table/TableInputSpecSlicerTest.java\n",
      "79\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocateRequest.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueue.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocateActionTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/common/actions/SegmentAllocationQueueTest.java\n",
      "80\n",
      "processing/src/main/java/org/apache/druid/math/expr/Exprs.java\n",
      "processing/src/main/java/org/apache/druid/query/expression/LookupExprMacro.java\n",
      "server/src/test/java/org/apache/druid/query/expression/LookupExprMacroTest.java\n",
      "81\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/FilterPartitionBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/FilteredAggregatorBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/GroupByTypeInterfaceBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/TopNTypeInterfaceBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IncrementalIndexReadBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexIngestionBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexMergeBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/indexing/IndexPersistBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/GroupByBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/ScanBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/SearchBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/TimeseriesBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/TopNBenchmark.java\n",
      "benchmarks/src/test/java/org/apache/druid/benchmark/query/timecompare/TimeCompareBenchmark.java\n",
      "extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramDruidModule.java\n",
      "extensions-core/histogram/src/main/java/org/apache/druid/query/aggregation/histogram/ApproximateHistogramFoldingSerde.java\n",
      "extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/stats/DruidStatsModule.java\n",
      "extensions-core/stats/src/main/java/org/apache/druid/query/aggregation/variance/VarianceSerde.java\n",
      "processing/src/main/java/org/apache/druid/jackson/AggregatorsModule.java\n",
      "processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/HyperUniquesSerde.java\n",
      "processing/src/main/java/org/apache/druid/query/aggregation/hyperloglog/PreComputedHyperUniquesSerde.java\n",
      "processing/src/test/java/org/apache/druid/frame/write/FrameWriterTest.java\n",
      "processing/src/test/java/org/apache/druid/frame/write/FrameWritersTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/SchemalessIndexTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestIndex.java\n",
      "processing/src/test/java/org/apache/druid/segment/generator/SegmentGenerator.java\n",
      "processing/src/test/java/org/apache/druid/segment/serde/ComplexMetricsTest.java\n",
      "82\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesOverlordModule.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycle.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactory.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/KubernetesWorkItem.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/DruidKubernetesClient.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClient.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/main/java/org/apache/druid/k8s/overlord/common/LogWatchInputStream.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Open :\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesPeonLifecycleTest.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesTaskRunnerFactoryTest.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/KubernetesWorkItemTest.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/KubernetesPeonClientTest.java\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/LogWatchInputStreamTest.java\n",
      "File Open :\n",
      "83\n",
      "server/src/main/java/org/apache/druid/server/security/PreResponseAuthorizationCheckFilter.java\n",
      "server/src/test/java/org/apache/druid/server/http/security/PreResponseAuthorizationCheckFilterTest.java\n",
      "84\n",
      "processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java\n",
      "processing/src/main/java/org/apache/druid/query/metadata/metadata/ColumnAnalysis.java\n",
      "processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java\n",
      "processing/src/test/java/org/apache/druid/query/metadata/metadata/ColumnAnalysisTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCache.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/schema/SegmentMetadataCacheTest.java\n",
      "85\n",
      "processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java\n",
      "processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java\n",
      "86\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/TaskLockType.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java\n",
      "87\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/guice/MSQDurableStorageModule.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/indexing/DurableStorageCleaner.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/indexing/DurableStorageCleanerTest.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/common/config/TaskConfig.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskMaster.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/config/TaskQueueConfig.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/DutySchedule.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDuty.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutor.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleaner.java\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfig.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/OverlordDutyExecutorTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerConfigTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/duty/TaskLogAutoCleanerTest.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/http/OverlordTest.java\n",
      "processing/src/main/java/org/apache/druid/common/config/Configs.java\n",
      "processing/src/main/java/org/apache/druid/tasklogs/TaskLogKiller.java\n",
      "processing/src/test/java/org/apache/druid/common/config/ConfigsTest.java\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataStorageActionHandler.java\n",
      "server/src/main/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfig.java\n",
      "server/src/test/java/org/apache/druid/server/coordinator/CoordinatorOverlordServiceConfigTest.java\n",
      "services/src/main/java/org/apache/druid/cli/CliOverlord.java\n",
      "88\n",
      "processing/src/main/java/org/apache/druid/query/metadata/SegmentAnalyzer.java\n",
      "processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java\n",
      "processing/src/test/java/org/apache/druid/query/metadata/SegmentAnalyzerTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexBuilder.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestHelper.java\n",
      "89\n",
      "processing/src/main/java/org/apache/druid/segment/join/JoinableFactoryWrapper.java\n",
      "processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java\n",
      "processing/src/test/java/org/apache/druid/segment/join/JoinableFactoryWrapperTest.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteJoinQueryTest.java\n",
      "90\n",
      "processing/src/main/java/org/apache/druid/audit/AuditInfo.java\n",
      "processing/src/test/java/org/apache/druid/audit/AuditInfoTest.java\n",
      "server/src/main/java/org/apache/druid/metadata/MetadataRuleManagerConfig.java\n",
      "server/src/main/java/org/apache/druid/metadata/SQLMetadataRuleManager.java\n",
      "server/src/main/java/org/apache/druid/server/http/RulesResource.java\n",
      "server/src/test/java/org/apache/druid/metadata/SQLMetadataRuleManagerTest.java\n",
      "server/src/test/java/org/apache/druid/server/audit/SQLAuditManagerTest.java\n",
      "91\n",
      "indexing-service/src/main/java/org/apache/druid/indexing/overlord/TaskLockbox.java\n",
      "indexing-service/src/test/java/org/apache/druid/indexing/overlord/TaskLockboxTest.java\n",
      "92\n",
      "processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java\n",
      "processing/src/test/java/org/apache/druid/query/NestedDataTestUtils.java\n",
      "processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java\n",
      "93\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/exec/ControllerImpl.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/input/external/ExternalInputSliceReader.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/DimensionSchemaUtils.java\n",
      "extensions-core/multi-stage-query/src/main/java/org/apache/druid/msq/util/MultiStageQueryContext.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/exec/MSQInsertTest.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/test/MSQTestBase.java\n",
      "extensions-core/multi-stage-query/src/test/java/org/apache/druid/msq/util/MultiStageQueryContextTest.java\n",
      "94\n",
      "extensions-contrib/kubernetes-overlord-extensions/src/test/java/org/apache/druid/k8s/overlord/common/PodTemplateTaskAdapterTest.java\n",
      "95\n",
      "processing/src/main/java/org/apache/druid/math/expr/Evals.java\n",
      "processing/src/main/java/org/apache/druid/math/expr/ExprEval.java\n",
      "processing/src/main/java/org/apache/druid/math/expr/ExpressionType.java\n",
      "processing/src/main/java/org/apache/druid/math/expr/Function.java\n",
      "processing/src/main/java/org/apache/druid/math/expr/vector/VectorProcessors.java\n",
      "processing/src/main/java/org/apache/druid/query/expression/NestedDataExpressions.java\n",
      "processing/src/main/java/org/apache/druid/query/filter/vector/DoubleVectorValueMatcher.java\n",
      "processing/src/main/java/org/apache/druid/query/filter/vector/FloatVectorValueMatcher.java\n",
      "processing/src/main/java/org/apache/druid/query/filter/vector/LongVectorValueMatcher.java\n",
      "processing/src/main/java/org/apache/druid/segment/AutoTypeColumnIndexer.java\n",
      "processing/src/main/java/org/apache/druid/segment/AutoTypeColumnMerger.java\n",
      "processing/src/main/java/org/apache/druid/segment/AutoTypeColumnSchema.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/ColumnBuilder.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/ColumnType.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/RowSignature.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/StringDictionaryEncodedColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/column/StringFrontCodedDictionaryEncodedColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/data/ComparableList.java\n",
      "processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java\n",
      "processing/src/main/java/org/apache/druid/segment/filter/ExpressionFilter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/CompressedNestedDataComplexColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/GlobalDictionaryEncodedFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedCommonFormatColumnSerializer.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedDataColumnV5.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/NestedDataComplexColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnAndIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarDoubleFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnAndIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarLongColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarLongFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringDictionaryEncodedColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ScalarStringFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/ValueDictionary.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantArrayColumn.java\n",
      "File Open :\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantArrayFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantColumn.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantColumnAndIndexSupplier.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantColumnSerializer.java\n",
      "processing/src/main/java/org/apache/druid/segment/nested/VariantFieldColumnWriter.java\n",
      "processing/src/main/java/org/apache/druid/segment/serde/NestedCommonFormatColumnPartSerde.java\n",
      "processing/src/main/java/org/apache/druid/segment/virtual/NestedFieldVirtualColumn.java\n",
      "processing/src/test/java/org/apache/druid/math/expr/EvalTest.java\n",
      "processing/src/test/java/org/apache/druid/math/expr/FunctionTest.java\n",
      "processing/src/test/java/org/apache/druid/math/expr/VectorExprSanityTest.java\n",
      "processing/src/test/java/org/apache/druid/query/aggregation/AggregationTestHelper.java\n",
      "processing/src/test/java/org/apache/druid/query/expression/NestedDataExpressionsTest.java\n",
      "processing/src/test/java/org/apache/druid/query/filter/vector/VectorValueMatcherColumnProcessorFactoryTest.java\n",
      "processing/src/test/java/org/apache/druid/query/groupby/NestedDataGroupByQueryTest.java\n",
      "processing/src/test/java/org/apache/druid/query/groupby/NestedGroupByArrayQueryTest.java\n",
      "processing/src/test/java/org/apache/druid/query/scan/NestedDataScanQueryTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/AutoTypeColumnIndexerTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexBuilder.java\n",
      "processing/src/test/java/org/apache/druid/segment/IndexIONullColumnsCompatibilityTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/NestedDataColumnIndexerTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/TestHelper.java\n",
      "processing/src/test/java/org/apache/druid/segment/column/ColumnTypeTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/filter/BaseFilterTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/filter/ColumnComparisonFilterTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/filter/ExpressionFilterTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/join/JoinTestHelper.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/NestedDataColumnSupplierV4Test.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/ScalarDoubleColumnSupplierTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/ScalarLongColumnSupplierTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/nested/VariantColumnSupplierTest.java\n",
      "processing/src/test/java/org/apache/druid/segment/virtual/ExpressionPlannerTest.java\n",
      "services/src/test/java/org/apache/druid/cli/DumpSegmentTest.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/DruidExpression.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/Expressions.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayAppendOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/ArrayOffsetOperatorConversion.java\n",
      "sql/src/main/java/org/apache/druid/sql/calcite/expression/builtin/CastOperatorConversion.java\n",
      "sql/src/test/java/org/apache/druid/sql/calcite/CalciteNestedDataQueryTest.java\n",
      "96\n",
      "extensions-contrib/graphite-emitter/src/main/java/org/apache/druid/emitter/graphite/DruidToGraphiteEventConverter.java\n",
      "97\n",
      "processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java\n",
      "server/src/main/java/org/apache/druid/server/QueryScheduler.java\n",
      "server/src/test/java/org/apache/druid/server/QueryResourceTest.java\n",
      "server/src/test/java/org/apache/druid/server/QuerySchedulerTest.java\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for commit in json_data:\n",
    "    if cnt > max_commit:\n",
    "        break\n",
    "    elif commit['changed_file_list'] != []:\n",
    "        cnt += 1\n",
    "        print(cnt)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    for file in commit['changed_file_list']:\n",
    "        print(file)\n",
    "        \n",
    "        subprocess.run(['git', 'checkout', commit['commitHash'], '--', file])\n",
    "        after_content = read_checkout_file(file) \n",
    "        file_path = os.path.join('commits', f'{cnt}_after_{os.path.basename(file)}')\n",
    "        write_checkout_file(file_path, after_content)\n",
    "        \n",
    "        subprocess.run(['git', 'checkout', commit['parent'], '--', file])\n",
    "        before_content = read_checkout_file(file)\n",
    "        file_path = os.path.join('commits', f'{cnt}_before_{os.path.basename(file)}')\n",
    "        write_checkout_file(file_path, before_content)\n",
    "        \n",
    "        subprocess.run(['git', 'checkout', 'HEAD', '--', file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba54a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
